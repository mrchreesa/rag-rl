{"id": "test_0", "question": "What is the mission of PolitiFact?", "golden_answers": ["To reduce false information and misleading statements in political speech and provide the public with a clear and accurate political information environment through professional fact-checking work."], "prediction": "The mission of PolitiFact is to reduce false information and misleading statements in political speech and provide the public with a clear and accurate political information environment through professional fact-checking work.", "f1": 0.923076923076923, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01394v1\nEach fact-checking news report on the PolitiFact website includes the source platform of the news, such as \nInstagram posts, TikTok posts, Facebook posts, X posts, Viral image, etc. Currently, we have analyzed the \nfact-checking news reports whose source platform is X posts and filtered out the links to the news sources \non the X platform or Twitter. Then, we collected data from the links on the X platform or Twitter, including \nthe fact-checking news reports. Twitter, founded by Jack Dorsey and his partners in March 2006 and officially launched in July of the same \nyear, is a trendsetting social media platform that allows users to post messages of up to 140 characters (with \nan expanded limit of 280 characters fo r Chinese, Japanese, and Korean). These messages are known as \n\"tweets.\" On July 23, 2023, CEO Musk announced through a tweet that the iconic \"bluebird\" icon would be \nreplaced with an \"X\" icon, marking a significant update to the brand image. Subsequently, on July 24, Musk \nrevealed that Twitter's website address would migrate from twitter.com to X.com. On July 31, Twitter's app \nname on the Apple App Store was officially changed to X. \n4.3. PolitiFact Data Collection and Filtering Methodology In this study, Python scraping technology was utilized to systematically collect all fact-checking news reports \npublished by PolitiFact since its establishment in 2007, totaling approximately 24,000 records. The specific \ncollection process is outlined below, \n4.3.1. Scraping PolitiFact \nDetermining the maximum page range , By analyzing the URL structure of the PolitiFact website's fact -\nchecking news report list page ( https://www.politifact.com/factchecks/?page=XXX), a large page number \n(such as 900) was input and observed for the \"No Results found\" prompt. Gradually decrementing the page \nnumber until the current valid page range was determined to be 809 pages. Iterating and scraping pages: From page 1 to page 809, each page was parsed and links to fact-checking news \nreports were extracted. Subsequently, the corresponding news report pages were downloaded for each link. Parsing news report content: The downloaded content of each fact-checking news report page was parsed to \nextract information including the judgment result, statement, statement source platform, statement date, \nfactchecker name, factcheck date, topic, page number, factcheck analysis link, data acquisition date, and list \nof news sources. Data recording and storage: Each fact-checking news report was assigned a unique ID and page number, then \norganized into a file. When initiating HTTP requests, a random waiting time mechanism was introduced to \nensure friendly access to the original website and avoid unnecessary access pressure. Data conversion and storage: After completing the scraping of all pages, the raw data was converted into \nJSON and parquet formats, and further transformed into XLS file format for subsequent data processing and \nanalysis. 4.3.2. Filtering PolitiFact \nPlatform source filtering: Within the XLS file, all fact -checking news reports originating from twitter or X \nplatforms were filtered based on the statement source platform.\n\n2503.01394v1\nSimilarly,  \n is the total number of interaction events (i.e., reply or retweet) at time point . After the propagation graph is constructed , we defined the Twitter rumor detection dataset as a collection of \nstatic graphs . Further, we can obtain the graph structure of each static \ngraph at multiple time points, thereby obtaining multiple dynamic graphs of the static graph in the time \ndimension, and use the following formula to represent it, \n. Rumor detection is typically framed as a multi -class classification task within the context of supervised \nlearning. In this paper, we classify source tweets into five distinct categories, \"False\", \"Pants on Fire\" , \"Half \nTrue\", \"Mostly False\" or \"Mostly True\". Our goal is to learn a classifier from the labeled propagation graph \nset, that is f,  , where  takes one of five classes. For source tweet , the classifier f \ncan figure out the classification result of propagation graph . 4. Datasets \nTo verify the effectiveness of the rumor identification algorithm in this study, we constructed a real-world \ndataset of politically related rumors through data collection. The collection scope includes the PolitiFact \nwebsite and Twitter. \n4.1. Introduction to the PolitiFact  \nPolitiFact is a nonpartisan, nonprofit fact -checking website operated by the Poynter Institute in Tampa. Its \nmission is to reduce false information and misleading statements in political speech and provide the public \nwith a clear and accurate political information environment through professional fact-checking work. The main task of this website is to conduct thorough fact -checking on political figures, political \nadvertisements, political news reports, etc., and assign ratings such as \"False\", \"Pants on Fire\" , \"Half True\", \n\"Mostly False\" or \" Mostly True\". The fact-checking team of PolitiFact consists of experienced journalists \nand editors who use their professional news literacy and fact -checking skills to strictly verify and evaluate \neach piece of information. In addition, PolitiFact also pays attention to political speech on social media and responds quickly to widely \ncirculated rumors and false information to dispel them. Through collaboration with major social media \nplatforms, it directly pushes the results of fact-checking to users, helping the public identify and avoid being \nmisled. The PolitiFact organization utilizes a unique rating system to provide a quantitative assessment of the \ncredibility of the verified subjects. The Truth-O-Meter rating system is divided into five categories, \"True,\" \nindicating that the statement is accurate with no significant omissions; \"Mostly True,\" indicating that the \nstatement is basically correct but may require further clarification or supplementation of additional \ninformation; \"Half True,\" indicating that the statement is only partially accurate with  important details \nmissing or a biased understanding of the context; \"Mostly False,\" indicating that the statement contains true \nelements but leaves the reader with a misleading impression due to the omission of key facts; \"False,\" \nindicating that the stat ement contains significant inaccuracies; and \"Pants on Fire,\" indicating that the\n\n9 \nstatement is not only inaccurate but also contains absurd and false elements. \n4.2. Introduction to Twitter\n\n2503.01394v1\nAfter filtering and verifying all data labeled as X posts in the news reports, a total of \n166 verified factcheck items were obtained. Among these 166 verified factcheck items, 16 of the source links \nin the data do not include Twitter.com or x.com, so they are excluded. Finally, we obtained a dataset of 150 \nverified factcheck items from the Twitter platform. The table, Table 1, and field explanations for PolitiFact \ndata are as follows, \nTable 1 \nNO. Field Field explanations \n1 verdict Judgment result \n2 statement Statement \n3 statement_originator Platform of statement origin \n4 statement_date Date of statement \n5 factchecker_name Name of factchecker \n6 factcheck_date Date of factcheck \n7 topics Topics \n8 page Page number \n9 factcheck_analysis_link Link to factcheck analysis \n10 date_retrieved Date of data retrieval \n11 oursource_links List of source links \n12 translate_links Source link address after translation \n13 translate_twitter_links Source link with tweet address after \ntranslation \nThe PolitiFact website webpage corresponding to the PolitiFact data field is as follows in Fig. 2 and Fig. 3 ,\n\n12 \n \nFig. 2.  \n \nFig. 3.  \n4.5.2. Twitter Data According to the Twitter collection method above, we collected a total of 94,440 tweet data, 94,440 comment \ndata, 618,387 retweet data, and 523,638 user data. 4.5.2.1. Tweet data \nThe table and field explanations for Twitter tweet data are as follows in Table 2, \nTable 2\n\n13 \nNO. Field Field explanations \n1 id Tweet ID \n2 link Original tweet link \n3 date Tweet date \n4 user_id User ID \n5 username Username \n6 place Location \n7 tweet Tweet content \n8 mentions Mentioned users \n9 replies Number of replies \n10 retweets Number of retweets \n11 hashtags Hashtags \n12 cashtags Cashtags \n13 language Language \n14 place_code Place code \n15 place_id Place ID \n16 geo Geolocation information \n17 source Source \n18 likes Number of likes \n19 quoted Number of quotes \n20 quote_url Quote URL \n21 refer_url Refer URL \n22 reply_url Reply URL \n23 photos Photos \nThe webpage corresponding to the Twitter tweet data field is as follows in Fig. 4 ,\n\n14 \n \nFig. 4. 4.5.2.2. Comment data \nThe table and field explanations for Twitter comment data are as follows in Table 3, \nTable 3 \nNO. Field Field explanations \n1 post_id Original tweet ID \n2 comment_id Comment ID \n3 user_id User ID \n4 comment Comment content \n5 reply_to Reply target (comment or user) \n6 date Comment date \n7 source Source \n8 retweets Number of retweets \n9 likes Number of likes \n10 replies Number of replies \n11 mentions Mentioned users\n\n15 \n12 thread_id Thread ID \n13 reply_post_id Replied tweet ID \nThe webpage corresponding to the Twitter comment data field is as follows, \n \nFig. 5.  \n4.5.2.3. Repost data \nThe table and field explanations for Twitter repost data are as follows, \nTable 4 \nNO. Field Field explanations \n1 post_id Original tweet ID \n2 user_id User ID \n3 name Full name \n4 username Username \nThe webpage corresponding to the Twitter repost data field is as follows,\n\n16 \n \nFig. 6. 4.5.2.4. User data \nThe table and field explanations for Twitter user data are as follows, \nTable 5 \nNO.", "metadata": {"type": "factual", "source": "2503.01394v1.pdf", "context": "website and Twitter. \n4.1. Introduction to the PolitiFact  \nPolitiFact is a nonpartisan, nonprofit fact -checking website operated by the Poynter Institute in Tampa. Its \nmission is to reduce false information and misleading statements in political speech and provide the public \nwith a clear and accurate political information environment through professional fact-checking work. \nThe main task of this website is to conduct thorough fact -checking on political figures, political \nadvertisements, p", "quality_score": 9.25}}
{"id": "test_1", "question": "What were the three models evaluated in Section 5.6?", "golden_answers": ["The original model (LLM without finetuning), the fined-tuned model (LLM finetuned with our synthetic examples), and a model that is trained on filtered data using the verifier."], "prediction": "The three models evaluated in Section 5.6 were Solution 3.0, VilBERT, and SOTA 2.", "f1": 0.05555555555555555, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.00025v1\nTwo questions in the 2025 exam were intentionally modified to reduce potential data leakage from sources already indexed by certain models. All MIR content was used strictly for research purposes and safeguarded to maintain confidentiality and exam integrity. Figure 1- Process Flow for MIR Exam A total of twenty-two LLMs were selected, ranging from high-profile general-purpose architectures (e.g., GPT-4 Turbo, Claude Sonet 3.5) to specialised models such as Miri Pro, which had undergone fine-tuning on Spanish medical corpora. To ensure consistency, every model was tested under zero-shot conditions, receiving no additional hints or clarifications beyond a standardised prompt. This prompt instructed the LLM to identify the single best answer (out of four choices) and provide a step-by-step explanation of its\n\nreasoning in Spanish. For multimodal-capable models, image-based questions were presented along with the relevant visual inputs. Text-only models are presented solely with the question, without any indication of an accompanying image, which prevents them from viewing or interpreting it. Instead, these models are supplied with written descriptions of the images that highlight the key visual features otherwise evident in the graphic. Each LLM processed the 210 questions from both the 2024 and 2025 exams, generating responses that were automatically stored and timestamped. Correctness was determined by matching the final answer to the official solution key provided by the Spanish Ministry of Health, yielding a raw accuracy score (number of correct responses out of 210) that was later converted to a percentage. These results were supplemented by metadata on whether each question required image interpretation or tested domain-specific knowledge. A human performance reference\u2014represented by the highest-achieving candidate in the 2025 MIR\u2014served as a benchmark for contextualising the relative performance of each model. To facilitate meaningful comparisons, accuracy data were subjected to basic descriptive statistics (mean, median, standard deviation). Further, models were grouped into categories (e.g., general-purpose vs. fine-tuned) for subgroup analyses. Paired tests were conducted to detect significant changes in individual models\u2019 performance from 2024 to 2025, while non-parametric methods were employed if the distributional assumptions for parametric tests were not met. Additionally, a series of omnibus tests was performed to ascertain whether performance differed significantly among multiple models, followed by post-hoc analyses where warranted. Throughout the study, robust data management protocols were maintained, with model outputs stored in encrypted repositories. This controlled, consistent framework for measuring each model\u2019s capacity to address a demanding medical licensing exam lays the groundwork for further exploration into how LLMs might be integrated into future clinical or educational contexts. 4. Analysis and Results 4.1. Analysis of Large Language Model Performance on the MIR 2024 and 2025 Examinations This section provides a detailed analysis of the performance of 22 Large Language Models (LLMs) evaluated on the Spanish Medical Internship and Residency (MIR) examinations for 2024 and 2025. The analysis focuses on two primary hypotheses: (1) the relationship between LLM performance and their ability to engage in complex clinical reasoning, and (2) the extent to which model performance reflects reasoning capabilities rather than memorisation.\n\n2503.00025v2\nTwo questions in the 2025 exam were intentionally modified to reduce potential data leakage from sources already indexed by certain models. All MIR content was used strictly for research purposes and safeguarded to maintain confidentiality and exam integrity. Figure 1- Process Flow for MIR Exam A total of twenty-two LLMs were selected, ranging from high-profile general-purpose architectures (e.g., GPT-4 Turbo, Claude Sonet 3.5) to specialised models such as Miri Pro, which had undergone fine-tuning on Spanish medical corpora. To ensure consistency, every model was tested under zero-shot conditions, receiving no additional hints or clarifications beyond a standardised prompt. This prompt instructed the LLM to identify the single best answer (out of four choices) and provide a step-by-step explanation of its\n\nreasoning in Spanish. For multimodal-capable models, image-based questions were presented along with the relevant visual inputs. Text-only models are presented solely with the question, without any indication of an accompanying image, which prevents them from viewing or interpreting it. Instead, these models are supplied with written descriptions of the images that highlight the key visual features otherwise evident in the graphic. Each LLM processed the 210 questions from both the 2024 and 2025 exams, generating responses that were automatically stored and timestamped. Correctness was determined by matching the final answer to the official solution key provided by the Spanish Ministry of Health, yielding a raw accuracy score (number of correct responses out of 210) that was later converted to a percentage. These results were supplemented by metadata on whether each question required image interpretation or tested domain-specific knowledge. A human performance reference\u2014represented by the highest-achieving candidate in the 2025 MIR\u2014served as a benchmark for contextualising the relative performance of each model. To facilitate meaningful comparisons, accuracy data were subjected to basic descriptive statistics (mean, median, standard deviation). Further, models were grouped into categories (e.g., general-purpose vs. fine-tuned) for subgroup analyses. Paired tests were conducted to detect significant changes in individual models\u2019 performance from 2024 to 2025, while non-parametric methods were employed if the distributional assumptions for parametric tests were not met. Additionally, a series of omnibus tests was performed to ascertain whether performance differed significantly among multiple models, followed by post-hoc analyses where warranted. Throughout the study, robust data management protocols were maintained, with model outputs stored in encrypted repositories. This controlled, consistent framework for measuring each model\u2019s capacity to address a demanding medical licensing exam lays the groundwork for further exploration into how LLMs might be integrated into future clinical or educational contexts. 4. Analysis and Results 4.1. Analysis of Large Language Model Performance on the MIR 2024 and 2025 Examinations This section provides a detailed analysis of the performance of 22 Large Language Models (LLMs) evaluated on the Spanish Medical Internship and Residency (MIR) examinations for 2024 and 2025. The analysis focuses on two primary hypotheses: (1) the relationship between LLM performance and their ability to engage in complex clinical reasoning, and (2) the extent to which model performance reflects reasoning capabilities rather than memorisation.\n\n2503.00054v1\nFirstly, our model was trained and evaluated exclusively on\nEnglish-language tweets, necessitating additional training\non different languages and code-mixed settings to broaden\nits applicability. Secondly, handling sarcasm remains chal-\nlenging due to the limited availability of curated sarcastic\nsamples. Conclusively, the proposed model, Solution 3.0, lives up to\nits name by offering a singular effective solution for three\ncritical tasks: managing multimodal information, perform-\ning multilabel aspect classification, and multitasking com-\nplaint identification with aspect classification. This high-\nlights the model\u2019s robustness and versatility in financial\ncomplaint mining. 5.2. Analytical Discussions\nQualitative Analysis with Human Expertise: In Table\n5, it\u2019s evident that the user explicitly reviewed debit card\nservices, emphasizing the perks of excessive transactions\nwith less security and ease of handling fraudulent incidents. Our model accurately predicted three aspects, whereas Vil-\nBERT only identified two, the Claimed Benefit & Service\nTypes aspect but failed to identify the Transaction aspect. However, SOTA 2 correctly identified the Transaction &\nService Types aspect, yet it failed to recognize the Claimed\nBenefit aspect and misclassified it as Miscellaneous. How-\never, T5 and Gemma exhibit significantly poor results by\nidentifying only one aspect and with one misclassified one. Furthermore, we performed a human evaluation on 60 sam-\nples from the test samples, but as mentioned in Table 5, our\nproposed Solution 3.0 outperformed all the other models. Additionally, Solution 3.0 performed a similar prediction to\nthe human annotator and intensified the performance qual-\nity validation. Error Analysis: We reviewed test set samples to assessSo-\nlution 3.0 model\u2019s predicted AC and CI labels against actual\nlabels, identifying potential instances of compromised per-\nformance and misclassification. i) Aspect Misinterpreta-\ntions: In instances involving theMiscellaneous and Service\nTypes aspects, the Solution 3.0 model occasionally misclas-\nsifies aspect categories and their associated complaint/non-\nComplaint labels, particularly in sentences containing mul-\ntiple aspects. For example, in a sentence with various as-\npects and a higher number of data samples in the training\nset, such as: After buying fruits online with my credit card,\nI noticed unanticipated additional charges applied, which I\nwas unaware of. It appears my credit card company also\nwant the fruits. The Solution 3.0 model erroneously labeled\nthe aspect as \u2019 Miscellaneous.\u2019 However, it should be cate-\ngorized as \u2019 Service Type,\u2019 since the company\u2019s actions vi-\nolated the transparency of user usage. This misinterpreta-\ntion likely stems from a paucity of training samples in the\nservice-type aspects, leading to model inaccuracies. ii) Ad-\nditional Misclassification: The proposed model also occa-\nsionally misclassifies samples, particularly under the Mis-\ncellaneous aspect category. For instance, tax implications,\nwhich fall under Miscellaneous aspects, were misclassified\nby the Solution 3.0 model as Service Type. These misclas-\nsifications highlight the model\u2019s tendency to inaccurately\ncategorize financial decision-based actions as Service-Type\naspects, suggesting a need for further refinement in training\ndata and model architecture. 6. Conclusion\nThe financial aspect-based complaint identification ( So-\nlution 3.0 ) model establishes a new standard in financial\nvideo complaint analysis by integrating aspect-level infor-\nmation in a multimodal setup.", "metadata": {"type": "factual", "source": "2503.01385v1.pdf", "context": "Section 5.6) where we evaluated (i) the original model (LLM without finetuning), (ii) the fined-tuned model (LLM\nfinetuned with our synthetic examples), and (iii) a model that is trained on filtered data using the verifier. This allows us\nto understand the impact of each of the NL-Q Verifier components on the NL \u2192 Q task.\nFeedback within QA systems The verifier can serve as an internal feedback mechanism within a QA system. When\nthe system generates a query translation for a user question, the Q", "quality_score": 9}}
{"id": "test_2", "question": "What kind of applications can an interaction-oriented world model support?", "golden_answers": ["A wide range of applications, including human-robot interaction, closed-loop simulators, intelligent sports coaching, and immersive VR/AR gaming experiences."], "prediction": "An interaction-oriented world model can support applications in process monitoring and control systems, enabling real-time adjustments to control parameters based on incoming process signals, ensuring stability and consistency in the presence of anomalies such as noise or disturbances.", "f1": 0.11320754716981131, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.00761v1\nWorld Model Implementation\nThe world model enforces physical, kinematic, and regula-\ntory constraints, ensuring that each proposed state transition\nremains feasible. Though implementations vary by domain,\nour framework relies on two components:\na) Kinematic Feasibility Module: This component ver-\nifies whether state transitions respect motion limits such as\nmaximum velocity, turning radius, and acceleration bounds. Implemented as a lightweight physics function, it evaluates\neach candidate step against the agent\u2019s operational parame-\nters and rejects physically impossible maneuvers. b) Domain Compliance Validator: Domain-specific\nrules and constraints C are implemented as boundary checks\nthat detect collisions with obstacles, violations of navigable\nzones, or breaches of right-of-way regulations. This module\n\nemploys geometric intersection tests and rule-based verifica-\ntion to maintain compliance with environmental restrictions. These components define a binary feasibility function F\nreturning 1 for valid transitions and 0 otherwise. Candidate\ntrajectories are retained only if all transitions satisfy F,\npruning infeasible branches and validating novel paths. V. E XPERIMENTS AND RESULTS\nMotivation: We evaluate TRACE in scenarios involving\ntwo agents, an observer and a target, operating in a shared\nenvironment. Due to real-world constraints (such as limited\nsensor range or communication bandwidth restrictions), the\nobserver receives only sporadic measurements of the target\nagent\u2019s state. Our goal is to predict the target\u2019s behavior\nhypotheses\u2013trajectories\u2013despite this measurement sparsity,\nenabling effective decision-making by the observer. A. Robot Setup\na) Hardware Experiments (Marine Navigation): Our\nreal-world in-the-wild tests utilize two SeaRobotics Surveyor\nAutonomous Surface Vehicles (ASVs) operating in a lake\ncontaining multiple fountains that serve as both physical\nobstacles and sources of water disturbance. The environment\ncontains designated safe navigable channels analogous to\nmaritime lanes and restricted areas (fountains and shorelines)\nthat must be avoided. Though less rigidly defined than road\nnetworks, these navigational constraints enforce a structured\nspace within which both ASVs must operate. The ASV\u2019s\naction space is defined by a = (\u03bb, \u03b1), where \u03bb \u2208 [0, \u03bbmax]\nrepresents propulsion torque ( \u03bbmax = 85 N\u00b7m), \u03b1 \u2208 [0, 2\u03c0)\nindicates steering angle. The maximum operational speed is\n2 knots. The ASVs are equipped with GPS for localization. The observer ASV , receives camera snapshots of the target\nASV at irregular intervals. Between camera observations, the\ntarget\u2019s state is entirely unknown. b) Simulated Experiments (Autonomous Driving): To\nevaluate TRACE under controlled conditions, we developed\na custom medium-fidelity simulator featuring a two-agent\ndriving scenario on a grid of roads and buildings in an urban\nsetting. The observer vehicle tracks a target vehicle using\nsimulated LiDAR readings obtained at sparse intervals. The\nvehicles operate with a maximum speed of 15 m/s, a turning\nradius of 5 meters, and maximum acceleration/deceleration\nof \u00b13 m/s2. Environmental constraints include road bound-\naries, building footprints, traffic rules, and intersection pro-\ntocols, providing well-defined restrictions. Our experiments use GPT-4 Turbo with Vision via\nthe OpenAI API, though TRACE\u2019s architecture is model-\nagnostic and compatible with any vision-language model. B.\n\n2503.01411v2\nHence, world models often fall back\non monolithic action space representations [22], [23]. We take\nthis approach as well. Joint embedding representation learning. The quality of\ninput reconstruction from a generative model does not neces-\nsarily correspond to the quality of the learned representations\n[24]. JEPAs have emerged as a promising SSL approach for\nrepresentation learning, offering an alternative to generative\nmodels: Instead of taking a loss in the reconstructed space,\nthey predict and compute the loss in latent space, conditioned\non actions. Recent self-supervised variants (I-JEPA [25] and\nV-JEPA [26]) predict masked parts of the input, learning\nrepresentations for computer vision tasks. We extend the JEPA\nframework by moving away from an implicit masking action\n(x\nmasking\n\u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2192y) to explicitly providing arbitrary actions in\n\na factored form ( x\na\n\u2212 \u2192y), facilitating learning a rich latent\nrepresentation of cause and effect economically. Thus, we\nextend the typical SSL framework by not being agnostic to\nexternal factors (like machine parameters). Instead, our approach is action-aware self-supervised learn-\ning, combining the strengths of self-supervised feature ex-\ntraction with task-specific guidance from actions (control\nparameters). Our world model uses them to directly guide\nrepresentation learning, ensuring that the learned embeddings\nare actionable. This avoids the need for contrastive pairs or\nnegative sampling strategies, reducing computational overhead\nand simplifying the training process. Control parameters (e.g.\nmachine parameters in injection molding) provide explicit\ndomain knowledge, making the representations interpretable\nand well-suited for process control. Furthermore, the supervisory signal through action condi-\ntioning in our approach naturally prevents the collapse of the\nlearned representations, eliminating the need for additional\nregularization techniques as otherwise common in SSL. Disentangled representation learning for time-series. Deep\nlearning has been proposed to learn effective representations\nof the time-series data for downstream applications [12], [27]\u2013\n[29]. To be useful for fine-grained process control, the learned\nrepresentations must be disentangled: A low-dimensional la-\ntent representation z = {z1, z2, . . . , zn} is sought such that\nall pairs of latent variables in Z are independent, i.e., the\nchange of the sequential patterns in the input corresponding to\nvariable zi is invariant to variablezj, denoted as zi \u22a5 \u22a5zj, \u2200i, j,\nwhere i, j\u2208 {1, 2, . . . , n} and i \u0338= j. The disentanglement\ncan be extended to group disentanglement so that a group of\nlatent variables is independent of other different groups. Most\nrepresentation learning relies on unsupervised learning due to\nthe label scarcity. However, unsupervised learning of disen-\ntangled representations is fundamentally impossible without\ninductive biases on both the models and the data [30]. While\ninterpretable semantic concepts often depend on the interaction\nof multiple factors rather than individual components, Li et al.\nargue that it is essential to interpret time-series data through\na single latent representation in industrial applications [31]. A\ndisentangled representation can be decomposed into separate\ndimensions, where the change in each dimension reflects a\ndistinctive change in the real world. Li et al.\n\n2503.01411v1\nHaving become a branch of ML research with notable progress in recent years [5\u20137],\nthey are typically understood as a learned representation of the physical world, capable of predicting the consequences\nof various actions on the world\u2019s state [8]. While many world models are built as generative models of specific\nenvironments (\u201cworld\u201d referring to any relevant part of the environment) to serve as simulations for AI agent training\narXiv:2503.01411v1  [cs.LG]  3 Mar 2025\n\nLearning Actionable World Models\nfor Industrial Process Control A PREPRINT\nFigure 1: Overview of world model training and application for process control. Top: World model training using\nrecorded process signal pairs ( x, y) that have been generated in the same environment (world) but with changed\ncontrol parameters (actions) a = a1, ..., an. The encoder ( Enc) generates latent representations ( zx, zy) used for\npredicting the actions \u02c6a through the action prediction module ( Pa). The latent predictive module ( Pz) guides the\nlearning of the latent representation by incorporating actions, ensuring the representations zx and zy align with the\nprocess\u2019s operational dynamics for more accurate and interpretable predictions. Detailed modeling and training is\ndiscussed in Section 3. Bottom: Application of the trained world model in real-time process control where the model\npredicts actions based on a reference process signal plus an observed process signal to maintain stability despite\nchanging external conditions or influences.\n(such as [5, 7]), we are concerned here withactionable world models that learn consequence-aware representations of\nworld states (process signals, e.g., time-series) and directly output actions (e.g., scalars). The integration of such world models into process monitoring and control systems presents a significant opportunity\nto advance intelligent, adaptive, and highly efficient industrial operations. Fig. 1 illustrates our proposed approach for\nprocess control, where the world model is trained on recorded process signal pairs and their control parameters and\ncan later be applied to a running process to bring it back to normal operation if it deviates from a reference signal. This\napproach enables real-time adjustments to control parameters based on incoming process signals, ensuring stability\nand consistency in the presence of anomalies such as noise or disturbances. That the world model\u2019s training integrates\nactions and states enriches the system\u2019s grasp of complex dynamics, enabling robust performance across varying\noperational conditions. In this paper, we introduce a novel world model for process control, inspired by joint embedding predictive archi-\ntectures (JEPAs) and contrastive learning [6, 9]. Our world model makes use of recorded process signals and cor-\nresponding actions in order to learn an action-aware latent representation, facilitating disentangled action prediction\nin the presence of many possible control parameter adjustments. Experimental results on a real-world use case from\nplastic injection molding control demonstrate that our world model achieves its goals with high sample efficiency.", "metadata": {"type": "factual", "source": "2503.01291v1.pdf", "context": "structing an interaction-oriented world model for humans,\nenabling reasonable adaptation to changes of interactive\nobjects or people. This interaction-oriented world model\ncan support a wide range of applications, including human-\nrobot interaction, closed-loop simulators, intelligent sports\ncoaching, and immersive VR/AR gaming experiences.\nAs the importance of interaction becomes increasingly\nrecognized, some studies have evolved from text-driven hu-\nman motion generation [4, 6, 16, 31, 32, 49]", "quality_score": 9}}
{"id": "test_3", "question": "What is the primary goal of the OptMetaOpenFOAM framework?", "golden_answers": ["The primary goal of OptMetaOpenFOAM is to bridge MetaOpenFOAM with external analysis and optimization tool libraries through a large language model (LLM)-driven chain-of-thought (COT) methodology, empowering non-expert users to perform sensitivity analyses and parameter optimizations with improved efficiency."], "prediction": "The primary goal of the OptMetaOpenFOAM framework is to automate complex CFD tasks via natural language inputs, empowering non-expert users to perform sensitivity analyses and parameter optimizations with markedly improved efficiency.", "f1": 0.6153846153846154, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01273v1\nThe \u201csimilarity\u201d approach was \nemployed to identify and match related chunks of \ndata. The simplest stacking approach was used, \ncombining retrieved documents with user input \nmessages. Additional information can be found in \nthe code repository: https://github.com/Terry-\ncyx/MetaOpenFOAM. In the external analysis and \noptimization tool library, the univariate \noptimization method, the L-BFGS-B optimization\n\n5 \n \n \nalgorithm, is invoked through the bounded method \nin scipy.optimize. For multivariable analysis and \noptimization, the active subspace method is used  \n[27]. 4 Results \nThe evaluation metrics used previously were \nbased on the CFD framework with natural \nlanguage inputs, with a primary focus on the user \nrequirements for Executability (ranging from 0 to \n7, corresponding to failure to flawless), Cost \n(including token usage, number of iterations, \nrunning time, etc.), and Pass@k [34, 35]. These \nmetrics remain significant in OptMetaOpenFOAM, \nbut due to the integration of fixed interfaces after \ncompleting the CFD simulation and postprocessing \ntasks, the Executability, Pass@k, and number of \niterations remain consistent with the previous \nstatistics in MetaOpenFOAM 2.0 [13]. Regarding \nCost, token usage slightly increases due to the \naddition of two new modules, while the running \ntime increases linearly with the addition of CFD \nsimulation tasks. Therefore, in addition to these \nthree metrics, the evaluation of \nOptMetaOpenFOAM increasingly focuses on the \nresult presentation. In this section, we will analyze five cases: \nPitzDaily, CounterFlowFlame, BuoyancyCavity, \nHIT, and Hydrogen Combustion Chamber. Among \nthese, the first four cases are OpenFOAM tutorials, \nwhile the latter is not. All the basic cases have been \nincorporated in to the database required for the \nRAG technique. All the figures presented in this \nsection were generated using OptMetaOpenFOAM \nbased on user prompts. It is important to note that \nthe prompt for textual response is provided in \nAppendix A, the full textual analysis provided by \nOptMetaOpenFOAM is included in Appendix B \nand the thought process provided by \nOptMetaOpenFOAM is included in Appendix C. \n4.1 PitzDaily \nThis case is an incompressible flow, simulated \nusing the RANS method. The following prompt is \nused to perform simulation for this case. CFD simulation task: Do a RANS simulation \nof incompressible PitzDaily flow. CFD postprocessing task: Extract max yplus at \nlatest time through post-processing \nInvestigating the relationship between inlet \nvelocity and y+ is one of the common CFD \nsensitivity analysis tasks. A similar analysis can be \nperformed for the relationship between inlet \nvelocity and the Courant number. The following \nprompt is used to study this case. CFD analysis tasks: \u2460 Analyze the effect of \nthe inlet flow velocity on max yplus . \u2461 Analyze \nthe effect of the inlet flow velocity and inlet \nturbulent kinetic energy on max yplus. Figure 2: Response surface of the inlet flow \nvelocity versus the max yPlus in PitzDaily. (a) \n \n(b) \nFigure 3:   Effect of inlet flow velocity and inlet \nturbulent kinetic energy on max y+ in PitzDaily \ncase. (a) response surface and (b) components of \nactive direction (\ud835\udc98\u0302). 6 \n \n \nCFD optimization task: Determine the optimal \ninlet flow velocity and inlet turbulent kinetic \nenergy at which the max yplus should be as close \nto 25 as possible.\n\n2503.01273v1\nAnd for analyses such as \n \nOptMetaOpenFOAM: Large Language Model Driven Chain of Thought for  \nSensitivity Analysis and Parameter Optimization based on CFD \n \nYuxuan Chena, Long Zhanga, Xu Zhua, Hua Zhoua, Zhuyin Rena* \na Institute for Aero Engine, Tsinghua University, Beijing 100084, China \n* Corresponding author: zhuyinren@tsinghua.edu.cn\n\n2 \n \n \nparameter sensitivity analysis, parameter \ncalibration, and para meter optimization, \nperforming multiple CFD simulations is essential. The former can naturally be seen as a specific type \nof CFD post -processing task, while the latter \ndemands the creation of new frameworks capable \nof performing multi -simulation analysis u sing \nnatural language inputs. This would further reduce \nthe usability threshold for industrial CFD software. In recent years, the rapid development of large \nlanguage models (LLMs), initially designed to \ntackle simple, quick -thinking tasks, has been \nexemplified by models such as GPT -4o [2] and \nDeepSeek v3 [6]. Later, models like GPT-o1 [4] \nand DeepSeek R1 [7] emerged to tackle more \ncomplex, slow -thinking problems. The former \nreflects pretrained scaling laws [1], while the latter \ndemonstrates post-training scaling laws  [8]. For \nCFD problems with natural language inputs, due to \ntheir complexity, high level of expertise, and \nreliance on external tools, using LLMs with general \nChain of Thought (COT) [23-26] reasoning models \nmay not be sufficient to accomplish the \ncorresponding CFD tasks. Moreover, since CFD \ntasks typically follow a fixed workflow, it becomes \nfeasible to develop a dedicated COT framework \ntailored specifically to CFD problems. MetaOpenFOAM 1.0 [12] and 2.0 [13] have \ndeveloped distinct COT structures to complete \nCFD simulation and postprocessing tasks, \nrespectively. The proposed scaling laws \ndemonstrated that increasing the number of COT \nsteps improves the accuracy of the framework  \nwhile increasing token usage, aligning with post -\ntraining scaling laws for LLM. Similarly, for \nanalysis and optimization tasks that require \nmultiple CFD simulations and postprocessing steps, \nspecialized COT structures are necessary to \nfacilitate the use o f external tools (e.g., active \nsubspace analysis [27], parameter optimization \n[28], etc.). The structure of the paper is organized as \nfollows: First, we introduce the basic framework of \nOptMetaOpenFOAM and the theoretical \nknowledge of the external tool libraries. Then, we \ndescribe the LLM settings used in the framework. Next, we present the inpu t, thought process, and \noutput results for specific cases in \nOptMetaOpenFOAM. Finally, we conclude with a \nsummary. 2 Methodology  \n2.1 MetaOpenFOAM 2.0 Framework \nFigure 1 illustrates how OptMetaOpenFOAM \nleverages a chain-of-thought mechanism to process \nsensitivity analysis and parameter optimization \ntasks based on CFD, using natural language inputs. First, OptMetaOpenFOAM establishes the \ncorresponding CFD simulati on, CFD \npostprocessing, CFD sensitivity analysis, and CFD \nparameter optimization tasks according to user \nrequirements. It is important to note that the \nparameter optimization task is typically conducted \nbased on the outcomes of the sensitivity analysis. Figure 1:  Framework of OptMetaOpenFOAM. Where QDCOT means chain of thought (COT) with \nquestion decomposition, Iterative COT (ICOT) means COT with iterative verification and \nrefinement, and RAG means retrieval-augmented generation. 3 \n \n \nNext, the framework extracts the sampling \nlower and upper range from the natural language \ninput to perform sampling.\n\n2503.01273v1\n1 \n \n \nAbstract \nMerging natural language interfaces with \ncomputational fluid dynamics (CFD) \nworkflows presents transformative \nopportunities for both industry and research. In this study, we introduce \nOptMetaOpenFOAM\u2014a novel framework \nthat bridges MetaOpenFOAM with \nexternal analysis and optimization tool \nlibraries through a large language model \n(LLM)-driven chain -of-thought (COT) \nmethodology. By automating complex \nCFD tasks via natural language inputs, the \nframework empowers non-expert users to \nperform sensitivity analyses and parameter \noptimizations with markedly improved \nefficiency. The test dataset comprises 11 \ndistinct CFD analysis or optimization tasks, \nincluding a baseline simulation task derived \nfrom an OpenFOAM tutorial covering fluid \ndynamics, combustion, and heat transfer. Results confirm that OptMetaOpenFOAM \ncan accurately interpret user requirements \nexpressed in natural language and \neffectively invoke external tool libraries \nalongside MetaOpenFOAM to complete \nthe tasks. Furthermore, validation on a non-\nOpenFOAM tutorial case \u2014namely, a \nhydrogen combustion chamber \u2014\ndemonstrates that a mere 200 -character \nnatural language input can trigger a \nsequence of simulation, postprocessing, \nanalysis, and optimization tasks spanning \nover 2,000 lines of code. These findings \nunderscore the transformative potential of \nLLM-driven COT methodologies in linking \nexternal tool for a dvanced analysis and \noptimization, positioning \nOptMetaOpenFOAM as an effective tool \nthat streamlines CFD simulations and \nenhances their convenience and efficiency \nfor both industrial and research applications. Code is available at  \nhttps://github.com/Terry-\ncyx/MetaOpenFOAM \n1 Introduction \nIn recent years, with the development of Large \nLanguage Models (LLMs) [1-8], many fields have \nundergone significant transformations, with \ncomputer simulation software for optimization and \nanalysis emerging as one of the most impacted \ndomains. Traditionally, interactions with analysis \nand optimization software have been facilitated \neither through coding  [9] or via graphical user \ninterfaces (GUIs) [10, 11] . However, with \nadvancements in natural language processing, \nintegrating natural language into simulation-based \nanalysis and optimization processes has emerged as \na promising new approach [12, 13]. Computational Fluid Dynamics (CFD) is a \ncomputational technique that employs numerical \nmethods and physical models to solve fluid flow, \nheat transfer, chemical reactions, and other related \nprocesses [14]. It is widely applied in various fields, \nincluding aerospace, energy [15-18], and biology. A complete CFD workflow typically includes \nmodules such as Computer-aided Design (CAD) \ngeometry generation, mesh generation, model and \nnumerical parameter selection, solver execution, \nand post-processing. For beginners or researchers \nfrom other domains, any of these modules can be \nhighly challenging. To lower the entry barriers for \neach sta ge in the workflow, frameworks using \nnatural language as input have been proposed for \ntasks like CAD geometry generation [19], CFD \nsimulation execution [12], and CFD post -\nprocessing [13]. Beyond these basic processes of CFD , \nsubsequent analyses based on CFD simulations are \nalso critical functionalities of industrial simulation \nsoftware. Common analytical methods include \nProper Orthogonal Decomposition (POD) [20], \nDynamic Mode Decomposition (DMD) [21], and \nChemical Explosion Mode Analysis (CEMA) [22], \nwhich focus on analyzing individual CFD \nsimulation results.", "metadata": {"type": "factual", "source": "2503.01273v1.pdf", "context": "1 \n \n \nAbstract \nMerging natural language interfaces with \ncomputational fluid dynamics (CFD) \nworkflows presents transformative \nopportunities for both industry and research. \nIn this study, we introduce \nOptMetaOpenFOAM\u2014a novel framework \nthat bridges MetaOpenFOAM with \nexternal analysis and optimization tool \nlibraries through a large language model \n(LLM)-driven chain -of-thought (COT) \nmethodology. By automating complex \nCFD tasks via natural language inputs, the \nframework empowers non-exp", "quality_score": 9}}
{"id": "test_4", "question": "What is the primary focus of the research presented in [12] V. V. Menon et al., 'EMES: Efficient Multi-Encoding Schemes for HEVC-Based Adaptive Bitrate Streaming'?", "golden_answers": ["The primary focus of this research is on developing efficient multi-encoding schemes for HEVC-based adaptive bitrate streaming."], "prediction": "The primary focus of the research presented in [12] is on developing efficient multi-encoding schemes for HEVC-based adaptive bitrate streaming.", "f1": 0.8823529411764706, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01404v1\n[9] H. Amirpour, E. C \u00b8 etinkaya, C. Timmerer, and M. Ghanbari, \u201cTowards\nOptimal Multi-Rate Encoding for HTTP Adaptive Streaming,\u201d in Mul-\ntiMedia Modeling: 27th International Conference, MMM 2021, Prague,\nCzech Republic, June 22\u201324, 2021, Proceedings, Part I 27, pp. 469\u2013480,\nSpringer, 2021. [10] E. Cetinkaya, H. Amirpour, C. Timmerer, and M. Ghanbari, \u201cFaME-\nML: Fast Multi-Rate Encoding for HTTP Adaptive Streaming Using\nMachine Learning,\u201d in 2020 IEEE International Conference on Visual\nCommunications and Image Processing (VCIP), pp. 87\u201390, IEEE, 2020. [11] E. Cetinkaya, H. Amirpour, C. Timmerer, and M. Ghanbari, \u201cFast multi-\nresolution and multi-rate encoding for http adaptive streaming using\nmachine learning,\u201d IEEE Open Journal of Signal Processing, vol. 2,\npp. 484\u2013495, 2021. [12] V . V . Menon, H. Amirpour, M. Ghanbari, and C. Timmerer, \u201cEMES:\nEfficient Multi-Encoding Schemes for HEVC-Based Adaptive Bitrate\nStreaming,\u201d ACM Transactions on Multimedia Computing, Communica-\ntions and Applications, vol. 19, no. 3s, pp. 1\u201320, 2023. [13] Y . Liu, H. Amirpour, M. Abdoli, C. Timmerer, and T. Guionnet,\n\u201cPreparing VVC for Streaming: A Fast Multi-Rate Encoding Approach,\u201d\nin 2023 IEEE International Conference on Visual Communications and\nImage Processing (VCIP), pp. 1\u20135, IEEE, 2023. [14] Q. Li, H. Meng, and Y . Li, \u201cTexture-Based Fast QTMT Partition\nAlgorithm in VVC Intra Coding,\u201d Signal, Image and Video Processing,\nvol. 17, no. 4, pp. 1581\u20131589, 2023. [15] X. Shang, G. Li, X. Zhao, H. Han, and Y . Zuo, \u201cFast CU Size Decision\nAlgorithm for VVC Intra Coding,\u201d Multimedia Tools and Applications,\nvol. 82, no. 18, pp. 28301\u201328322, 2023. [16] R. Yang, X. He, S. Xiong, Z. Zhao, and H. Chen, \u201cFast CU Partition\nStrategy Based on Texture and Neighboring Partition Information for\nVersatile Video Coding Intra Coding,\u201d Multimedia Tools and Applica-\ntions, vol. 83, no. 10, pp. 28323\u201328340, 2024. [17] X. Jiang, W. Li, and T. Song, \u201cLow-Complexity Enhancement VVC\nEncoder for Vehicular Networks,\u201d EURASIP Journal on Advances in\nSignal Processing, vol. 2023, no. 1, p. 122, 2023. [18] Y . Song, S. Cheng, M. Wang, and X. Peng, \u201cFast CU Partition for VVC\nIntra-Frame Coding via Texture Complexity,\u201d IEEE Signal Processing\nLetters, 2024. [19] J.-J. Chen, Y .-G. Chou, and C.-S. Jiang, \u201cSpeed Up VVC Intra-Coding\nby Learned Models and Feature Statistics,\u201d IEEE Access, 2023.\n[20] M. Kherchouche, F. Galpin, T. Dumas, D. Menard, and L. Zhang, \u201cRD-\ncost Regression Speed Up Technique for VVC Intra Block Partitioning,\u201d\nin ICASSP 2024-2024 IEEE International Conference on Acoustics,\nSpeech and Signal Processing (ICASSP), pp. 3530\u20133534, IEEE, 2024. [21] M. Li, Z. Wang, and Q. Zhang, \u201cFast CU Size Decision and Intra-\nPrediction Mode Decision Method for H.266/VVC,\u201d EURASIP Journal\non Image and Video Processing, vol. 2024, no. 1, p. 7, 2024. [22] W. Kuang, X. Li, X. Zhao, and S. Liu, \u201cUnified Fast Partitioning\nAlgorithm for Intra and Inter Predictions in Versatile Video Coding,\u201d\nin 2022 Picture Coding Symposium (PCS), pp. 271\u2013275, IEEE, 2022. [23] Y . Li, Z. He, and Q. Zhang, \u201cFast Decision-Tree-Based Series Parti-\ntioning and Mode Prediction Termination Algorithm for H.266/VVC,\u201d\nElectronics, vol. 13, no. 7, p. 1250, 2024. [24] Y .\n\n2503.01404v1\nMulti-resolution Encoding for HTTP Adaptive\nStreaming using VVenC\nKamran Qureshi1, Hadi Amirpour 1, and Christian Timmerer 1\n1 Christian Doppler Laboratory ATHENA, Alpen-Adria-Universitat, Klagenfurt, Austria\nAbstract\u2014HTTP Adaptive Streaming (HAS) is a widely\nadopted method for delivering video content over the Internet,\nrequiring each video to be encoded at multiple bitrates and\nresolution pairs, known as representations, to adapt to various\nnetwork conditions and device capabilities. This multi-bitrate\nencoding introduces significant challenges due to the compu-\ntational and time-intensive nature of encoding multiple repre-\nsentations. Conventional approaches often encode these videos\nindependently without leveraging similarities between different\nrepresentations of the same input video. This paper proposes\nan accelerated multi-resolution encoding strategy that utilizes\nrepresentations of lower resolutions as references to speed up the\nencoding of higher resolutions when using Versatile Video Coding\n(VVC); specifically in VVenC, an optimized open-source software\nimplementation. For multi-resolution encoding, a mid-bitrate\nrepresentation serves as the reference, allowing interpolated\nencoded partition data to efficiently guide the partitioning process\nin higher resolutions. The proposed approach uses shared en-\ncoding information to reduce redundant calculations, optimizing\npartitioning decisions. Experimental results demonstrate that the\nproposed technique achieves a reduction of up to 17% compared\nto medium preset in encoding time across videos of varying\ncomplexities with minimal BDBR/BDT of 0.12 compared to the\nfast preset. Index Terms\u2014Compression, HTTP adaptive streaming, multi-\nresolution, multi-rate. I. I NTRODUCTION The rapid growth of streaming services has made efficient\nvideo delivery a fundamental requirement for modern content\ndistribution. Among the various streaming techniques, HTTP\nAdaptive Streaming (HAS) has emerged as the industry stan-\ndard due to its ability to dynamically adjust video quality in\nresponse to varying network conditions. To ensure smooth\nplayback and adaptability, each video must be encoded at\nmultiple resolutions and bitrates, known as representations [1],\nenabling seamless switching based on network bandwidth\nand device capability. However, encoding these multiple rep-\nresentations introduces significant computational challenges,\nas each resolution and bitrate combination typically requires\nseparate encoding processes. To meet the demands of large-scale, real-time streaming,\nefficient encoders have been developed to reduce the compu-\ntational burden while maintaining high-quality compression. One of the most advanced solutions in this context is Versatile\nVideo Coding (VVC) [2], which offers substantial improve-\nments in compression efficiency \u2013 up to 40% compared to\nits predecessor, High-Efficiency Video Coding (HEVC) [3]\nFig. 1: Overview of the MEVHAS framework. A reference\nrepresentation is first encoded at a lower resolution, which\nhelps accelerate the encoding of dependent representations at\nhigher resolutions across all bitrates.\n\u2013 while supporting new media formats such as ultra-high-\ndefinition (UHD) and 360-degree/immersive video. However,\nthe benefits of VVC come at a cost: its encoding process is\ncomputationally intensive, making real-time applications more\nchallenging. To mitigate VVC\u2019s complexity and enhance its suitability\nfor practical streaming, an optimized open-source implemen-\ntation known as VVenC [4] was developed. VVenC accelerates\nthe encoding process by incorporating a range of speed-\nup techniques, such as early termination of encoding modes\nand optimized partitioning decisions, without sacrificing the\ncompression efficiency inherent to VVC.\n\n2503.01404v1\nAs a result, VVenC\nenables faster encoding, making it a more feasible solution\nfor real-time streaming scenarios while still leveraging the\nadvanced compression capabilities of the VVC standard. Despite advances in compression efficiency with VVenC,\nencoding multiple representations for HAS remains a signifi-\ncant challenge, especially for live-streaming scenarios where\ntime constraints are critical. This requires accelerated genera-\ntion of multiple representations to meet time constraints. In recent years, substantial research has been dedicated to\noptimizing video encoding to reduce computational complex-\nity and improve encoding speed, particularly for multiple-\nquality representations. Schroeder et al. [5] introduced a\nmethod for high-resolution encoding that determines a thresh-\nold for early termination of low-resolution video representation\narXiv:2503.01404v1 [cs.MM]  3 Mar 2025\n\nencoding, thereby streamlining the process. In follow-up work,\nSchroeder et al. [6] utilized the highest quality representation\n(QP 22) to accelerate the encoding of lower quality versions of\nthe same video and later combined these strategies to identify\nspecific encoding parameters that enhance the efficiency of\ndependent representations [7]. Meanwhile, Amirpour et al.[8]\nproposed a double bond approach, which predicts block parti-\ntioning for lower quality representations based on the highest\nquality version, facilitating better control of the intermediate\nquality representation. In further studies, Amirpour et al. [9]\ndemonstrated that using a middle-quality representation as a\nreference for all other dependent representations effectively\nminimizes encoder complexity. Cetinkaya et al. [10] lever-\naged machine learning to expedite the encoding of multiple\nrepresentations, focusing initially on parallel encoding. They\nlater extended this work to incorporate multi-resolution en-\ncoding through machine learning models, which improved the\nencoding process further [11]. Menon et al. [12] explored\nserial and parallel encoding optimizations, proposing multi-\nencoding schemes considering the trade-offs between com-\npression efficiency and encoding time. In a different approach,\nLiu et al. [13] applied a multi-rate encoding technique in\nVVenC, using lower-quality representations to save time when\nencoding higher-quality versions. Despite substantial efforts to reduce the encoding com-\nplexity of VVC, most optimizations have focused on VTM\nrather than VVenC, primarily targeting enhancements in intra-\nframe [14]\u2013[21] and inter-frame [22]\u2013[26] coding techniques. Moreover, while the multi-rate approach has been explored\nfor VVC [13], multi-resolution acceleration remains largely\nuncharted. This research aims to achieve the speed-up by using the\nfeatures from a lower resolution representation, also known as\nreference representation, to accelerate the encoding of a higher\nresolution, also known as the dependent representation, across\nall required bitrates (b) in VVenC, as shown in Fig. 1. This\napproach is called the Multiresolution Encoding in VVenC\nfor HTTP Adaptive Streaming ( MEVHAS) and is effective\nin streaming services where it can assist in adaptive bitrate\nstreaming by providing more representations of the same\ncontent or can benefit real-time encoding, like live-streaming\nor video conferencing, to produce content at a faster rate.\nII. VVC B ACKGROUND\nVVC is a block-based hybrid video codec designed similarly\nto its predecessors. It delivers around 40% bitrate reduction\nby supporting multiple new high-level extensions and block-\nlevel coding tools. The partitioning scheme integrated in VVC\nprovides the most efficiency gains [27] but", "metadata": {"type": "factual", "source": "2503.01404v1.pdf", "context": "[12] V . V . Menon, H. Amirpour, M. Ghanbari, and C. Timmerer, \u201cEMES:\nEfficient Multi-Encoding Schemes for HEVC-Based Adaptive Bitrate\nStreaming,\u201d ACM Transactions on Multimedia Computing, Communica-\ntions and Applications, vol. 19, no. 3s, pp. 1\u201320, 2023.\n[13] Y . Liu, H. Amirpour, M. Abdoli, C. Timmerer, and T. Guionnet,\n\u201cPreparing VVC for Streaming: A Fast Multi-Rate Encoding Approach,\u201d\nin 2023 IEEE International Conference on Visual Communications and\nImage Processing (VCIP), pp. 1\u20135, IEEE, ", "quality_score": 9}}
{"id": "test_5", "question": "What is the first part of the dot product calculation in Equation (6)?", "golden_answers": ["The vector multiplication operation, where the result is stored in an intermediate vector."], "prediction": "The first part of the dot product calculation in Equation (6) is given by \\( ( e^{n+1}_{\\rho} - e^{n}_{\\rho} \\delta t , (e^{n+1}_{\\rho})^{2p-1} ) \\).", "f1": 0.14814814814814817, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.00873v1\nThus, since \u03b1,\u03b2 \u22650, to prove (6.10), it is enough to show that\n(6.12) \u03b1+ 2\u03b2= E,\nwhere E satisfies the estimate |E|\u2272|Q(S\u2217)|. Let us begin by treating \u03b2. First using the equation L\u2217u = 0, then integrating by parts, we obtain\n\u03b2=\nZZZ\n\u2212(div A\u2207u) utu\u03b7=\nZZZ\nA\u2207u \u00b7\u2207(utu\u03b7) = E +\nZZZ\nA\u2207u \u00b7\u2207ut u\u03b7+\nZZZ\nA\u2207u \u00b7\u2207u ut\u03b7,\nwhere, after using the product rule, the error term is of type E2. Next, we will use this fact:\n(6.13) (1 /2) \u2202t(A\u2207u \u00b7\u2207u) = A\u2207u \u00b7\u2207ut + (1/2)(\u2202tA)\u2207u \u00b7\u2207u. To verify it, just expand and remember that A is symmetric. Using this identity to continue rewrit-\ning \u03b2, it turns out that, up to a new error term of type E6, we have\n\u03b2= E +\nZZZ\n(1/2) \u2202t(A\u2207u \u00b7\u2207u) u\u03b7+\nZZZ\nA\u2207u \u00b7\u2207u ut\u03b7. Finally, integrating by parts in t on the first term we have, up to a new \u201cerror term\u201d of type E1,\n(6.14) \u03b2= E \u22121\n2\nZZZ\nA\u2207u \u00b7\u2207u ut\u03b7+\nZZZ\nA\u2207u \u00b7\u2207u ut\u03b7= E + 1\n2\nZZZ\nA\u2207u \u00b7\u2207u ut\u03b7. Next, our goal is to show that \u03b1is nearly of the same form as \u03b2, to get cancellations. First, using\nthe product rule both for \u2202xk (ai,juxi ) and \u2202xj (ak,\u2113ux\u2113) simultaneously, we obtain\n\u03b1=\nZZZ\nu \u2202xk (ai,juxi ) \u2202xj (ak,\u2113ux\u2113) \u03b7\u2212E8 \u2212E7 \u2212E7,\n\nV ARIABLE COEFFICIENT FBP FOR Lp-SOLV ABILITY 25\nand we will abbreviate the errors by E. Next, we integrate by parts in xk and use the product rule to\nobtain, up to a new error term of type \u2212E4 \u2212E5 (when \u2202xk lands on \u03b7),\n\u03b1= E \u2212\nZZZ\nuxk (ai,juxi ) \u2202xj (ak,\u2113ux\u2113) \u03b7\u2212\nZZZ\nu (ai,juxi ) \u2202xk \u2202xj (ak,\u2113ux\u2113) \u03b7=: E + I + II . We estimateI and II separately, starting withII . Using the equationL\u2217u = 0 (and exchanging the\norder of derivatives when needed) and rewriting the resulting expression using thatA is symmetric,\nthen invoking (6.13) (and hence introducing an error term of typeE6), and lastly integrating by parts\nin t (introducing an error of type E1), we have\nII = \u2212\nZZZ\nu (ai,juxi ) \u2202xj \u2202xk (ak,\u2113ux\u2113) \u03b7=\nZZZ\nu (ai,juxi ) \u2202xj ut \u03b7=\nZZZ\nu A\u2207u \u00b7\u2207ut \u03b7\n= E + 1\n2\nZZZ\nu \u2202t(A\u2207u \u00b7\u2207u) \u03b7= E \u22121\n2\nZZZ\nA\u2207u \u00b7\u2207u ut\u03b7. We have a desirable estimate for II and now turn to I. We start by integrating by parts in xj, to\nobtain, up to a new error term of type E3,\nI = E +\nZZZ\nuxk,xj (ai,juxi )(ak,\u2113ux\u2113) \u03b7+\nZZZ\nuxk \u2202xj (ai,juxi ) ak,\u2113ux\u2113 \u03b7=: E + I1 + I2,\nBy the equation L\u2217u = 0 and symmetry of A, we simply compute\nI2 = \u2212\nZZZ\nA\u2207u \u00b7\u2207u ut\u03b7. To handle I1 and get some cancellation with I2 in this form, we use a similar identity to (6.13),\n(1/2) \u2202xk (A\u2207u \u00b7\u2207u) = A\u2207u \u00b7\u2207uxk + (1/2) (\u2202xk A)\u2207u \u00b7\u2207u.\n\n2503.01427v1\nTaking the inner product of the error equation (6.8) with ( en+1\n\u03c1 )2p\u22121, this leads to\n( en+1\n\u03c1 \u2212 en\n\u03c1\n\u03b4t , (en+1\n\u03c1 )2p\u22121\n) \u2212\n(\n\u25b3en+1\n\u03c1 , (en+1\n\u03c1 )2p\u22121)\n= \u2212 \u03c7\n(\n\u2207 \u00b7\n(\n\u03c1(tn+1)\u2207en\nc + en+1\n\u03c1 \u2207cn)\n, (en+1\n\u03c1 )2p\u22121)\n+\n(\nT\u03c1(tn+1), (en+1\n\u03c1 )2p\u22121)\n.\n(6.20)\nNext, we estimate the bound of each term of this equation. For the \ufb01rst term, we have\n( en+1\n\u03c1 \u2212 en\n\u03c1\n\u03b4t , (en+1\n\u03c1 )2p\u22121\n)\n= 1\n\u03b4t\u2225en+1\n\u03c1 \u22252p\nL2p \u2212 1\n\u03b4t\n(\nen\n\u03c1 , (en+1\n\u03c1 )2p\u22121)\n, (6.21)\nand 1\n\u03b4t\n(\nen\n\u03c1 , (en+1\n\u03c1 )2p\u22121)\n\u2264 1\n\u03b4t\u2225en\n\u03c1 \u2225L2p \u2225en+1\n\u03c1 \u22252p\u22121\nL2p\n\u2264 1\n\u03b4t\n( 1\n2p\u2225en\n\u03c1 \u22252p\nL2p + 2p \u2212 1\n2p \u2225en+1\n\u03c1 \u22252p\nL2p\n) (6.22)\nby H\u00a8 older inequality and Young\u2019s inequality. For the second term,\n\u2212\n(\n\u25b3en+1\n\u03c1 , (en+1\n\u03c1 )2p\u22121)\n= 2p \u2212 1\np2 \u2225\u2207(en+1\n\u03c1 )p\u22252\nL2 . (6.23) For the last term, using H\u00a8 older inequality and Young\u2019s inequality, we o btain\n(\nT\u03c1(tn+1), (en+1\n\u03c1 )2p\u22121)\n\u2264\u2225T\u03c1(tn+1)\u2225L2p \u2225en+1\n\u03c1 \u22252p\u22121\nL2p\n\u2264 1\n2p\u2225T\u03c1(tn+1)\u22252p\nL2p + 2p \u2212 1\n2p \u2225en+1\n\u03c1 \u22252p\nL2p .\n(6.24)\n23 For the the third and the most complex term, we treat it as two part s \u2212\u03c7\n(\n\u2207 \u00b7 (en+1\n\u03c1 \u2207cn)\n,\n(en+1\n\u03c1 )2p\u22121) and \u2212\u03c7\n(\n\u2207 \u00b7 (\u03c1(tn+1)\u2207en\nc ) , (en+1\n\u03c1 )2p\u22121)\nbelow. According to the Green formula,\nthe equation about cn (1.6) and the positivity of cn for all n, the \ufb01rst part is estimated as\n\u2212 \u03c7\n(\n\u2207 \u00b7\n(\nen+1\n\u03c1 \u2207cn)\n, (en+1\n\u03c1 )2p\u22121)\n=\u03c7(2p \u2212 1)\n(\n(en+1\n\u03c1 )2p\u22121\u2207cn, \u2207en+1\n\u03c1\n)\n=(2p \u2212 1)\u03c7\n2p\n(\n|en+1\n\u03c1 |2p, \u2212\u2206 cn) =(2p \u2212 1)\u03c7\n2p\n(\n|en+1\n\u03c1 |2p, \u2212\u03c4 cn \u2212 cn\u22121\n\u03b4t \u2212 \u03b1c n + \u03b3\u03c1n\n) \u2264(2p \u2212 1)\u03c7\n2p\n(\n|en+1\n\u03c1 |2p, \u03b3\u03c1 n) \u2212 (2p \u2212 1)\u03c7\n2p\n(\n|en+1\n\u03c1 |2p, \u03c4 cn \u2212 cn\u22121\n\u03b4t\n)\n.\n(6.25) By Cauchy-Schwarz inequality, Gagliardo-Nirenberg inequality and Y oung\u2019s inequality, we\nderive\n(\n|en+1\n\u03c1 |2p, \u03b3\u03c1 n)\n\u2264\u03b3\u2225\u03c1n\u2225L2 \u2225(en+1\n\u03c1 )2p\u2225L2\n\u2264\u03b3Cgn\u2225\u03c1n\u2225L2 \u2225(en+1\n\u03c1 )p\u2225L2\n(\n\u2225\u2207(en+1\n\u03c1 )p\u2225L2 + \u2225(en+1\n\u03c1 )p\u2225L2\n) \u2264\u03b3Cgn ( 1\n\u03b5\u2225\u03c1n\u22252\nL2 + \u2225\u03c1n\u2225L2\n)\n\u2225(en+1\n\u03c1 )p\u22252\nL2 + \u03b3Cgn\u03b5\u2225\u2207(en+1\n\u03c1 )p\u22252\nL2\n\u2264\u03b3Cgn\n( 1\n\u03b5K4 + K\n1\n2\n4\n)\n\u2225(en+1\n\u03c1 )p\u22252\nL2 + \u03b3Cgn\u03b5\u2225\u2207(en+1\n\u03c1 )p\u22252\nL2 ,\n(6.26)\nwhere \u2225\u03c1n\u22252\nL2 \u2264 K4 for any n is known in Lemma 5.3. Similarly,\n\u2212 \u03c4\n(\n|en+1\n\u03c1 |2p, cn \u2212 cn\u22121\n\u03b4t\n)\n\u2264\u03c4Cgn\n(\n1\n\u03b5\n\ued79\n\ued79\n\ued79\n\ued79\ncn \u2212 cn\u22121\n\u03b4t\n\ued79\n\ued79\n\ued79\n\ued79\n2\nL2\n+\n\ued79\n\ued79\n\ued79\n\ued79\ncn \u2212 cn\u22121\n\u03b4t\n\ued79\n\ued79\n\ued79\n\ued79\nL2\n)\n\u2225(en+1\n\u03c1 )p\u22252\nL2 + \u03c4Cgn\u03b5\u2225\u2207(en+1\n\u03c1 )p\u22252\nL2\n(6.27)\n\n2503.01299v1\nTo this end, we write a reference state\u03a8\ud835\udefc\n0 in the form of matrix product state (MPS):\n|\u03a8\ud835\udefc\n0 \u27e9=\n\u2211\ufe01\n\ud835\udc5b1\ud835\udc5b2\u00b7\u00b7\u00b7\ud835\udc5b\ud835\udc3f\nA[1]\ud835\udc5b1 A[2]\ud835\udc5b2 \u00b7\u00b7\u00b7 A[\ud835\udc3f]\ud835\udc5b\ud835\udc3f |\ud835\udc5b1\ud835\udc5b2 ...\ud835\udc5b \ud835\udc3f\u27e9, (6)\nwhere \ud835\udc3fis the number of active orbitals (sites) and \ud835\udc5b\ud835\udc59 labels the occupation state of site \ud835\udc59. Every\nmatrix A[\ud835\udc59]with 1 <\ud835\udc59 < \ud835\udc3fis of dimension \ud835\udc40\u00d7\ud835\udc40, while the leftmost and rightmost matrices are\n6\n\n1 \u00d7\ud835\udc40 and \ud835\udc40\u00d71 vectors, respectively. The parameter \ud835\udc40 is the so-called MPS bond dimension,\nwhich controls the accuracy and complexity of the DMRG algorithm. In Eq. (6) and the following,\nwe drop the state label \ud835\udefcin the reference state for brevity. The active space eigenvalue problem [e.g., Eq. (5)] is equivalent to minimizing the Rayleigh\nquotient R=\u27e8\u03a8\ud835\udefc\n0 |\u02c6\ud835\udc3b|\u03a8\ud835\udefc\n0 \u27e9/\u27e8\u03a8\ud835\udefc\n0 |\u03a8\ud835\udefc\n0 \u27e9for the Hamiltonian \u02c6\ud835\udc3b. Here, \u02c6\ud835\udc3bis also in the matrix-product\nform, termed matrix product operators (MPOs). 3,4 The minimization of Ris achieved via the\nsweep algorithm,76 which optimizes the MPS matrices step by step. We adopt the state-averaged\nrepresentation for solving the ground and excited states. 77 Briefly, we find \ud835\udc5b orthogonal states\nin a common basis of renormalized states constructed at a given site during the sweep. The\ndensity matrices of these states are then averaged to build the common renormalized basis in the\nnext iteration. The computational and memory complexities of the state-averaged DMRG are\n\ud835\udc42(\ud835\udc5b\ud835\udc3f3 \ud835\udc403 +\ud835\udc3f4\ud835\udc402)and \ud835\udc42(\ud835\udc3f2\ud835\udc402), respectively. We assume the spin-adapted formalism 78\u201380 in\nall DMRG computations. Further details on ab initioDMRG can be found in Refs. 4, 13 and 81. Given an optimized MPS |\u03a8\ud835\udefc\n0 \u27e9with bond dimension \ud835\udc40, the spin-traced RDMs are computed\nusing a DMRG-like sweep algorithm. At every iteration during a sweep, we obtain a few RDM\nelements via tensor contractions and reuse the partially contracted intermediates for efficiency.25,26\nFor each state, the complexity of building\ud835\udc58-RDM scales as\ud835\udc42(\ud835\udc3f\ud835\udc58+1\ud835\udc403 +\ud835\udc3f2\ud835\udc58\ud835\udc402)in computational\ntime25 and \ud835\udc42(\ud835\udc3f\ud835\udc58\ud835\udc402)in memory. We note that algorithms with lower memory requirements exist,\nyet a larger prefactor emerges in the computational cost and the cost of writing scratch files.81\nC. SA-DSRG based on DMRG reference wave functions\nThe combination of SA-DSRG and DMRG is straightforward. We employ DMRG to obtain wave\nfunctions within the active space and subsequently correct for the missing dynamical correlation\nusing DSRG. The key ingredients can be summarized as follows. Given an ordering of the\nactive orbitals, the zeroth-order reference states of SA-DSRG are obtained by the SA-DMRG self-\nconsistent field (SCF), where both MPSs and molecular orbitals are simultaneously optimized. Then, the 1-, 2-, and 3-RDMs of the converged MPSs are computed. However, the 3-RDM can be\nsafely ignored without affecting the vertical transition energies as stated in Sec. II A. At this stage,\nwe can build the DSRG Hamiltonian and solve for the cluster amplitudes for a given value of \ud835\udc60\n[Eq. (2)]. Finally, the active-space eigenvalue problem with the DSRG transformed Hamiltonian\nis solved using DMRG to obtain the relaxed energies [Eq. (5)].", "metadata": {"type": "factual", "source": "2503.01313v1.pdf", "context": "Equation (6), PVU decompose the dot product calculation into\ntwo parts. The first part is the vector multiplication operation,\nwhere the result is stored in an intermediate vector. The second\npart is the accumulation operation, where the elements of the\nintermediate vector are summed to obtain the final dot product\nresult.\nFirst, PVU reuse the existing vector multiplication module,\nand store the result in an intermediate variable. Before per-\nforming the accumulation, PVU need to align all the e", "quality_score": 8.75}}
{"id": "test_6", "question": "What is the expression for CCDW(r) in terms of correlation functions?", "golden_answers": ["(\u22121)i+j\u27e8(Zi,A + Zi,B)(Zj,A + Zj,B)\u27e9 \u2212(\u22121)i+j\u27e8(Zi,A + Zi,B)\u27e9\u27e8(Zj,A + Zj,B)\u27e9 = ( \u22121)i+j \u00ee \u27e8c\u2020 i,Acj,A\u27e9\u27e8ci,Ac\u2020 j,A\u27e9 + \u27e8c\u2020 i,Bcj,B\u27e9\u27e8ci,Bc\u2020 j,B\u27e9"], "prediction": "CCDW(r) \u2261 (\u22121)i+j\u27e8(Zi,A + Zi,B)(Zj,A + Zj,B)\u27e9 \u2212(\u22121)i+j\u27e8(Zi,A + Zi,B)\u27e9\u27e8(Zj,A + Zj,B)\u27e9 = ( \u22121)i+j \u00ee \u27e8c\u2020 i,Acj,A\u27e9\u27e8ci,Ac\u2020 j,A\u27e9 + \u27e8c\u2020 i,Bcj,B\u27e9\u27e8ci,Bc\u2020 j,B\u27e9 \u00f3 = ( \u22121)r+1 2 sin2(\u03c0r/2) (\u03c0r)2.", "f1": 0.8, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "good title\nSimilarly, we can obtain the connected correlation functions for the CDW and BDW channels as follows:\nCCDW(r) \u2261 (\u22121)i+j\u27e8(Zi,A + Zi,B)(Zj,A + Zj,B)\u27e9 \u2212(\u22121)i+j\u27e8(Zi,A + Zi,B)\u27e9\u27e8(Zj,A + Zj,B)\u27e9\n= ( \u22121)i+j\n\u00ee\n\u27e8c\u2020\ni,Acj,A\u27e9\u27e8ci,Ac\u2020\nj,A\u27e9 + \u27e8c\u2020\ni,Bcj,B\u27e9\u27e8ci,Bc\u2020\nj,B\u27e9\n\u00f3\n= ( \u22121)r+1 2 sin2(\u03c0r/2)\n(\u03c0r)2 , (S10)\nand\nCBDW(r) \u2261 (\u22121)i+j\u27e8(Di,A \u2212 Di,B)(Dj,A \u2212 Dj,B)\u27e9 \u2212(\u22121)i+j\u27e8(Di,A \u2212 Di,B)\u27e9\u27e8(Dj,A \u2212 Dj,B)\u27e9\n= ( \u22121)i+j X\n\u03b1\nh\n\u27e8c\u2020\ni,\u03b1cj+1,\u03b1\u27e9\u27e8ci+1,\u03b1c\u2020\nj,\u03b1\u27e9 + \u27e8c\u2020\ni,\u03b1cj,\u03b1\u27e9\u27e8ci+1,\u03b1c\u2020\nj+1,\u03b1\u27e9\n+ \u27e8c\u2020\ni+1,\u03b1cj+1,\u03b1\u27e9\u27e8ci,\u03b1c\u2020\nj,\u03b1\u27e9 + \u27e8c\u2020\ni+1,\u03b1cj,\u03b1\u27e9\u27e8ci,\u03b1c\u2020\nj+1,\u03b1\u27e9\ni\n= 4( \u22121)r+1\n\u00c7\nsin2(\u03c0r/2)\n(\u03c0r)2 + sin[\u03c0(r + 1)/2] sin[\u03c0(r \u2212 1)/2]\n\u03c02(r + 1)(r \u2212 1)\n\u00e5\n. (S11)\nB. Finite-bond and finite-size extrapolations of the correlation functions at the deconfined critical point\nAs shown in Fig. 2(b) in the main text, the bulk-bulk connected correlations are computed by infinite-size DMRG\nsimulations. Although the thermodynamic limit is approached in a natural way, the calculation of the correlation\nfunctions is still affected by the finite-bond effect (or the finite-entanglement effect). To this end, we first perform a\n\n12\n100 300 500\n\u00ac\n0.02\n0.03\n0.04\n0.05\n0.06\n0.07\nCCDW(r, \u00ac)\nCCDW(r = 15)\nCCDW(r = 25)\nCBDW(r = 15)\nCBDW(r = 25)\n128 192 256\nL\n3\u00a310\u00b05\n4\u00a310\u00b05\n5\u00a310\u00b05\n6\u00a310\u00b05\nCCDW(r, L)\nCCDW(r = 56)\nCCDW(r = 64)\nCBDW(r = 56)\nCBDW(r = 64)0.11\n0.12\n0.13\n0.14\n0.15\n0.16\n0.17\nCBDW(r, \u00ac)\n0.010\n0.011\n0.012\n0.013\nCBDW(r, L) <latexit sha1_base64=\"2RRwxLXlY8TROIoM98j2WcOjpro=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoMQL2FXgnoMevEY0TwgWcLspDcZMju7zMwKIeQTvHhQxKtf5M2/cZLsQRMLGoqqbrq7gkRwbVz328mtrW9sbuW3Czu7e/sHxcOjpo5TxbDBYhGrdkA1Ci6xYbgR2E4U0igQ2ApGtzO/9YRK81g+mnGCfkQHkoecUWOlhzI97xVLbsWdg6wSLyMlyFDvFb+6/ZilEUrDBNW647mJ8SdUGc4ETgvdVGNC2YgOsGOppBFqfzI/dUrOrNInYaxsSUPm6u+JCY20HkeB7YyoGeplbyb+53VSE177Ey6T1KBki0VhKoiJyexv0ucKmRFjSyhT3N5K2JAqyoxNp2BD8JZfXiXNi4p3WaneV0u1myyOPJzAKZTBgyuowR3UoQEMBvAMr/DmCOfFeXc+Fq05J5s5hj9wPn8Ai5mNUw==</latexit>\n( a )\n<latexit sha1_base64=\"KWh0RLJ0bw8em/x3PU2+HIlN2FQ=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoMQL2FXgnoMevEY0TwgWcLspDcZMju7zMwKIeQTvHhQxKtf5M2/cZLsQRMLGoqqbrq7gkRwbVz328mtrW9sbuW3Czu7e/sHxcOjpo5TxbDBYhGrdkA1Ci6xYbgR2E4U0igQ2ApGtzO/9YRK81g+mnGCfkQHkoecUWOlh3Jw3iuW3Io7B1klXkZKkKHeK351+zFLI5SGCap1x3MT40+oMpwJnBa6qcaEshEdYMdSSSPU/mR+6pScWaVPwljZkobM1d8TExppPY4C2xlRM9TL3kz8z+ukJrz2J1wmqUHJFovCVBATk9nfpM8VMiPGllCmuL2VsCFVlBmbTsGG4C2/vEqaFxXvslK9r5ZqN1kceTiBUyiDB1dQgzuoQwMYDOAZXuHNEc6L8+58LFpzTjZzDH/gfP4AjR6NVA==</latexit>\n( b )\nFIG. S4. (a) Each data point of the bulk-bulk correlation function for BDW and CDW orders shown in Fig.2(b) in the main\ntext is obtained by extrapolating to infinite MPS bond dimensions. The dotted and dashed lines are least-squares fittings with\nthe form C(r, \u03c7) = a(100/\u03c7)b + C(r, \u03c7\u2192 \u221e). (b) Each data of the boundary-bulk correlations displayed in Fig.2(c) in the\nmain text is obtained by extrapolating toL \u2192 \u221ewith the fitting form,C(r, L) = a/Lb + C(r, L\u2192 \u221e), whereL is the ladder\nlength. Numerical data are obtained from infinite-size DMRG calculations for (a) and finite-size DMRG calculations for (b)\nwith a sufficiently large bond dimension\u03c7 = 2048 to ensure the convergence of the results forL up to256.\n0 1 2 3 4 5\nk\n0\n1\n2\n3\n4\n5Ek(L)\u00b0E0(L) L= 16\nL= 32\nL= 48\nL= 64\nL= 80\nL= 96\n20 30 40 50 60 70 8090100\nL\n0.5\n0.6\n0.7\n0.8\n0.91.0\n2.0\ne(L) \u00a5E2(L)\u00b0E0(L)\ne(L)\u00aaaL\u00b0z\nz(L)= \u00b0d(lne(L))/d(lnL)\n0.00 0.01 0.02 0.03\n1/L\n0.950\n0.975\n1.000\nz(L)\n\ngood title\nfinite bond extrapolation for eachr of CCDW/BDW(r, \u03c7) to the limit\u03c7 \u2192 \u221eas shown in Fig. S4(a). The extrapolated\nresults CCDW/BDW(r, \u03c7\u2192 \u221e) are then fed into the scaling analysis shown in Fig. 2(b) in the main text. However, the boundary-bulk correlations are obtained from finite-size DMRG calculations. Having chosen a suffi-\nciently large MPS bond dimension, such as\u03c7 = 2048, we can expect the results to converge well with\u03c7. In contrast\nto the bulk-bulk correlations, the accuracy of the boundary-bulk correlations are mainly limited by the finite system\nsize. As shown in Fig. S4(b) , the finite-size effect is eliminated here by extrapolating to the thermodynamic limit using\nCCDW/BDW(r, L) with L up to256. Finally, the extrapolated resultsCCDW/BDW(r, L\u2192 \u221e) are used in Fig. 2(c) in\n\n13\n0.44\n0.41\n-0.31\n-0.34\n0.29\n0.26\n-0.23\n-0.26\n0.23\n0.20\n-0.18\n-0.21\n0.19\n0.14\n-0.16\n-0.17\n0.16\n0.09\n-0.14\n-0.13\n0.13\n0.04\n-0.14\n-0.09\n0.10\n-0.02\n-0.14\n-0.06\n0.09\n-0.05\n-0.14\n-0.04\n0.08\n-0.07\n-0.14\n-0.04\n0.09\n-0.05\n-0.14\n-0.06\n0.10\n-0.02\n-0.14\n-0.09\n0.13\n0.04\n-0.14\n-0.13\n0.16\n0.09\n-0.16\n-0.17\n0.19\n0.14\n-0.18\n-0.21\n0.23\n0.20\n-0.23\n-0.26\n0.29\n0.26\n-0.31\n-0.34\n0.44\n0.41\n0.35\n0.44\n0.52\n0.35\n0.34\n0.57\n0.60\n0.32\n0.30\n0.64\n0.66\n0.28\n0.27\n0.69\n0.70\n0.26\n0.26\n0.72\n0.71\n0.26\n0.28\n0.71\n0.69\n0.30\n0.34\n0.67\n0.63\n0.38\n0.43\n0.59\n0.54\n0.49\n0.54\n0.49\n0.43\n0.59\n0.63\n0.38\n0.34\n0.67\n0.69\n0.30\n0.28\n0.71\n0.71\n0.26\n0.26\n0.72\n0.70\n0.26\n0.27\n0.69\n0.66\n0.28\n0.30\n0.64\n0.60\n0.32\n0.34\n0.57\n0.52\n0.35\n0.35\n0.44\n0.00\n-0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n0.00\n0.41\n0.44\n-0.34\n-0.31\n0.26\n0.29\n-0.26\n-0.23\n0.20\n0.23\n-0.21\n-0.18\n0.14\n0.19\n-0.17\n-0.16\n0.09\n0.16\n-0.13\n-0.14\n0.04\n0.13\n-0.09\n-0.14\n-0.02\n0.10\n-0.06\n-0.14\n-0.05\n0.09\n-0.04\n-0.14\n-0.07\n0.08\n-0.04\n-0.14\n-0.05\n0.09\n-0.06\n-0.14\n-0.02\n0.10\n-0.09\n-0.14\n0.04\n0.13\n-0.13\n-0.14\n0.09\n0.16\n-0.17\n-0.16\n0.14\n0.19\n-0.21\n-0.18\n0.20\n0.23\n-0.26\n-0.23\n0.26\n0.29\n-0.34\n-0.31\n0.41\n0.44\n0.44\n0.35\n0.35\n0.52\n0.57\n0.34\n0.32\n0.60\n0.64\n0.30\n0.28\n0.66\n0.69\n0.27\n0.26\n0.70\n0.72\n0.26\n0.26\n0.71\n0.71\n0.28\n0.30\n0.69\n0.67\n0.34\n0.38\n0.63\n0.59\n0.43\n0.49\n0.54\n0.49\n0.54\n0.59\n0.43\n0.38\n0.63\n0.67\n0.34\n0.30\n0.69\n0.71\n0.28\n0.26\n0.71\n0.72\n0.26\n0.26\n0.70\n0.69\n0.27\n0.28\n0.66\n0.64\n0.30\n0.32\n0.60\n0.57\n0.34\n0.35\n0.52\n0.44\n0.35\n-0.00\n0.00\n-0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n<latexit sha1_base64=\"nslKz2SyATc1OXvZmjuedvLA/7c=\">AAACE3icbVA9TxtBEN0DkhiTDwdKmhVWJJPCuoushNKChtJIGCz5HGtub2yv2Nu77M6hWMf9B5r8lTQUIERLQ8e/Yf1REMiTRnp6b0Yz86JMSUu+/+itrK69efuusl7deP/h46fa580Tm+ZGYFekKjW9CCwqqbFLkhT2MoOQRApPo7ODmX96jsbKVB/TNMNBAmMtR1IAOWlY+9qAYJeHv3KIi5Jf8DCzclj45c8iJPxNRVyWPDSgxwqHtbrf9Ofgr0mwJHW2RGdYewjjVOQJahIKrO0HfkaDAgxJobCshrnFDMQZjLHvqIYE7aCY/1TyL06J+Sg1rjTxufp8ooDE2mkSuc4EaGJfejPxf14/p9HeoJA6ywm1WCwa5YpTymcB8VgaFKSmjoAw0t3KxQQMCHIxVl0IwcuXX5OTb83ge7N11Kq395dxVNg222ENFrAfrM0OWYd1mWCX7C+7ZjfeH+/Ku/XuFq0r3nJmi/0D7/4JmwieDQ==</latexit>\n( a 1) |  d\n0 i\n<latexit sha1_base64=\"xK/Hgv+M0nP5CVeMcrsE3j2hnE4=\">AAACE3icbVA9TxtBEN2D8BHz5UCZZoWFBBTWHUKBEkGT0kjxh+Qz1tze2KzY27vszqFYx/0HGv4KTQqiiDZNuvwb1h9FwDxppKf3ZjQzL8qUtOT7/7yFxQ9LyyurHytr6xubW9VP2y2b5kZgU6QqNZ0ILCqpsUmSFHYyg5BECtvRzcXYb9+isTLV32iUYS+BoZYDKYCc1K8e7sPRAQ+/5xAXJb/jYWZlvwjKqyIk/EFFXJY8NKCHCvvVml/3J+DzJJiRGpuh0a/+DeNU5AlqEgqs7QZ+Rr0CDEmhsKyEucUMxA0MseuohgRtr5j8VPI9p8R8kBpXmvhE/X+igMTaURK5zgTo2r71xuJ7XjenwWmvkDrLCbWYLhrkilPKxwHxWBoUpEaOgDDS3crFNRgQ5GKsuBCCty/Pk9ZRPfhSP748rp2dz+JYZZ/ZLttnATthZ+wra7AmE+yePbIn9st78H56v73naeuCN5vZYa/g/XkBnkueDw==</latexit>\n( a 2) |  d\n1 i\n<latexit sha1_base64=\"qbzpsuEokG0govxlDprVv2VJ8R4=\">AAACBnicbVBNS8NAEN34WetX1KMIi0XwVBIp6rHoxWMFq0JTw2YzrYubTdidiCXm5MW/4sWDIl79Dd78N25rD349GHi8N8PMvCiTwqDnfTgTk1PTM7OVuer8wuLSsruyemrSXHNo81Sm+jxiBqRQ0EaBEs4zDSyJJJxFV4dD/+watBGpOsFBBt2E9ZXoCc7QSqG7cUuDzIiw8MqLIkC4wSIuSxpopvoSQrfm1b0R6F/ij0mNjNEK3fcgTnmegEIumTEd38uwWzCNgksoq0FuIGP8ivWhY6liCZhuMXqjpFtWiWkv1bYU0pH6faJgiTGDJLKdCcNL89sbiv95nRx7+91CqCxHUPxrUS+XFFM6zITGQgNHObCEcS3srZRfMs042uSqNgT/98t/yelO3d+tN44btebBOI4KWSebZJv4ZI80yRFpkTbh5I48kCfy7Nw7j86L8/rVOuGMZ9bIDzhvn+SImWk=</latexit>\n|  d\n0 i\n<latexit sha1_base64=\"wdSdFFF0U84YsspLv8GvvrFvJ/A=\">AAACBnicbVBNS8NAEN34WetX1KMIi0XwVBIp6rHoxWMFq0JTw2YzrYubTdidiCXm5MW/4sWDIl79Dd78N25rD349GHi8N8PMvCiTwqDnfTgTk1PTM7OVuer8wuLSsruyemrSXHNo81Sm+jxiBqRQ0EaBEs4zDSyJJJxFV4dD/+watBGpOsFBBt2E9ZXoCc7QSqG7cUuDzIiw8MuLIkC4wSIuSxpopvoSQrfm1b0R6F/ij0mNjNEK3fcgTnmegEIumTEd38uwWzCNgksoq0FuIGP8ivWhY6liCZhuMXqjpFtWiWkv1bYU0pH6faJgiTGDJLKdCcNL89sbiv95nRx7+91CqCxHUPxrUS+XFFM6zITGQgNHObCEcS3srZRfMs042uSqNgT/98t/yelO3d+tN44btebBOI4KWSebZJv4ZI80yRFpkTbh5I48kCfy7Nw7j86L8/rVOuGMZ9bIDzhvn+YgmWo=</latexit>\n|  d\n1 i\n<latexit sha1_base64=\"VrdkJi09t8gm0wuCYM5oilERs9c=\">AAAB/nicbVDLSgNBEJyNrxhfq+LJy2AQPIVdCeoxxIvHiOYByRJmJ51kyOyDmV4xLAF/xYsHRbz6Hd78GyfJHjSxoKGo6p7pLj+WQqPjfFu5ldW19Y38ZmFre2d3z94/aOgoURzqPJKRavlMgxQh1FGghFasgAW+hKY/up76zQdQWkThPY5j8AI2CEVfcIZG6tpHHYRHTO8SX8eMA60yLfSkaxedkjMDXSZuRookQ61rf3V6EU8CCJFLpnXbdWL0UqZQcAmTQifRYN4fsQG0DQ1ZANpLZ+tP6KlRerQfKVMh0pn6eyJlgdbjwDedAcOhXvSm4n9eO8H+lZeKME4QQj7/qJ9IihGdZkF7QgFHOTaEcSXMrpQPmWIcTWIFE4K7ePIyaZyX3ItS+bZcrFSzOPLkmJyQM+KSS1IhN6RG6oSTlDyTV/JmPVkv1rv1MW/NWdnMIfkD6/MHmB2V5w==</latexit>\nSubspace Basis\n<latexit sha1_base64=\"komu+cSBmmmb6Pqy5yHyo0I49Tc=\">AAACInicbVDLSgMxFM3UV62vqks3wWJxVWak+FgIRTcuK9gHdIYhk962oZnMkGSkZei3uPFX3LhQ1JXgx5g+QG09kHByzr3k3hPEnClt259WZml5ZXUtu57b2Nza3snv7tVVlEgKNRrxSDYDooAzATXNNIdmLIGEAYdG0L8e+417kIpF4k4PY/BC0hWswyjRRvLzF24AXSbSOCRassEI27iIHey65iqahwui/WNeYlexbkj8dDDy8wW7ZE+AF4kzIwU0Q9XPv7vtiCYhCE05Uarl2LH2UiI1oxxGOTdREBPaJ11oGSpICMpLJyuO8JFR2rgTSXOExhP1d0dKQqWGYWAqzbA9Ne+Nxf+8VqI7517KRJxoEHT6USfhWEd4nBduMwlU86EhhEpmZsW0RySh2qSaMyE48ysvkvpJyTktlW/LhcrVLI4sOkCH6Bg56AxV0A2qohqi6AE9oRf0aj1az9ab9TEtzViznn30B9bXN1UHols=</latexit>\n\u2713\n01\n10\n\u25c6\n= \u0000 x\n<latexit sha1_base64=\"uXDSvYBMpdHihJTDvmUyGVHyeNc=\">AAACI3icbVDLSgMxFM34rPVVdekmWCxuLDNSVASh6MZlBfuAzjBk0ts2NJMZkoxYh/6LG3/FjQuluHHhv5g+QG09kHA4517uvSeIOVPatj+thcWl5ZXVzFp2fWNzazu3s1tTUSIpVGnEI9kIiALOBFQ10xwasQQSBhzqQe965NfvQSoWiTvdj8ELSUewNqNEG8nPXbgBdJhI45BoyR4G2MEFbGPXNV8BHzvYBdH6cS+xq1gnJH76OPBzebtoj4HniTMleTRFxc8N3VZEkxCEppwo1XTsWHspkZpRDoOsmyiICe2RDjQNFSQE5aXjGwf40Cgt3I6keULjsfq7IyWhUv0wMJVm2a6a9Ubif14z0e1zL2UiTjQIOhnUTjjWER4FhltMAtW8bwihkpldMe0SSag2sWZNCM7syfOkdlJ0Toul21K+fDWNI4P20QE6Qg46Q2V0gyqoiih6Qi/oDb1bz9arNbQ+JqUL1rRnD/2B9fUNz3eilA==</latexit>\n\u2713\n10\n0\n\ngood title\nfinite bond extrapolation for eachr of CCDW/BDW(r, \u03c7) to the limit\u03c7 \u2192 \u221eas shown in Fig. S4(a). The extrapolated\nresults CCDW/BDW(r, \u03c7\u2192 \u221e) are then fed into the scaling analysis shown in Fig. 2(b) in the main text. However, the boundary-bulk correlations are obtained from finite-size DMRG calculations. Having chosen a suffi-\nciently large MPS bond dimension, such as\u03c7 = 2048, we can expect the results to converge well with\u03c7. In contrast\nto the bulk-bulk correlations, the accuracy of the boundary-bulk correlations are mainly limited by the finite system\nsize. As shown in Fig. S4(b) , the finite-size effect is eliminated here by extrapolating to the thermodynamic limit using\nCCDW/BDW(r, L) with L up to256. Finally, the extrapolated resultsCCDW/BDW(r, L\u2192 \u221e) are used in Fig. 2(c) in\n\n13\n0.44\n0.41\n-0.31\n-0.34\n0.29\n0.26\n-0.23\n-0.26\n0.23\n0.20\n-0.18\n-0.21\n0.19\n0.14\n-0.16\n-0.17\n0.16\n0.09\n-0.14\n-0.13\n0.13\n0.04\n-0.14\n-0.09\n0.10\n-0.02\n-0.14\n-0.06\n0.09\n-0.05\n-0.14\n-0.04\n0.08\n-0.07\n-0.14\n-0.04\n0.09\n-0.05\n-0.14\n-0.06\n0.10\n-0.02\n-0.14\n-0.09\n0.13\n0.04\n-0.14\n-0.13\n0.16\n0.09\n-0.16\n-0.17\n0.19\n0.14\n-0.18\n-0.21\n0.23\n0.20\n-0.23\n-0.26\n0.29\n0.26\n-0.31\n-0.34\n0.44\n0.41\n0.35\n0.44\n0.52\n0.35\n0.34\n0.57\n0.60\n0.32\n0.30\n0.64\n0.66\n0.28\n0.27\n0.69\n0.70\n0.26\n0.26\n0.72\n0.71\n0.26\n0.28\n0.71\n0.69\n0.30\n0.34\n0.67\n0.63\n0.38\n0.43\n0.59\n0.54\n0.49\n0.54\n0.49\n0.43\n0.59\n0.63\n0.38\n0.34\n0.67\n0.69\n0.30\n0.28\n0.71\n0.71\n0.26\n0.26\n0.72\n0.70\n0.26\n0.27\n0.69\n0.66\n0.28\n0.30\n0.64\n0.60\n0.32\n0.34\n0.57\n0.52\n0.35\n0.35\n0.44\n0.00\n-0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n0.00\n0.41\n0.44\n-0.34\n-0.31\n0.26\n0.29\n-0.26\n-0.23\n0.20\n0.23\n-0.21\n-0.18\n0.14\n0.19\n-0.17\n-0.16\n0.09\n0.16\n-0.13\n-0.14\n0.04\n0.13\n-0.09\n-0.14\n-0.02\n0.10\n-0.06\n-0.14\n-0.05\n0.09\n-0.04\n-0.14\n-0.07\n0.08\n-0.04\n-0.14\n-0.05\n0.09\n-0.06\n-0.14\n-0.02\n0.10\n-0.09\n-0.14\n0.04\n0.13\n-0.13\n-0.14\n0.09\n0.16\n-0.17\n-0.16\n0.14\n0.19\n-0.21\n-0.18\n0.20\n0.23\n-0.26\n-0.23\n0.26\n0.29\n-0.34\n-0.31\n0.41\n0.44\n0.44\n0.35\n0.35\n0.52\n0.57\n0.34\n0.32\n0.60\n0.64\n0.30\n0.28\n0.66\n0.69\n0.27\n0.26\n0.70\n0.72\n0.26\n0.26\n0.71\n0.71\n0.28\n0.30\n0.69\n0.67\n0.34\n0.38\n0.63\n0.59\n0.43\n0.49\n0.54\n0.49\n0.54\n0.59\n0.43\n0.38\n0.63\n0.67\n0.34\n0.30\n0.69\n0.71\n0.28\n0.26\n0.71\n0.72\n0.26\n0.26\n0.70\n0.69\n0.27\n0.28\n0.66\n0.64\n0.30\n0.32\n0.60\n0.57\n0.34\n0.35\n0.52\n0.44\n0.35\n-0.00\n0.00\n-0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n<latexit sha1_base64=\"nslKz2SyATc1OXvZmjuedvLA/7c=\">AAACE3icbVA9TxtBEN0DkhiTDwdKmhVWJJPCuoushNKChtJIGCz5HGtub2yv2Nu77M6hWMf9B5r8lTQUIERLQ8e/Yf1REMiTRnp6b0Yz86JMSUu+/+itrK69efuusl7deP/h46fa580Tm+ZGYFekKjW9CCwqqbFLkhT2MoOQRApPo7ODmX96jsbKVB/TNMNBAmMtR1IAOWlY+9qAYJeHv3KIi5Jf8DCzclj45c8iJPxNRVyWPDSgxwqHtbrf9Ofgr0mwJHW2RGdYewjjVOQJahIKrO0HfkaDAgxJobCshrnFDMQZjLHvqIYE7aCY/1TyL06J+Sg1rjTxufp8ooDE2mkSuc4EaGJfejPxf14/p9HeoJA6ywm1WCwa5YpTymcB8VgaFKSmjoAw0t3KxQQMCHIxVl0IwcuXX5OTb83ge7N11Kq395dxVNg222ENFrAfrM0OWYd1mWCX7C+7ZjfeH+/Ku/XuFq0r3nJmi/0D7/4JmwieDQ==</latexit>\n( a 1) |  d\n0 i\n<latexit sha1_base64=\"xK/Hgv+M0nP5CVeMcrsE3j2hnE4=\">AAACE3icbVA9TxtBEN2D8BHz5UCZZoWFBBTWHUKBEkGT0kjxh+Qz1tze2KzY27vszqFYx/0HGv4KTQqiiDZNuvwb1h9FwDxppKf3ZjQzL8qUtOT7/7yFxQ9LyyurHytr6xubW9VP2y2b5kZgU6QqNZ0ILCqpsUmSFHYyg5BECtvRzcXYb9+isTLV32iUYS+BoZYDKYCc1K8e7sPRAQ+/5xAXJb/jYWZlvwjKqyIk/EFFXJY8NKCHCvvVml/3J+DzJJiRGpuh0a/+DeNU5AlqEgqs7QZ+Rr0CDEmhsKyEucUMxA0MseuohgRtr5j8VPI9p8R8kBpXmvhE/X+igMTaURK5zgTo2r71xuJ7XjenwWmvkDrLCbWYLhrkilPKxwHxWBoUpEaOgDDS3crFNRgQ5GKsuBCCty/Pk9ZRPfhSP748rp2dz+JYZZ/ZLttnATthZ+wra7AmE+yePbIn9st78H56v73naeuCN5vZYa/g/XkBnkueDw==</latexit>\n( a 2) |  d\n1 i\n<latexit sha1_base64=\"qbzpsuEokG0govxlDprVv2VJ8R4=\">AAACBnicbVBNS8NAEN34WetX1KMIi0XwVBIp6rHoxWMFq0JTw2YzrYubTdidiCXm5MW/4sWDIl79Dd78N25rD349GHi8N8PMvCiTwqDnfTgTk1PTM7OVuer8wuLSsruyemrSXHNo81Sm+jxiBqRQ0EaBEs4zDSyJJJxFV4dD/+watBGpOsFBBt2E9ZXoCc7QSqG7cUuDzIiw8MqLIkC4wSIuSxpopvoSQrfm1b0R6F/ij0mNjNEK3fcgTnmegEIumTEd38uwWzCNgksoq0FuIGP8ivWhY6liCZhuMXqjpFtWiWkv1bYU0pH6faJgiTGDJLKdCcNL89sbiv95nRx7+91CqCxHUPxrUS+XFFM6zITGQgNHObCEcS3srZRfMs042uSqNgT/98t/yelO3d+tN44btebBOI4KWSebZJv4ZI80yRFpkTbh5I48kCfy7Nw7j86L8/rVOuGMZ9bIDzhvn+SImWk=</latexit>\n|  d\n0 i\n<latexit sha1_base64=\"wdSdFFF0U84YsspLv8GvvrFvJ/A=\">AAACBnicbVBNS8NAEN34WetX1KMIi0XwVBIp6rHoxWMFq0JTw2YzrYubTdidiCXm5MW/4sWDIl79Dd78N25rD349GHi8N8PMvCiTwqDnfTgTk1PTM7OVuer8wuLSsruyemrSXHNo81Sm+jxiBqRQ0EaBEs4zDSyJJJxFV4dD/+watBGpOsFBBt2E9ZXoCc7QSqG7cUuDzIiw8MuLIkC4wSIuSxpopvoSQrfm1b0R6F/ij0mNjNEK3fcgTnmegEIumTEd38uwWzCNgksoq0FuIGP8ivWhY6liCZhuMXqjpFtWiWkv1bYU0pH6faJgiTGDJLKdCcNL89sbiv95nRx7+91CqCxHUPxrUS+XFFM6zITGQgNHObCEcS3srZRfMs042uSqNgT/98t/yelO3d+tN44btebBOI4KWSebZJv4ZI80yRFpkTbh5I48kCfy7Nw7j86L8/rVOuGMZ9bIDzhvn+YgmWo=</latexit>\n|  d\n1 i\n<latexit sha1_base64=\"VrdkJi09t8gm0wuCYM5oilERs9c=\">AAAB/nicbVDLSgNBEJyNrxhfq+LJy2AQPIVdCeoxxIvHiOYByRJmJ51kyOyDmV4xLAF/xYsHRbz6Hd78GyfJHjSxoKGo6p7pLj+WQqPjfFu5ldW19Y38ZmFre2d3z94/aOgoURzqPJKRavlMgxQh1FGghFasgAW+hKY/up76zQdQWkThPY5j8AI2CEVfcIZG6tpHHYRHTO8SX8eMA60yLfSkaxedkjMDXSZuRookQ61rf3V6EU8CCJFLpnXbdWL0UqZQcAmTQifRYN4fsQG0DQ1ZANpLZ+tP6KlRerQfKVMh0pn6eyJlgdbjwDedAcOhXvSm4n9eO8H+lZeKME4QQj7/qJ9IihGdZkF7QgFHOTaEcSXMrpQPmWIcTWIFE4K7ePIyaZyX3ItS+bZcrFSzOPLkmJyQM+KSS1IhN6RG6oSTlDyTV/JmPVkv1rv1MW/NWdnMIfkD6/MHmB2V5w==</latexit>\nSubspace Basis\n<latexit sha1_base64=\"komu+cSBmmmb6Pqy5yHyo0I49Tc=\">AAACInicbVDLSgMxFM3UV62vqks3wWJxVWak+FgIRTcuK9gHdIYhk962oZnMkGSkZei3uPFX3LhQ1JXgx5g+QG09kHByzr3k3hPEnClt259WZml5ZXUtu57b2Nza3snv7tVVlEgKNRrxSDYDooAzATXNNIdmLIGEAYdG0L8e+417kIpF4k4PY/BC0hWswyjRRvLzF24AXSbSOCRassEI27iIHey65iqahwui/WNeYlexbkj8dDDy8wW7ZE+AF4kzIwU0Q9XPv7vtiCYhCE05Uarl2LH2UiI1oxxGOTdREBPaJ11oGSpICMpLJyuO8JFR2rgTSXOExhP1d0dKQqWGYWAqzbA9Ne+Nxf+8VqI7517KRJxoEHT6USfhWEd4nBduMwlU86EhhEpmZsW0RySh2qSaMyE48ysvkvpJyTktlW/LhcrVLI4sOkCH6Bg56AxV0A2qohqi6AE9oRf0aj1az9ab9TEtzViznn30B9bXN1UHols=</latexit>\n\u2713\n01\n10\n\u25c6\n= \u0000 x\n<latexit sha1_base64=\"uXDSvYBMpdHihJTDvmUyGVHyeNc=\">AAACI3icbVDLSgMxFM34rPVVdekmWCxuLDNSVASh6MZlBfuAzjBk0ts2NJMZkoxYh/6LG3/FjQuluHHhv5g+QG09kHA4517uvSeIOVPatj+thcWl5ZXVzFp2fWNzazu3s1tTUSIpVGnEI9kIiALOBFQ10xwasQQSBhzqQe965NfvQSoWiTvdj8ELSUewNqNEG8nPXbgBdJhI45BoyR4G2MEFbGPXNV8BHzvYBdH6cS+xq1gnJH76OPBzebtoj4HniTMleTRFxc8N3VZEkxCEppwo1XTsWHspkZpRDoOsmyiICe2RDjQNFSQE5aXjGwf40Cgt3I6keULjsfq7IyWhUv0wMJVm2a6a9Ubif14z0e1zL2UiTjQIOhnUTjjWER4FhltMAtW8bwihkpldMe0SSag2sWZNCM7syfOkdlJ0Toul21K+fDWNI4P20QE6Qg46Q2V0gyqoiih6Qi/oDb1bz9arNbQ+JqUL1rRnD/2B9fUNz3eilA==</latexit>\n\u2713\n10\n0", "metadata": {"type": "factual", "source": "2503.01198v1.pdf", "context": "CCDW(r) \u2261 (\u22121)i+j\u27e8(Zi,A + Zi,B)(Zj,A + Zj,B)\u27e9 \u2212(\u22121)i+j\u27e8(Zi,A + Zi,B)\u27e9\u27e8(Zj,A + Zj,B)\u27e9\n= ( \u22121)i+j\n\u00ee\n\u27e8c\u2020\ni,Acj,A\u27e9\u27e8ci,Ac\u2020\nj,A\u27e9 + \u27e8c\u2020\ni,Bcj,B\u27e9\u27e8ci,Bc\u2020\nj,B\u27e9\n\u00f3\n= ( \u22121)r+1 2 sin2(\u03c0r/2)\n(\u03c0r)2 , (S10)\nand\nCBDW(r) \u2261 (\u22121)i+j\u27e8(Di,A \u2212 Di,B)(Dj,A \u2212 Dj,B)\u27e9 \u2212(\u22121)i+j\u27e8(Di,A \u2212 Di,B)\u27e9\u27e8(Dj,A \u2212 Dj,B)\u27e9\n= ( \u22121)i+j X\n\u03b1\nh\n\u27e8c\u2020\ni,\u03b1cj+1,\u03b1\u27e9\u27e8ci+1,\u03b1c\u2020\nj,\u03b1\u27e9 + \u27e8c\u2020\ni,\u03b1cj,\u03b1\u27e9\u27e8ci+1,\u03b1c\u2020\nj+1,\u03b1\u27e9\n+ \u27e8c\u2020\ni+1,\u03b1cj+1,\u03b1\u27e9\u27e8ci,\u03b1c\u2020\nj,\u03b1\u27e9 + \u27e8c\u2020\ni+1,\u03b1cj,\u03b1\u27e9\u27e8ci,\u03b1c\u2020\nj+1,\u03b1\u27e9\ni\n= 4( \u22121)r+1\n\u00c7\nsin2(\u03c0r/2)\n(\u03c0r)2 + sin[\u03c0(r + 1)/2] sin[\u03c0(r \u2212 1)/2]\n\u03c02(r + 1)(r \u2212 1", "quality_score": 8.75}}
{"id": "test_7", "question": "What is the purpose of training a transformer sequence model according to the procedure described in the text?", "golden_answers": ["The training procedure enables the model to learn the single-step predictive distributions that collectively define the full sequence likelihood."], "prediction": "The purpose of training a transformer sequence model is to generate a sequence conditioned on various inputs such as text descriptions, timestamps, and audio tokens, effectively learning long-term dependencies to produce coherent musical compositions that adhere to the intended genre and structure.", "f1": 0.18867924528301885, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.00289v1\nWe then trained new Potts, MSA\nTransformer, and Independent models on the 6M syn-\nthetic training MSA and generated synthetic \u201cevalua-\ntion\u201d MSAs containing 6M sequences for all models. We\nrepeated a similar process for the MSA Transformer using\nthe same input. This approach addresses \ufb01nite sampling\nlimitations by generating MSAs with any desired number\nof sequences.\n\n2503.01190v1\nThese components are embedded\ninto the transformer\u2019s latent space using dedicated projec-\ntion heads: Vemb, Demb and Lemb.\ncA V= Vemb\n\u0000\nAV\n\u0001\n, c CD = Demb\n\u0000\nCD\n\u0001\n, c L = Lemb\n\u0000\nL\n\u0001\n. To handle both fully and partially conditional cases, we\nused user input (UI) tokens. Each token indicates whether\na component is user-defined (guided) or neutral (uncondi-\ntional). During training, each layout component is either\nprovided or masked with a certain probability, allowing the\nmodel to learn both conditional and unconditional scenar-\nios. This probabilistic masking is applied independently\nto each component. When a component is masked, it is\nreplaced with a \u201cblack\u201c image embedding, and its corre-\nsponding UI token is updated to signal the absence of guid-\nance:\nUI = [UIA V, UICD, UIL],\nallowing flexible control over the conditioning process. The\nfinal conditioning vector is computed as:\nc = cA V+ cCD + cL.\nwhich is fed into the transformer as part of a sequence:\n[BOC, UI, c,EOC, zt],\nwhere BOC and EOC mark the beginning and end of the\nconditioning tokens, respectively. After the transformer\nprocesses this sequence, only the image tokens are retained\nto produce zt\u22121. This design ensures that conditioning sig-\nnals guide the denoising process without remaining entan-\ngled in the final latent representation. A schematic overview\nof our architecture is provided in Figure 2. Training Objective. Following DDPM [27], we adopt a\nnoise prediction loss. Instead of directly modeling \u00b5\u03b8 and\n4\n\n\u03a3\u03b8, our model predicts the noise\u03f5 added at a randomly cho-\nsen timestep t:\nLsimple = Ez0,t,\u03f5\n\u0002\n\u2225\u03f5 \u2212 \u02c6\u03f5\u03b8(zt, t, c)\u22252\u0003\n. (3)\nMinimizing this MSE loss enables the model to accu-\nrately denoise latent representations, effectively learning to\nreverse the diffusion process. By incorporating tokens that\ndifferentiate between user-defined and neutral embeddings\nfor each layout component, the model can both generate\nanatomically guided images when specific conditions are\nprovided, and produce diverse, unconstrained samples in\nthe absence of such guidance. This flexibility ensures that\nthe model adapts seamlessly to varying levels of conditional\ninput, balancing anatomical fidelity with generative diver-\nsity. Sampling. To generate new images, we start from a ran-\ndom Gaussian latent zT \u223c N(0, I) and iteratively remove\nnoise at each diffusion step t. Our model predicts the added\nnoise \u02c6\u03f5\u03b8(zt, t, c), where c includes tokens for A V , CD, and\nL layouts. We employ classifier-free guidance [26] to control how\nclosely the model adheres to provided conditions. At each\nstep, two predictions are made: one conditional (c) and one\nunconditional (c = \u2205). These are combined as:\n\u02c6\u03f5guided\n\u03b8 (zt, t, c) = \u02c6\u03f5\u03b8(zt, t,\u2205) +w\n\u0000\n\u02c6\u03f5\u03b8(zt, t, c) \u2212 \u02c6\u03f5\u03b8(zt, t,\u2205)\n\u0001\n,\n(4)\nwhere w is a guidance scale. Higher w yields more faithful\nadherence to the conditions, lower w allows more diversity. By iteratively applying guided noise predictions until\nreaching z0, we decode z0 using the V AE to produces\na synthetic retinal fundus image.\n\n2503.00084v1\nThe transformer trains using a next-token prediction objective, where the model generates a\nsequence conditioned on the input text descriptions, captions, tags ( st), timestamps including\ntime start ( ts) and time end ( te), music structures ( s), label( l), and audio tokens ( sa), as S =\n{s1\nt , s2\nt , \u00b7\u00b7\u00b7 , sm\nt , sts, ste, ss, sl, s1\na, s2\na, \u00b7\u00b7\u00b7 , sn\na}, where T = m + n + 4. Train the AR transformer\nto effectively learn the long-term dependencies and ensures that the generated sequence adheres to\nthe intended musical genre, descriptions, timestamps, and structures. Our experiments indicate that\nthis module is capable of generating coherent musical compositions over extended durations. The\ninput dimension sizes of 0.5B and 1.5B models are 896 and 1536, respectively. The choice of Qwen 2.5 as the backbone language model is motivated by the performance, flexibility,\nand scalability of the model. Its design suits sequential generation tasks, such as music, where long-\nrange dependencies must be captured between tokens. The use of a large language model in audio\ngeneration allows InspireMusic to leverage techniques from natural language processing, enabling\nit to generate coherent, structured, and meaningful music compositions from text or audio prompts. In this work, we develop a series of models based on Qwen 2.5 with different parameter sizes. The InspireMusic-0.5B model is based on the Qwen2.5-0.5B model, whereas the more advanced\nvariants, InspireMusic-1.5B and InspireMusic-1.5B-Long, rely on the Qwen2.5-1.5B model. In-\n4\n\nWork in progress\nspireMusic has capacity to learn long-form coherence of the music and structural patterns in music\nfor music generation tasks. Classifier-free guidance (CFG) (Ho & Salimans (2021)) proves effective in improving the generation\nquality of generative models. Therefore, we adapt the CFG into the AR transformer model. During\ntraining, we randomly drop the conditions with a fixed probability of 0.7, enabling the AR model\nto learn both conditional and unconditional distributions. During inference, CFG also applies to the\noutputs of the AR model, and we recommend using a guidance scale of 3.0. During the decoding\nprocess, the top-K sampling method samples the generated tokens with the default value of 350. 3.3 S UPER -RESOLUTION FLOW-MATCHING\nIn the audio domain, super-resolution refers to the process of upscaling audio with a low sam-\npling rate to a higher sample rate while preserving information in low-frequency components and\nenhancing fine-grained details in high-frequency components. In the context of audio generation,\nthis typically means taking audio inputs sampled at a lower sampling rate (e.g., 24kHz ) and trans-\nforming them into higher-quality audio at a higher resolution (e.g.,48kHz ). Super-resolution in this\nsetting aims to enhance the perceptual quality of audio while maintaining or improving the structural\nintegrity of the original sound. We propose a Super-Resolution Flow-Matching (SRFM) model to enhance low-resolution coarse au-\ndio tokens to high-resolution fine-grained audio outputs by learning optimal transformation paths be-\ntween distributions.", "metadata": {"type": "factual", "source": "2503.01215v1.pdf", "context": "For simplicity, denotebP\u03d5( \u02c6Yi+1 = y|\u02c6Y1:i) as bP(i+1)\n\u03d5 (y). This training procedure enables the model\nto learn the single-step predictive distributions that collectively define the full sequence likelihood.\nOnce trained, given any observed datay1:t, the transformer sequence model can generate future\nsamples autoregressively: \u02c6Yt+1:\u221e \u223c bP\u03d5(\u00b7|y1:t).\nNext, we examine how these trained sequence models can be applied to decision-making, high-\nlighting the limitations of one-step inference and how m", "quality_score": 8.75}}
{"id": "test_8", "question": "What type of system was used to conduct the experiments?", "golden_answers": ["An Ubuntu 22.04.1 LTS system equipped with two 32-core Intel(R) Xeon(R) Platinum 8358 CPUs at 2.60GHz, four NVIDIA A100 Tensor Core GPUs, and 1TB of physical memory."], "prediction": "TCR-pMHC systems.", "f1": 0.0, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.00648v1\nExperimental measurements are done across three\nreplicates, and the reported GFP levels in Figs. 4, S5 for each condition are averaged over the three replicates. We\nconsider a peptide to have activated T-cells if its induced replicate-averaged GFP level met two criteria: 1) it exceeded\n0.5%, and 2) it surpassed the mean plus three standard deviations of the GFP level negative controls (no-peptide). According to these criteria, the GFP activation cutoffs were 0.5% for the NY-ESO system, 0.64% for the EBV system,\nand 0.76% for the MAGE system. VI. EXPERIMENTAL ACTIVITIES OF THE DESIGNED PEPTIDES\nComparing design success rates across the three TCR-pMHC systems. Among the designed peptides, 50%\nin the NY-ESO system (Fig. 4A), 16% in the EBV system (Fig. 4B), and 26% in the MAGE system induce significant\nT-cell activities. However, it should be noted that the designed NY-ESO peptides were closer in sequence to their\nwild-type templates (2-7 amino acid differences) than the peptides designed for the EBV (3-9 differences) or MAGE\n(3-8 differences) systems. We find that the activity of designs decays with increasing distance from the respective\nwild-type, with almost no designs beyond 5 amino-acid distance from the wild-types activating their respective T-cells\n(Fig. 4, S6, S7, S8). This underscores the difficulty of exploring peptide variants far from the wild-type sequences. If any positive designs do exist at these greater distances, they represent an exponentially smaller fraction of the\nsequence space, and when in complex with the TCR-MHC, are likely to adopt a different binding mode compared to\nthat of the wild-type. Minor adjustments to the design protocols, aimed at better exploring the design space, may have also contributed\nto the observed differences in performance across the systems. For NY-ESO, which achieved the highest design\nsuccess rate, peptides with highest PAE scores were chosen for experimental validation, whereas in EBV and MAGE,\npeptides were sampled uniformly above the set PAE thresholds. In MAGE, fixing the amino-acid at position 1 to\na Glutamic Acid (E) for the one-third of the designs led to an elevated success rate in this subset (Fig. S8D); E 1 is\nshared between the two wild-type peptides and this design choice allowed us to assess the importance of this amino\nacid for function. The design potential of different HERMES models. In panel A of Figures S6 (NY-ESO), S7 (EBV),\nand S8 (MAGE), we show the fidelity of designs using the four HERMES models: HERMES- fixed with no noise,\nHERMES-fixed with 0.5 \u02daA noise, HERMES-relaxed with no noise, and HERMES- relaxed with 0.5 \u02daA noise. Although\nPyRosetta relaxations allows HERMES- relaxed to explore the sequence space more broadly, the resulting designs\nthat are made at greater distances from the wild-types seldom succeed in activating T-cells. This pattern is also\nobserved with using models trained with 0.5 \u02daA Gaussian noise. Indeed, successful designs lie within five amino acid\nsubstitutions from the wild-types, and for these designs, the un-noised HERMES-fixed model demonstrates the highest\noverall fidelity.\n\n2503.00077v1\nNotably, in 40 studies (36%), the purpose of CC\nidentification or generation was not explicitly stated, thus they\nwere excluded from this analysis. 1) Testing and Validation: CCs are extensively utilized to\ntest and validate ADS, helping to assess their performance,\nsafety, and robustness in rare and critical scenarios. The\nprimary objective is to assess how well an ADS handles rare\nand critical scenarios, evaluating if it meets safety expectations\nbefore deployment. Many studies highlight the use of CCs to\nvalidate ADS performance under extreme conditions, bench-\nmarking against regulatory and safety requirements [36], [38],\n[65], [67], [68], [70], [71], [79], [81], [87], [92], [96], [101],\n[106], [113], [117]\u2013[119], [121], [125], [127]\u2013[132], [136],\n[138], [140], [150], [154], [157]\u2013[161], [164], [165], [167],\n[169]. By simulating these scenarios, researchers can measure\nthe effectiveness of the system, identify performance limita-\ntions, and refine models accordingly. Comprehensive testing\nframeworks based on CCs have been shown to help identify\nweaknesses and support the effective operation of ADS in\ndiverse environments, potentially accelerating the develop-\nment process [113], [154], [158]. Additionally, these testing\nmethods contribute to maintaining critical safety standards\nthroughout the system\u2019s lifecycle in its operational design\ndomain. 2) Training and Optimization: The generation and iden-\ntification of CCs also serve as a foundation for improving\nthe learning process and optimization of A V systems. Studies\nfocus on using CCs to enhance the training datasets for model\ncontrol development [86], [105], [107], [142], [144] aiming to\nimprove A V control and safety. For instance, algorithms that\nfine-tuning with rare scenarios seek to enhance the system\u2019s\nability to handle unforeseen situations effectively [88], [122]. Training with enriched pedestrian datasets, for example, can\ndirectly improve detection and control algorithms, which in\nturn supports the development of more robust and adaptive\nADS policies capable of efficiently responding to critical\nscenarios [142], [145]. 3) Dataset Generation and Augmentation: Another sig-\nnificant application of CCs is in generating diverse and\ncomprehensive datasets. Some studies highlight how CCs\nenrich datasets to capture rare, critical, or unexpected sce-\nnarios, which are often underrepresented in standard datasets\n[74], [102], [135], [151]. This enrichment is essential for\nbenchmarking, developing test cases, and improving ADS\nalgorithms. For example, synthetic data generated from CCs\ncan effectively reduce the cost and time associated with\nacquiring real-world data, while ensuring extensive coverage\nof challenging scenarios [91]. Furthermore, the importance of\naugmenting datasets to improve simulation-based evaluation\nframeworks is emphasized, as it plays a key role in enabling\nA V systems to adequately address the variability and complex-\nity inherent in real-world environments [76], [98], [166]. 4) Safety Assessment and Standardization: CCs are instru-\nmental in assessing the safety of A V systems and defining\nstandards for their performance. [85], [126], [155] illustrate\nhow CCs can be used to evaluate compliance with safety\nbenchmarks and regulatory requirements. For instance, [100]\ndiscusses leveraging CCs to supplement existing testing frame-\nworks and establish test schemes that ensure A Vs meet strin-\ngent safety criteria. This category underscores the critical role\nof CCs in fostering public trust and regulatory acceptance of\nautonomous technologies.\n\n2503.00946v1\nAdditionally, multi-condition experiments may investigate the impact of different configurations\nor modules within the proposed system. For example, researchers may compare the performance\nof their fully-featured tool against a version with only a subset of its modules or functionalities,\nshedding light on the contribution of specific components to the overall ideation process. Within the multi-condition experiments, 15 papers (77%) employed a within-subjects design, where\neach participant experienced all the conditions being investigated. This design allows for direct\ncomparisons of user experiences and reduces the impact of individual differences on the results. Conversely, 8 papers (19%) utilized a between-subjects design, assigning each participant to only\none of the conditions. This approach minimizes potential carry-over effects and learning biases\nthat may arise from exposure to multiple conditions. Only 2 papers (4%) adopted a mixed-factorial\ndesign, combining elements of both within-subjects and between-subjects designs to investigate the\ninteractions between different factors. To control for potential order effects in within-subjects and mixed-factorial designs, researchers em-\nployed various counterbalancing techniques. Two papers (5%) used random counterbalancing, where\nthe order of conditions was randomized for each participant. This approach helps to distribute any\norder effects evenly across the conditions. Six papers (14%) utilized complete counterbalancing de-\nsigns, ensuring that all possible order permutations were equally represented in the study. Two\n\n31\npaper (5%) employed a Latin square design, a systematic method for assigning participants to differ-\nent condition sequences. The choice of experiment design and counterbalancing techniques reflects the researchers\u2019 efforts\nto minimize confounding factors and enhance the internal validity of their studies. By carefully\nconsidering these methodological aspects, the reviewed papers aim to provide robust and reliable\nfindings that contribute to the understanding of LLM-assisted ideation from a user perspective. 6.2 Qualitative Analysis\nAmong the 43 papers that conducted user studies, 34 (79%) employed qualitative analysis methods\nto gain in-depth insights into user experiences, perceptions, and behaviors related to LLM-assisted\nideation. As shown in table 9, the qualitative methods used in these studies can be broadly cate-\ngorized into five types: interview-based methods, observation-based methods, log-based methods,\nsurvey-based methods, and other methods. Table 9. Qualitative Analysis\nQualitative Method Qualitative Form Qualitative Data Analysis Ref. inductive\n[82], [86], [60], [89],\n[77], [61], [49], [53],\n[46], [48], [43], [45],\n[66], [67], [68], [57],\n[58], [65], [63], [59]Interview-based Methods\nsemi-structured interview\ninductive & deductive [55], [44]\ngrounded theory [47]\nunstructured Interview inductive [73]\nsimulated Interview inductive [34]\ninductive [89], [58]observation inductive & deductive [44]\nObservation-based Methods think-aloud inductive [60], [39], [49], [45],\n[67], [65]\ninductive [60], [42], [49]screen recordings grounded theory [47]\nsystem log inductive [73], [66], [67]\nLog-based Methods prompts log inductive [94]\nchat log grounded theory [36]\n- [79]\nSurvey-based Methods survey inductive [94], [82], [88], [76],\n[86]\nautoethnography inductive [50]Other Methods case study method - [75]\nInterview-based methods (25 out of 34, or 74%) were the most commonly employed, with semi-\nstructured interviews being the predominant form. Semi-structured interviews allow researchers to\nexplore specific topics of interest while providing flexibility for participants to share their thoughts\nand experiences.", "metadata": {"type": "factual", "source": "2503.01319v1.pdf", "context": "4 Experiment setup\nTo verify the testing effectiveness of ABFS on LLM-based NLP software, we conducted\na series of experiments on three text classification datasets and five threat models.\nAll experiments were performed on an Ubuntu 22.04.1 LTS system equipped with\ntwo 32-core Intel(R) Xeon(R) Platinum 8358 CPUs at 2.60GHz, four NVIDIA A100\nTensor Core GPUs, and 1TB of physical memory. Each experiment was repeated three\ntimes, and the results for each metric were averaged. Similar to previous st", "quality_score": 8.75}}
{"id": "test_9", "question": "What is a limitation of conventional image classification models in soybean leaf disease detection?", "golden_answers": ["Conventional models offer limited explainability, providing little insight into which leaf regions drive predictions and reducing interpretability and trust among agricultural experts."], "prediction": "Conventional image classification models in soybean leaf disease detection often overlook critical relational information between images, leading to misclassifications, especially when diseases present visually similar symptoms triggered by different factors. Additionally, they offer limited explainability, providing little insight into which leaf regions drive predictions, reducing interpretability and trust among agricultural experts.", "f1": 0.5753424657534247, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01284v2\nNumerous studies have highlighted their effectiveness in soybean leaf disease\nclassification (Chen et al, 2020; Sethy et al, 2020; Dou et al, 2023; Sheng et al,\n2024; Bera et al, 2024; Rahman et al, 2024; Janarthan et al, 2024; Wang et al,\n2025; Wu et al, 2024). However, most existing approaches \u2014 whether CNNs or\ntransfer learning techniques are used (Karlekar and Seal, 2020; Wu et al, 2023)\n\u2014 focus on extracting features from individual images, overlooking critical\nrelational information between images. This becomes particularly problematic\nwhen diseases present visually similar symptoms triggered by different fac-\ntors, such as nutrient deficiencies, pest damage, or environmental stress, often\n\nSoybean Disease Detection via Interpretable Hybrid CNN-GNN 3\nleading to misclassifications. Moreover, these conventional models offer limited\nexplainability, providing little insight into which leaf regions drive predictions\nand reducing interpretability and trust among agricultural experts. To address these limitations, graph neural networks (GNNs) have emerged\nas a complementary approach capable of modeling relational dependencies\nbetween samples. GNNs are particularly well suited for cases where relation-\nships between images, such as symptom similarity or shared environmental\nconditions, provide valuable diagnostic cues (T. Senthil Prakash and Kiran,\n2023; Li, 2024). By treating images as nodes and defining edges on the basis\nof pairwise similarities, GNNs aggregate information from neighboring images,\nenabling context-aware classification incorporating local features and global\nrelational patterns. However, GNNs alone lack the ability to extract fine-\ngrained spatial features directly from raw images \u2014 a key strength of CNNs. Therefore, combining CNNs and GNNs into a hybrid framework offers a syn-\nergistic advantage: CNNs capture localized spatial features within individual\nimages, whereas GNNs enrich these representations with relational context\nacross images. This hybrid approach is particularly valuable for soybean leaf\ndisease classification, where local lesion characteristics and broader symptom\nsimilarity across fields, varieties, and conditions are essential for accurate and\ninterpretable diagnosis. To address these gaps, we propose an interpretable hybrid sequential CNN-\nGNN architecture that sequentially combines MobileNetV2 for efficient spatial\nfeature extraction and graph sample and aggregation (GraphSAGE), a GNN\narchitecture, for relational dependency modeling between soybean leaf images. By constructing a similarity graph where nodes represent leaf images and\nedges encode pairwise feature similarity, GraphSage (Hamilton et al, 2017a)\naggregates information from neighboring nodes, enriching the feature rep-\nresentations with a relational context. This fusion of local spatial learning\nand global relational learning enhances classification accuracy while ensur-\ning computational efficiency, making the model suitable for real-time field\ndeployment. Additionally, we incorporate Grad-CAM and Eigen-CAM visu-\nalizations to provide interpretable heatmaps that highlight the specific leaf\nregions influencing each classification decision, bridging the gap between model\npredictions and expert validation. To the best of our knowledge, this is the\nfirst interpretable CNN-GNN hybrid framework applied to soybean leaf disease\ndetection, addressing critical gaps in relational modeling, model transparency,\nand computational efficiency in plant disease classification research. We make the following key contributions in this work:\n1.\n\n2503.01284v3\nNumerous studies have high-\nlighted their effectiveness in soybean leaf disease classifica-\ntion [1]\u2013[9]. However, most existing approaches \u2014 whether\nCNNs or transfer learning techniques are used [10], [11]\n\u2014 focus on extracting features from individual images,\noverlooking critical relational information between images. This becomes particularly problematic when diseases present\nvisually similar symptoms triggered by different factors,\nsuch as nutrient deficiencies, pest damage, or environmental\nstress, often leading to misclassifications. Moreover, these\nconventional models offer limited explainability, providing\nlittle insight into which leaf regions drive predictions and\nreducing interpretability and trust among agricultural experts. To address these limitations, graph neural networks\n(GNNs) have emerged as a complementary approach capa-\nble of modeling relational dependencies between samples. GNNs are particularly well suited for cases where rela-\ntionships between images, such as symptom similarity or\nshared environmental conditions, provide valuable diagnostic\ncues [12], [13]. By treating images as nodes and defining\nedges on the basis of pairwise similarities, GNNs aggre-\ngate information from neighboring images, enabling context-\naware classification incorporating local features and global\nrelational patterns. However, GNNs alone lack the ability\nto extract fine-grained spatial features directly from raw\nimages \u2014 a key strength of CNNs. Therefore, combining\nCNNs and GNNs into a hybrid framework offers a synergistic\nadvantage: CNNs capture localized spatial features within\nindividual images, whereas GNNs enrich these represen-\ntations with relational context across images. This hybrid\napproach is particularly valuable for soybean leaf disease\nclassification, where local lesion characteristics and broader\nsymptom similarity across fields, varieties, and conditions are\nessential for accurate and interpretable diagnosis. To address these gaps, we propose an interpretable hybrid\nsequential CNN-GNN architecture that sequentially com-\nbines MobileNetV2 for efficient spatial feature extraction and\ngraph sample and aggregation (GraphSAGE), a GNN archi-\ntecture, for relational dependency modeling between soybean\nleaf images. By constructing a similarity graph where nodes\nrepresent leaf images and edges encode pairwise feature sim-\nilarity, GraphSage [14] aggregates information from neigh-\nboring nodes, enriching the feature representations with a\nrelational context. This fusion of local spatial learning and\nglobal relational learning enhances classification accuracy\nwhile ensuring computational efficiency, making the model\nsuitable for real-time field deployment. Additionally, we\nincorporate Grad-CAM and Eigen-CAM visualizations to\nprovide interpretable heatmaps that highlight the specific leaf\nregions influencing each classification decision, bridging the\ngap between model predictions and expert validation. To the\nbest of our knowledge, this is the first interpretable CNN-\nGNN hybrid framework applied to soybean leaf disease de-\ntection, addressing critical gaps in relational modeling, model\ntransparency, and computational efficiency in plant disease\nclassification research. We make the following key contributions in this work:\n1) Sequential CNN-GNN Architecture:We propose a\nnovel pipeline combining a pretrained MobileNetV2\nfor local feature extraction and a GraphSAGE model\nfor global relational reasoning, enhancing our model\u2019s\nability to capture fine-grained disease symptoms and\ninter-symptom dependencies.\n\n2503.01284v3\n[21], and plant disease detection [12], [13],\nwhere capturing both local and global structural dependen-\ncies enhances classification accuracy. Hybrid CNN-GNN architectures have emerged as promis-\ning solutions to combine the strengths of spatial feature\nextraction and relational modeling. Thangamariappan et al. [22] demonstrated that integrating CNN-extracted spatial\nfeatures with GNN-derived relational embeddings improves\nclassification for structured images. Similarly, Nikolentzos\net al. [23] proposed converting images into graphs, where\nnodes represent pixels or segments and edges capture spatial\nor semantic proximity, enabling explicit relational modeling. Hua and Li [24] applied a multiscale attention-enhanced\nCNN-GNN framework to remote sensing change detection,\nwhich demonstrated improved spatial coherence and detec-\ntion accuracy. Tang et al. [25] further optimized graph con-\nstruction to reduce computational overhead while preserving\nclassification performance. While these studies highlight the\npotential of CNN-GNN hybrids, they focus largely on struc-\ntured imagery, leaving agricultural disease classification,\nwhere symptoms are often subtle, variable, and environment-\ndependent, relatively underexplored. In the domain of soybean leaf disease detection, current\nresearch has focused largely on standalone CNN models and\ntransfer learning techniques, with limited attention given to\nrelational modeling. Existing studies [10], [11] primarily em-\nploy deep CNN architectures trained directly on leaf images,\nwhich achieve reasonable accuracy but lack mechanisms to\ncapture inter-image relationships that could improve robust-\nness, especially in cases where different diseases present\nvisually similar symptoms. Furthermore, most existing meth-\nods lack interpretability, providing little insight into the spe-\ncific features or regions driving predictions, which reduces\nconfidence and usability for domain experts such as plant\npathologists and agronomists.\nIII. METHODOLOGY This section outlines the methodology used in this work\nfor classifying soybean leaf diseases via a sequential CNN-\nGNN model. The overall pipeline, consisting of data pre-\nprocessing, augmentation, and model development used in\nthis study, is illustrated in Figure 1. The pipeline consists\nof several key steps, including image acquisition, resizing,\npixel normalization, augmentation, dataset splitting, and one-\nhot encoding, ensuring a standardized dataset for training\nand evaluation. During model development, images are first\npassed through a MobileNetV2 architecture to extract local\nfeatures. These features are then structured into a graph, with\nedges representing the relationships between image features\nwithin the data. Finally, the aggregated features are fed into\na classifier to predict soybean leaf diseases. This integrated\napproach ensures local feature extraction and global depen-\ndency modeling, leveraging the strengths of both the CNN\nand GNN architectures for improved disease classification. A. MODEL FRAMEWORK AND ARCHITECTURE The proposed Sequential CNN-GNN model combines a\nCNN for extracting local features from images and a GNN\nfor capturing the relationships between these features. The\nmodel is designed sequentially: the CNN first extracts de-\ntailed local features, and then the GNN processes these\nfeatures to understand global dependencies, enhancing clas-\nsification accuracy. The model begins by taking an input image I \u2208\nRH\u00d7W\u00d7C, where H, W, and C represent the height, width,\nand number of channels (3 for RGB), respectively. The\ninput image is first passed through the MobileNetV2 CNN,\nwhich is known for its efficiency and low computational\ncost.", "metadata": {"type": "factual", "source": "2503.01284v3.pdf", "context": "Jahin et al.: Soybean Disease Detection via Interpretable Hybrid CNN-GNN\nmance in image classification tasks by automatically learn-\ning spatial features from raw images, eliminating the need\nfor manual feature extraction. Numerous studies have high-\nlighted their effectiveness in soybean leaf disease classifica-\ntion [1]\u2013[9]. However, most existing approaches \u2014 whether\nCNNs or transfer learning techniques are used [10], [11]\n\u2014 focus on extracting features from individual images,\noverlooking cri", "quality_score": 8.5}}
{"id": "test_10", "question": "What is the role of the exchange tensor in model (1)?", "golden_answers": ["The exchange tensor, denoted as Jabij, couples the spins at sites a, i and b, j."], "prediction": "The exchange tensor in model (1) is used to evaluate the contributions of the \u03b4(r) term and to project the potentials into certain partial waves by sandwiching the spin operators in the potentials between the partial waves of the initial and final states.", "f1": 0.12500000000000003, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01322v1\nIn the phenomenological view, the \u03b4(r)\nterm can mimic the role of contact interaction [81], which is\nalso related to the regularization scheme [71]. In Refs. [15,\n101], after removing the \u03b4(r) term, the hadronic molecular\npicture for some observed hidden-charm states is discussed\nwith the one-pion-exchange potential, which is assumed to be\nof long-range. In this work, we will separately analyze the\npoles in the system with or without the \u03b4(r) term. For this\npurpose, we introduce a parameter a to distinguish these two\ncase,\nA \u00b7qB \u00b7q\nq2 + \u00b52ex\n\u2212a\n3A \u00b7B = 1\n3\n(\nA \u00b7B\n \n1 \u2212a \u2212 \u00b52\nex\nq2 + \u00b52ex\n! \u2212S (A,B,\u02c6q) |q|2\nq2 + \u00b52ex\n)\n. (14) After performing the Fourier transformation of Eq. (14), we\nhave\nZ d3q\n(2\u03c0)3\n A \u00b7qB \u00b7q\nq2 + \u00b52ex\n\u2212a\n3A \u00b7B\n! \u02dc\u039b2 \u2212\u00b52\nex\nq2 + \u02dc\u039b2\n! 2\neiq\u00b7r\n= \u22121\n3[A \u00b7BCex + S (A,B,\u02c6r)Tex], (15)\nwhere S (A,B,\u02c6r) = 3A \u00b7\u02c6rB \u00b7\u02c6r \u2212A \u00b7B is the tensor operator\nin coordinate space, and the functions Cex and Tex read\nCex = 1\nr2\n\u2202 \u2202r r2 \u2202\n\u2202r Yex + a\n(2\u03c0)3\nZ  \u02dc\u039b2 \u2212\u00b52\nex\nq2 + \u02dc\u039b2\n! 2\neiq\u00b7rd3q, (16)\nTex = r \u2202\n\u2202r\n1\nr\n\u2202\n\u2202r Yex. (17)\nApparently, the contribution of the \u03b4(r) term is fully included\n(excluded) when a = 0(1) [81, 86]. Similarly, the Fourier\ntransformation of the function (A\u00d7q) \u00b7(B \u00d7q)/(q2 +\u00b52\nex) can\nbe evaluated with the help of the relation (A \u00d7q) \u00b7(B \u00d7q) =\nA \u00b7B|q|2 \u2212A \u00b7qB \u00b7q.\nWith the prescription above, the coordinate space represen-\ntations of the potentials in Eqs. (24) can be written in terms of\nYex, Cex and Tex given in Eqs. (12) and (15). The potentials\nshould be projected into certain partial waves by sandwiching\nthe spin operators in the potentials between the partial waves\nof the initial and final states. We refer to Refs. [80, 81] for\ncomputing the partial wave projections. In this work, we fo-\ncus on the positive parity states which are possibly bound in\nS-wave and more easily form the molecular states respect to\nnegative ones. The partial waves corresponding to the spin-\nparities of JP = 0+,1+,2+ are shown in Table I.\nIn our numerical calculation, the masses of exchanged par-\n\n4\nTABLE I. Partial waves in the givenJP. P\u00afP P \u00afP\u2217/P\u2217\u00afP P \u2217\u00afP\u2217\nJp = 0+ 1S 0 - 1S 0,5D0 Jp = 1+ - 3S 1,3D1 3S 1,3D1,5D1\nJp = 2+ 1D2 3D2 5S 2,1D2,3D2,5D2\nticles are taken as m\u03c3 = 600.0 MeV , m\u03c0 = 138.0 MeV ,\nm\u03b7 = 547.9 MeV ,m\u03c1 = 770.7 MeV and m\u03c9 = 782.0 MeV . The coupling constants in the Lagrangian can be extracted\nfrom experimental data or deduced from various theoretical\nmodels. Here we adopt the values given in Refs.\n\n2503.00443v1\nPerturbing the effective potential \ud835\udc49eff leads\nto a much more balanced distribution of \ud835\udc47S around the value at the ground state \ud835\udc47gs\nS . 7\n\nRepresentation and Architecture\nA compact representation of electron density \ud835\udf0ccan be obtained in terms of a linear combination of\natom-centered basis functions {\ud835\udf14\ud835\udf07}[14],\n\ud835\udf0c(r)=\n\u2211\ufe01\n\ud835\udf07\n\ud835\udc5d\ud835\udf07\ud835\udf14\ud835\udf07(r). (2)\nWe use an even-tempered Gaussian basis {\ud835\udf14\ud835\udf07}[26]. While this representation does not guarantee\npositivity, regions of unphysical negative densities are no failure case that we encounter in practice,\nsee fig. S.2. The presently most successful class of architectures in molecular machine learning are atomistic\nmessage passing graph neural networks [27]. These iteratively exchange messages between atoms,\nalong edges which are typically not defined by chemical bonds but rather by some distance cutoff\nor even by a fully connected graph. As desired, atomistic message passing predictions of molecular\nproperties are invariant to the (mostly arbitrary) order in which the constituent atoms are presented. Similarly, as physical quantities transform equivariantly when the entire system is translated or\nrotated, so should the predictions. Scalar quantities, such as the energy, should be \ud835\udc38(3)-invariant. This equivariance with respect to rigid motions is commonly accomplished either by relying\non the tensor product [28] as basic bilinear operation, or by \u201clocal canonicalization\u201d [29, 30, 19]. The latter finds local coordinate systems, equivariant \u201clocal frames,\u201d for each atom based on its few\nnearest neighbors. Having experimented extensively with either class of architecture (e.g. [31, 32, 33]), we\nobtain broadly comparable results with representatives of both; but we currently find the best\ncost/performance tradeoff with a Graphormer [33, 34] type architecture. The latter profits from a\nself-attention mechanism, but is limited by the fact that it can only send scalar messages between\nnodes. In response, we invoke the formalism recently proposed in [19] to generalize the architecture\nto allow sending tensorial messages between nodes. The input to our model consists of the density coefficientsp from Eq. 2 as well as the molecular\ngeometry Mgiven by atom positions{R\ud835\udc4e}and types {\ud835\udc4d\ud835\udc4e}. The model predicts the energy\ud835\udc38while\nits gradient \u2207p\ud835\udc38 is computed variationally using automated differentiation. The atomic basis functions {\ud835\udf14\ud835\udf07}overlap and so the density coefficients are not independent. We follow [13] in first transforming the coefficients into an orthonormal basis by means of a global\n\u201cnatural reparametrization\u201d and then subjecting coefficients and energy gradients to dimension-wise\nrescaling and atomic reference modules, see [13] for details. Importantly, for larger molecules, we use a distance cutoff in the definition of atomic adjacency,\nmaking for a message passing mechanism that scales gracefully with system size. For detailed\nmodel specifications, see materials and methods. 8\n\nOrbital-free DFT: A new status quo\nBuilding on a compact representation of the electron density (Eq. 2, [14]), state-of-the-art machine\nlearning architectures [33, 19], automated differentiation [35], efficient training data generation and\nreparametrization [13] and a strategy to create more balanced training samples [12], orbital-free\nDFT is finally starting to fulfill the promise that was implicit in the Hohenberg-Kohn theorems. We concentrate here on organic molecules with a mass of up to a few hundred Dalton.\n\nStable and Accurate Orbital-Free DFT Powered by Machine Learning\nHowever, accurately representing these small gradients\nproved challenging in practice. Table S.9 summarizes the results of training with each target. The \ud835\udc47\ud835\udc46 \u2212APBEK target, while\nviable, exhibits higher energy and density errors compared to the \ud835\udc38TXC target. Furthermore, \ud835\udc47\ud835\udc46 \u2212\nAPBEK requires numerical integration on a grid for the evaluation of the APBEK functional and\nan XC functional, increasing the computational cost. Models trained on \ud835\udc38tot fail to converge to\nmeaningful densities, highlighting the difficulty of directly learning the total energy. The superior\nperformance and grid-free nature of \ud835\udc38TXC made it our target of choice. Tensorial vs. scalar messages: We explore the impact of \u201ctensorial\u201d messages [31] in equivariant\nmessage passing based on local canonicalization, which allow the communication of non-scalar\ngeometric information between nodes. We evaluate the performance of the standard Graphormer,\nwhich uses only scalar messages, against our modified version incorporating tensorial messages,\nas described in section S.2. Table S.1 shows results for the QM9 dataset. The additional geometric information improves\nthe model, with the energy error improving slightly and the density error significantly. Networks\ntrained with tensorial messages also showed lower gradient loss during training. S23\n\nNumber of Graphormer layers: The depth of the network, represented by the number of\nGraphormer layers, influences both the model\u2019s capacity and its computational cost. We inves-\ntigated the effect of varying the number of layers, with results presented in Table S.10. Performance\ninitially improves as the number of layers increases, allowing the model to capture more complex\nrelationships. However, when no cutoff is used, we observe a significant degradation in performance\nbeyond 4 layers, likely due to higher instability of the gradient produced by the network. This led\nus to select 4 layers as the optimal balance between expressivity and training stability for QM9, and\n8 layers for QMugs. Table S.10: Ablation of the number of Graphormer layers in the neural network on QM9.For\nthese experiments only a single seed was used. #Layers #Parameters |\u0394\ud835\udc38| | \u0394\ud835\udc38|/\ud835\udc41\ud835\udc34 \u2225\u0394\ud835\udf0c\u22252 \u2225\u0394\ud835\udf0c\u22252/\ud835\udc41\ud835\udc52\n(106) (mHa) (mHa) (10 \u22124)\n1 8.1 1.22 0.074 0.025 3.8\n2 11.6 0.75 0.044 0.017 2.6\n3 15.1 0.92 0.053 0.015 2.3\n4 18.7 0.64 0.038 0.014 2.1\n6 25.8 439.29 19.871 0.198 29.4\n8 32.9 322.92 14.214 0.097 14.4\nFully connected vs. radial cutoff: The Graphormer architecture [45] was originally designed for\nfully connected graphs. However, for scalability to larger systems, incorporating a radial cutoff is\nessential. In Table S.11 we show that introducing a cutoff not only lowers computational cost but\nalso yields smaller prediction errors. Table S.11: Comparison of using a local vs. fully-connected graph on the QMugs dataset.The\nexperiment was done after training on the mixed dataset of QM9 and QMugs molecules, without\nfurther fine-tuning. local |\u0394\ud835\udc38| |\u0394\ud835\udc38|/\ud835\udc41\ud835\udc34 \u2225\u0394\ud835\udf0c\u22252 \u2225\u0394\ud835\udf0c\u22252/\ud835\udc41\ud835\udc52\n(mHa) (mHa) (10 \u22124)\n\u2713 26 0.25 0.071 1.7\n\u00d7 580 8.80 0.195 7.3\nS24\n\nS.11 Runtime comparison of KS-DFT and OF-DFT computations\nFigure S.8 compares the runtimes of OF-DFT as embodied by STRUCTURES25 and KS-DFT as\nimplemented in GPU4PySCF [89, 90], which can exploit the parallelism of the identical hardware.", "metadata": {"type": "factual", "source": "2503.01283v2.pdf", "context": "2\nX\nabij\nST\naiJabijSbj, (1)\nwhere Sai is the spin operator for site a in unit cell i\nand Jabij is the exchange tensor that couples the spins\nat sites a, iand b, j. Single-ion anisotropy terms are in-\ncluded through the onsite components J aaii of the ex-\nchange tensor. In order to calculate the thermal prop-\nerties of the model (1) one needs the magnetic excita-\ntion spectrum, which requires one to determine the mag-\nnetic ground state. Except for simple ferromagnets, the\nground state of the mod", "quality_score": 8.5}}
{"id": "test_11", "question": "Why is it necessary to determine the magnetic ground state of model (1) in order to calculate its thermal properties?", "golden_answers": ["The magnetic excitation spectrum is required to calculate the thermal properties, and this requires determining the magnetic ground state."], "prediction": "It is necessary to determine the magnetic ground state of model (1) in order to calculate its thermal properties because the magnetic excitation spectrum, which is essential for understanding thermal behavior, depends on the configuration that minimizes the classical energy of the system.", "f1": 0.4074074074074074, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01283v2\nIn Sec. II A, we\nbriefly discuss the Heisenberg model and single- Q spiral\nground states. We then introduce the methodologies for\ncalculating thermal properties of spin spiral structures\nusing renormalized HP bosononization (Sec. II B), the\nGreen\u2019s function method in (Sec. II C) and the Mean\nField approximation (Sec. II D). In Sec. III, we bench-\nmark the methods against the experimental results for a\nrange of real materials.\nII. THEORY\nA. Spiral ground states\nOur starting point is the generalized Heisenberg Hamil-\ntonian\nH = \u22121\n2\nX\nabij\nST\naiJabijSbj, (1)\nwhere Sai is the spin operator for site a in unit cell i\nand Jabij is the exchange tensor that couples the spins\nat sites a, iand b, j. Single-ion anisotropy terms are in-\ncluded through the onsite components J aaii of the ex-\nchange tensor. In order to calculate the thermal prop-\nerties of the model (1) one needs the magnetic excita-\ntion spectrum, which requires one to determine the mag-\nnetic ground state. Except for simple ferromagnets, the\nground state of the model is non-trivial and the starting\npoint will thus be the spin configuration that minimizes\nthe classical energy. For an isotropic model on a Bravais\nlattice, the minimizing spin configuration can be deter-\nmined using the Luttinger-Tisza (LT) method [21] and\n\n3\nthe result is known to be a coplanar spin spiral charac-\nterized by a magnetic ordering vector Q [13]. The result\ncan be generalized to include antisymmetric exchange,\nwhich then determines the orientation of the spiral plane\n[22]. The LT method has also been generalized to non-\nBravais lattices [23, 24] and under rather general circum-\nstances (but not always) the classical ground state for an\nisotropic model remains a planar spin spiral given by\nSai = Sa\n\uf8ee\n\uf8f0\n0\nsin(Q \u00b7 ri + \u03d5a)\ncos(Q \u00b7 ri + \u03d5a)\n\uf8f9\n\uf8fb, (2)\nwhere Q is the magnetic ordering vector, \u03d5a is the phase\nangle of the spin at sitea, ri is a lattice vector for unit cell\ni, and Sa is the maximal eigenvalue ofSz\na (the magnitude\nof the classical spin vector). We note that the assumption\nof an isotropic model implies that any orientation of the\nspiral plane yields the same ground state energy and we\nhave chosen the yz-plane here to be specific. Such a\nmagnetic structure is often referred as a single- Q spin\nspiral and is derived from the model in appendix A. The\ndiscussion in the remainder of this work will focus solely\non single-Q spin spirals. When considering excitations of spiral ground states\nit will be convenient to transform the system to a local\ncoordinate system where all spin fluctuations are perpen-\ndicular to the localz-axis. Here we reiterate the approach\nof Ref. 12 regarding this transformation, which will be\nneeded for reference below. We can write the spin opera-\ntors in terms of a cell-dependent rotation matrix Ri such\nthat\nSai = RiS\u2032\nai, (3)\nRi = R\u02c6 n(Q \u00b7 ri), (4)\nwhere \u02c6 nis the global rotation axis.\n\n2503.01283v1\nIn Sec. II A, we\nbriefly discuss the Heisenberg model and single- Q spiral\nground states. We then introduce the methodologies for\ncalculating thermal properties of spin spiral structures\nusing renormalized HP bosononization (Sec. II B), the\nGreen\u2019s function method in (Sec. II C) and the Mean\nField approximation (Sec. II D). In Sec. III, we bench-\nmark the methods against the experimental results for a\nrange of real materials.\nII. THEORY\nA. Spiral ground states\nOur starting point is the generalized Heisenberg Hamil-\ntonian\nH = \u22121\n2\nX\nabij\nST\naiJabijSbj, (1)\nwhere Sai is the spin operator for site a in unit cell i\nand Jabij is the exchange tensor that couples the spins\nat sites a, iand b, j. Single-ion anisotropy terms are in-\ncluded through the onsite components J aaii of the ex-\nchange tensor. In order to calculate the thermal prop-\nerties of the model (1) one needs the magnetic excita-\ntion spectrum, which requires one to determine the mag-\nnetic ground state. Except for simple ferromagnets, the\nground state of the model is non-trivial and the starting\npoint will thus be the spin configuration that minimizes\nthe classical energy. For an isotropic model on a Bravais\nlattice, the minimizing spin configuration can be deter-\nmined using the Luttinger-Tisza (LT) method [20] and\n\n3\nthe result is known to be a coplanar spin spiral charac-\nterized by a magnetic ordering vector Q [13]. The result\ncan be generalized to include antisymmetric exchange,\nwhich then determines the orientation of the spiral plane\n[21]. The LT method has also been generalized to non-\nBravais lattices [22, 23] and under rather general circum-\nstances (but not always) the classical ground state for an\nisotropic model remains a planar spin spiral given by\nSai = Sa\n\uf8ee\n\uf8f0\n0\nsin(Q \u00b7 ri + \u03d5a)\ncos(Q \u00b7 ri + \u03d5a)\n\uf8f9\n\uf8fb, (2)\nwhere Q is the magnetic ordering vector, \u03d5a is the phase\nangle of the spin at sitea, ri is a lattice vector for unit cell\ni, and Sa is the maximal eigenvalue ofSz\na (the magnitude\nof the classical spin vector). We note that the assumption\nof an isotropic model implies that any orientation of the\nspiral plane yields the same ground state energy and we\nhave chosen the yz-plane here to be specific. Such a\nmagnetic structure is often referred as a single- Q spin\nspiral and is derived from the model in appendix A. The\ndiscussion in the remainder of this work will focus solely\non single-Q spin spirals. When considering excitations of spiral ground states\nit will be convenient to transform the system to a local\ncoordinate system where all spin fluctuations are perpen-\ndicular to the localz-axis. Here we reiterate the approach\nof Ref. 12 regarding this transformation, which will be\nneeded for reference below. We can write the spin opera-\ntors in terms of a cell-dependent rotation matrix Ri such\nthat\nSai = RiS\u2032\nai, (3)\nRi = R\u02c6 n(Q \u00b7 ri), (4)\nwhere \u02c6 nis the global rotation axis.\n\n2503.01283v3\nWe then introduce the methodologies for\ncalculating thermal properties of spin spiral structures\nusing renormalized HP bosononization (Sec. II B), the\nGreen\u2019s function method Sec. II C) and the Mean Field\napproximation (Sec. II D). In Sec. III, we benchmark the\nmethods against the experimental results for a range of\nreal materials.\nII. THEORY\nA. Spiral ground states\nOur starting point is the generalized Heisenberg Hamil-\ntonian\nH = \u22121\n2\nX\nabij\nST\naiJabijSbj, (1)\nwhere Sai is the spin operator for site a in unit cell i\nand Jabij is the exchange tensor that couples the spins\nat sites a, iand b, j. Single-ion anisotropy terms are in-\ncluded through the onsite components J aaii of the ex-\nchange tensor. In order to calculate the thermal prop-\nerties of the model (1) one needs the magnetic excita-\ntion spectrum, which requires one to determine the mag-\nnetic ground state. Except for simple ferromagnets, the\nground state of the model is non-trivial and the starting\npoint will thus be the spin configuration that minimizes\nthe classical energy. For an isotropic model on a Bravais\nlattice, the minimizing spin configuration can be deter-\nmined using the Luttinger-Tisza (LT) method [21] and\nthe result is known to be a coplanar spin spiral charac-\nterized by a magnetic ordering vector Q [13]. The result\ncan be generalized to include antisymmetric exchange,\nwhich then determines the orientation of the spiral plane\n[22]. The LT method has also been generalized to non-\n\n3\nBravais lattices [23, 24] and under rather general circum-\nstances (but not always) the classical ground state for an\nisotropic model remains a planar spin spiral given by\nSai = Sa\n\uf8ee\n\uf8f0\n0\nsin(Q \u00b7 ri + \u03d5a)\ncos(Q \u00b7 ri + \u03d5a)\n\uf8f9\n\uf8fb, (2)\nwhere Q is the magnetic ordering vector, \u03d5a is the phase\nangle of the spin at sitea, ri is a lattice vector for unit cell\ni, and Sa is the maximal eigenvalue ofSz\na (the magnitude\nof the classical spin vector). We note that the assumption\nof an isotropic model implies that any orientation of the\nspiral plane yields the same ground state energy and we\nhave chosen the yz-plane here to be specific. Such a\nmagnetic structure is often referred as a single- Q spin\nspiral and is shown to be the ground state in appendix\nA. The discussion in the remainder of this work will focus\nsolely on single-Q spin spirals. When considering excitations of spiral ground states\nit will be convenient to transform the system to a local\ncoordinate system where all spin fluctuations are perpen-\ndicular to the localz-axis. Here we reiterate the approach\nof Ref. 12 regarding this transformation, which will be\nneeded for reference below. We can write the spin opera-\ntors in terms of a cell-dependent rotation matrix Ri such\nthat\nSai = RiS\u2032\nai, (3)\nRi = R\u02c6 n(Q \u00b7 ri), (4)\nwhere \u02c6 nis the global rotation axis.", "metadata": {"type": "reasoning", "source": "2503.01283v2.pdf", "context": "2\nX\nabij\nST\naiJabijSbj, (1)\nwhere Sai is the spin operator for site a in unit cell i\nand Jabij is the exchange tensor that couples the spins\nat sites a, iand b, j. Single-ion anisotropy terms are in-\ncluded through the onsite components J aaii of the ex-\nchange tensor. In order to calculate the thermal prop-\nerties of the model (1) one needs the magnetic excita-\ntion spectrum, which requires one to determine the mag-\nnetic ground state. Except for simple ferromagnets, the\nground state of the mod", "quality_score": 8.5}}
{"id": "test_12", "question": "What is the purpose of the component that operates exclusively during the training phase?", "golden_answers": ["It generates blurred region-of-interest (ROI) prompts through its convolution-based stochastic scaling algorithm."], "prediction": "The purpose of the component that operates exclusively during the training phase is to allow participants to get familiar with both the task and the exoskeleton, ensuring they can perform the task accurately before recording their performance.", "f1": 0.0, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.00259v1\nThe training phase involves the agent in-\nteracting with a simulated MAC layer environment, which\nmodels the behavior of 5G NR-U and Wi-Fi transmitters\nunder realistic coexistence conditions. At each time step,\nthe agent observes the current augmented state, selects\nan action which is adjusting contention window sizes, and\nobserves performance functions. The constraint is carefully\ndesigned to penalize violations of QoS requirements. Expe-\nrience replay is used to store and sample past transitions,\nand a target network is updated periodically to stabilize\nlearning. Training is conducted across varying number of\ntransmitters to ensure the generalization. In the execution phase, the trained policy is deployed\nin the simulation environment to evaluate its effective-\nness. The augmented state representation ensures that the\nTABLE I\nHYPER -PARAMETERS OF QASAL ALGORITHM\nParameter Value\nInteraction time T 20 s\nStep duration 2.5 ms\nDiscount factor 0.99\nReplay buffer size 100,000\nRange of \u03f5 1 to 0.1\nDQN learning rate 10\u22124\nBatch size 16\nHidden layers 32 \u00d732 \u00d732\n\u03b7\u03bb,\u03bbmax,T0 in (10) 0.1, 10, 5\nagent adapts dynamically to changing network conditions,\nmaking real-time adjustments to contention window sizes\nto optimize system performance. The QaSAL algorithm\neffectively balances competing objectives, ensuring that\nhigh-priority traffic meets its delay requirements while\npromoting fairness between 5G NR-U and Wi-Fi networks. The hyperparameters of QaSAL algorithm are summarized\nin Table I. The step duration is selected to be large enough\nto include several transmission attempts to enable the\naccurate calculation of the transmission delay. VI. S IMULATION RESULTS\nIn this section, we highlight the performance of the\nproposed QaSAL algorithm. For the simulation scenario, we\nconsider one gNB PC1 transmitter sharing the channel with\nvarying number of AP PC3 transmitters, and evaluate the\nperformance of primal-dual method (Section III) and QaSAL\nalgorithm (Section IV). The simulations were conducted to\nanalyze the algorithm\u2019 s ability to balance fairness and delay\nmetrics across different numbers of Wi-Fi\u2019 s low-priority\ntransmitters. Figs. 3 and 4 illustrate the transmission delay dynamics\nfor gNB PC1 traffic coexisting with 25 AP PC3 transmitters\nduring both the training and execution phases of the\nprimal-dual and QaSAL algorithms, respectively. While the\n\nFig. 6. Average Transmission delay of PC1 transmitter with QaSAL algo-\nrithm for various delay thresholds and varying number of PC3 transmitters. Fig. 7. JFI among Wi-Fi and NR-U networks with QaSAL algorithm for\nvarious delay thresholds and varying number of PC3 transmitters. policy derived from the primal-dual algorithm can solve\nproblem (11) on average, it does not guarantee near-\noptimality at a specific episode k. In contrast, the QaSAL\nalgorithm effectively enforces the constraint by incorporat-\ning dual variables into the state space, leading to improved\nconstraint satisfaction. Fig. 5 illustrates the evolution of the\ndual variable associated with the delay constraint of gNB\nPC1, as defined in (11b), during the execution phase. The\ndual variable adjusts dynamically in response to constraint\nviolations, ensuring that the delay remains within the spec-\nified threshold. Figs.\n\n2503.00480v1\nOnce a scaled model was\nconstructed, the markers were removed and the partici-\npants were fitted with the exoskeleton. The exoskeleton\nwas adjusted to the dimensions of each participant to\nensure a tight and comfortable fit, and a good align-\nment between the joints of the exoskeleton and the joints\nof the participant. While wearing the exoskeleton, the\nparticipants were asked to perform a trajectory tracking\ntask with their right leg, while their left leg was used to\nsupport their weight on an elevated platform, which was\nused to avoid contact between the user\u2019s right leg and\nthe ground (Figure 4). Side rails were provided to help\nthe participants maintain their balance. This task was\nselected in order to reduce the computational demands\nof the optimisation, and uncertainties involved with the\noptimisation of balance. The participants were then informed about the ex-\nperimental protocol and were asked to follow the steps\nshown in Figure 4b. At all stages, the participants were\ninformed about the state of the exoskeleton. Prior to\nrecording the participants\u2019 performance, a training period\nwas prescribed to allow the participants to get famil-\niar with both the task and the exoskeleton (Figure 4). This training period included four phases complemented\nby visual feedback: (1) a position controlled exoskele-\nton ( qexo(t) = qref (t)), (2) a transparent exoskeleton\n(\u03c4 e = 0), (3) an assistive exoskeleton ( \u03c4 e \u0338= 0), and (4) a\ntransparent exoskeleton again. Each training phase lasted\nbetween 2-5 minutes, depending on the user\u2019s confidence\nlevel. The visual feedback included a virtual image of the\nexoskeleton\u2019s leg, as well as a graphical representation of\nthe reference kinematic path in joint space with the real-\ntime pose of the exoskeleton and the corresponding refer-\nence point (Figure 4a). The visual queues were explained\nto the participants and the participants were instructed to\nfollow the reference path as accurately as possible. After\n\nPAPER ID: TMRB-06-24-OA-0958 7\nFig. 4. (a) Data collection setup. Participant wearing an exoskeleton and performing a unilateral tracking task with the help of visual\nfeedback. (b) Experimental protocol including four phases of pretest training with visual feedback and the experimental validation where\nthe baseline controller and the optimised controller were tested in a randomised order. the training period, the visual feedback was removed for\nall experiments following the training period to prevent\nfurther learning of the task and capture the participant\u2019s\nkinematics that reflect the internal model of motor control\nconstructed by the participants during this period. The\nparticipants were asked to perform the task they practiced\nwith the exoskeleton in transparent mode and their motion\nwas recorded and used for the estimation of the human\nbehaviour model. Based on this recorded motion, a personalised set of\nexoskeleton stiffnesses was obtained for each participant\nthrough our offline model-based optimisation method. This included the exoskeleton\u2019s stiffness for both the hip\nand the knee joints during the two different phases as\nshown in Figure 3.\n\n2503.00077v1\nNotably, in 40 studies (36%), the purpose of CC\nidentification or generation was not explicitly stated, thus they\nwere excluded from this analysis. 1) Testing and Validation: CCs are extensively utilized to\ntest and validate ADS, helping to assess their performance,\nsafety, and robustness in rare and critical scenarios. The\nprimary objective is to assess how well an ADS handles rare\nand critical scenarios, evaluating if it meets safety expectations\nbefore deployment. Many studies highlight the use of CCs to\nvalidate ADS performance under extreme conditions, bench-\nmarking against regulatory and safety requirements [36], [38],\n[65], [67], [68], [70], [71], [79], [81], [87], [92], [96], [101],\n[106], [113], [117]\u2013[119], [121], [125], [127]\u2013[132], [136],\n[138], [140], [150], [154], [157]\u2013[161], [164], [165], [167],\n[169]. By simulating these scenarios, researchers can measure\nthe effectiveness of the system, identify performance limita-\ntions, and refine models accordingly. Comprehensive testing\nframeworks based on CCs have been shown to help identify\nweaknesses and support the effective operation of ADS in\ndiverse environments, potentially accelerating the develop-\nment process [113], [154], [158]. Additionally, these testing\nmethods contribute to maintaining critical safety standards\nthroughout the system\u2019s lifecycle in its operational design\ndomain. 2) Training and Optimization: The generation and iden-\ntification of CCs also serve as a foundation for improving\nthe learning process and optimization of A V systems. Studies\nfocus on using CCs to enhance the training datasets for model\ncontrol development [86], [105], [107], [142], [144] aiming to\nimprove A V control and safety. For instance, algorithms that\nfine-tuning with rare scenarios seek to enhance the system\u2019s\nability to handle unforeseen situations effectively [88], [122]. Training with enriched pedestrian datasets, for example, can\ndirectly improve detection and control algorithms, which in\nturn supports the development of more robust and adaptive\nADS policies capable of efficiently responding to critical\nscenarios [142], [145]. 3) Dataset Generation and Augmentation: Another sig-\nnificant application of CCs is in generating diverse and\ncomprehensive datasets. Some studies highlight how CCs\nenrich datasets to capture rare, critical, or unexpected sce-\nnarios, which are often underrepresented in standard datasets\n[74], [102], [135], [151]. This enrichment is essential for\nbenchmarking, developing test cases, and improving ADS\nalgorithms. For example, synthetic data generated from CCs\ncan effectively reduce the cost and time associated with\nacquiring real-world data, while ensuring extensive coverage\nof challenging scenarios [91]. Furthermore, the importance of\naugmenting datasets to improve simulation-based evaluation\nframeworks is emphasized, as it plays a key role in enabling\nA V systems to adequately address the variability and complex-\nity inherent in real-world environments [76], [98], [166]. 4) Safety Assessment and Standardization: CCs are instru-\nmental in assessing the safety of A V systems and defining\nstandards for their performance. [85], [126], [155] illustrate\nhow CCs can be used to evaluate compliance with safety\nbenchmarks and regulatory requirements. For instance, [100]\ndiscusses leveraging CCs to supplement existing testing frame-\nworks and establish test schemes that ensure A Vs meet strin-\ngent safety criteria. This category underscores the critical role\nof CCs in fostering public trust and regulatory acceptance of\nautonomous technologies.", "metadata": {"type": "factual", "source": "2503.01265v1.pdf", "context": "calization of suspected lesion regions within these scans. This\ncomponent operates exclusively during the training phase,\ngenerating blurred region-of-interest (ROI) prompts through\nits convolution-based stochastic scaling algorithm, which is\ndetailed in Algorithm 1. It defines a series of convolution\n1The Transformer module adopts the design of Restormer [36], a simplified\nTransformer that reduces the computational cost, enabling its use across\nmultiple levels.", "quality_score": 8.5}}
{"id": "test_13", "question": "According to Burrows et al. (2024), what two classes of progenitors lead to different ranges of natal kicks?", "golden_answers": ["Low mass and low compactness that lead to kicks of \u223c100\u2212200 km/s, and high mass and high compactness that lead to kicks of \u223c300\u22121000 km/s."], "prediction": "Low mass and low compactness that lead to kicks of \u223c100\u2212200 km/s, and high mass and high compactness that lead to kicks of \u223c300\u22121000 km/s.", "f1": 1.0, "em": 1.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "A kinematically constrained kick distribution for isolated neutron stars\nSmall natal kicks could also be the result of interac-\ntions in binary stars, which are relevant since the population of\nisolated NS contains NSs that are born in binaries and have re-\nceived a kick large enough to unbind the system (although binary\ndisruptions due to mass loss or natal kicks result in different ve-\nlocities for the escaped pulsar, see e.g. Beniamini & Piran 2024). Mass transfer in a binary can strip the NS progenitor and lead to\nstripped and ultra-stripped SNe (Podsiadlowski et al. 2004; Tau-\nris et al. 2013, 2015), which in turn result in small natal kicks. However, it has been shown that these smaller kicks would not\nbe sufficient to unbind the binary, and hence that isolated NSs\nborn in binaries can only represent the upper tail of the kick dis-\ntribution (Kuranov et al. 2009). More recently, SN simulations\nsuggest that there are likely multiple ranges of zero-age main-\nsequence masses leading to NS formation (e.g. Ertl et al. 2016;\nM\u00fcller et al. 2016; Kresse et al. 2021). In particular, Burrows\net al. (2024) find two classes of progenitors: low mass and low\ncompactness that lead to kicks of\u223c100\u2212200 km/s and high mass\nand high compactness that lead to kicks of \u223c300\u22121000 km /s. These two classes could hypothetically correspond to the two\nMaxwellians found by Verbunt et al. (2017) and Igoshev (2020). The methods of Hobbs et al. (2005), Verbunt et al. (2017),\nand Igoshev (2020) constrain natal kicks by analysing the ve-\nlocities of young pulsars. This motivation of this choice is that a\nsample of old pulsars would be biased toward low kick in at least\ntwo ways: (1) the Galactic trajectories become more eccentric as\na result of the kicks, because of which the objects are more likely\nto be observed near their Galactic apocentre where they have re-\nduced speeds relative to their initial velocities (Hansen & Phin-\nney 1997; Disberg et al. 2024a), and (2) NSs that receive high\nkicks migrate outwards more quickly and therefore become less\nlikely to be observed as they age (Cordes 1986; Lyne & Lorimer\n1994). In order to eliminate the first of these biases, Disberg et al.\n(2024b) proposed a method of inferring kicks (i.e. the systemic\nkicks of binary NSs) based on the shape of their Galactic trajec-\ntory, which remains close to circular for low kicks and becomes\nmore eccentric for increasing kick magnitude. This method em-\nploys the entire Galactic orbit instead of the present-day circular\nvelocity to infer kicks and should therefore also provide rela-\ntively accurate estimates for older NSs. The advantages of such\nan approach are two-fold. Firstly, the use of older pulsars pro-\nvides a second, entirely independent sample of neutron stars on\nwhich the kick distribution can be determined while accounting\nfor the evolution of their velocity as they migrate through the\nGalactic potential.\n\n2503.01429v1\nMass trans-\nfer in a binary can strip the NS progenitor and lead to stripped\nand ultra-stripped SNe (Podsiadlowski et al. 2004; Tauris et al.\n2013, 2015), which in turn result in small natal kicks. However,\nit has been shown that these smaller kicks would not be su ffi-\ncient to unbind the binary, and hence that isolated NSs born in\nbinaries can only represent the upper tail of the kick distribution\n(Kuranov et al. 2009). More recently, SN simulations suggest\nthat there are likely multiple ranges of zero-age main-sequence\nmasses leading to NS formation (e.g. Ertl et al. 2016; M\u00fcller\net al. 2016; Kresse et al. 2021). In particular, Burrows et al.\n(2024) find two classes of progenitors: low mass and low com-\npactness that lead to kicks of \u223c100\u2212200 km /s and high mass\nand high compactness that lead to kicks of \u223c300\u22121000 km /s. These two classes could hypothetically correspond to the two\nMaxwellians found by Verbunt et al. (2017) and Igoshev (2020). The methods of Hobbs et al. (2005), Verbunt et al. (2017),\nand Igoshev (2020) constrain natal kicks by analysing the ve-\nlocities of young pulsars. This motivation of this choice is that a\nsample of old pulsars would be biased toward low kick in at least\ntwo ways: (1) the Galactic trajectories become more eccentric\nas a result of the kicks, because of which the objects are more\nlikely to be observed near their Galactic apocentre where they\nhave reduced speeds relative to their initial velocities (Hansen\n& Phinney 1997; Disberg et al. 2024a), and (2) NSs that re-\nceive high kicks migrate outwards more quickly and therefore\nbecome less likely to be observed as they age (Cordes 1986;\nLyne & Lorimer 1994). In order to eliminate the first of these\nbiases, Disberg et al. (2024b) proposed a method of inferring\nkicks (i.e. the systemic kicks of binary NSs) based on the shape\nof their Galactic trajectory, which remains close to circular for\nlow kicks and becomes more eccentric for increasing kick mag-\nnitude. This method employs the entire Galactic orbit instead of\nthe present-day circular velocity to infer kicks and should there-\nfore also provide relatively accurate estimates for older NSs. The\nadvantages of such an approach are two-fold. Firstly, the use of\nolder pulsars provides a second, entirely independent sample of\nneutron stars on which the kick distribution can be determined\nwhile accounting for the evolution of their velocity as they mi-\ngrate through the Galactic potential. Secondly, the older pulsars\nexpand the sample with measured parallax, making it less prone\nto Poisson noise compared to the sample containing only young\nsample with measured parallax, while retaining the advantage of\nparallax measurements over (likely more uncertain) distance es-\ntimates through dispersion measures. We applied the method of Disberg et al. (2024b) to the iso-\nlated pulsars from the samples of Verbunt et al. (2017) and Igo-\nshev (2020) in order to kinematically constrain the natal kick dis-\ntribution of NSs and compare it to the results from literature. In\nSect.\n\nA kinematically constrained kick distribution for isolated neutron stars\nIntroduction\nNeutron stars (NSs) that are observed as isolated pulsars (i.e. pul-\nsars without a binary companion) are known to have relatively\nhigh velocities compared to their progenitor stars (e.g. Gunn\n& Ostriker 1970; Lyne & Lorimer 1994; Lorimer et al. 1997;\nCordes & Cherno ff 1998), because of which they are thought\nto have received a (natal) kick at their formation (e.g. Dewey\n& Cordes 1987; Bailes 1989; Van Paradijs & White 1995; Iben\n& Tutukov 1996; Fryer & Kalogera 1997; Van den Heuvel &\nVan Paradijs 1997). These natal kicks are most often associ-\nated with anisotropic supernova (SN) explosions (e.g. Janka &\nM\u00fcller 1994; Burrows et al. 1995; Burrows & Hayes 1996; Janka\n2017; Gessner & Janka 2018; M\u00fcller et al. 2019), although jets\nlaunched by the newly-formed NS could also potentially play a\nsignificant role (e.g. Soker 2010; Bear et al. 2025; Soker 2024;\nWang et al. 2024). Moreover, some studies argue that a \u201crocket\u201d\nmechanism, caused by anisotropic emission of electromagnetic\nradiation due to the spin-down of the NS, could provide (minor)\ncontributions to the observed velocities (e.g. Harrison & Tade-\nmaru 1975; Lai et al. 2001; Agalianou & Gourgouliatos 2023;\nIgoshev et al. 2023; Hirai et al. 2024). \u22c6 e-mail: paul.disberg@monash.edu\nCore-collapse SNe can not only form NSs but also stellar-\nmass black holes, which are therefore potential recipients of na-\ntal kicks as well (e.g. Brandt et al. 1995; Nelemans et al. 1999;\nJonker & Nelemans 2004; Repetto et al. 2012; Mandel 2016;\nAndrews & Kalogera 2022; Banagiri et al. 2023; Vigna-G\u00f3mez\net al. 2024). In addition, when kicked objects are part of a binary,\nthe system also experiences a Blaauw kick through recoil due\nto mass-loss (Blaauw 1961; Van den Heuvel et al. 2000). This\nmeans that the total (systemic) kick imparted on a binary con-\nsists of a natal kick and a Blaauw kick for each component that\nhas experienced a SN (e.g. Hills 1983; Tauris et al. 2017 ; An-\ndrews & Zezas 2019). Determining the magnitude of NS kicks\nis therefore not only important for studying the Galactic distri-\nbution of NSs (e.g. Prokhorov & Postnov 1994; Kiel & Hurley\n2009; Ofek 2009; Sartore et al. 2010; Sweeney et al. 2022; Song\net al. 2024) but also for the rates and locations of the mergers of\ncompact binaries and the resulting transient signals (e.g. Fryer\net al. 1999; V oss & Tauris 2003; Church et al. 2011; Abbott et al.\n2017; Vigna-G\u00f3mez et al. 2018; Zevin et al. 2020; Iorio et al.\n2023; Gaspari et al. 2024a,b; Wagg et al. 2025), as well as impor-\ntant for understanding the SN mechanism (e.g. Nagakura et al.\n2019; M\u00fcller 2020; Coleman & Burrows 2022; Burrows et al.\n2024; Kondratyev et al. 2024; Janka & Kresse 2024) and there-\nArticle number, page 1 of 15\n\nA&A proofs:manuscript no. main\nfore also the mass distributions of compact objects (e.g. Disberg\n& Nelemans 2023; Schneider et al. 2023; Laplace et al. 2025).", "metadata": {"type": "factual", "source": "2503.01429v2.pdf", "context": "sequence masses leading to NS formation (e.g. Ertl et al. 2016;\nM\u00fcller et al. 2016; Kresse et al. 2021). In particular, Burrows\net al. (2024) find two classes of progenitors: low mass and low\ncompactness that lead to kicks of\u223c100\u2212200 km/s and high mass\nand high compactness that lead to kicks of \u223c300\u22121000 km /s.\nThese two classes could hypothetically correspond to the two\nMaxwellians found by Verbunt et al. (2017) and Igoshev (2020).\nThe methods of Hobbs et al. (2005), Verbunt et al. (2017),\nand ", "quality_score": 8.5}}
{"id": "test_14", "question": "How does SBI (Stochastic Bayesian Inference) operate in scenarios with missing data?", "golden_answers": ["SBI methods cannot operate on missing values, and so imputing xmis is necessary before proceeding to inference."], "prediction": "SBI operates in scenarios with missing data by requiring imputation of the missing values before proceeding with inference. The SBI posterior is formulated as an expectation over the missing values given the observed data, which is mathematically expressed as an integral involving the true predictive distribution of the missing values. If the missing values are not accurately imputed, the resulting SBI posterior can become biased. The proposed method, RISE, addresses this issue by jointly learning the imputation model and the inference network, allowing for robust inference outcomes even with varying levels of missing data.", "f1": 0.163265306122449, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01287v1\nPublished as a conference paper at ICLR 2025\nROBUST SIMULATION -BASED INFERENCE\nUNDER MISSING DATA VIA NEURAL PROCESSES\nYogesh Verma, Ayush Bharti\nDepartment of Computer Science, Aalto University\n{yogesh.verma, ayush.bharti}@aalto.fi\nVikas Garg\nYaiYai Ltd and Aalto University\nvgarg@csail.mit.edu\nABSTRACT\nSimulation-based inference (SBI) methods typically require fully observed data to\ninfer parameters of models with intractable likelihood functions. However, datasets\noften contain missing values due to incomplete observations, data corruptions\n(common in astrophysics), or instrument limitations (e.g., in high-energy physics\napplications). In such scenarios, missing data must be imputed before applying any\nSBI method. We formalize the problem of missing data in SBI and demonstrate that\nnaive imputation methods can introduce bias in the estimation of SBI posterior. We\nalso introduce a novel amortized method that addresses this issue by jointly learning\nthe imputation model and the inference network within a neural posterior estimation\n(NPE) framework. Extensive empirical results on SBI benchmarks show that our\napproach provides robust inference outcomes compared to standard baselines\nfor varying levels of missing data. Moreover, we demonstrate the merits of our\nimputation model on two real-world bioactivity datasets (Adrenergic and Kinase\nassays). Code is available at https://github.com/Aalto-QuML/RISE. 1 I NTRODUCTION\nMechanistic models for studying complex physical or biological phenomena have become indispens-\nable tools in research fields as diverse as genetics (Riesselman et al., 2018), epidemiology (Kypraios\net al., 2017), gravitational wave astronomy (Dax et al., 2021), and radio propagation (Bharti et al.,\n2022a). However, fitting such models to observational data can be challenging due to the intractabil-\nity of their likelihood functions, which renders standard Bayesian inference methods inapplicable.\nSimulation-based inference (SBI) methods (Cranmer et al., 2020) tackle this issue by relying on\nforward simulations from the model instead of evaluating the likelihood. These simulations are then\neither used to train a conditional density estimator (Papamakarios and Murray, 2016; Lueckmann\net al., 2017b; Greenberg et al., 2019; Papamakarios et al., 2019; Radev et al., 2020), or to measure dis-\ntance with the observed data (Sisson, 2018; Briol et al., 2019; Pesonen et al., 2023), to approximately\nestimate the posterior distribution of the model parameters of interest. SBI methods implicitly assume that the observed data distribution belongs to the family of distri-\nbutions induced by the model; i.e., the model is well-specified. However, this assumption is often\nviolated in practice where models tend to be misspecified since the complex real-world phenomena\nunder study are not accurately represented. Even if the model is well-specified, the data collection\nmechanism might hinder the applicability of SBI methods since it can induce missing data due to, for\ninstance, incomplete observations (Luken et al., 2021), instrument limitations (Kasak et al., 2024), or\nunfavorable experimental conditions.\n\n2503.01287v1\nIn this paper, we introduce a novel SBI method that is robust to shift in the posterior\ndistribution due to missing data. Our method, named RISE (short for \u201cRobust Inference under\nimputed SimulatEd data\u201d), jointly performs imputation and inference by combining NPE with latent\nneural processes (Foong et al., 2020). Doing so allows us to learn an amortized model unlike other\nrobust SBI methods in the literature, and to handle missing data under different assumptions (Little\nand Rubin, 2019). We summarize our main contributions below:\n\u2022 we motivate the problem of missing data in SBI, arguing how it can induce bias in posterior\nestimation;\n\u2022 we propose RISE, an amortized method, that jointly learns an imputation and inference\nnetwork to deal with missing data;\n\u2022 RISE outperforms competing baselines in inference and imputation tasks across varying\nlevels of missingness, demonstrating robust performance in settings entailing missing data. 2 P RELIMINARIES\nConsider a simulator-based model p(\u00b7| \u03b8) that takes in a parameter vector \u03b8 \u2208 \u0398 \u2286 Rp and maps it to\na point x = [x1, . . . , xd]\u22a4 in some data spaceX \u2286Rd. We assume thatp(\u00b7| \u03b8) is intractable, meaning\nthat its associated likelihood function is unavailable and cannot be evaluated point-wise. However,\nin our setting, generating independent and identically distributed (iid) realisations x \u223c p(\u00b7| \u03b8) for\na fixed \u03b8 is straightforward. Given a dataset \u02dcx collected via real-world experiments from some\ntrue data-generating process and a prior distribution on the parameters p(\u03b8), we are interested in\napproximating the posterior distribution p(\u03b8 | \u02dcx) \u221d p(\u02dcx |\u03b8)p(\u03b8). This can be achieved, for instance,\nusing the popular neural posterior estimation (NPE) method, which we now introduce. Neural posterior estimation. NPE (Papamakarios and Murray, 2016) involves training conditional\ndensity estimators, such as normalizing flows (Papamakarios et al., 2021), to learn a mapping from\neach datum x to the posterior distribution p(\u03b8 |x). Specifically, we can approximate the posterior\n2\n\nPublished as a conference paper at ICLR 2025\ndistribution with q\u03d5(\u03b8 |x) using learnable parameters \u03d5. In particular, we can train q\u03d5 by minimizing\nan empirical loss\n\u2113NPE(\u03d5) \u225c \u22121\nn\nnX\ni=1\nlog q\u03d5(\u03b8i |xi) \u2248 \u2212E\u03b8\u223cp(\u03b8)[Ex\u223cp(x |\u03b8)[log q\u03d5(\u03b8 |x)]], (1)\nusing the dataset {(\u03b8i, xi)}n\ni=1 simulated from the joint distribution p(\u03b8, x) = p(x |\u03b8)p(\u03b8). When\nthe data space X is high-dimensional, or there are multiple observations X = [x(1), . . . ,x(m)] for\neach \u03b8, we can use a summary function \u03b7 : X \u2192 S(such as a deep set (Zaheer et al., 2017)) to enable\na condensed representation. Assuming that the summary function is parameterized by \u03ba, the joint\nNPE loss with respect to both \u03d5 and \u03ba can be defined as \u2113NPE(\u03d5, \u03ba) \u225c \u22121\nn\nPn\ni=1 log q\u03d5(\u03b8i |\u03b7\u03ba(xi)). Once both q\u03d5 and \u03b7\u03ba are trained, the NPE posterior estimate q\u02c6\u03d5(\u03b8 |\u03b7\u02c6\u03ba(\u02dcx)) for any given real data \u02dcx\nis obtained by a simple forward pass of \u02dcx through the trained networks, making NPEs amortized. We\nnow provide a brief background on the missing data problem, which is the focus of this work.\n\n2503.01287v1\nMissing data background. In the context of missing data, each data sample is composed of\nan observed part xobs and a missing (or unobserved) part xmis such that x = ( xobs, xmis). The\nmissingness pattern for each x is described by a binary mask variables \u2208 {0, 1}d, where si = 1 if the\nelement xi is observed and si = 0 if xi is missing, i \u2208 {1, . . . , d}. The joint distribution of x and s\ncan be factorized asp(x, s) = p(s |x)p(x). Based on specific assumptions about what the conditional\ndistribution of the mask (or the missingness mechanism) depends on, three different scenarios arise\n(Little and Rubin, 2019): (i) missing-completely-at-random (MCAR), where p(s |x) = p(s); (ii)\nmissing-at-random (MAR), where p(s |x) = p(s |xobs); and (iii) missing-not-at-random (MNAR),\nwhere p(s |x) = p(s |xobs, xmis). The missingness mechanism can be ignored for both MCAR and MAR when learning p(xobs, s), but\nnot for MNAR where it depends on xmis (Ipsen et al., 2020). We aim to handle all the three cases\nwhen performing SBI.\n3 M ETHOD We begin by analyzing the issue of missing data in SBI settings in Section 3.1. We then present\nRISE \u2014 our method for handling missing data in SBI. Section 3.2 outlines our learning objective,\nand Section 3.3 describes how we parameterize the imputation model in RISE using neural processes.\n3.1 M ISSING DATA PROBLEM IN SBI\nWe assume that the simulator can faithfully replicate the true data-generating process (i.e., the\nsimulator is well-specified), however, the data collection mechanism induces missing values in\neach data point x. As a result, x contains both observed and missing values, 1 represented as\nx = ( xobs, xmis). For instance, x = ( 0.1 1.2 \u2212 0.9) exemplifies a scenario where a specific\ncoordinate xi is missing (indicated by \u2018\u2212\u2019). Naturally, SBI methods cannot operate on missing values,\nand so imputing xmis is necessary before proceeding to inference. However, if the missing values are\nnot imputed accurately, then the corresponding SBI posterior becomes biased (e.g., as observed in\nFigure 1 due to constant imputation). We now describe this problem mathematically.\nDefinition 1 (SBI posterior under true imputation) . Let ptrue(xmis |xobs) be the true predictive\ndistribution of the missing values given the observed data. Then, the SBI posterior can be written as\npSBI(\u03b8 |xobs) =\nZ\npSBI(\u03b8 |xobs, xmis)| {z }\nInference\nptrue(xmis |xobs)| {z }\nImputation\ndxmis. (2)\nWe thus have a distribution over the missing values given xobs, and the problem of SBI under\nmissing data is formulated as an expectation of the SBI posterior pSBI(\u03b8 |xobs, xmis) with respect to\nptrue(xmis |xobs), analogous to traditional (likelihood-based) Bayesian inference methods (Schafer\nand Schenker, 2000; Zhou and Reiter, 2010). Therefore, estimating the above expectation requires\n1Note that during training, xobs and xmis are partitions of the simulated data x, while during inference we\nonly observe \u02dcxobs from the real world.", "metadata": {"type": "factual", "source": "2503.01287v1.pdf", "context": "each data point x. As a result, x contains both observed and missing values, 1 represented as\nx = ( xobs, xmis). For instance, x = ( 0.1 1.2 \u2212 0.9) exemplifies a scenario where a specific\ncoordinate xi is missing (indicated by \u2018\u2212\u2019). Naturally, SBI methods cannot operate on missing values,\nand so imputing xmis is necessary before proceeding to inference. However, if the missing values are\nnot imputed accurately, then the corresponding SBI posterior becomes biased (e.g., as observed in\nFigure 1 du", "quality_score": 8.5}}
{"id": "test_15", "question": "What happens to the SBI posterior if the missing values are not imputed accurately?", "golden_answers": ["The corresponding SBI posterior becomes biased."], "prediction": "If the missing values are not imputed accurately, the SBI posterior estimates become biased and drift away from the true parameter value.", "f1": 0.25, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01287v1\nAlthough the former problem of model misspecification has been studied in a number of works\n(Frazier et al., 2020; Dellaporta et al., 2022; Fujisawa et al., 2021; Bharti et al., 2022b; Ward\net al., 2022; Schmitt et al., 2023; Gloeckler et al., 2023; Huang et al., 2023; Gao et al., 2023;\nKelly et al., 2024), the latter problem of missing data in SBI has received relatively less atten-\ntion. A notable exception is the work of Wang et al. (2024), which attempts to handle miss-\ning data by augmenting and imputing constant values (e.g., zero or sample mean) and perform-\ning inference with a binary mask indicator. However, this approach can lead to biased esti-\nmates, reduced variability, and distorted relationships between variables (Graham et al., 2007). This is exemplified in Figure 1 where we investigate the impact of missing data on neural pos-\n1\narXiv:2503.01287v1  [cs.LG]  3 Mar 2025\n\nPublished as a conference paper at ICLR 2025\nterior estimation (NPE, Papamakarios and Murray (2016))\u2014a popular SBI method\u2014on a pop-\nulation genetics model. We observe that simply incorporating missing values and their corre-\nsponding masks in NPE methods as in Wang et al. (2024) leads to biased posterior estimates. 0 10\n1\n5\n10\n15\n202\nTrue \n= 0%\n= 10%\n= 25%\n= 60%\nFigure 1: Effect of missing data on SBI.\nNPE posterior for the two-parameter Ricker\nmodel (Wood, 2010) where the method of\nWang et al. (2024) (with zero augmentation)\nis used to handle \u03b5% of values missing in\nthe data. As \u03b5 increases, the NPE posteriors\nbecome biased and drift away from the true\nparameter value, denoted by the black lines. Other SBI works that address missing data include\nLueckmann et al. (2017a) and Gloeckler et al. (2024),\nhowever, they fail to account for the underlying mech-\nanism that leads to missing values in the data. Outside of SBI, the problem of missing data has\nbeen extensively studied (Van Buuren and Groothuis-\nOudshoorn, 2011), with Rubin (1976) categoriz-\ning it into three types: missing completely at ran-\ndom (MCAR), missing at random (MAR), and miss-\ning not at random (MNAR). Recent advances in\nmachine learning have led to the development of\nnovel methods for addressing this problem using\ngenerative adversarial networks (GANs, Luo et al.\n(2018); Yoon et al. (2018); Li et al. (2019); Yoon and\nSull (2020)), variational autoencoders (V AEs, Naz-\nabal et al. (2020); Collier et al. (2020); Mattei and\nFrellsen (2019); Ipsen et al. (2020); Ghalebikesabi\net al. (2021b)), Gaussian processes (Casale et al.,\n2018; Fortuin et al., 2020; Ramchandran et al., 2021;\nOng et al., 2024), and optimal transport (Muzellec\net al., 2020; Zhao et al., 2023; V o et al., 2024). These\nmethods offer new perspectives on the problem of\nmissing data imputation, but their application has\nbeen primarily limited to predicting missing values. Notably, they have not been developed for inference\nover missing values, which remains a significant challenge for SBI.\nContributions.\n\n2503.01287v1\nIn this paper, we introduce a novel SBI method that is robust to shift in the posterior\ndistribution due to missing data. Our method, named RISE (short for \u201cRobust Inference under\nimputed SimulatEd data\u201d), jointly performs imputation and inference by combining NPE with latent\nneural processes (Foong et al., 2020). Doing so allows us to learn an amortized model unlike other\nrobust SBI methods in the literature, and to handle missing data under different assumptions (Little\nand Rubin, 2019). We summarize our main contributions below:\n\u2022 we motivate the problem of missing data in SBI, arguing how it can induce bias in posterior\nestimation;\n\u2022 we propose RISE, an amortized method, that jointly learns an imputation and inference\nnetwork to deal with missing data;\n\u2022 RISE outperforms competing baselines in inference and imputation tasks across varying\nlevels of missingness, demonstrating robust performance in settings entailing missing data. 2 P RELIMINARIES\nConsider a simulator-based model p(\u00b7| \u03b8) that takes in a parameter vector \u03b8 \u2208 \u0398 \u2286 Rp and maps it to\na point x = [x1, . . . , xd]\u22a4 in some data spaceX \u2286Rd. We assume thatp(\u00b7| \u03b8) is intractable, meaning\nthat its associated likelihood function is unavailable and cannot be evaluated point-wise. However,\nin our setting, generating independent and identically distributed (iid) realisations x \u223c p(\u00b7| \u03b8) for\na fixed \u03b8 is straightforward. Given a dataset \u02dcx collected via real-world experiments from some\ntrue data-generating process and a prior distribution on the parameters p(\u03b8), we are interested in\napproximating the posterior distribution p(\u03b8 | \u02dcx) \u221d p(\u02dcx |\u03b8)p(\u03b8). This can be achieved, for instance,\nusing the popular neural posterior estimation (NPE) method, which we now introduce. Neural posterior estimation. NPE (Papamakarios and Murray, 2016) involves training conditional\ndensity estimators, such as normalizing flows (Papamakarios et al., 2021), to learn a mapping from\neach datum x to the posterior distribution p(\u03b8 |x). Specifically, we can approximate the posterior\n2\n\nPublished as a conference paper at ICLR 2025\ndistribution with q\u03d5(\u03b8 |x) using learnable parameters \u03d5. In particular, we can train q\u03d5 by minimizing\nan empirical loss\n\u2113NPE(\u03d5) \u225c \u22121\nn\nnX\ni=1\nlog q\u03d5(\u03b8i |xi) \u2248 \u2212E\u03b8\u223cp(\u03b8)[Ex\u223cp(x |\u03b8)[log q\u03d5(\u03b8 |x)]], (1)\nusing the dataset {(\u03b8i, xi)}n\ni=1 simulated from the joint distribution p(\u03b8, x) = p(x |\u03b8)p(\u03b8). When\nthe data space X is high-dimensional, or there are multiple observations X = [x(1), . . . ,x(m)] for\neach \u03b8, we can use a summary function \u03b7 : X \u2192 S(such as a deep set (Zaheer et al., 2017)) to enable\na condensed representation. Assuming that the summary function is parameterized by \u03ba, the joint\nNPE loss with respect to both \u03d5 and \u03ba can be defined as \u2113NPE(\u03d5, \u03ba) \u225c \u22121\nn\nPn\ni=1 log q\u03d5(\u03b8i |\u03b7\u03ba(xi)). Once both q\u03d5 and \u03b7\u03ba are trained, the NPE posterior estimate q\u02c6\u03d5(\u03b8 |\u03b7\u02c6\u03ba(\u02dcx)) for any given real data \u02dcx\nis obtained by a simple forward pass of \u02dcx through the trained networks, making NPEs amortized. We\nnow provide a brief background on the missing data problem, which is the focus of this work.\n\n2503.01287v1\nPublished as a conference paper at ICLR 2025\nROBUST SIMULATION -BASED INFERENCE\nUNDER MISSING DATA VIA NEURAL PROCESSES\nYogesh Verma, Ayush Bharti\nDepartment of Computer Science, Aalto University\n{yogesh.verma, ayush.bharti}@aalto.fi\nVikas Garg\nYaiYai Ltd and Aalto University\nvgarg@csail.mit.edu\nABSTRACT\nSimulation-based inference (SBI) methods typically require fully observed data to\ninfer parameters of models with intractable likelihood functions. However, datasets\noften contain missing values due to incomplete observations, data corruptions\n(common in astrophysics), or instrument limitations (e.g., in high-energy physics\napplications). In such scenarios, missing data must be imputed before applying any\nSBI method. We formalize the problem of missing data in SBI and demonstrate that\nnaive imputation methods can introduce bias in the estimation of SBI posterior. We\nalso introduce a novel amortized method that addresses this issue by jointly learning\nthe imputation model and the inference network within a neural posterior estimation\n(NPE) framework. Extensive empirical results on SBI benchmarks show that our\napproach provides robust inference outcomes compared to standard baselines\nfor varying levels of missing data. Moreover, we demonstrate the merits of our\nimputation model on two real-world bioactivity datasets (Adrenergic and Kinase\nassays). Code is available at https://github.com/Aalto-QuML/RISE. 1 I NTRODUCTION\nMechanistic models for studying complex physical or biological phenomena have become indispens-\nable tools in research fields as diverse as genetics (Riesselman et al., 2018), epidemiology (Kypraios\net al., 2017), gravitational wave astronomy (Dax et al., 2021), and radio propagation (Bharti et al.,\n2022a). However, fitting such models to observational data can be challenging due to the intractabil-\nity of their likelihood functions, which renders standard Bayesian inference methods inapplicable.\nSimulation-based inference (SBI) methods (Cranmer et al., 2020) tackle this issue by relying on\nforward simulations from the model instead of evaluating the likelihood. These simulations are then\neither used to train a conditional density estimator (Papamakarios and Murray, 2016; Lueckmann\net al., 2017b; Greenberg et al., 2019; Papamakarios et al., 2019; Radev et al., 2020), or to measure dis-\ntance with the observed data (Sisson, 2018; Briol et al., 2019; Pesonen et al., 2023), to approximately\nestimate the posterior distribution of the model parameters of interest. SBI methods implicitly assume that the observed data distribution belongs to the family of distri-\nbutions induced by the model; i.e., the model is well-specified. However, this assumption is often\nviolated in practice where models tend to be misspecified since the complex real-world phenomena\nunder study are not accurately represented. Even if the model is well-specified, the data collection\nmechanism might hinder the applicability of SBI methods since it can induce missing data due to, for\ninstance, incomplete observations (Luken et al., 2021), instrument limitations (Kasak et al., 2024), or\nunfavorable experimental conditions.", "metadata": {"type": "reasoning", "source": "2503.01287v1.pdf", "context": "each data point x. As a result, x contains both observed and missing values, 1 represented as\nx = ( xobs, xmis). For instance, x = ( 0.1 1.2 \u2212 0.9) exemplifies a scenario where a specific\ncoordinate xi is missing (indicated by \u2018\u2212\u2019). Naturally, SBI methods cannot operate on missing values,\nand so imputing xmis is necessary before proceeding to inference. However, if the missing values are\nnot imputed accurately, then the corresponding SBI posterior becomes biased (e.g., as observed in\nFigure 1 du", "quality_score": 8.5}}
{"id": "test_16", "question": "How can the Q-NL Verifier enhance the robustness of QA systems?", "golden_answers": ["By preventing incorrect query execution through self-assessment capability, which allows the system to take corrective actions such as refining the translation or prompting the user for clarification."], "prediction": "The Q-NL Verifier can enhance the robustness of QA systems by serving as an internal feedback mechanism that assesses whether the generated query translation is semantically equivalent to the user's input. If the verifier identifies a likely incorrect translation or has low confidence in it, the system can take corrective actions such as refining the translation, attempting an alternative parsing strategy, or prompting the user for clarification. This self-assessment capability helps prevent incorrect query execution.", "f1": 0.45454545454545453, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01385v1\nThis task is central to QA systems. The\nidea is to fine-tune the LLMs, using supervised finetuning, where the model is directly trained to predict the correct\nSPARQL query token by token using the synthetically generated pairs. To test this, we conducted experiments (cf.\nSection 5.6) where we evaluated (i) the original model (LLM without finetuning), (ii) the fined-tuned model (LLM\nfinetuned with our synthetic examples), and (iii) a model that is trained on filtered data using the verifier. This allows us\nto understand the impact of each of the NL-Q Verifier components on the NL \u2192 Q task. Feedback within QA systems The verifier can serve as an internal feedback mechanism within a QA system. When\nthe system generates a query translation for a user question, the Q-NL Verifier can assess whether the translation\nis semantically equivalent to the input. If the verifier determines that the translation is likely incorrect or has low\nconfidence, the system can take corrective actions such as refining the translation, attempting an alternative parsing\nstrategy, or prompting the user for clarification. This self-assessment capability enhances the robustness of QA systems\nby preventing incorrect query execution. User support. Lastly, the verifier can be employed as an assistive tool for users who manually translate natural\nlanguage questions into SPARQL queries. Writing SPARQL queries requires familiarity with the underlying knowledge\ngraph schema, making it challenging for many users, especially those without extensive expertise in semantic web\ntechnologies. By providing real-time feedback, the verifier can indicate whether a user-constructed query accurately\nreflects the intent of their natural language question. This can be integrated into query-building interfaces, where the\nsystem suggests corrections or highlights potential mismatches between the intended meaning and the generated query. 5 Experimental Study\nIn the experiments, we first investigate research questions associated with the effectiveness of Q-NL Verifier:\n(RQ1) Which of the studied modern LLMs is the most effective for Q\u2192NL translation to train the verifier?\n(RQ2) Which verifier architecture (cross-encoder or bi-encoder) can better distinguish between correct and incorrect\ntranslations?\n(RQ3) Does the verifier improve the overall quality of Q/NL datasets? Next, we investigate research questions related to the application of Q-NL Verifier as described in Section 4.3:\n(RQ4) Can Q-NL Verifier be used as a replacement for NLP metrics for query translation?\n(RQ5) Does the verifier improve NL \u2192 Q translations with LLMs?\n5.1 Experimental Setup\nDataset. We use the well-known benchmark LC-QuAD 2.0 [6]. The dataset has a total of 24, 000 questions, a natural\nlanguage verbalization of those, and the corresponding SPARQL queries. The dataset has queries for both Wikidata and\nDBpedia 2018, but we focus solely on the Wikidata queries. The natural language verbalizations of the queries were\ngenerated using Amazon Mechanical Turk. The dataset contains various queries, including single facts, multi-joins,\nblank nodes, aggregations using COUNT, filtering of values with FILTER, etc.\n8\n\nQ-NL Verifier\nLanguage Models. We tested several different LLMs, from small open-source models to large proprietary frontier\nmodels.\n\n2503.01385v1\nQ-NL V ERIFIER : L EVERAGING SYNTHETIC DATA FOR ROBUST\nKNOWLEDGE GRAPH QUESTION ANSWERING\nTim Schwabe\nTechnical University of Munich\nHeilbronn, Germany\ntim.schwabe@tum.de\nLouisa Siebel\nTechnical University of Munich\nHeilbronn, Germany\nlouisa.siebel@tum.de\nPatrik Valach\nTechnical University of Munich\nHeilbronn, Germany\npatrik.valach@tum.de\nMaribel Acosta\nTechnical University of Munich\nHeilbronn, Germany\nmaribel.acosta@tum.de\nABSTRACT\nQuestion answering (QA) requires accurately aligning user questions with structured queries\u2014a\nprocess often limited by the scarcity of high-quality query\u2013natural language (Q\u2013NL) pairs. To\novercome this, we present Q-NL Verifier, an approach to generating high-quality synthetic pairs\nof queries and NL translations. Our approach relies on large language models (LLMs) to generate\nsemantically precise natural language paraphrases of structured queries. Building on these synthetic\nQ\u2013NL pairs, we introduce a learned verifier component that automatically determines whether a\ngenerated paraphrase is semantically equivalent to the original query. Our experiments with the\nwell-known LC-QuAD 2.0 benchmark show that Q-NL Verifier generalizes well to paraphrases\nfrom other models and even human-authored translations. Our approach strongly aligns with human\njudgments across varying query complexities and outperforms existing NLP metrics in assessing\nsemantic correctness. We also integrate the verifier into QA pipelines, showing that verifier-filtered\nsynthetic data has significantly higher quality in terms of translation correctness and enhances NL\nto Q translation accuracy. Lastly, we release an updated version of the LC-QuAD 2.0 benchmark\ncontaining our synthetic Q-NL pairs and verifier scores, offering a new resource for robust and\nscalable QA. Keywords Knowledge Graphs \u00b7 Question Answering (QA) \u00b7 Large Language Models\n1 Introduction\nSemi-structured information stored in knowledge graphs (KGs) is invaluable to many processes and downstream\napplications. However, due to its semi-structured nature and reliance on specific query languages, such as SPARQL\nor Cypher, accessing this information remains a challenge for users without domain expertise. To bridge this gap,\nknowledge graph question-answering (KGQA) systems have been developed, allowing users to interact with KGs using\nnatural language (NL). These systems translate NL questions into structured queries, enabling seamless retrieval of\nrelevant data from the KG. As a result, QA systems play a crucial role in making (semi-)structured data more accessible\nto a broader audience.\nMotivation. Building effective QA systems requires the creation of large-scale, high-quality datasets consisting of\naligned query-question pairs. These datasets serve as the foundation for training machine-learning-based approaches. However, obtaining such datasets is a major bottleneck in the development of QA systems. Some efforts have fo-\ncused on generating natural language to query (NL \u2192 Q) translations through manual approaches [1]. Yet, manually\ncurating query/NL pairs is expensive, time-consuming, and demands expert annotators to ensure semantic accu-\nracy. The scarcity of these datasets limits the effectiveness of QA systems, particularly when dealing with complex\narXiv:2503.01385v1 [cs.CL]  3 Mar 2025\n\nQ-NL Verifier\nqueries involving aggregation, subqueries, or advanced filtering. Nonetheless, recent advances in Large Language\nModels (LLMs) have demonstrated that these models are highly effective in generating natural language representa-\ntions of structured queries (Q \u2192 NL).\n\n2503.01385v1\nThe verifier has a broad set of downstream tasks or applications: cleaning datasets for QA systems, feedback signal in\ntraining of learned QA models, during usage of QA models to catch wrong translations as well as interactive feedback\nfor users that want to manually translate natural language questions to queries. Lastly, we show that the synthetic\ntranslations, in combination with the verifier, can be used as training data for QA systems.\nPaper Structure. The remainder of this paper is structured as follows. Section 2 provides background on QA over\nknowledge graphs and LLMs. Section 3 details related work, and Section 4 presents our approach Q-NL Verifier. Section 5 presents our experimental study. In Section 6, we describe a newly released version of the LC-QuAD 2.0\nbenchmark generated with Q-NL Verifier. Finally, Section 7 concludes our key findings and future research. 2 Preliminaries\n2.1 Question Answering (QA) Systems\nA QA system aims to retrieve the correct answer to a user\u2019s (natural language) question. This paper focuses on QA\nsystems over knowledge graphs (KGs). A KG is composed of entities and relationships represented as a directed graph\n2\n\nQ-NL Verifier\nG = (E, R) where E is the set of entities and R is the set of relations linking those entities. Questions over Knowledge\nGraphs are formulated using query languages like SPARQL. A given question in natural languaget can be reformulated\nto a semantically equivalent query q. The goal of a QA system is to perform the correct conversion from t to q in order\nto retrieve factual answers based on the underlying KG.\n2.2 Large Language Models (LLMs)\nAn LLM is a neural network\u2013based architecture (most often a decoder-only Transformer) trained on massive text\ncorpora. Given a prompt P, the LLM autoregressively predicts the next words, conditioning on both the prompt and all\nwords generated so far, thereby generating a response R. By iterating this process word by word, the model produces\ncoherent text that can be used in different applications, including text completion, summarization, question-answering,\nprogramming, and more. More recently, so-called Large Reasoning models have been introduced. Instead of directly returning an answer, they\nfirst produce a long chain of thought, akin to an inner monologue. Within this monologue, the model reasons about\nthe best answer to the prompt, reevaluates its proposed answer and backtracks if necessary. This has been shown to\nsignificantly improve performance on various benchmarks [29]. 3 Related Work\nThe problem of generating queries and their corresponding natural language questions has been approached from\nmultiple perspectives. Earlier works proposed rule- and template-based approaches to generate translations. More\nrecent works rely on machine learning and provide solutions either for the Q \u2192 NL translation task, or the NL \u2192 Q\ntranslation task. Rule- and Template-Based Translations. SPARQL2NL [12] uses a rule-based approach that first normalizes the\nquery structure, followed by handcrafted linguistic rules to verbalize the query. The approach shows good results\non simpler queries but degrades for more complex ones beyond the defined linguistic patterns. LD2NL", "metadata": {"type": "reasoning", "source": "2503.01385v1.pdf", "context": "Section 5.6) where we evaluated (i) the original model (LLM without finetuning), (ii) the fined-tuned model (LLM\nfinetuned with our synthetic examples), and (iii) a model that is trained on filtered data using the verifier. This allows us\nto understand the impact of each of the NL-Q Verifier components on the NL \u2192 Q task.\nFeedback within QA systems The verifier can serve as an internal feedback mechanism within a QA system. When\nthe system generates a query translation for a user question, the Q", "quality_score": 8.5}}
{"id": "test_17", "question": "In which case does the combination of IC24 with SK-atm result in a lower \u2206\u03c72 value compared to IC19 without SK-atm?", "golden_answers": ["The IO case, as shown by comparing Tables 4 and 5"], "prediction": "In the NO case.", "f1": 0.15384615384615383, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.00216v2\n( 19) are\nc1 =\n\uf8f1\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f2\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f3\n[\n1 +E4 +2E2(\u03b12 \u2212\u03b22 \u22121)\n(1 +\u03b12 +\u03b22 )2\n] 1\n2 [\n1 +E4 +2E2(\u03b12 +\u03b22 \u22121)\n(1 +\u03b12 +\u03b22 )2\n] 1\n2\n\u00d7\n\uf8ee\n\uf8ef\n\uf8ef\n\uf8ef\n\uf8ef\n\uf8ef\n\uf8ef\n\uf8f0\n\u03b2\n(\n\u03b12 +2\u03b1\u03b2\u2212\u03b22\n)\n2\n\u221a\n\u03b12 +1\n+\n\u03b2\n(\n3\u03b12 +\u03b22 +2\n)\n\u22122\u03b1\n(\n\u03b12 +1\n)\n2\n\u221a\n\u03b12 +1(1 +\u03b12 +\u03b22 )\nE2\n\uf8f9\n\uf8fa\n\uf8fa\n\uf8fa\n\uf8fa\n\uf8fa\n\uf8fa\n\uf8fb\n\u2212 4\u03b24 +2\u03b1\u03b23 \u22124\u03b12 \u03b22\n(1 +\u03b12 +\u03b22 )\n3\n2\nE4 \u2212 \u03b23 (4\u03b13 \u22124\u03b23 +6\u03b1)\n(1 +\u03b12 +\u03b22 )\n5\n2\nE2\n+ (2\u03b1\u2212\u03b2)(3\u03b1+\u03b13 ) +4\n(1 +\u03b12 +\u03b22)\n3\n2\n+\u03b24 (2 \u2212\u03b1\u03b2) +\u03b1\u03b2(1 \u2212\u03b12)2 \u22122\u03b12(1 +\u03b12) \u22124\n(1 +\u03b12 +\u03b22 )\n5\n2\n+\n\uf8ee\n\uf8ef\n\uf8ef\n\uf8ef\n\uf8ef\n\uf8ef\n\uf8ef\n\uf8f0\n\u03b1\n(\n\u03b12 +2\u03b1\u03b2\u2212\u03b22 +2\n)\n+2\u03b2\n(1 +\u03b12 +\u03b22 )\n3\n2\n\u03b2E3 \u2212 \u03b12 +2\u03b1\u03b2\u2212\u03b22\n\u221a\n1 +\u03b12 +\u03b22\n\u03b1\u03b2E\n\uf8f9\n\uf8fa\n\uf8fa\n\uf8fa\n\uf8fa\n\uf8fa\n\uf8fa\n\uf8fb\n\u00d7\n\uf8ee\n\uf8ef\n\uf8ef\n\uf8ef\n\uf8ef\n\uf8ef\n\uf8ef\n\uf8f01 +\nE4 +2E2 (\n\u03b12 \u2212\u03b22 \u22121\n)\n(1 +\u03b12 +\u03b22 )2\n\uf8f9\n\uf8fa\n\uf8fa\n\uf8fa\n\uf8fa\n\uf8fa\n\uf8fa\n\uf8fb\n1\n2\n\uf8fc\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8fd\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8fe\n[\n1 +E4 +2E2(\u03b12 +\u03b22 \u22121)\n(1 +\u03b12 +\u03b22 )2\n] \u22121\n. (B1)\n\n6\nc2 =\n\uf8f1\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f2\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f3\u2212\n(\n\u03b13 +2\u03b12 \u03b2\u2212\u03b2\u03b12 )\n\u221a\n\u03b12 +\u03b22 +1\n4(1 +\u03b12 )\n\u2212\n\u03b1\n(\n\u03b12 +2\u03b1\u03b2\u2212\u03b22 +2\n)\n+2\u03b2\n2\n\u221a\n1 +\u03b12 (1 +\u03b12 +\u03b22 )\n3\n2\nE4\n\u2212\n\u03b12 \u03b2\n(\n3\u03b12 +4\n)\n\u2212\n(\n\u03b15 +\u03b13\n)\n+\u03b12 \u03b23 +2\u03b1\u03b22\n(\u03b12 +1)(1 +\u03b12 +\u03b22 )\n3\n2\nE3\n+ \u03b13 +2\u03b12 \u03b2\u2212\u03b1\u03b22 +\u03b1+\u03b2\u221a\n(\u03b12 +1)(1 +\u03b12 +\u03b22 )\nE2\n\u2212\n\u03b12 \u03b2\n(\n3\u03b12 +2\n)\n\u22122\u03b1\n(\n\u03b12 +1\n)2\n+\u03b12 \u03b23 \u22122\u03b1\u03b22\n(\u03b12 +1)\n\u221a\n1 +\u03b12 +\u03b22\nE\n\uf8fc\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8fd\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8fe\n\u00d7\n\uf8ee\n\uf8ef\n\uf8ef\n\uf8ef\n\uf8ef\n\uf8ef\n\uf8ef\n\uf8f01 +\nE4 +2E2\n(\n\u03b12 \u2212\u03b22 \u22121\n)\n(\u03b12 +\u03b22 +1)2\n\uf8f9\n\uf8fa\n\uf8fa\n\uf8fa\n\uf8fa\n\uf8fa\n\uf8fa\n\uf8fb\n\u22121\n2\n. (B2)\n[1] R. Saadati, F . Hammad, S. Novoa-Cattivelli, M. Simard and\nN. Fleury , \u201cSpin precession and neutrino helicity \ufb02ip in var ious\nspacetimes, \u201d [\narXiv:2502.15593]. [2] P . M\u00b4 esz\u00b4 aros, D. B. Fox, C. Hanna and K. Murase, \u201cMulti-\nmessenger astrophysics, \u201d\nNat. Rev . Phys. 1, 585 (2019)\n[arXiv:1906.10212]. [3] R. Abbasi et al. , \u201c A Search for IceCube sub-T eV Neutri-\nnos Correlated with Gravitational-W ave Events Detected By\nLIGO/Virgo, \u201d\nApJ 959, 96 (2023) ; Erratum: ApJ 971, 192\n(2024) [arXiv:2303.15970]. [4] M. Dvornikov , \u201cNeutrino spin oscillations in external \ufb01eld s\nin curved spacetime, \u201d Phys. Rev . D 99, 116021 (2019)\n[arXiv:1902.11285]. [5] M. Mathisson, \u201cNeue Mechanik materieller Systeme, \u201d Acta\nPhys. Polon. 6, 163 (1937) [Translated and republished in Gen. Relativ . Gravit. 42, 1011 (2010) ]. [6] A.\n\n2503.01399v1\nThe latter is denoted as \u03c72\nmin. Panel (a)\ncorresponds to the NO case, while panel (b) corresponds to the IO case. The red (blue) curves are\nbased on \u03c72 data from NuFIT 6.0 \u201cIC24 without SK-atm\u201d (\u201cIC19 w/o SK-atm\u201d). The dashed lines\nrepresent cases that, in addition to oscillation data, data from the direct neutrino mass measurement\nby KATRIN is included. Through a detailed spectral shape analysis near the endpoint, KATRIN places an upper bound on\nm\u03b2, finding no significant deviation from the standard massless neutrino hypothesis [40],\nm\u03b2 < 0.45 eV (90% CL). (3.7)\nWe extract the \u03c72 values for m2\n\u03b2 from Ref. [40] and fit them with a quadratic function. Figure 4\nshows \u2206\u03c72 as a function of m\u03b2, with the blue line representing the fitted result. The dashed lines\nin Fig. 3 illustrate \u2206\u03c72 when KATRIN data is incorporated into the neutrino oscillation analysis. Note that the estimation ofm\u03b2 requires knowledge of the full PMNS matrix and all three neutrino\nmasses. In the minimal U(1)L\u00b5\u2212L\u03c4 model, the constraints in Eqs. (2.9) and (2.10) impose two relations\namong m1, m2, and m3. As a result, when applying Wilks\u2019 theorem, the \u03c72 test must be performed\nwith two degrees of freedom. One important point should be emphasized here. For instance, when comparing the \u2206 \u03c72 values\nbetween the analysis using only oscillation data in Tab. 2 and the analysis incorporating direct\nneutrino mass measurement results, the latter yields slightly larger values. However, as discussed\nabove, the latter requires a \u03c72 analysis with two degrees of freedom. Consequently, the constraints\nobtained from this combined analysis are weaker than those derived solely from neutrino oscillation\ndata. This indicates that incorporating additional information into the analysis does not necessarily\nstrengthen the constraints. This can be understood as follows. Wilks\u2019 theorem assumes that the likelihood ratio test statistic\n9\n\n0\n2\n4\n6\n8\n10\n12\n14\n0.01 0.1 1\nm\ntot\n(Planck+DESI) m\ntot\n(Planck)\nm\n\u03b2\u03b2\n|M\n0\u03bd\nXe\n|(KamLAND-Zen)\nm\n\u03b2(KATRIN)\n\u2206\u03c72\nmtot, m\u03b2\u03b2 \u00d7|M0\u03bd\nXe|,m\u03b2 [eV]\nFigure 4: The \u2206 \u03c72 values for the various neutrino mass parameters. The blue solid line represents\n\u2206\u03c72 from the direct mass measurement by KATRIN as a function of m\u03b2 in Eq. (3.6). The red\nsolid line corresponds to \u2206 \u03c72 from neutrinoless double-beta decay measured by KamLAND-ZEN\nas a function of m\u03b2\u03b2 \u00d7 |M0\u03bd\nXe| in Eq. (3.8). The black solid (dashed) lines indicate \u2206 \u03c72 from the\ncosmological observation of the total neutrino mass by Planck (Planck+DESI).\nfollows a \u03c72 distribution, which in turn requires the Fisher information matrix to be well-conditioned. In the present case, some eigenvalues of the Fisher information matrix can be nearly zero, indicating\nthat certain parameter directions are weakly constrained. As a result, the likelihood function deviates\nfrom a quadratic form near its maximum, leading to a breakdown of the\u03c72 approximation underlying\nWilks\u2019 theorem. In such cases, relying solely on neutrino oscillation data provides a more conservative\nbound, as indicated by \u2020 in Tab.\n\n2503.01399v1\nTo see the correlation between parameters, let us consider the ratio between the solar and atmo-\nspheric mass-squared differences,\nRNO := \u2206m2\n21\n\u2206m2\n31\n= r2\n21 \u2212 1\nr2\n31 \u2212 1 , (2.11)\nfor the NO case and\nRIO := \u2206m2\n12\n\u2206m2\n32\n= 1 \u2212 r2\n21\nr2\n31 \u2212 r2\n21\n, (2.12)\nfor the IO case. Then, by taking the observed values of RNO,IO extracted from NuFIT 6 .0 [34], we\nshow the correlation between \u03b823 and \u03b4CP in Fig. 1. Other parameters and the value of R are varied\nwithin their 3\u03c3 ranges according to NuFIT 6.0 (IC24 with SK-atm), where the 1\u03c3 ranges of \u03b823 are\nindicated by bars. For the NO case, the correlation between the mixing angles and \u03b4CP can be understood as\nfollows. From Eq. (2.10), we find that r31 is at most O(1). Thus, the observed value RNO = O(10\u22122)\nis realized only when r21 \u2243 1, which leads to\ncos \u03b4CP \u2243 cot 2\u03b812 cot 2\u03b823 csc \u03b813 . (2.13)\nUsing the best-fit values of the mixing angles from NuFIT 6.0, we obtain cos\u03b4CP \u2243 0.17, correspond-\ning to \u03b4CP values around \u03c0/2 and 3\u03c0/2 for the NO case. 4\n\nFigure 2: The neutrino mass spectrum as a function of \u03b823 for the NO case (left) and \u03b4CP for the IO\ncase (right), varying the mixing parameters within their 3 \u03c3 ranges based on NuFIT 6.0 ( IC24 with\nSK-atm). For the IO case, \u03b823 is in the vicinity of \u03c0/4. For the IO case, on the other hand, the correlation emerges along \u03b823 \u2243 \u03c0/4, where r21 \u2243 1. Expanding s23 around \u03b823 \u2243 \u03c0/4 as s23 \u2243 1/\n\u221a\n2 + \u03f5 (|\u03f5| \u226a1), we find\nr21 \u2243 1 + 4\n\u221a\n2 cos\u03b4CP\nsin \u03b813 sin 2\u03b812\n\u03f5 + O\n\u0000\n\u03f52\u0001\n. (2.14)\nThus, the observed value RIO = O(10\u22122) can be achieved with a small \u03f5.\nFor both the NO and IO cases, we find that r21 \u2243 1, implying\nm2\n1 , m2\n2 \u226b \u2206m2\n21 , (2.15)\nwhich indicates that m1 and m2 are nearly degenerate. Figure 2 presents the neutrino mass spectrum\nas a function of \u03b823 for the NO case and \u03b4CP for the IO case, with the oscillation parameters\nvaried within their 3 \u03c3 ranges based on NuFIT 6.0 ( IC24 with SK-atm). For the NO case, the\nspectrum exhibits mild degeneracy between m3 and m1,2, whereas in the IO case, the masses are\nfully degenerate, particularly near \u03b823 \u2243 \u03c0/4. This strong degeneracy results in a relatively large\ntotal neutrino mass in the minimal U(1)L\u00b5\u2212L\u03c4 model. As discussed in the next section, cosmological\nobservations impose stringent constraints on the total neutrino mass, placing significant restrictions\non the model\u2019s viability. Before closing this section, we briefly comment on the radiative corrections to the two-zero minor\nstructure of the neutrino mass matrix. At the leading order, this structure remains invariant under\nrenormalization group running below the seesaw scale.", "metadata": {"type": "reasoning", "source": "2503.01399v2.pdf", "context": "Table 4: Constraints on neutrino properties under the two-zero texture condition (m\u03bd)\u00b5\u00b5 = (m\u03bd)\u03c4\u03c4 =\n0 in the NO case.\nOscillation m\u03b2 Cosmology \u2206\u03c72(NO) Confidence Level\nIC19 w/o SK-atm (NuFIT 6.0)\nNuFIT 6.0 - - 3.6 94% CL\nNuFIT 6.0 KATRIN - 4.1 94% CL\u2020\nNuFIT 6.0 - Planck 13 3.2\u03c3\nNuFIT 6.0 - Planck + DESI 57 7.2\u03c3\nIC24 with SK-atm (NuFIT 6.0)\nNuFIT 6.0 - - 2.0 84% CL\nNuFIT 6.0 KATRIN - 2.6 84% CL\u2020\nNuFIT 6.0 - Planck 12 3.0\u03c3\nNuFIT 6.0 - Planck + DESI 55 7.1\u03c3\nTable 5: Same as Tab. 4, but for the IO ca", "quality_score": 8.5}}
{"id": "test_18", "question": "Using Leibniz's formula and equation (2.8), how does the differentiation result change when m \u2265 2?", "golden_answers": ["The result changes to Pm(s,t) + 2msPm\u22121(s,t) + ((m-1)/m)(s^2 + t^2)Pm\u22122(s,t) / (\u221a(s^2 + t^2))^(2m-1)"], "prediction": "The differentiation result changes when m \u2265 2 by introducing additional terms that account for the higher order derivatives of the function involved, as indicated by the structure of the integrals and the application of Leibniz's formula in the context of the specific equations being analyzed.", "f1": 0.0851063829787234, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01270v1\nTaking the L2-scalar product of (5.3) with \u03c9\u03b1 \u2212 \u03c9 we have\nd\ndt\n(\n\u2225\u03c9\u03b1 \u2212 \u03c9\u22252\n2 + \u03b1\u2225\u2207\u03c9\u03b1 \u2212 \u2207\u03c9\u22252\n2\n)\n= \u22122\n\u222b\n(u\u03b1 \u2212 u) \u00b7 \u2207\u03c9 (\u03c9\u03b1 \u2212 \u03c9) dx\n\u2212 2\u03b1\n\u222b\n\u2207(u \u00b7 \u2207\u03c9)(\u2207\u03c9\u03b1 \u2212 \u2207\u03c9) dx.\nThus, by integrating in time and using (1.6) we obtain\n(5.4)\n\u2225\u03c9\u03b1 \u2212 \u03c9\u22252\n2 + \u03b1\u2225\u2207\u03c9\u03b1 \u2212 \u2207\u03c9\u22252\n2 \u2272 \u2225\u03c9\u03b1\n0 \u2212 \u03c90\u22252\n2 + \u03b1\u2225\u2207\u03c9\u03b1\n0 \u2212 \u2207\u03c90\u22252\n2\n+\n\u222b t\n0\n\u222b\n|u\u03b1 \u2212 u||\u2207\u03c9||\u03c9\u03b1 \u2212 \u03c9| dxd\u03c4\n+ \u03b1\n\u222b t\n0\n\u222b\n|\u2207u||\u2207\u03c9||\u2207\u03c9\u03b1 \u2212 \u2207\u03c9| dxd\u03c4\n+ \u03b1\n\u222b t\n0\n\u222b\n|u||D2\u03c9||\u2207\u03c9\u03b1 \u2212 \u2207\u03c9| dxd\u03c4. By using H\u00a8 older inequality and (2.6) we have that\n\u222b t\n0\n\u222b\n|u\u03b1 \u2212 u||\u2207\u03c9||\u03c9\u03b1 \u2212 \u03c9| dxds \u2272\n\u222b t\n0\n\u2225u\u03b1 \u2212 u\u22254\u2225\u2207\u03c9\u22254\u2225\u03c9\u03b1 \u2212 \u03c9\u22252 d\u03c4\n\u2272\n\u222b t\n0\n\u2225u\u03b1 \u2212 u\u2225\n1\n2\n2 \u2225u\u03b1 \u2212 u\u2225\n1\n2\n1, 2\u2225u\u2225\n1\n2\n2, 2\u2225u\u2225\n1\n2\n3, 2\u2225\u03c9\u03b1 \u2212 \u03c9\u22252 d\u03c4\n\u2272\n\u222b t\n0\n\u2225u\u2225s, 2\u2225\u03c9\u03b1 \u2212 \u03c9\u22252\n2 ds \u2272 Cs,T\nu0\n\u222b t\n0\n\u2225\u03c9\u03b1 \u2212 \u03c9\u22252\n2 d\u03c4 \u2272\n\u222b t\n0\n\u2225\u03c9\u03b1 \u2212 \u03c9\u22252\n2 d\u03c4. Moreover, by Proposition 2.5, (1.6), Sobolev embedding, an d Young\u2019s inequality we have\nthat\n\u03b1\n\u222b t\n0\n\u222b\n|\u2207u||\u2207\u03c9||\u2207\u03c9\u03b1 \u2212 \u2207\u03c9| dxd\u03c4 \u2272 \u03b1\n\u222b t\n0\n\u2225\u2207u\u2225\u221e\u2225\u2207\u03c9\u22252\u2225\u2207\u03c9\u03b1 \u2212 \u2207\u03c9\u22252 d\u03c4\n\u2272 T (Cs,T\nu0 )4\u03b1 + \u03b1\n\u222b t\n0\n\u2225\u2207\u03c9\u03b1 \u2212 \u2207\u03c9\u22252\n2 d\u03c4\n\u2272 \u03b1 + \u03b1\n\u222b t\n0\n\u2225\u2207\u03c9\u03b1 \u2212 \u2207\u03c9\u22252\n2 d\u03c4,\n\nCONVERGENCE OF THE EULER-VOIGT APPROXIMATION 14\nand\n\u03b1\n\u222b t\n0\n\u222b\n|u||D2\u03c9||\u2207\u03c9\u03b1 \u2212 \u2207\u03c9| dxd\u03c4 \u2272 \u03b1\n\u222b t\n0\n\u2225u\u2225\u221e\u2225u\u2225s, 2\u2225\u2207\u03c9\u03b1 \u2212 \u2207\u03c9\u22252 d\u03c4\n\u2272 T (Cs,T\nu0 )4\u03b1 + \u03b1\n\u222b t\n0\n\u2225\u2207\u03c9\u03b1 \u2212 \u2207\u03c9\u22252\n2 d\u03c4\n\u2272 \u03b1 + \u03b1\n\u222b t\n0\n\u2225\u2207\u03c9\u03b1 \u2212 \u2207\u03c9\u22252\n2 d\u03c4. Collecting the previous estimate we obtain\n\u2225\u03c9\u03b1 \u2212 \u03c9\u22252\n2 + \u03b1\u2225\u2207\u03c9\u03b1 \u2212 \u2207\u03c9\u22252\n2 \u2272\n\u222b t\n0\n(\n\u2225\u03c9\u03b1 \u2212 \u03c9\u22252\n2 + \u03b1\u2225\u2207\u03c9\u03b1 \u2212 \u2207\u03c9\u22252\n2\n)\nd\u03c4\n+ \u03b1 + \u2225\u03c9\u03b1\n0 \u2212 \u03c90\u22252\n2 + \u03b1\u2225\u2207\u03c9\u03b1\n0 \u2212 \u2207\u03c90\u22252\n2,\nand by Gr\u00a8 onwall lemma\n\u2225\u03c9\u03b1 \u2212 \u03c9\u22252\n2 \u2272 (\u03b1 + \u2225\u03c9\u03b1\n0 \u2212 \u03c90\u22252\n2 + \u03b1\u2225\u2207\u03c9\u03b1\n0 \u2212 \u2207\u03c90\u22252\n2)\n1\n2 . Next, we consider the case 2 < s < 3. The argument is slightly more involved. Given\nu0 \u2208 Hs(T2) with 2 < s < 3, we de\ufb01ne uN\n0 as\nuN\n0 (x) =\n\u2211\n0<|k|\u2264N\n\u02c6u0k eik\u00b7x,\nwhere \u02c6u0k is the Fourier coe\ufb03cients of u0 associated with the wave-number k. Given\ns \u2208 (2, 3) it holds that\n(5.5)\n\u2225uN\n0 \u2225s, 2 \u2264 \u2225 u0\u2225s, 2,\n\u2225uN\n0 \u2225s\u2032, 2 \u2264 Ns\u2032\u2212s\u2225u0\u2225s, 2, s \u2032 > s,\n\u2225uN\n0 \u2212 u0\u2225\u00afs, 2 \u2264 \u2225u0\u2225s, 2\nNs\u2212\u00afs , 0 \u2264 \u00afs <\n\n2503.00873v1\nNow,\nfollowing [BHMN25], we use (8.27), introduce an approximate identity on f and integrate several\ntimes by parts (we will explain this below) to obtain\n(8.30) \u2212\nZZ\nIQ\nP \u03c8S(x) \u2202t f (x) dx = \u2212\nZZ\nIQ\nP \u02dc\u03c8(0; x) \u2202t f (x) dx\n= \u2212\nZ diam(Q)\n0\nZZ\n2Q\n\u2202r[DQ\nt \u02dc\u03c8(r; x)P\u03b3r f (x)] dx dr + b1\n=\nZ diam(Q)\n0\nZZ\n2Q\n\u22022\nr [DQ\nt \u02dc\u03c8(r; x)P\u03b3r f (x)] dx r dr + b1 \u2212b2 =: I + b1 \u2212b2,\nwhere the boundary terms b1 and b2 are defined by\n(8.31) b1 := \u2212\nZZ\n2Q\nIQ\nP \u02dc\u03c8(diam(Q); x)\u2202tP\u03b3diam(Q) f (x) dx =\nZZ\n2Q\nDQ\nt \u02dc\u03c8(diam(Q),x)P\u03b3diam(Q) f (x) dx,\nwhere we have integrated by parts in t recalling that DQ\nt = \u2202t \u25e6IQ\nP (see (8.12)), and in turn\n(8.32) b2 :=\nZZ\n2Q\n\u2202r[DQ\nt \u02dc\u03c8(r; x)P\u03b3r f (x)]\n\f\f\nr=diam(Q) diam(Q) dx. Let us explain (8.30) more carefully. First, note the fact that all the integrals are taken over\n2Q = 100Q0 because \u03b3 \u226an 1/100 and f being supported in Q imply that P\u03b3r f is supported in 2Q\nfor r < diam(Q). Then, the first equality in (8.30) is just (8.27). In turn, in the second inequality,\nwe first use the fundamental theorem of calculus in the variable r (so that we obtain the boundary\nterm b1), and then we integrate by parts in t in the main term, passing the \u2202t from f to IQ\nP (recall\nDQ\nt = \u2202t \u25e6IQ\nP ). This actually makes sense because we will show in (8.38) below that DQ\nt \u02dc\u03c8(r; x) is\nwell defined for r >0. Lastly, the third equality is an elementary 1D integration by parts in r. To continue, we claim, and will prove in (sub)section 8.7 below, that\n(8.33) |b1|+ |b2|\u2272|Q|1/2. This leaves the contribution of the main term I, in which we distribute the r-derivatives:\nI =\nZ diam(Q)\n0\nZZ\n2Q\nDQ\nt \u22022\nr \u02dc\u03c8(r; x) P\u03b3r f (x) dx r dr + 2\nZ diam(Q)\n0\nZZ\n2Q\nDQ\nt \u2202r \u02dc\u03c8(r; x) \u2202rP\u03b3r f (x) dx r dr\n+\nZ diam(Q)\n0\nZZ\n2Q\nDQ\nt \u02dc\u03c8(r; x) \u22022\nr P\u03b3r f (x) dx r dr =: I1 + I2 + I3.(8.34)\nTo deal with these terms, we will use Littlewood-Paley theory. So let us defineQ( j)\nr = Q( j,Q)\nr by\nQ(1)\nr := r DQ\nt P\u03b3r, Q(2)\nr := IQ\nP \u2202rP\u03b3r, Q(3)\nr := r IQ\nP \u22022\nr P\u03b3r . Then, recall that IQ\nP is the smoothly truncated fractional integral operator of order 1 (see (8.11)), and\nis self-adjoint. This implies (by an integration by parts in t, at least when we test against functions\nwith compact suppport, as is our case) that DQ\nt = \u2202t \u25e6IQ\nP is skew-adjoint.\n\n2503.01246v1\nWe proceed to analyze the integral I2m\u22121 by the explicit expression of \u2126 and P2m.\nIt follows that\nI2m\u22121 =\nm\u2211\ni=0\na2m, 2i\n\u222b\n\u2126\n1\n|y|\n(y1 \u2212 1\nj )2i(y2\n2 + y2\n3)m\u2212i\n|y\u2212 zj|4m+1 y2m\u22121\n1 dy\n= 2 \u03c0\nm\u2211\ni=0\na2m, 2i\n\u222b 0\n\u22121\n\u222b 1\n0\n1\u221a\ny2\n1 + r2\n(y1 \u2212 1\nj )2ir2(m\u2212i)\n\u221a\n(y1 \u2212 1\nj )2 + r2\n4m+1 y2m\u22121\n1 rdrdy1\n= \u2212\u03c0\nm\u2211\ni=0\na2m, 2i\n\u222b 1\n0\n\u222b 1\n0\n1\u221a\ny2\n1 + r\n(y1 + 1\nj )2irm\u2212i\n\u221a\n(y1 + 1\nj )2 + r\n4m+1 y2m\u22121\n1 drdy1. We spilt I2m\u22121 into two parts. For 0 \u2264 i\u2264 m, de\ufb01ne\nI(1)\n2m\u22121,i :=\n\u222b 1\n0\n\u222b 1\n0\n(y1 + 1\nj )2irm\u2212i\n((y1 + 1\nj )2 + r)2m+1 y2m\u22121\n1 drdy1,\nI(2)\n2m\u22121,i :=\n\u222b 1\n0\n\u222b 1\n0\n\uf8eb\n\uf8ed 1\n\u221a\ny2\n1 + r\n\u2212 1\u221a\n(y1 + 1\nj )2 + r\n\uf8f6\n\uf8f8 (y1 + 1\nj )2irm\u2212i\n\u221a\n(y1 + 1\nj )2 + r\n4m+1 y2m\u22121\n1 drdy1. Clearly, I2m\u22121 = \u2212\u03c0\u2211 m\ni=0 a2m, 2i(I(1)\n2m\u22121,i + I(2)\n2m\u22121,i ). From the basic knowledge of\ncalculus, it is seen that\nI(1)\n2m\u22121,i =\nm\u2212i\u2211\nl=0\n\u222b 1\n0\n(y1 + 1\nj)2(m\u2212l)y2m\u22121\n1\n(\u222b (y1+ 1\nj )2+1\n(y1+ 1\nj )2\n(\u22121)m\u2212i\u2212lCl\nm\u2212i\n1\ns2m+1\u2212l ds\n)\ndy1\n=\n(m\u2212i\u2211\nl=0\n(\u22121)m\u2212i\u2212lCl\nm\u2212i\n2m\u2212 l\n) \u222b 1\n0\ny2m\u22121\n1\n(y1 + 1\nj )2m dy1 + O(1)\n=\n(m\u2212i\u2211\nl=0\n(\u22121)lCl\nm\u2212i\nm+ i+ l\n)[ \u222b 1\nj +1\n1\nj\n2m\u22121\u2211\nl=0\nCl\n2m\u22121\n(\n\u2212 1\nj\n) 2m\u22121\u2212l 1\ns2m\u2212l ds\n]\n+ O(1)\n= 1\n2mCm\u2212i\n2m\u22121\nln j+ O(1),\nwhere we note that the identity\nm\u2212i\u2211\nl=0\n(\u22121)lCl\nm\u2212i\nm+ i+ l = 1\n2mCm\u2212i\n2m\u22121\n\n10 C. Wu and J. Yang\nholds. Further, direct calculation shows that\n\u23d0\n\u23d0\n\u23d0\n\u23d0\n\u23d0\n\u23d0\n1\n\u221a\ny2\n1 + r\n\u2212 1\u221a\n(y1 + 1\nj )2 + r\n\u23d0\n\u23d0\n\u23d0\n\u23d0\n\u23d0\n\u23d0\n=\n\u23d0\n\u23d0\n\u23d0\n\u23d0\n\u23d0\n\u23d0\n1\nj (2y1 + 1\nj )\n\u221a\ny2\n1 + r\n\u221a\n(y1 + 1\nj )2 + r(\n\u221a\ny2\n1 + r+\n\u221a\n(y1 + 1\nj )2 + r)\n\u23d0\n\u23d0\n\u23d0\n\u23d0\n\u23d0\n\u23d0\n\u2264 1\nj\n1\u221a\ny2\n1 + r\n1\u221a\n(y1 + 1\nj )2 + r\nfor ( y1,r ) \u2208 (0, 1)2, which implies\n|I(2) 2m\u22121,i | \u2264 1\nj\n\u222b 1\n0\n\u222b 1\n0\n1\u221a\ny2\n1 + r\n(y1 + 1\nj )2irm\u2212i\n((y1 + 1\nj )2 + r)2m+1 y2m\u22121\n1 drdy1\n\u2264 1\nj\n\u222b 1\n0\n\u222b 1\n0\n(y1 + 1\nj )2irm\u2212i\n((y1 + 1\nj )2 + r)2m+1 y2m\u22122\n1 drdy1.", "metadata": {"type": "reasoning", "source": "2503.01246v1.pdf", "context": "\u2202m\ns\n(\n(s2 + t2) 1\u221a\ns2 + t2\n)\n= \u2202m\u22121\ns\n( s\u221a\ns2 + t2\n)\n.\nApplying Leibniz\u2019s formula and (2.8), we deduce that for m\u2265 2\n\u2202m\ns\n(\n(s2 + t2) 1\u221a\ns2 + t2\n)\n= Pm(s,t ) + 2 msPm\u22121(s,t ) + ( m\u2212 1)m(s2 + t2)Pm\u22122(s,t )\n(\u221a\ns2 + t2) 2m\u22121", "quality_score": 8.5}}
{"id": "test_19", "question": "What is the expression for the sampling complexity after applying the union bound?", "golden_answers": ["m = \u2126 min p\u2208[k] max p2s2(p) logn, ks(p) logn"], "prediction": "m = \u2126\n{\nmin\np\u2208[k]\nmax\n[p2s2(p) logn, ks(p) logn]\n}", "f1": 1.0, "em": 1.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01335v1\nFor any constant 0 <\n\u03b4 <1 satisfying\n\u03b42 \u2265 2 \u2212 2\ns\u0012\n1 \u2212 \u03b32\n4\n\u00133\n+ \u03b32\n4 , (48)\nStep 4 produces a signal estimation z falling into the\n\u03b4-neighborhood of x, i.e.,\ndist(z, x) \u2264 \u03b4\u2225x\u2225 (49)\nwith probability exceeding 1 \u2212 2e\u2212c\u03b4m providing that\nm \u2265 C\u03b4k log n, where c\u03b4 and C\u03b4 are numerical constants\ndepending on \u03b4. Now we are proceeding to prove the theorems in Section III.\nProof of Theorem 1. Collecting all the results in Proposition 1\n\u2013 4 with p\u2032 = p, we can show that the sampling complexity is\nm = \u2126\n\u0000\nmax\n\b\np2s2(p), ks(p)\n\t\nlog n\n\u0001\n, (50)\nand the overall probability is 1 \u2212 e\u2212cm. Since we take the\noptimal value for p as\npopt = arg minp\u2208[k] max\n\b\np2s2(p), ks(p)\n\t\n,\nwe obtain the desired results. Proof of Theorem 2. For each fixed p \u2208 [k], collecting all the\nresults in Proposition 1 \u2013 4 with p\u2032 = p, we can show that\nthe final estimate z falls into the \u03b4-neighborhood of x with\nprobability exceeding 1 \u2212 e\u2212cm when\nm = \u2126\n\u0000\nmax\n\b\np2s2(p), ks(p)\n\t\nlog n\n\u0001\n. To ensure that at least one estimate z satisfies dist(z, x) \u2264\n\u03b4\u2225x\u2225, we can apply the union bound for all p \u2208 [k]. Then the\nsampling complexity can be reduced to\nm = \u2126\n\u0012\nmin\np\u2208[k]\nmax\n\b\np2s2(p) logn, ks(p) logn\n\t\u0013\n,\nand the probability is at least 1\u2212ke\u2212cm. It is actually 1\u2212e\u2212cm\nif we take a sufficiently large constant c since m > k. Thus\nthe proof is complete. Proof of Theorem 3. For any p \u2208 [k], denote S\u2032 as the set\ncorresponding to the largest p diagonal elements of Z. Note\nthat S0 corresponds to the largest k diagonal elements of Z.\nIt holds that\n\u2225xS0 \u22252\n\u2225x\u22252\n(a)\n\u2265 \u2225xS\u2032\u22252\n\u2225x\u22252\n(b)\n\u2265 1\n2s(p), (51)\nwhere (a) is because k \u2265 p, and (b) holds via applying\nProposition 1 on the set S\u2032 when \u2265 Cp2s2(p) logn.\nThen, from the results above and in Proposition 2 \u2013 4 (with\np\u2032 = k), it holds that for any p \u2208 [k], when\nm = \u2126\n\u0000\nmax\n\b\np2s2(p) logn, ks2(p) logn\n\t\u0001\n, (52)\nthe final estimate z falls into the \u03b4-neighborhood of x with\nprobability exceeding 1 \u2212 e\u2212cm. This result also holds for all\np \u2208 [k] since we can take the union bound, and the probability\nwill be 1 \u2212 ke\u2212cm. It is actually 1 \u2212 e\u2212cm if we take a\nsufficiently large constant c since m > k.\nNote that the choice of p \u2208 [k] is arbitrary. Therefore, we\ncan choose the best p to make the sampling complexity (52)\nsmallest, which becomes\nm = \u2126\n\u0012\nmin\np\u2208[k]\nmax\n\b\np2s2(p) logn, ks2(p) logn\n\t\u0013\n, (53)\nThe remaining thing is to show that (53) is equivalent to (43). As stated following Definition 2, ps(p) is monotonously\nincreasing, and s(p) is monotonously decreasing.\n\n2503.01335v1\nIn the following, we introduce several results concentrating on\nthe effect of the ceiling sign on the sampling complexity.\nLemma 1. For the ceiling function in the asymptotic notation,\nwe have\n\u2126(\u2308\n\u221a\nk\u2309) = \u2126(\n\u221a\nk) (A.4)\n\u2126(s(\u2308\n\u221a\nk\u2309) = \u2126(s(c\u2308\n\u221a\nk\u2309)), (A.5)\nwhere c is a fixed positive integer. Proof. Note that\n\u221a\nk \u2264 \u2308\n\u221a\nk\u2309 \u2264\n\u221a\nk + 1, then (A.4) can be\neasily derived from the following relationship. lim\nk\u2192\u221e\n\u221a\nk + 1\u221a\nk\n= 1. As for (A.5), recall from the definition of s(p), we have\ns(c\u2308\n\u221a\nk\u2309) = \u2225x\u22252\nPc\u2308\n\u221a\nk\u2309\nj=1 |x(j)|2\n. Since x(j)\u2019s are the rearrangement of the entries of x with\na descend order in their modulus, the summation in the\ndenominator can be estimated as\n\u2308\n\u221a\nk\u2309X\nj=1\n|x(j)|2 \u2264\nc\u2308\n\u221a\nk\u2309X\nj=1\n|x(j)|2 \u2264 c\n\u2308\n\u221a\nk\u2309X\nj=1\n|x(j)|2,\nwhich in turn yields\n1\nc s(\u2308\n\u221a\nk\u2309) \u2264 s(c\u2308\n\u221a\nk\u2309) \u2264 s(\u2308\n\u221a\nk\u2309). In that c is a constant as k and n tend to infinity, (A.5) is a\nnatural derivation. We then introduce the Bernstein inequality for complex\ncases. 10\nLemma 2. Let Xi be independent, mean-zero complex sub-\nexponential random variables for i \u2208 [m], then for any \u03f5 >0,\nwe have\nP\n \f\f\f\f\f\n1\nm\nmX\ni=1\nXi\n\f\f\f\f\f \u2265 \u03f5\n! \u2264 4 exp\n\u0012\n\u2212cm min\n\u001a \u03f52\nK2 , \u03f5\nK\n\u001b\u0013\n,\nwhere K = maxi\u2208[m] \u2225Xi\u2225\u03c81 and c is the numerical constant. Next, the difference between \u03bb2 and \u2225x\u22252 is analyzed. Lemma 3. Given k-sparse signal x, for any constant \u03b2 >0,\nsuppose that ai\u2019s are complex Gaussian random variables. Then provided that m \u2265 C\u03b2\u03ba2,\n(1 \u2212 \u03b2\n\u03ba)\u2225x\u22252 \u2264 1\nm\nmX\ni=1\n|a\u2217 i x|2 \u2264 (1 + \u03b2\n\u03ba)\u2225x\u22252\nholds with probability at least 1 \u2212 e\u2212c\u03b2m, where \u03ba can be\nsubstitute by any quantity satisfying \u03b2\n\u03ba < 1, such as ps(p),\nand c\u03b2 and C\u03b2 are numerical constants determined by \u03b2.\nProof. It is easy to find that |a\u2217\ni x|2\u2019s are independent sub-\nexponential random variables with mean E[|a\u2217 i x|2] = \u2225x\u22252\nand c0\u2225x\u22252 as their squared sub-exponential norms. Hence,\nemploying Bernstein\u2019s inequality yields\nP\n \f\f\f\f\f\n1\nm\nmX\ni=1\n|a\u2217 i x|2 \u2212 \u2225x\u22252\n\f\f\f\f\f > \u03b2\n\u03ba\u2225x\u22252\n! \u2264 2 exp\n\u0012\n\u2212C\u03b2m min\n\u001a \u03b22\n\u03ba2K2 , \u03b2\n\u03baK\n\u001b\u0013\n,\nwhere K = maxi\u2208[m] \u2225|a\u2217\ni x|2\u2225\u03c81 /\u2225x\u22252 and C\u03b2 is the numer-\nical constant. Thus we obtain the desired result. Finally, we introduce a useful lemma that measures the\nsimilarity between the exponential spectral Z and its estimator\nE[Z0].\nLemma 4. Suppose a constant \u03b7 >0 and a positive integer\nq \u2264 k. For all S \u2286 [n] satisfying |S| = q, let T be a subset of\nCn such that \u2225z\u2225 \u22641 holds for all z \u2208 T. Given any constant\n\u03f5 \u2208 (0, 1), let N(T, \u03f5) be the covering number\n\n2503.00345v1\nBy union bound, we know that with probability at least 1 \u2212 |\u03a62\n\u03b1|\u03b41, for\nany \u00af\u03d5 \u2208 \u03a62\n\u03b1, the induced \u00afUi(\u00af\u03d5) satisfy inequality (10), therefore\n1\n2\n\r\r\r \u02c6ft \u2212 f\u03b8\n\r\r\r\n2\n2,Et\n\u2264\nMX\ni=1\nD\n\u03b7t,i, \u02dcf(i)\nt (Xt,i)\nE\n(12)\n=\nMX\ni=1\n\u03b7\u22a4\nt,i \u00b7 UiQi \u02dcwt,i =\nMX\ni=1\n\u03b7\u22a4\nt,i \u00b7 (Ui \u2212 \u00afUi + \u00afUi)Qi \u02dcwt,i (13)\n=\nMX\ni=1\n\u03b7\u22a4\nt,i \u00b7 \u00afUiQi \u02dcwt,i +\nMX\ni=1\n\u03b7\u22a4\nt,i \u00b7 (Ui \u2212 \u00afUi)Qi \u02dcwt,i (14)\n\u2264\nvuut\nMX\ni=1\n\r\r\r \u00afU\u22a4\ni \u03b7t,i\n\r\r\r\n2\n\u00b7\nvuut\nMX\ni=1\n\u2225Qi \u02dcwt,i\u22252 +\nMX\ni=1\nD\n\u03b7t,i, \u02dcft \u2212 \u00afft\nE\n(15)\n\u2264\nvuut\nMX\ni=1\n\r\r\r \u00afU\u22a4\ni \u03b7t,i\n\r\r\r\n2\n\u00b7\nvuut\nMX\ni=1\n\u2225UiQi \u02dcwt,i\u22252 +\nMX\ni=1\nD\n\u03b7t,i, \u02dcft \u2212 \u00afft\nE\n(16)\n=\nvuut\nMX\ni=1\n\r\r\r \u00afU\u22a4\ni \u03b7t,i\n\r\r\r\n2\n\u00b7\n\r\r\r \u02dcf\n\r\r\r\n2,Et\n+\nMX\ni=1\nD\n\u03b7t,i, \u02dcft \u2212 \u00afft\nE\n(17)\n\u2264\np\n2Mk + log(1/\u03b41) \u00b7\n\r\r\r \u02dcf\n\r\r\r\n2,Et\n+\nvuut\nMX\ni=1\n\u2225\u03b7t,i\u22252 \u00b7\n\r\r\r \u02dcft \u2212 \u00afft\n\r\r\r\n2,Et\n(18)\nThe first term of (18) comes from (10), and the second term is from Cauchy inequality. We\nassign \u03b4t = \u03b42\nT failure probability for event\n\u03c9t :\nMX\ni=1\n\u2225\u03b7t,i\u22252 \u2265 Mt + log(2Mt/\u03b4t). 29\n\nTowards Understanding the Benefit of Multitask Representation Learning\nBy union bound, we have\nP\n \n\u2203t \u2208 [T] :\nMX\ni=1\n\u2225\u03b7t,i\u22252 \u2265 Mt + log(2Mt2/\u03b42)\n! \u2264\nTX\nt=1\n\u03b4t \u2264 \u03b42. (19)\nNext we will give a bound for \u2225 \u02dcft \u2212 \u00afft\u22252,Et. \u02dcft \u2212 \u00afft\n\r\r\r\n2\n2,Et\n=\nMX\ni=1\ntX\ns=1\n\f\f\f\u02dc\u03d5t(xs,i)\u22a4 \u02dcws,i \u2212 \u00af\u03d5t(xs,i)\u22a4 \u02dcws,i\n\f\f\f\n2\n(20)\n=\nMX\ni=1\ntX\ns=1\n\f\f\f(\u02dc\u03d5t(xs,i) \u2212 \u00af\u03d5t(xs,i))\u22a4 \u02dcws,i\n\f\f\f\n2\n(21)\n\u2264\nMX\ni=1\ntX\ns=1\n\r\r\r\u02dc\u03d5t(xs,i) \u2212 \u00af\u03d5t(xs,i)\n\r\r\r\n2\n2\n\u00b7 \u2225\u02dcws,i\u22252\n2 (22)\nAccording to our assumption, we know \u2225 \u02dcws,i\u22252 \u2264 2\u2225ws,i\u22252 + 2\u2225 \u02c6ws,i\u22252 \u2264 4k, from (11) we\nknow\n\r\r\r\u02dc\u03d5t(xs,i) \u2212 \u00af\u03d5t(xs,i)\n\r\r\r\n2\n\u2264 \u03b1, hence\n\r\r\r \u02dcft \u2212 \u00afft\n\r\r\r\n2\n2,Et\n\u22644Mtk\u03b12 (23)\nPlug (19) and (23) back into (18), we know with probability at least 1 \u2212 \u03b42 \u2212 |\u03a62\n\u03b1|\u03b41, for any\nt \u2208 N\n1\n2\n\r\r\r \u02dcft\n\r\r\r\n2\n2,Et\n\u2264\np\n2Mk + log(1/\u03b41) \u00b7\n\r\r\r \u02dcft\n\r\r\r\n2,Et\n+\np\nMt + log(2Mt2/\u03b42) \u00b7\n\u221a\n4Mtk\u03b12 (24)\nSome simple algebraic transform gives\n\r\r\r \u02c6ft \u2212 f\u03b8\n\r\r\r\n2\n2,Et\n=\n\r\r\r \u02dcft\n\r\r\r\n2\n2,Et\n\u2264 6(2Mk + log(1/\u03b41)) + 8\u03b1\np\nMtk(Mt + log(2Mt2/\u03b42)) (25)\nLet \u03b41 = \u03b4/|\u03a62\n\u03b1|, \u03b42 = \u03b4, and notice log |\u03a62\n\u03b1| \u22642 log (N(\u03a6, \u03b1,\u2225 \u00b7 \u2225\u221e)), we conclude that with\nprobability at least 1 \u2212 2\u03b4, for every t \u2208 N\n\r\r\r \u02c6ft \u2212 f\u03b8\n\r\r\r\n2\n2,Et\n\u2264 12Mk + 12 log (N(\u03a6, \u03b1,\u2225 \u00b7 \u2225\u221e)/\u03b4) + 8\u03b1\np\nMtk(Mt + log(2Mt2/\u03b4)) (26)\nwhere the right handside is exactly our defined \u03b2t(\u03a6, \u03b1, \u03b4), hence our conclusion holds. Lemma 2. If (\u03b2t \u2265 0 | t \u2208 N) is a nondecreasing sequence and\nFt :=\nn\nf \u2208 F\u2297M : \u2225f \u2212 \u02c6fLS\nt \u22252,Et \u2264\np\n\u03b2t\no\n.", "metadata": {"type": "factual", "source": "2503.01335v1.pdf", "context": "\u03b4\u2225x\u2225, we can apply the union bound for all p \u2208 [k]. Then the\nsampling complexity can be reduced to\nm = \u2126\n\u0012\nmin\np\u2208[k]\nmax\n\b\np2s2(p) logn, ks(p) logn\n\t\u0013\n,\nand the probability is at least 1\u2212ke\u2212cm. It is actually 1\u2212e\u2212cm\nif we take a sufficiently large constant c since m > k. Thus\nthe proof is complete.\nProof of Theorem 3. For any p \u2208 [k], denote S\u2032 as the set\ncorresponding to the largest p diagonal elements of Z. Note\nthat S0 corresponds to the largest k diagonal elements of Z.\nIt holds that\n\u2225xS0 \u22252", "quality_score": 8.5}}
{"id": "test_20", "question": "What is the purpose of the Under-Segmentation Score (USS) and the Over-Segmentation Score (OSS)?", "golden_answers": ["To evaluate if the model fails to detect certain regions or assigns excessive labels to a class."], "prediction": "The purpose of the Under-Segmentation Score (USS) is to evaluate if the model fails to detect certain regions, indicating under-segmentation, while the Over-Segmentation Score (OSS) assesses if the model over-predicts a class, leading to over-segmentation.", "f1": 0.5, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01248v1\nY|`| D1\nY \u02c6Y | |D\u02c6Y Y|`| DY \u02c6Y | (8)\nSpecial attention is needed for fluid evaluation. For True\nNegative(TN) cases where both ground truth and predicted\nfluid are absent, the NSD score should be the correct pre-\ndiction. For False Positive(FP) and False Negative(FN) cases\nwhere the fluid is only present in one of the ground truths\nor predicted segmentations, the NSD score should be zero as\nthe incorrect prediction. We set \u03c4 to 10 pixels for all classes,\nroughly 3% of the shortest image edge. The model perfor-\nmance will be evaluated without any of the post-processing\nsteps mentioned in the original papers. Additionally, we define the Under-Segmentation Score\n(USS) and the Over-Segmentation Score (OSS) to evaluate if\nthe model fails to detect certain regions or assigns excessive\nlabels to a class. Given the confusion matrix for N classes:\nCM \u201c\n\u00bb\n\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2013\nTP1 FP1,2 FP1,3 . . .FP1,N FN2,1 TP2 FP2,3 . . .FP2,N FN3,1 FN3,2 TP3 . . .FP3,N\n... ... ... ... ...\nFNN,1 FNN,2 FNN,3 . . . TPN\nfi\nffiffiffiffiffiffiffifl\n(9)\nWe compute the USS and OSS for certain class C as:\nUSS C \u201c\n\u0159\n@j\u2030C CMrC, js\u0159CMrC, :s (10)\nOSSC \u201c\n\u0159\n@i\u2030C CMri, Cs\u0159CMr:, Cs (11) A higher USS score indicates that a significant portion of\nthe ground truth class C was not detected, leading to under-\nsegmentation, while a higher OSS score suggests that the\nmodel over-predicts class C, leading to over-segmentation. G. Thickness Analysis\nLayer thickness computation is performed using the K-\nNearest Neighbors (K-NN) algorithm. The layer boundaries\nare converted into 3D point clouds. For each data point on\nthe upper layer, the closest corresponding point on the lower\nlayer is identified based on Euclidean distance. Due to their\nunbounded nature on one side, the Vitreous and Choroid layers\nare excluded from these calculations. Given the anatomical\ncomplexity of the foveal pit, the central region thickness\nis excluded from the analysis to ensure more reliable and\ninterpretable measurements. The thickness of fluid and hyperreflective foci (HRF) re-\ngions is computed through direct accumulation, which is\nsubsequently projected onto an en-face view for visualization. The Early Treatment Diabetic Retinopathy Study (ETDRS)\ngrid is employed to assess thickness variations systematically\nacross different macular regions. As depicted in Figure 3,\nthis grid divides the macula into three concentric circles with\ndiameters of 1mm, 3mm, and 6mm, all centered on the fovea. These circles define the central, inner, and outer subfields,\nsubdivided into four quadrants: superior, inferior, nasal, and\ntemporal.\nFig. 3: ETDRS diagram for both left and right eyes. The diameters of\nthe central circle, inner ring, and outer ring were 1 mm, 3 mm, and 6\nmm, respectively. Nine subfields are numbered and named as follows:\n1-CS(Central Subfield), 2-SI(Superior Inner), 3-NI(Nasal Inner), 4-\nII(Inferior Inner), 5-TI(Temporal Inner), 6-SO(Superior Outer), 7-\nNO(Nasal Outer), 8-IO(Inferior Outer), 9-TO(Temporal Outer). III. R ESULTS\nA. Segmentation\nTable II presents the segmentation results for four models,\nwith values averaged across five-fold cross-validation. Tables\nIIa and IIb separately report the DSC and NSD metrics.\n\nComprehensive Evaluation of OCT-based Automated Segmentation of Retinal Layer, Fluid and Hyper-Reflective Foci: Impact on Clinical Assessment of Diabetic Retinopathy Severity\nFor\nTrue Negative(TN) cases where both ground truth and\npredicted fluid are absent, the NSD score should be\nthe correct prediction. For False Positive(FP) and False\nNegative(FN) cases where the fluid is only present in one\nof the ground truths or predicted segmentations, the NSD\nscore should be zero as an incorrect prediction. We set\n\u03c4 to 10 pixels for all classes, roughly 3% of the shortest\nimage edge. The model performance will be evaluated\nwithout any of the post-processing steps mentioned in\nthe original papers. Additionally, we defined the Under-Segmentation\nScore (USS) and the Over-Segmentation Score (OSS)\nto evaluate if the model fails to detect certain regions or\nassigns excessive labels to a class. Given the confusion\nmatrix for N classes:\nCM \u201c\n\u00bb\n\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2013\nTP1 FP1,2 FP1,3 . . .FP1,N FN2,1 TP2 FP2,3 . . .FP2,N FN3,1 FN3,2 TP3 . . .FP3,N\n... ... ... ... ...\nFNN,1 FNN,2 FNN,3 . . . TPN\nfi\nffiffiffiffiffiffiffifl\n(9)\nWe computed the USS and OSS for certain class C\nas:\nUSS C \u201c\n\u0159\n@j\u2030C CMrC, js\u0159CMrC, :s (10)\nOSSC \u201c\n\u0159\n@i\u2030C CMri, Cs\u0159CMr:, Cs (11) A higher USS score indicates that a significant portion\nof the ground truth class C is not detected, leading to\nunder-segmentation, while a higher OSS score suggests\nthat the model over-predicts class C, leading to over-\nsegmentation. We used a heuristic cutoff value of 0.2\nto determine if there is under-segmentation or over-\nsegmentation. 6\nG. Retinal Layer Thickness Analysis\nLayer thickness computation was performed using\nthe K-Nearest Neighbors (K-NN) algorithm. The layer\nboundaries were converted into 3D point clouds. For\neach data point on the upper layer, the closest corre-\nsponding point on the lower layer was identified based\non Euclidean distance. The distance is properly adjusted\nby the voxel dimension along each axis. The thickness\nmaps are resized to the resolution of 350 \u02c6350 for\nconsistent representation. The vitreous and choroid lay-\ners were excluded from these calculations due to their\nunbounded nature on one side. Given that the inner reti-\nnal layers\u2014including RNFL, GCL+IPL, INL, OPL, and\nONL+IS\u2014converge at the foveal pit, the central region\nwas excluded from their thickness analysis to ensure\nmore reliable and anatomically consistent measurements. The Early Treatment Diabetic Retinopathy Study (ET-\nDRS) grid was employed to assess thickness variations\nsystematically across different macular regions. As de-\npicted in Figure 2, this grid divides the macula into three\nconcentric circles with diameters of 1 mm, 3 mm, and\n6mm, all centered on the fovea. These circles define the\ncentral, inner, and outer subfields, subdivided into four\nquadrants: superior, inferior, nasal, and temporal.\nFig. 2: ETDRS diagram for both left and right eyes. The diam-\neters of the central circle, inner ring, and outer ring are 1 mm, 3\nmm, and 6 mm, respectively. Nine subfields are numbered and\nnamed as follows: 1-C(Central field), 2-SI(Superior Inner), 3-\nNI(Nasal Inner), 4-II(Inferior Inner), 5-TI(Temporal Inner), 6-\nSO(Superior Outer), 7-NO(Nasal Outer), 8-IO(Inferior Outer),\n9-TO(Temporal Outer).\n\n2503.01248v2\nFor True\nNegative(TN) cases where both ground truth and predicted\nfluid are absent, the NSD score should be the correct pre-\ndiction. For False Positive(FP) and False Negative(FN) cases\nwhere the fluid is only present in one of the ground truths\nor predicted segmentations, the NSD score should be zero as\nthe incorrect prediction. We set \u03c4 to 10 pixels for all classes,\nroughly 3% of the shortest image edge. The model perfor-\nmance will be evaluated without any of the post-processing\nsteps mentioned in the original papers. Additionally, we define the Under-Segmentation Score\n(USS) and the Over-Segmentation Score (OSS) to evaluate if\nthe model fails to detect certain regions or assigns excessive\nlabels to a class. Given the confusion matrix for N classes:\nCM \u201c\n\u00bb\n\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2013\nTP1 FP1,2 FP1,3 . . .FP1,N FN2,1 TP2 FP2,3 . . .FP2,N FN3,1 FN3,2 TP3 . . .FP3,N\n... ... ... ... ...\nFNN,1 FNN,2 FNN,3 . . . TPN\nfi\nffiffiffiffiffiffiffifl\n(9)\nWe compute the USS and OSS for certain class C as:\nUSS C \u201c\n\u0159\n@j\u2030C CMrC, js\u0159CMrC, :s (10)\nOSSC \u201c\n\u0159\n@i\u2030C CMri, Cs\u0159CMr:, Cs (11) A higher USS score indicates that a significant portion of\nthe ground truth class C was not detected, leading to under-\nsegmentation, while a higher OSS score suggests that the\nmodel over-predicts class C, leading to over-segmentation. G. Thickness Analysis\nLayer thickness computation is performed using the K-\nNearest Neighbors (K-NN) algorithm. The layer boundaries\nare converted into 3D point clouds. For each data point on\nthe upper layer, the closest corresponding point on the lower\nlayer is identified based on Euclidean distance. The distance\nis properly adjusted by the voxel dimension along each axis. The thickness maps are resized to the resolution of 350 \u02c6350\nfor consistent representation. Due to their unbounded nature\non one side, the Vitreous and Choroid layers are excluded\nfrom these calculations. Given the anatomical complexity\nof the foveal pit, the central region thickness is excluded\nfrom the analysis to ensure more reliable and interpretable\nmeasurements. The thickness of fluid and hyperreflective foci (HRF) re-\ngions is computed through direct accumulation, which is\nsubsequently projected onto an en-face view for visualization. The Early Treatment Diabetic Retinopathy Study (ETDRS)\ngrid is employed to assess thickness variations systematically\nacross different macular regions. As depicted in Figure 3,\nthis grid divides the macula into three concentric circles with\ndiameters of 1mm, 3mm, and 6mm, all centered on the fovea. These circles define the central, inner, and outer subfields,\nsubdivided into four quadrants: superior, inferior, nasal, and\ntemporal.\nFig. 3: ETDRS diagram for both left and right eyes. The diameters of\nthe central circle, inner ring, and outer ring were 1 mm, 3 mm, and 6\nmm, respectively. Nine subfields are numbered and named as follows:\n1-CS(Central Subfield), 2-SI(Superior Inner), 3-NI(Nasal Inner), 4-\nII(Inferior Inner), 5-TI(Temporal Inner), 6-SO(Superior Outer), 7-\nNO(Nasal Outer), 8-IO(Inferior Outer), 9-TO(Temporal Outer). III. R ESULTS\nA. Segmentation\nTable II presents the segmentation results for four models,\nwith values averaged across five-fold cross-validation.", "metadata": {"type": "factual", "source": "2503.01248v4.pdf", "context": "the original papers.\nAdditionally, we defined the Under-Segmentation\nScore (USS) and the Over-Segmentation Score (OSS)\nto evaluate if the model fails to detect certain regions or\nassigns excessive labels to a class. Given the confusion\nmatrix for N classes:\nCM \u201c\n\u00bb\n\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2013\nTP1 FP1,2 FP1,3 . . .FP1,N\nFN2,1 TP2 FP2,3 . . .FP2,N\nFN3,1 FN3,2 TP3 . . .FP3,N\n... ... ... ... ...\nFNN,1 FNN,2 FNN,3 . . . TPN\nfi\nffiffiffiffiffiffiffifl\n(9)\nWe computed the USS and OSS for certain class C\nas:\nUSS C \u201c\n\u0159\n@j\u2030C", "quality_score": 8.5}}
{"id": "test_21", "question": "What is a crucial property of any magnetic material, according to the text?", "golden_answers": ["The critical temperature for magnetic order"], "prediction": "A crucial property of any magnetic material is the maximum current, which sets a maximum toroidal strength.", "f1": 0.10526315789473682, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01409v2\nTwo of the components identified as important by Kojima\n(2024) for the failure problem, namely those in the r\u03b8 (left)\nand \u03b8\u03b8 \u2212 \u03d5\u03d5 (right) directions, are shown in Figure 6 for\nBp = 0.5b. Attention has been restricted to the \u2018crust\u2019 0 .9 \u2a7d\nr \u2a7d 1 and, for simplicity, only poloidal stresses are shown\n(i0 = 0). The ratios span the range 0 .87 \u2272 R \u2272 1.08 with\nthe lower and upper limits reached near polar ( \u03b8 \u2248 0, \u03c0) and\nequatorial (\u03b8 \u2248 \u03c0/2) colatitudes, respectively, at the base of\nthe crust ( r \u2248 0.9). The fact that R exceeds unity near the\nequator implies one may expect more frequent failures there\nrelative to the Maxwell case, with the reverse applying near\nthe poles, since the elastic stress should counterbalance the\nelectromagnetic stress. This is likely to skew the anticipated\nwaiting time distribution for flares to later times, as Hall\ndrift tends to tangle field lines near the pole and hence build\nstresses there (see figure 2 in Perna & Pons 2011). This will\nbe investigated in future work. 5.5 Magnetic (anti)-glitches\nAs first described by Ioka (2001), rapid changes to the\nquadrupolar ellipticity of a magnetar may bring about glitch-\nlike activity. By angular momentum conservation, a sudden\nreequilibriation \u03f5i \u2192 \u03f5f would lead to a fractional change in\nf of order\n\u03b4f f \u2248 2\n3 (\u03f5i \u2212 \u03f5f) . (49)\nWhile this model was discussed by Garcia & Ranea-Sandoval\n(2015) in the context of theanti-glitch seen in 1E 2259+586, a\npositive glitch is also possible if \u03f5i > \u03f5f (Mastrano, Suvorov &\nMelatos 2015). In the latter case, a dynamical decay (growth)\nin the poloidal (toroidal) sector could be expected. Such a\nrapid rearrangement would likely be accompanied by high-\nenergy activity; for instance, crustal yielding could lead to\na local relaxation in the magnetic field and hence a small\nchange in \u03f5. In the BI theory, maximum values for the toroidal elliptic-\nity also imply an upper limit to the size of a magnetically-\ninduced glitch. For SGR 1935+2154 with Bp \u2248 4 \u00d7 1014 G,\nresults from Tab. 4.1 indicate a maximum shift of \u2248 5\u00d710\u22126\nfor b = 1016 G. Using equation (49), this implies a maximum\nglitch magnitude of \u03b4f \u2248 (b/1016 G)2 \u00b5Hz for P = 3.25 s.\nMNRAS 000, 1\u201315 (?)\n\n12 Arthur G. Suvorov & Jos\u00b4 e A. Pons\nFigure 6.Dimensionless ratios of BI-to-Maxwell stresses (48) in the r\u03b8 (left) and \u03b8\u03b8 \u2212 \u03d5\u03d5 (right) directions within a \u2018crust\u2019 for the field\n(27), with redder shades indicating a greater ratio R. The classical polar strength is fixed as Bp = b/2. This is about half the size of the large glitch seen in this\nobject prior to the release of a fast radio burst in 2020 Oc-\ntober ( \u03b4f \u2248 1.8+0.7\n\u22120.5 \u00b5Hz; Younes et al. 2023) suggesting a\nfloor b \u2a7e\n\u221a\n2 \u00d7 1016 G, assuming magnetic rearrangement\nwas responsible for the burst and glitch. 6 DISCUSSION\n\n2503.01409v2\n(13)\nThe formula (13) has important implications for the magnetic\nfields pertaining to magnetars, as it imposes the bound\nI(\u03c8)2 < b2r2 sin2 \u03b8, (14)\nelse the toroidal field diverges and subsequently becomes\nimaginary. Requiring that the toroidal flux function I(\u03c8)\nnot exceed some maximum value (14), and also tend to zero\naround the poles and origin, implies a range of viable energy\npartitions (i.e., limits on |i0|) for a given poloidal geometry,\nset by \u03c8; see Sec. 3.2. One may physically interpret inequal-\nity (14) by noticing that regularising the classical electron\nself-energy must set a maximum current, and hence maxi-\nmum toroidal strength. In the toroidally-dominated limit, the\nright-hand side of (7) behaves as \u223c T/\np\n1 + T2/b2r2 sin2 \u03b8 \u2a7d\nbr sin \u03b8, which cannot match I(\u03c8) beyond some cutoff. A sim-\nilar conclusion should hold in non-axisymmetry using a gen-\neral Helmholtz decomposition for B.\n2.3 Parameterised post-Maxwellian theory\nRather than working with some specific theory, one can in-\ntroduce a set of free parameters so as to consider a theory-\nagnostic range of corrections in the form\nL(F2) = \u2212F2 + \u03b1PMF4 + \u03b1PPMF6 + O(F8), (15)\nfor some hierarchy of parameters \u03b1PM, \u03b1PPM, ..., with units\nof Gauss \u22122, Gauss \u22124, and so on. These coefficients can be\nread off from Maclaurin expansions for any given theory. At leading order, one can also invert expression (7) analyt-\nically using the cubic root formula. A critical feature of the\nMNRAS 000, 1\u201315 (?)\n\n4 Arthur G. Suvorov & Jos\u00b4 e A. Pons\nMaxwell\nBI; exact\nBI;\u2134(F 4) BI;\u2134(F 6)\n0.0 0.2 0.4 0.6 0.8 1.0\n-0.6\n-0.5\n-0.4\n-0.3\n-0.2\n-0.1\n0.0\nB/b\nL/b2\nFigure 1.Comparison between the (normalised) BI function (11),\nat either exact (dotted, black), post-Maxwellian (solid, blue), or\npost-post-Maxwellian (solid, red) orders (12), as compared to the\nMaxwell case (dashed, black).\nsolution is that there is similarly a square root term in the\ndenominator of T as in the BI case (13), which behaves as\nTPM(r, \u03b8) \u221d\nnh\n\u03b1PMr4 csc2 \u03b8I(\u03c8)2\n\u2212 4\n27\n\u0000\nr2 \u2212 \u03b1PM csc2 \u03b8\u2207\u03c8 \u00b7 \u2207\u03c8\n\u00013 i1/2\n\u2212 r2\u03b11/2\nPM csc \u03b8I(\u03c8) o\u22121/3\n.\n(16) The above implies a maximum limit to the toroidal field\nstrength for a different reason than for the BI case, namely\nthat L\u2032(F2) can tend to zero. Of course, higher-order coun-\nterterms or non-polynomial turnovers could neutralise this\nfeature. 3 HYDROMAGNETIC STRUCTURE We are now in a position to tackle one of the main goals of\nthis work: to estimate the impact of structural changes to\nmagnetar interiors due to strong magnetic fields in NLED.\n3.1 Force-free poloidal fields\nWe begin with a simplified version of the problem, where the\nleft-hand side of (6) is ignored together with currents, viz.\n0 = \u02dc\u2206\u03c8. (17)\nA necessary step towards approaching the fluid problem in-\nvolves solving for a force-free configuration via equation (17),\nas the latter defines matching conditions at the stellar sur-\nface.\n\n2503.00487v1\nMagnetic In-\nteractions in Molecules and Highly Correlated Materials:Physical Content, Analytical\nDerivation, and Rigorous Extraction ofMagnetic Hamiltonians.Chem. Rev.2014, 114,\n429 \u2013 492. (37) Neese, F.; Solomon, E. I. In Magnetism: Molecules to Materials IV ; Miller, J. S.,\nDrillon, M., Eds.; Wiley, 2002; Chapter 9, pp 345 \u2013466. (38) Maganas, D.; Sottini, S.; Kyritsis, P.; Groenen, E. J. J.; Neese, F. Theoretical Analysis\nof the Spin Hamiltonian Parameters in (CoS4)-S-(II) Complexes, Using Density Func-\ntional Theory and Correlated Ab Initio Methods.Inorg. Chem.2011, 50, 8741\u20138754. (39) Maurice, R.; Bastardis, R.; Graaf, C.; Suaud, N.; Mallah, T.; Guih\u00e9ry, N. Universal the-\noretical approach to extract anisotropic spin hamiltonians.J. Chem. Theory Comput. 2009, 5, 2977\u20132984. (40) Andersson, K.; Malmqvist, P.; Roos, B. O. Second-order perturbation theory witha\ncomplete active space self-consistentfield reference function.J. Chem. Phys.1992, 96,\n1218 \u2013 1226. 21\n\n(41) Angeli, C.; Cimiraglia, R.; Evangelisti, S.; Leininger, T.; Malrieu, J.-P. Introduction\nof n -Electron Valence States for Multireference Perturbation Theory.J. Chem. Phys. 2001, 114, 10252\u201310264. (42) Code is available at https://github.com/IrisA144/liblan_preview. (43) Sun, Q.; Berkelbach, T. C.; Blunt, N. S.; Booth, G. H.; Guo, S.; Li, Z. D.; Liu, J. Z.; Mc-\nClain, J. D.; Sayfutyarova, E. R.; Sharma, S.; Wouters, S.; Chan, G. K.-L. PySCF: The\nPython-based Simulations of Chemistry Framework.Wiley Interdiscip. Rev.: Comput. Mol. Sci.2018, 8, e1340. (44) Sun, Q. et al. Recent Developments in the PySCF Program Package.J. Chem. Phys. 2020, 153, 024109. (45) Sun, Q. Libcint: An Efficient General Integral Library for Gaussian Basis Functions. J. Comput. Chem.2015, 36, 1664\u20131671. (46) Schlegel, H. B.; McDouall, J. J. W. In Computational Advances in Organic Chem-\nistry: Molecular Structure and Reactivity; \u00d6gretir, C., Csizmadia, I. G., Eds.; Kluwer\nAcademic Publishers, 1991; pp 167 \u2013 185. (47) Pulay, P. Improved SCF Convergence Acceleration.J. Comput. Chem.1982, 3, 556 \u2013\n560. (48) Helgaker, T.; J\u00f8rgensen, P.; Olsen, J. Molecular Electronic-Structure Theory; John\nWiley & Sons, Ltd, 2000. (49) Thom, A. J. W.; Head-Gordon, M. Locating Multiple Self-Consistent Field Solutions:\nAn Approach Inspired by Metadynamics.Phys. Rev. Lett.2008, 101, 193001. (50) Gilbert, A. T. B.; Besley, N. A.; Gill, P. M. W. Self-Consistent Field Calculations of\nExcited States Using the Maximum Overlap Method (MOM).J. Phys. Chem. A2008,\n112, 13164\u201313171. 22\n\n(51) Carter-Fenk, K.; Herbert, J. M. State-Targeted Energy Projection: A Simple and Ro-\nbust Approach to Orbital Relaxation of Non-Aufbau Self-Consistent Field Solutions.J. Chem. Theory Comput.2020, 16, 5067 \u2013 5082. (52) Briganti, M.; Santanni, F.; Tesi, L.; Totti, F.; Sessoli, R.; ; Lunghi, A. A complete ab\ninitio view of Orbach and Raman spin\u2013lattice relaxation in a dysprosium coordination\ncompound. J. Am. Chem. Soc.2021, 143, 13633\u201313645. (53) Meng, Y.-S.; Wang, C.-H.; Zhang, Y.-Q.; Leng, X.-B.; Wang, B.-W.; Chen, Y.-F.;\nGao, S. (boratabenzene)(cyclooctatetraenyl) Lanthanide Complexes: A New Type of\nOrganometallic Single-ion Magnet.Inorg. Chem. Front.2016, 3, 828\u2013835. (54) Goodwin, C. A. P.; Ortu, F.; Reta, D.; Chilton, N. F.; Mills, D. P. Molecular Magnetic\nHysteresis at 60 Kelvin in Dysprosocenium.Nature 2017, 548, 439\u2013442. (55) Liu, W. J.; Peng, D. L. Exact Two-component Hamiltonians Revisited.J. Chem. Phys. 2009, 131, 031104. (56) Aquilante, F.; Lindh, R.; Pedersen, T. B.", "metadata": {"type": "factual", "source": "2503.01283v2.pdf", "context": "Predicting the N\u00b4 eel temperatures in general helimagnetic materials: a comparison\nbetween mean field theory, random phase approximation, renormalized spin wave\ntheory and classical Monte Carlo simulations\nVarun Rajeev Pavizhakumari 1 and Thomas Olsen 1, \u2217\n1CAMD, Computational Atomic-Scale Materials Design, Department of Physics,\nTechnical University of Denmark, 2800 Kgs. Lyngby Denmark\nThe critical temperature for magnetic order comprises a crucial property of any magnetic material\nand ranges f", "quality_score": 8.5}}
{"id": "test_22", "question": "Why does it suffice to analyze the sheaf \u03c0\u2217Y(HDR,Y) on \u2126?", "golden_answers": ["By Corollary 2.35, since (\u03c0\u2217Y(HDR,Y))\u0393 Y(I) = HanDR,Y."], "prediction": "It suffices to analyze the sheaf \u03c0\u2217Y(HDR,Y) on \u2126 because, by Corollary 2.35, Han DR,Y is equal to (\u03c0\u2217Y(HDR,Y))\u0393 Y(I), which indicates that understanding \u03c0\u2217Y(HDR,Y) on \u2126 will provide the necessary information to describe Han DR,Y.", "f1": 0.24390243902439024, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01357v1\nWe denote by HDR,un the unique locally free sheaf extension of HDR,un to M2\nI\nsuch that its formal completion at M2\nI\\M2\nI is determined by the module \u2295nI\ni=1(H[[Xi]]\u03b7i,1 \u2295\nH[[Xi]]\u03b7i,2). 7.2. The de Rham sheaf on \u2126 . Let Bbe an a\ufb03noid algebra so that Sp( B) is an admissible\nopen subset of \u2126. Recall the Drinfeld module ( Ga,\u2126 ,\u03a8 Y) from \u00a72.8 and \u03a8 Y\n| Sp(B) denote its\nrestriction to Sp( B), so that\n\u03a8 Yz\na| Sp(B) = a+\n2 deg(a)\u2211\ni=1\n(gi,a)| Sp(B) \u03c4i \u2208 B[\u03c4].\nRecall the quotient map \u03c0 from \u00a72.6. We denote by \u03c0Y : \u2126 \u2192 MY the composite map\n\u2126\n\u03c0\n\u2212 \u2192\u0393Y(I)\\\u2126\niY\n\u2212 \u2192MY. Let HDR,Y be the restriction of HDR,un, after base change with C\u221e, to MY and Han\nDR,Y be its\nanalyti\ufb01cation. In what follows, we explicitly describe the pull backs i\u2217\nY(HDR,Y) = Han\nDR,Y\nand \u03c0\u2217\nY(HDR,Y) which are sheaves on \u0393 Y(I)\\\u2126 and \u2126 respectively. Note, by Corollary\n2.35,\nthat Han\nDR,Y = ( \u03c0\u2217\nY(HDR,Y))\u0393 Y(I). Therefore it su\ufb03ces to analyze the sheaf \u03c0\u2217\nY(HDR,Y) on \u2126.\nProposition 7.5. The sheaf \u03c0\u2217\nY(HDR,Y) is the unique sheaf on \u2126 so that for any a\ufb03noid\nsubdomain j : Sp( B) \u2192 \u2126 , its sections over Sp(B) is given by the B-module HDR(\u03a8 Y\n| Sp(B)).\nProof. The morphism \u03c0Y \u25e6 j : Sp( B) \u2192 MY factors through a canonical map \u02dcj : Spec( B) \u2192\nMY. Note that the coherent sheaves j\u2217(\u03c0\u2217\nY(HDR,Y)) on Sp( B) and ( \u02dcj)\u2217HDR,Y on Spec( B)\ncorrespond to the same \ufb01nitely generated B-module, say N. In other words, they are\nobtained by the \u02dc() operation on N, with respect to the corresponding topologies. But\nby the a\ufb03ne base change property of de Rham cohomology [\nGek89, Thm.4.5], we have\n(\u02dcj)\u2217HDR,Y = HDR(\u03a8 Y\n| Sp(B)) which implies the desired statement. \u25a1\nIn what follows, we denote the sheaf \u03c0\u2217\nY(HDR,Y) by HDR(\u03a8 Y). Since HDR,Y is a locally free\nsheaf of rank 2 on MY, so is HDR(\u03a8 Y) on \u2126. Furthermore, since \u2126 is a Stein space [\nSS91,\nThm.4], HDR(\u03a8 Y) is generated by its global sections. In our next proposition, we ex plicitly\ndescribe these sections to show that HDR(\u03a8 Y) is indeed a free sheaf of rank two over O\u2126 . 44 O \u02d8GUZ GEZM \u02d9IS \u00b8 AND SRIRAM CHINTHALAGIRI VENKATA\nLet \u03b71,B be the local section of HDR(\u03a8 Y\n| Sp(B)) given by\n\u03b71,B := \u03b7(1)\nB := [ a\u21a6\u2192a\u2212 \u03a8 Y\na| Sp(B)] \u2208 H0(Sp(B),HDR(\u03a8 Y\n| Sp(B))). Recall the false Eisenstein series E de\ufb01ned in \u00a74. We further de\ufb01ne the local section \u03b72,B of\nHDR(\u03a8 Y\n| Sp(B)) given by\n\u03b72,B := d\ndz(\u03b71,B) \u2212 E\u03b71,B \u2208 H0(Sp(B),HDR(\u03a8 Y\n| Sp(B))). Note that for a\ufb03noid subdomains j : Sp( B) \u2192 \u2126, the local sections \u03b71,B and ( \u03b72,B respec-\ntively) glue together to form a global section of HDR(\u03a8 Y), denoted by \u03b71 (\u03b72 respectively). Lemma 7.6 (Hodge decomposition) .\n\n2503.01357v1\nPart (ii) follows from (i) and the\nfunctional equation ( 4.8) of the false Eisenstein series E. \u25a1\nObserve that O\u2126 \u03b71 \u2282 HDR(\u03a8 Y) is a \u0393 Y(I)-subsheaf. Before we state our next lemma,\nrecall that \u03c9un = Lie( Eun\nI )\u2228 and \u03c9Y is its restriction to MY, after base change with C\u221e.\nLemma 7.9. We have \u03c0\u2217\nY(\u03c9Y) \u223c= O\u2126 \u03b71 as \u0393Y(I)-sheaves.\nProof. We aim to show that \u03c0\u2217\nY(\u03c9Y) is isomorphic to O\u2126 with a \u0393 Y(I)-structure given by\nmultiplication by j(\u03b3,\u2212)\u22121. Recall the notation in \u00a72.8 and let g \u2208 GL2( \u02c6A) be such that\n\u03c0g = \u03c0Y. By Proposition\n2.40, we see that \u03c0\u2217\nY(\u03c9Y) \u223c= O\u2126 . Using the commutative diagram\nin the proof of [ BBP21, Lem. 10.5], we obtain\n\u03c0\u2217\nY(\u03c9Y) O\u2126\n\u03b3\u2217\u03c0\u2217\nY(\u03c9Y) \u03b3\u2217O\u2126 = O\u2126 . \u223c\n= multiplication by j(\u03b3,\u2212)\n\u223c\nHence under the trivialization \u03c0\u2217\nY(\u03c9Y) \u223c= O\u2126 , we see that \u03b3\u2217O\u2126 = O\u2126 \u2192 O \u2126 is the map\ngiven by the multiplication by j(\u03b3,\u2212)\u22121. Equivalently, the map O\u2126 \u2192 \u03b3\u2217O\u2126 = O\u2126 obtained\nby adjunction, is also the multiplication by j(\u03b3,\u2212)\u22121, \ufb01nishing the proof of the lemma. \u25a1\nDe\ufb01nition 7.10. We de\ufb01ne HDR(\u03a8\nY\n) := HDR(\u03a8 Y)\u0393 Y(I). Furthermore, we set \u03c9(\u03a8 Y) :=\nO\u2126 \u03b71 and \u03c9(\u03a8\nY\n) := \u03c9(\u03a8 Y)\u0393 Y(I).\nRemark 7.11. Note that by Corollary 2.35, HDR(\u03a8\nY\n) = i\u2217\nY(HDR,Y) = Han\nDR,Y. Similarly\n\u03c9(\n\u03a8\nY\n) = \u03c9an\nY . We conclude this section with the following useful lemma. Lemma 7.12. Let r and k be non-negative integers so that k \u2265 r. Then there exists a\ncanonical isomorphism\nSymr(HDR(\u03a8\nY\n)) \u2297 \u03c9(\u03a8\nY\n)\u2297(k\u2212r) \u2243 (Symr(HDR(\u03a8 Y)) \u2297 \u03c9(\u03a8 Y)\u2297(k\u2212r))\u0393 Y(I). Proof. By de\ufb01nition, we have\nSymr(HDR(\u03a8\nY\n)) \u2297 \u03c9(\u03a8\nY\n)\u2297(k\u2212r) \u2243 Symr(HDR(\u03a8 Y)\u0393\nY(I)) \u2297 (\u03c9(\u03a8 Y)\u0393 Y(I))\u2297(k\u2212r). By Corollary\n2.35, applying () \u0393 Y(I) commutes with Sym r and \u2297, and hence we obtain the\nresult. \u25a1\n\n46 O \u02d8GUZ GEZM \u02d9IS \u00b8 AND SRIRAM CHINTHALAGIRI VENKATA\n8. Algebraic nearly holomorphic Drinfeld modular forms\nFor the convenience of the reader, we recall our notation from \u00a76. Let Y be the projective\nA-module of rank two embedded in K2 by Y = g(1,0) + h(0,1) \u2282 K2 for some fractional\nideals g and h of A, which are, without loss of generality, assumed to be integral ideals of\nA. Let I be an ideal of A such that |V(I)| \u2265 2. Let M2\nI,C\u221e = Spec( C\u221e) \u00d7Spec(A) M2\nI and\nset ( M2\nI,C\u221e )an to be the analyti\ufb01cation of M2\nI,C\u221e . Let MY \u2282 (M2\nI,C\u221e )an be the connected\ncomponent of M2\nI,C\u221e so that MY(C\u221e) = \u0393 Y(I) \\ \u2126 and set iY : MY \u2192 M2\nI,C\u221e to be the\ncorresponding inclusion. We also \ufb01x an embedding H \u2192 C\u221e so that MY = M2\nI \u00d7H C\u221e and\nMY := M2\nI \u00d7H C\u221e. We further denote by \u03c9Y the restriction of \u03c9un, after base change with\nC\u221e, to MY.\n\n2503.01357v1\nLet \u03b71,\u03b72 \u2208 HDR(\u03a8 Y)(\u2126) be as above. Then the\nnatural map\nO\u2126 \u2295 O\u2126 \u2192 HDR(\u03a8 Y) sending (1,0) \u21a6\u2192\u03b71 and (0,1) \u21a6\u2192\u03b72 is an isomorphism of O\u2126 -sheaves. Proof. The proof is essentially the content of [\nGek90, Prop.7.7] but we give it for the sake\nof completeness. Observe that it is enough to show the isomorphism when restricted to any\na\ufb03noid subdomain Sp( T) \u2192 \u2126. For all z \u2208 Sp(T), let Tz denote the localization of T at the\nmaximal ideal corresponding to z. This is a local ring and let \u02c6Tz denote the corresponding\ncompletion. We have\n(7.7) \u02c6Tz \u2243 \u02c6O\u2126 ,z \u2243 \u02c6O\u0393 Y(I)\\\u2126 ,\u03c0(z) \u2243 \u02c6OMY,\u03c0Y(z)\nwhere the \ufb01rst isomorphism follows from [\nFvdP04, Prop.4.6.1], the second isomorphism from\nProposition 2.27 and the last one follows since \u0393 Y(I)\\\u2126 = Man\nY . The completed localization\nat z of the map O\u2126 \u2295 O\u2126 \u2192 HDR(\u03a8 Y) via ( 7.7) is given by the injective map\n\u02c6i : \u02c6OMY,\u03c0Y(z) \u2295 \u02c6OMY,\u03c0Y(z) \u2192 HDR(\u03a6 \u02c6OMY,\u03c0Y(z)\n, \u02c6OMY,\u03c0Y(z))\nwhere \u03a6 \u02c6OMY,\u03c0Y(z)\nis the pull back of the universal Drinfeld A-module via Spec( \u02c6OMY,\u03c0Y(z)) \u2192\nMY. As in the proof of [ Gek90, Prop.7.7], \u03b72 generates H 2(\u03a6 \u02c6OMY,\u03c0Y(z)\n, \u02c6OMY,\u03c0Y(z)). Moreover,\nsince, by construction, \u03b71 generates H 1(\u03a6 \u02c6OMY,\u03c0Y(z)\n, \u02c6OMY,\u03c0Y(z)), we obtain\nIm(\u02c6i) = H 1(\u03a6 \u02c6OMY,\u03c0Y(z)\n, \u02c6OMY,\u03c0Y(z)) \u2295 H2(\u03a6 \u02c6OMY,\u03c0Y(z)\n, \u02c6OMY,\u03c0Y(z)). Thus, by ( 2.22), \u02c6i is surjective and hence it is an isomorphism. We obtain that the coker nel\nof the map O\u2126 | Sp(T) \u2295 O \u2126 | Sp(T) \u2192 HDR(\u03a8 Y)| Sp(T), being represented by a \ufb01nitely gener-\nated T-module, vanishes at the localization by maximal ideals of T, hence must be zero. Consequently the map is surjective. \u25a1\nNote that, by de\ufb01nition, HDR(\u03a8 Y) is the pull back of a coherent sheaf on \u0393 Y(I)\\\u2126 by\n\u03c0 and hence is a \u0393 Y(I)-sheaf in the sense of De\ufb01nition 2.32. In what follows, we explicitly\ndescribe this action, which is induced from the action of \u0393 Y(I) on ( Ga,\u2126 ,\u03a8 Y) described at\nthe end of \u00a72.8. . Proposition 7.8. For any \u03b3 =\n(\na b\nc d\n)\n\u2208 \u0393Y(I), let\n\u03b1\u03b3 : HDR(\u03a8 Y) = O\u2126 \u03b71 \u2295 O\u2126 \u03b72 \u2192 \u03b3\u2217HDR(\u03a8 Y) := ( \u03b3\u2217O\u2126 )\u03b3\u2217\u03b71 \u2295 (\u03b3\u2217O\u2126 )\u03b3\u2217\u03b72\n\nON NEARLY HOLOMORPHIC DRINFELD MODULAR FORMS 45\nbe the \u0393Y(I)-sheaf structure. The following statements hold. (i) The map \u03b1\u03b3 may be represented by\n[\n\u03b71\n\u03b72\n]\n\u21a6\u2192\n[\nj(\u03b3; \u2212)\u22121 0\n0 j(\u03b3; \u2212)\n] [\n\u03b3\u2217\u03b71\n\u03b3\u2217\u03b72\n]\n. and the maps O\u2126 \u2192 \u03b3\u2217O\u2126 in the \ufb01rst and second coordinates, sends a function\nf \u2208 O \u2126 (U) to f\u03b3 := [ z \u21a6\u2192f(\u03b3z)] \u2208 O \u2126 (\u03b3\u22121U). (ii) Let \u03b7\u2032\n2 := \u03b72 + E\u03b71. Then \u03b7\u2032\n2 forms a global section of HDR(\u03a8 Y). Moreover, \u03b1\u03b3 may\nbe also represented by[\n\u03b71\n\u03b7\u2032\n2\n]\n\u21a6\u2192\n[\nj(\u03b3; \u2212)\u22121 0\n\u2212c j (\u03b3; \u2212)\n] [\n\u03b3\u2217\u03b71\n\u03b3\u2217\u03b7\u2032\n2\n]\n. Proof. Part (i) is a consequence of [ Gek90, Eq.7.16].", "metadata": {"type": "reasoning", "source": "2503.01357v1.pdf", "context": "Let HDR,Y be the restriction of HDR,un, after base change with C\u221e, to MY and Han\nDR,Y be its\nanalyti\ufb01cation. In what follows, we explicitly describe the pull backs i\u2217\nY(HDR,Y) = Han\nDR,Y\nand \u03c0\u2217\nY(HDR,Y) which are sheaves on \u0393 Y(I)\\\u2126 and \u2126 respectively. Note, by Corollary\n2.35,\nthat Han\nDR,Y = ( \u03c0\u2217\nY(HDR,Y))\u0393 Y(I). Therefore it su\ufb03ces to analyze the sheaf \u03c0\u2217\nY(HDR,Y) on \u2126.\nProposition 7.5. The sheaf \u03c0\u2217\nY(HDR,Y) is the unique sheaf on \u2126 so that for any a\ufb03noid\nsubdomain j : Sp( B) \u2192 \u2126 , its section", "quality_score": 8.5}}
{"id": "test_23", "question": "What is assumed about static friction in the PD controller for simplicity?", "golden_answers": ["Static friction is typically greater than dynamic friction, but it is assumed they are equal."], "prediction": "Static friction is typically not randomized in conventional approaches.", "f1": 0.33333333333333337, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01255v1\nImpact of Static Friction on Sim2Real in Robotic Reinforcement\nLearning\nXiaoyi Hu1, Qiao Sun 1, Bailin He 1, Haojie Liu 1, Xueyi Zhang 1, Chunpeng lu 1 and Jiangwei Zhong 1\nAbstract\u2014 In robotic reinforcement learning, the Sim2Real\ngap remains a critical challenge. However, the impact of Static\nfriction on Sim2Real has been underexplored. Conventional\ndomain randomization methods typically exclude Static friction\nfrom their parameter space. In our robotic reinforcement learn-\ning task, such conventional domain randomization approaches\nresulted in significantly underperforming real-world models. To address this Sim2Real challenge, we employed Actuator\nNet as an alternative to conventional domain randomization. While this method enabled successful transfer to flat-ground\nlocomotion, it failed on complex terrains like stairs. To fur-\nther investigate physical parameters affecting Sim2Real in\nrobotic joints, we developed a control-theoretic joint model and\nperformed systematic parameter identification. Our analysis\nrevealed unexpectedly high friction-torque ratios in our robotic\njoints. To mitigate its impact, we implemented Static friction-\naware domain randomization for Sim2Real. Recognizing the\nincreased training difficulty introduced by friction modeling,\nwe proposed a simple and novel solution to reduce learning\ncomplexity. To validate this approach, we conducted com-\nprehensive Sim2Sim and Sim2Real experiments comparing\nthree methods: conventional domain randomization (without\nStatic friction), Actuator Net, and our Static friction-aware\ndomain randomization. All experiments utilized the Rapid\nMotor Adaptation (RMA) algorithm. Results demonstrated that\nour method achieved superior adaptive capabilities and overall\nperformance. I. INTRODUCTION In the realm of robotic reinforcement learning, Sim2Real\nproblem is a consistently significant challenge. This gap\noften results in robots that perform admirably in simulated\nenvironments but underperform in real-world settings. While\nit is possible for robots to learn directly from real-world\nsampling, this approach is fraught with drawbacks, including\npotential harm to the robot and exorbitant costs [1]. To en-\nhance the data efficiency of reinforcement learning, Model-\nBased Reinforcement Learning (MBRL) presents a viable\nalternative [2]. However, MBRL shares a common issue with\nModel Predictive Control (MPC), where the efficacy of learn-\ning is heavily contingent on the accuracy of the environment\nmodel and struggles to accommodate unpredictable external\ndisturbances during robot operation [3], [4]. It is due to these\nchallenges that Model-free Reinforcement Learning (MFRL)\nhas become the predominant learning method in robotic\nreinforcement learning [5]. Nonetheless, MFRL is inherently\ndata-inefficient, prompting the exploration of simulation en-\nvironments as a means to emulate real-world robotics. In\nCorresponding author: Jiangwei Zhong\n1X. Hu, Q. Sun, B. He, H. Liu, X. Zhang, C. Lu and J.Zhong are with\nthe Smart Devices & Solutions Lab, Lenovo Research Shanghai, Shanghai\n200003, China zhongjw@lenovo.com\nsuch simulations, robots can bypass direct interaction with\nthe physical environment and significantly boost data col-\nlection efficiency through parallelization strategies [6], [7]. Yet, in practical applications, disparities between simulated\nand real environments often arise due to computational\ncomplexity and technical limitations. These discrepancies,\nthough not obvious, frequently lead to suboptimal robot\nperformance upon deployment [8]. To address this challenge, a series of methods have\nbeen proposed to bridge the Sim2Real gap, many of which\nhave demonstrated promising results.\n\n2503.01255v1\nHowever, when using Actuator Net,\nthe robot exhibited significant abnormal behavior, eventually\nleading to system failure. With domain randomization that\nincluded Static friction, the robot displayed irregular jittering\nand jumping but was still capable of ascending and descend-\ning stairs. This is primarily due to the RMA algorithm\u2019s\nability to adapt to varying Static friction levels. In the Sim2Real experiments, domain randomization with-\nout Static friction enabled the robot to walk backward on\nflat ground, but forward walking caused it to fall. Using\nActuator Net allowed the robot to walk forward, albeit\nunsteadily, and it was unable to climb stairs. In contrast,\ndomain randomization with Static friction achieved stable\nwalking on flat ground and successful stair navigation. The success of domain randomization without Static fric-\ntion in Sim2Sim experiments indicates that our reinforce-\n\nment learning training algorithm does not suffer from input-\noutput interface configuration errors during deployment. However, its failure in Sim2Real experiments suggests a\nsignificant discrepancy between simulation and reality. The\nfact that Actuator Net performed well in Sim2Real flat-\nground walking but failed in Sim2Sim further supports the\nhypothesis that this discrepancy arises from differences in\njoint dynamics between simulation and reality. Based on our\nearlier control-theoretic analysis, we hypothesized that Static\nfriction is the primary cause of this discrepancy. To validate\nthis hypothesis, we implemented domain randomization with\nStatic friction. The experimental results demonstrated that\nthis approach significantly improved Sim2Real performance,\nalbeit with a slight sacrifice in Sim2Sim performance. Given\nits strong adaptability to varying Static friction, we believe\nthis method not only compensates for joint friction in robotic\nreinforcement learning but also serves as an effective means\nto counteract joint wear and fatigue. VII. C ONCLUSION\nOur experiments demonstrate that Static friction signifi-\ncantly impacts the Sim2Real of robotic reinforcement learn-\ning. To mitigate this effect, we propose integrating Static\nfriction into the training process. Although the introduction\nof Static friction will cause the model to fail to train, we\npropose a simple trick to solve the problem. Additionally,\nwe hypothesize that using joints with lower Static friction-\nto-torque ratios could further alleviate this issue. Over time, robots inevitably experience mechanical fatigue\nand wear, leading to changes in Static friction. While RL\nmodels trained with randomized Static friction theoretically\nexhibit robustness against such degradation, our experimental\nconstraints prevented direct validation of this hypothesis. We\nbelieve this topic warrants further investigation. REFERENCES [1] S. Gu, E. Holly, T. P. Lillicrap, and S. Levine, \u201cDeep reinforcement\nlearning for robotic manipulation,\u201d arXiv preprint arXiv:1610.00633 ,\nvol. 1, p. 1, 2016. [2] T. M. Moerland, J. Broekens, A. Plaat, C. M. Jonker et al., \u201cModel-\nbased reinforcement learning: A survey,\u201d Foundations and Trends\u00ae in\nMachine Learning, vol. 16, no. 1, pp. 1\u2013118, 2023. [3] Q. Huang, \u201cModel-based or model-free, a review of approaches in\nreinforcement learning,\u201d in 2020 International Conference on Com-\nputing and Data Science (CDS) . IEEE, 2020, pp. 219\u2013221.\n\n2503.01255v1\nIn conventional domain randomization, parameters such\nas Ij, Bj, kmotor, kp, and kd are randomized. From the\ndynamics equation, it is evident that kd and Bj can cancel\neach other out, so only one of them needs to be randomized. Additionally, Static friction fj(t) is typically not random-\nized in conventional approaches. However, our experiments\nrevealed that Static friction fj(t) significantly impacts the\nrobot\u2019s performance. To analyze the magnitude of fj(t), we\nperformed parameter identification for the motor\u2019s physical\nparameters using the following method:\n\u03b8\u2217\nj (t) =A sin(\u03c9t)\nmin f(Ij, Bj, bc\nj) = 1\nN\nNX\ni=0\n\u0000\n\u03b8\u2217\nj (ti) \u2212 \u03b8j(ti)\n\u00012\nsubject to Ij > 0, Bj > 0, bc\nj > 0\n(13)\nHere, \u03b8\u2217\nj (t) is the excitation signal, A is its amplitude, \u03c9\nis its frequency, \u03b8j(ti) is the sampled joint angle, and \u03b8\u2217\nj (ti)\nis the true value of the excitation signal. We used the least\nsquares method to identify Ij, Bj, and bc\nj. The results of\nthis parameter identification are presented in the Experiments\nsection. After parameter identification, we introduced Static fric-\ntion fj(t) into the domain randomization process. However,\nthe inclusion of fj(t) introduced nonlinearity, significantly\nincreasing training difficulty. We observed that directly in-\ncorporating the identified Static friction fj(t) into the robot\nor manually compensating for it in the RL-generated actions\nat caused the robot to remain stationary during training. We hypothesize that this is due to the chaotic nature of\nearly RL actions, with Static friction acting as a strong\nfilter. Fine-tuning a pre-trained model (trained without Static\nfriction) by introducing fj(t) also failed, likely because the\nmodel weights were already trapped in local optima or saddle\npoints, preventing effective gradient descent. To train a robot capable of handling randomized Static\nfriction fj(t), we developed two methods: the iterative\nmethod and the deception method. In the iterative method,\nwe fine-tuned the teacher model (trained without Static\nfriction) multiple times, gradually introducing small amounts\nof fj(t). However, models trained with this method exhibited\nsevere jitter during real-world deployment, even making\nstable standing difficult. As an alternative, we proposed the\ndeception method, where we no longer aimed for perfect\nalignment between simulated and real-world Static friction. Instead, we significantly expanded the randomization range\nof fj(t). This approach successfully enabled real-world de-\nployment. We attribute the effectiveness of increased Static\nfriction randomization to two factors: 1. During simulation\ntraining, increased randomization allows the robot to en-\ncounter scenarios with negligible Static friction, reducing\ntraining difficulty. 2. During Sim2Real, real-world joint\nTABLE II\nDOMAIN RANDOMIZATION PARAMETERS\nParameter Range Unit\nJoint armature [0.8, 1.2] multiplier\nJoint damping [0.8, 1.2] multiplier\nJoint Static friction [0.0, 1.2] multiplier\nKp [0.95, 1.05] multiplier\nMotor strength [0.8, 1.2] multiplier\nGround friction [0.2, 2.0] multiplier\nPayload [-2, 3] kg\nCenter of mass [-0.25, 0.25] m\nPush interval 8 s\nPush velocity 1 m/s\nStatic friction may vary due to wear. Expanding the random-\nization range enhances the robot\u2019s robustness to mechanical\nwear. The parameters used in our domain randomization are\nlisted in Table 2.", "metadata": {"type": "factual", "source": "2503.01255v1.pdf", "context": "and kd are the proportional and derivative gains of the PD\ncontroller. Although static friction is typically greater than\ndynamic friction in reality, we assume they are equal for\nsimplicity.\nIn conventional domain randomization, parameters such\nas Ij, Bj, kmotor, kp, and kd are randomized. From the\ndynamics equation, it is evident that kd and Bj can cancel\neach other out, so only one of them needs to be randomized.\nAdditionally, Static friction fj(t) is typically not random-\nized in conventiona", "quality_score": 8.5}}
{"id": "test_24", "question": "What is the purpose of using automatically generated sketches for generation tasks in this method?", "golden_answers": ["They aid the analysis of sketch-to-mesh correspondence by the CLIP and LPIPS scores."], "prediction": "The purpose of using automatically generated sketches for generation tasks in this method is to enable further sketch-based editing, allowing for iterative manipulation and refinement of the output mesh to achieve a precise artistic vision.", "f1": 0.09302325581395349, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.00928v1\nA prevalent approach involves train-\ning generative models by leveraging construction sequences\nas supervision (Wu, Xiao, and Zheng 2021; Xu et al. 2022,\n2023; Wang et al. 2024). These methods typically repre-\nsent sketch-and-extrude sequences as parameterized discrete\nsequences, enabling the application of powerful sequence\nlearning techniques to the task of CAD model generation. Despite the demonstrated success of sequence-based\narXiv:2503.00928v1  [cs.GR]  2 Mar 2025\n\nFigure 2: Sample data from DeepCAD dataset. Previous\nmethods, constrained by sequence length limitations, were\nrestricted to learning a subset of simpler shapes within the\ndataset (gray). Our raster-based sketch representation en-\nables the learning of more complex shapes (green). learning methods for CAD model generation, several limita-\ntions remain: 1) The reliance on sequences introduces a bot-\ntleneck, limiting the complexity of representable sketches\nand the number of commands that can be effectively uti-\nlized. This constraint restricts the generation of intricate\nmodels. 2) Current methods often generate semantically in-\nvalid command sequences for CAD modeling, resulting in\nnon-viable models and hindering the reliability and usability\nof the output. 3) Representing sketches as discrete parameter\nsequences makes generating smooth and continuous shape\ntransformations difficult, leading to unnatural results for la-\ntent space interpolation, as illustrated in Fig.1. This poses a\nchallenge for generating plausible sketches, for which plau-\nsible interpolation is essential (Radford, Metz, and Chintala\n2015; Goodfellow et al. 2014; Higgins et al. 2017). In this paper, we revisit the CAD generation task and\npropose a novel representation that follows the sketch-and-\nextrude paradigm without using command sequences. In-\nstead of representing sketches as curve sequences, we lever-\nage raster images. Extrusion parameters, such as origin, di-\nrection, and Boolean operation type, are implicitly deter-\nmined by the dimensions and type of the extrusion box. This\nnew representation addresses the limitations of sequence-\nbased methods in several key ways. Using raster images\nto represent sketches allows for depicting highly complex\nshapes, overcoming the bottleneck imposed by discrete pa-\nrameter sequences (e.g., fixed maximum length of curves per\nloop), as shown in Fig.2. Additionally, the intuitive nature of\nimage-based sketches reduces the likelihood of generating\nsemantically or geometrically invalid commands, leading to\nmore reliable and usable outputs. Moreover, representing\nsketches as images facilitates the generation of smooth and\ncontinuous shape transformations, unlike the discrete nature\nof previous methods. Finally, by employing extrusion boxes,\nour method provides a concise and intuitive way to control\nthe topological relationships between extruded shapes, fur-\nther enhancing the modeling process. Building upon this novel sketch-extrusion representation,\nwe present RECAD, a novel generative framework that\ngenerates sketch-extrusion pairs using Denoising Diffusion\nProbabilistic Models (DDPM) (Ho, Jain, and Abbeel 2020). Concretely, RECAD comprises a sketch image V AE and\ntwo diffusion networks. A Variational Autoencoder (V AE)\n(Kingma and Welling 2013) is utilized to learn the latent\nfeatures of raster sketches. Two diffusion networks are em-\nployed in a sequential generation process. The first diffu-\nsion network generates the coordinates defining the extru-\nsion boxes. Conditioned on these boxes, the second network\ngenerates latent features representing the raster sketches.\n\n2503.01425v2\nAfter each addition or deletion operation, we automatically generate an updated sketch\ncorresponding to the current output mesh, to enable further sketch-based editing.\ncontrast to 3D representations such as voxels [19, 20, 49],\npoints [56, 59, 64], or neural implicit representations [28,\n31, 42], triangle meshes represent surfaces in a compact,\nstructured fashion, as well as enabling efficient fine-scale\ndetail and naturally integrating into modern rendering and\nediting pipelines, achieving high fidelity with relatively few\nprimitives. Recent advances in generative 3D models have shown\nsignificant potential in generating 3D meshes directly [16,\n17, 27, 51, 55]; however, these output meshes are not ed-\nitable, which is a crucial component for artistic design in\ncontent creation. More specifically, artistic content creation\nis an iterative process that encompasses not only the initial\ngeneration, but also requires multiple cycles of manipula-\ntion and editing in order to refine an output to achieve a\nprecise artistic vision. In order for such editing to fit with\ncontent creation pipelines, various edits must be performed\ninteractively, affecting only the intended region of the mesh. We thus propose MeshPad, an interactive sketch-based\napproach for 3D mesh generation and editing. From an\ninput sketch of a shape drawn by a user, we produce a\ncorresponding 3D mesh. The resulting mesh can then be\nedited simply by editing the sketch. To achieve efficient and\nprecise mesh editing, we decompose this into simpler sub-\ntasks: deletion and addition of mesh geometry by remov-\ning or adding strokes in the sketch. Crucially, this model-\ning paradigm also leads to easy supervised training of both\ndeletion and addition of elements in the mesh (by simply\nremoving and adding back parts of ground-truth meshes),\nwithout requiring collection of real mesh editing sequences\nfor supervision. Our editing-based approach allows for the\ngeneration of more complex triangle meshes by iteratively\napplying a series of edits to construct the final shape. Algorithmically, MeshPad leverages a hybrid approach\ncombining an autoregressive network for addition and a\ntoken-classification network for deletion. Unlike existing\nartist-designed mesh generation methods, our addition net-\nwork generates partial shapes only corresponding to new\nsketch strokes, rather than repeatedly synthesizing the en-\ntire mesh. This naturally solves the problem of preserving\nunedited mesh regions during editing. Additionally, based\non the triangle sequence representation [17], we introduce\na vertex-aligned speculative decoder to accelerate autore-\ngressive generation and reduce computational time. Instead\nof predicting one vertex coordinate at a time, the specula-\ntor allows us to predict 3 coordinates, i.e., one vertex, at a\ntime. We find that jointly training the speculative head and\naligning it with the vertex tokens reduces generation time\nwhile maintaining generation quality. We further demon-\nstrate our method through a user interface (Fig. 1) that al-\nlows users to interactively edit 3D meshes by drawing on\n2D sketches. Extensive experiments show that our method\noutperforms state-of-the-art methods in sketch-conditioned\nmesh generation, producing cleaner meshes that more ac-\ncurately align with the sketch input and excelling in partial\nmesh editing tasks.\n\n2503.00928v1\nLater works further improve the performance of\nshape generation by employing auto-regressive generative\nmodels (Xu et al. 2022), designing a hierarchical tree of neu-\nral codes mastering both high level concepts and local level\ngeometry (Xu et al. 2023), and integrating discrete diffusion\nmodels (Wang et al. 2024). In the field of 3D model recon-\nstruction, approaches learning 2D sketches and predicting\nthe corresponding extrusions to reconstruct the CAD mod-\nels in supervised (Uy et al. 2022), and unsupervised (Li et al. 2023a; Ren et al. 2022; Li et al. 2024) manners are proposed. This work explores CAD model generation, focusing\nspecifically on the sketch-and-extrude modeling paradigm. Departing from prior art that relies on discrete parametric\nrepresentations of sketches, we propose leveraging raster\nimages as a more flexible and expressive alternative. Fur-\nthermore, we encapsulate all extrusion information within\nan extrusion box. Generative diffusion models. DDPM (Ho, Jain, and\nAbbeel 2020) are good at generative tasks, especially in im-\nage generation and restoration (Ho, Jain, and Abbeel 2020;\nSaharia et al. 2022; Lugmayr et al. 2022). Latent diffusion\nmodels (LDM) operate in a low-dimensional latent space\nrather than original data space, resulting in more efficient\nsampling and promising generative performance on numer-\nous tasks such as high-resolution image synthesis (Vahdat,\nKreis, and Kautz 2021; Rombach et al. 2022). Diffusion\nmodels also show the ability to generate geometry with\n(Shabani, Hosseini, and Furukawa 2023; Liu et al. 2024)\nor without topology as input conditioning (Alliegro et al. 2023; Xu et al. 2024). Borrowing architecture from VQ-\nDiffusion (Gu et al. 2022) which combines VQ-V AE (Van\nDen Oord, Vinyals et al. 2017) and conditional DDPM, VQ-\nCAD (Wang et al. 2024) integrates discrete diffusion models\nfor CAD model generation. Our work includes two diffu-\nsion networks for generating 3D extrusion boxes and raster\nsketches representing detailed 2D geometry. Representation and Overview\nIn this section, we first introduce our novel representation\nusing raster sketches paired with extrusion boxes. We then\nprovide an overview of our proposed approach for generat-\ning CAD models based on this representation. Novel Sketch-Extrusion Representation\nSequence-based representations, while commonly used in\nCAD model generation, limit design complexity, semantic\nvalidity, and smooth shape transformations. To address these\nchallenges, we propose a novel sketch-extrusion paradigm\nthat leverages raster images for sketch representation, allow-\ning for greater complexity and smoother transformations. Additionally, we introduce extrusion boxes, establishing a\ndirect mapping between the 2D sketch and the 3D extru-\nsion. This representation simplifies the extrusion parameters\nthemselves into a few key controls within the extrusion box,\nallowing for intuitive manipulation of the resultant topology. Below, we detail our raster sketch representation and the ex-\ntrusion box concept. Raster sketch. A raster sketch is a binary image depict-\ning the shape of the sketch. Pixel values of 1 correspond\nto areas suitable for extrusion, while 0 represents empty\nspace. This image-based representation allows for the por-\ntrayal of complex geometries without concern for the count\nof internal loops and curves.", "metadata": {"type": "factual", "source": "2503.01425v3.pdf", "context": "generation task. To further show the robustness of our\nmethod, we use the IKEA dataset [38, 55], which con-\ntains 188 furniture models. We use automatically generated\nsketches (following Sec. 3.4) for generation tasks because\nthey aid the analysis of sketch-to-mesh correspondence by\nthe CLIP and LPIPS scores. In our qualitative experi-\nments, we show that our method generalizes to hand-drawn\nsketches. Additionally, we randomly select50 shapes of air-\nplanes, chairs, and lamps (on which SENS is t", "quality_score": 8.5}}
{"id": "test_25", "question": "Based on Figure 5, what does the presence of five distinct peaks with minimal overlap in the density plot indicate about the expert weights learned with the user-aware router and constraint loss?", "golden_answers": ["It indicates that the users can be clustered into five groups based on their averaged expert weights"], "prediction": "The presence of five distinct peaks with minimal overlap in the density plot indicates that the experts learn distinct group preferences.", "f1": 0.17647058823529413, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01303v1\nAs shown in Figure 6, the\nmain computational and storage load in personal-\nized LLMs is in the user-level adaptation stage,\nwhich scales with the number of users. Both OPPU\nand PROPER introduce 552M parameters for 100\nusers. Regarding training time, PROPER takes\nslightly longer (180 min per batch) than OPPU\n(146 min) for 100 users. PROPER also introduces\ntwo additional components: the group-level adap-\ntation and the LoRA-aware router. These compo-\nnents are one-time processes that do not scale with\nuser growth, adding minimal computation (146 min\nfor group-level adaptation and 150 min for LoRA-\naware router) and storage overhead (91M and 4M,\nrespectively). Despite these additions, PROPER\nremains efficient overall due to its improvements.\n0.18 0.19 0.20 0.21 0.22\nExpert weight\nDensity\nExperts\nexpert 1\nexpert 2\nexpert 3\nexpert 4\nexpert 5\n0.14 0.16 0.18 0.20 0.22 0.24 0.26\nExpert weight\nDensity\nExperts\nexpert 1\nexpert 2\nexpert 3\nexpert 4\nexpert 5\nCluster\nCluster 0\nCluster 1\nCluster 2\nCluster 3\nCluster 4\nFigure 5: The Visualization of expert weights and user\nembeddings learned in the group-level adaptation. The\nupper left: density plot of expert weights with the user-\naware router and constraint loss; The bottom left: den-\nsity plot of expert weights with regular LoRAMoE;The\nright: Scatter plot of user embeddings after detention\nreduction, colored by the clusters.\n4.5 Visualization\nTo answer RQ5, we visualize the user embeddings\nlearned in Stage 2 and the expert weights for the\ngroup experts. For the expert weights, we aver-\nage the weights for each user and compare the\ndensity plots of expert weights learned with the\nuser-aware router and constraint loss versus those\nlearned with regular LoRAMoE. For the user em-\nbeddings, we average the embeddings across layers\nfor each user and apply t-SNE (Van der Maaten\nand Hinton, 2008) to map them into a 2D space. We then cluster the users into 5 groups based on\ntheir averaged expert weights and color the user\nembeddings according to their cluster. As shown\nin Figure 5, the density plot of expert weights with\nthe user-aware router and constraint loss shows\nfive distinct peaks with minimal overlap, indicating\n7\n\nthat the experts learn distinct group preferences. In contrast, the expert weights from regular Lo-\nRAMoE are highly overlapping, suggesting that\nthe experts are learning redundant information. In\nthe user embedding visualization, we observe that\nthe clustering of user embeddings aligns with the\nexpert weight patterns, demonstrating a clear cor-\nrelation between the behavior of user embeddings\nand expert weight distribution.\n4.6 Case Study\nTo answer RQ6, we conduct a case study on the\nLaMP-7: Personalized Tweet Paraphrasing task for\nuser #21 (user_id: 13002361) in the test set. To\ndemonstrate the effectiveness of progressive learn-\ning, we visualize the training and test samples for\nuser #21, as well as a subset of training samples for\nother users. For text visualization, we use a BERT\nencoder (Reimers and Gurevych, 2019) to generate\ntext embeddings and apply T-SNE for dimensional-\nity reduction.\n\n2503.01437v1\nAs the medium network contains 12.4\ntimes more weights than the small network (see Table 1), the small network should perform well\nwith 62% (= 12.4 \u00d7 5%) of its weights. This means that one could set sF to 0.38 (= 1 \u2212 0.62) for\ntraining the small network. However, even if PolyPruneDQN would achieve good performances at\nthis final sparsity level, it would be significantly lower than the lowest final sparsity level discovered\nby EauDeDQN (0.79 on Pong). 5.2 Offline Q-Learning\nEauDeQN is also designed to work offline as it relies on the cumulated loss to select sparsity levels. Therefore, we evaluate the proposed approach on the same set of 10 Atari games, using an offline\ndataset that is composed of 5% of the samples collected by a DQN agent during 200M environ-\nment interactions (Agarwal et al., 2020). In Figure 6 (left), EauDeCQL outperforms PolyPruneCQL\nfor the small network while reaching high sparsity levels, as shown on the right side of the fig-\nure. Nonetheless, we note that the confidence intervals overlap and that there is a gap between\nEauDeCQL and CQL performances. For the larger network, all algorithms reach similar return,\nwith slowly decreasing return over time, as also observed in Ceron et al. (2024). We attribute this\nbehavior to overfitting as the cumulated losses increase over time (see Figure 12, left). Notably, the\nsparsity levels reached by EauDeCQL are higher for the larger network, as desired (see Figure 6). 5.3 Actor-Critic Method\nWe verify that the proposed framework can be used in an actor-critic setting. Similarly to the online\nAtari experiments in Section 5.1, we observe in Figure 7 a stable behavior of EauDeSAC, which\nyields comparable performances to SAC when the network architecture and the training length vary. On the other hand, PolyPruneSAC suffers when evaluated on small network sizes. The small net-\nwork corresponds to the commonly used architecture ( 256 neurons for each of the 2 linear layers\n(Haarnoja et al., 2018)), the number of neurons per layer is scaled by 5 for the medium network\nand by 8 for the large network. As a sanity check, we verified that the final sparsity levels discov-\nered by EauDeSAC can also be used by PolyPruneSAC to achieve high returns. In Figure 7 (bot-\ntom), PolyPruneSAC (oracle) validates this hypothesis by reaching similar performances as SAC\nand EauDeSAC. Cover Page\n0.0 0.3 0.7 1.00.0\n0.5\n1.0\nSmall network\n0.0 0.3 0.7 1.0\nMedium network\n0.0 0.3 0.7 1.0\nLarge network\n0.0 0.1 0.2 0.30.0\n0.5\n1.0\nSmall network\n0.0 0.1 0.2 0.3\nEnvironment Steps (in millions)\nMedium network\n0.0 1.0 2.0 3.0\nSmall network\nIQM SAC Norm Score\nEauDeSAC PolyPruneSAC PolyPruneSAC (oracle) SAC\nFigure 7: Thanks to its adaptive capability, EauDeSAC performs similarly to its dense counterpart\non 6 MuJoCo games across different network sizes (top row) and training lengths (bottom row). PolyPruneSAC struggles to reach similar returns due to its hard-coded sparsity schedule.\n\n2503.00324v1\nNumerical features, such as Root_DIR_Access and Re-\nmote_Port_ Access , exhibited significant scale variations,\nspanning 100 to 104 (Figure 4). Such disparities can bias\nML models, as algorithms like RF and SVM often prioritize\nfeatures with larger magnitudes, potentially leading to skewed\nperformance. To mitigate this, Minimum\u2013Maximum Normal-\nization method [53] was applied, ensuring all numerical\nfeatures were scaled to a comparable range while preserving\ntheir intrinsic distributions. OpensnoopTraces FeaturesTCPTraces Features\nFig. 4. A boxplot of numerical features from OpensnoopTraces and TCP-\nTraces (before rescaling) on a logarithmic x-axis shows a significant median\ndifference between benign and malicious packages. C. Features Extraction and Selection\nThe initial set consisted of 62 Candidate Features (CFs),\ncapturing various installation behaviors across six trace cat-\negories. However, 22 features were identified as Dependent\nFeatures (DFs) due to high correlation ( |r| > 0.50) and\nwere removed using Pearson Correlation Analysis (r) [54] to\nmitigate multicollinearity. This filtering step resulted in 40 In-\ndependent Features (IDFs) for further evaluation. To illustrate,\nin FiletopTraces, five features were retained, while four were\nremoved due to high correlation. In contrast, PatternTraces\nexhibited no strong correlations ( |r| \u22640.49). This highlights\nthe unique behaviors, reinforcing their importance in detecting\nmalicious patterns. To further refine the feature set, Importance Scores (IMS)\nfrom four ML models were used to select the most relevant\nfeatures [53], [55]. Features with an IMS > 0.05 in at least\none model were retained to ensure flexible feature selection. The final SEF set was determined using Equation 1. SEF =\n(\nf \u2208 CF | |rf | < 0.50, max\nm\u2208M\nIMS m(f) > 0.05\n)\n\u2229\n(\nf | max\nm\u2208M\nIMS m(f) > 0.08\n)\n(1)\nwhere:\n\u2022 CF represents the initial set of candidate features. \u2022 |rf | < 0.50 removes highly correlated features. \u2022 IMS m(f) is the importance score of feature f evaluated\nby model m, where M is the set of all ML models used. \u2022 maxm\u2208M IMS m(f) > 0.05 retains a feature if at least\none model assigns it an importance score > 0.05. \u2022 maxm\u2208M IMS m(f) > 0.08 further filters the features,\nselecting only those with a higher importance threshold. Table III provides an overview of the feature selection\nprocess. For example, all 10 PatternTraces features surpassed\nthe IMS baseline threshold > 0.05 and met the Selected\nEngineered Features (SEF) threshold > 0.08. In contrast,\n\n7\nSystemCallTraces retained only 6 out of 17 features, as one\nfeature failed to meet the SEF threshold in RF, leading to its\nexclusion. After filtering out correlated and low-importance\nfeatures, the CombinedTraces feature set was reduced from\n62 CFs to 36 SEFs, a 58% reduction. The final feature\nset prioritized low inter-feature correlation, high-importance\nscores across models, and computational efficiency. TABLE III\nFEATURE SELECTION AND REDUCTION PROCESS , FILTERING CORRELATED\nFEATURES AND SELECTING IMPORTANT FEATURES .", "metadata": {"type": "reasoning", "source": "2503.01303v1.pdf", "context": "expert 3\nexpert 4\nexpert 5\nCluster\nCluster 0\nCluster 1\nCluster 2\nCluster 3\nCluster 4\nFigure 5: The Visualization of expert weights and user\nembeddings learned in the group-level adaptation. The\nupper left: density plot of expert weights with the user-\naware router and constraint loss; The bottom left: den-\nsity plot of expert weights with regular LoRAMoE;The\nright: Scatter plot of user embeddings after detention\nreduction, colored by the clusters.\n4.5 Visualization\nTo answer RQ5, we visualize th", "quality_score": 8.5}}
{"id": "test_26", "question": "According to the text, what is a limitation of most existing studies on retinal fluid segmentation?", "golden_answers": ["Most existing studies focus on either the retinal layer or fluid segmentation, with limited efforts dedicated to integrating segmentation outcomes with clinical statistical analysis."], "prediction": "Most existing studies focus on either the retinal layer or fluid segmentation, with varying levels of segmentation performance on pathological clinical features, and limited efforts are dedicated to investigating the effect of automated segmentation performance on NPDR/PDR classification or prognosis.", "f1": 0.5901639344262294, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01248v1\nIn cases where excessive\nfluid penetrates the layer boundaries, some portions of the\nlayer become invisible or physically diminished. More clinical\nexpertise is needed to segment the extreme instances properly. HRF segmentation suffers from inconsistencies in ground-truth\nannotations, as small, widely distributed foci are challenging\nto delineate manually. Interestingly, in some cases, automated\nmodels provided more precise segmentations than the manual\nground truth, particularly for HRF regions. Figure 9 shows\nthat the model prediction outperforms the ground truth in HRF\nsegmentation. This suggests that deep learning models could\nbe leveraged for segmentation and refining human annotations. Additionally, using more pre-processing and post-processing\ntechniques may help improve the performance, such as the\npixel-wise relative positional map as an extra input and random\nforest classifier as a label refiner(Ma et al., 2021). Second, additional model comparisons may be necessary\nto provide a more comprehensive evaluation of segmentation\napproaches. While SwinUNETR and VM-UNet demonstrated\nsuperior performance, other architectures excel in certain per-\nspectives. For example, MedSAM enables universal medical\nimage segmentation with zero-shot capabilities(Ma et al.,\n2023). The self-supervised few-shot semantic segmentation\ncan be used for a limited number of labels(Ouyang et al.,\n2022). A broader comparison across multiple deep learning\nmodels could offer more insights into the trade-offs between\nperformance, efficiency, and generalizability. Third, this study\u2019s cross-sectional nature limits its ability\nto track disease progression over time. Longitudinal studies\nwould provide better insights into how retinal layer thickness\nevolves in DR. For example, this study observes RNFL\nthickening in PDR, but longitudinal research often reports\nRNFL thinning due to neurodegeneration. This suggests that\nthe transient swelling observed in cross-sectional studies may\neventually lead to structural atrophy, which can only be\nconfirmed through long-term follow-up studies. Fourth, while the sample size is sufficient to detect sig-\nnificant differences, it may limit the generalizability of the\nfindings. A larger dataset encompassing a broader range of DR\nseverities and treatment histories could provide more robust\nconclusions. Expanding the cohort to include more diverse\npatient populations would also improve the applicability of\nthe findings across different clinical settings. Fifth, the lack of a detailed NPDR severity grading sys-\ntem may limit the ability to distinguish early, intermediate,\nand severe NPDR stages. Different NPDR severities likely\nexhibit distinct retinal layer changes, and a more granular\nclassification system could enhance the understanding of DR\nprogression. Future studies should explore integrating severity-\nbased stratification to assess how thickness variations differ\nacross NPDR subtypes. To our best knowledge, most DR\ngrading datasets with public access focus on fundus color\nimages like Messidor 3 and DRTiD4.\nLastly, integrating multi-modal imaging techniques such as\nOCT angiography (OCTA) could provide additional insights\ninto the vascular changes associated with DR. For example,\nAlam et al. discovered the difference of vascular complex-\nity features between NPDR and PDR patients(Alam et al.,\n2021). Multiple OCT parameters are significantly correlated\nwith DR severity(Laotaweerungsawat et al., 2020). Combining\nstructural OCT findings with functional vascular imaging may\nimprove disease characterization and facilitate more targeted\ntherapeutic interventions. V. C ONCLUSION\n\n2503.01248v3\nIt\nhas been successfully applied to retinal layer segmentation,\nfluid detection, and HRF analysis, achieving state-of-the-art\n(SOTA) performance (Ma et al., 2021, Roy et al., 2017,\nSchlegl et al., 2018, Tennakoon et al., 2018). Generative\nadversarial networks (GANs) were also used for retinal bound-\nary augmentation and segmentation adaptation cross multiple\nOCT domains(Chen et al., 2023, Kugelman et al., 2023). Vision Transformers (ViTs) have recently outperformed CNNs\nin large-scale datasets. Unlike CNNs, which rely on local\nreceptive fields, ViTs employ self-attention mechanisms to\ncapture global dependencies, which is particularly beneficial\nfor detecting diffuse fluid regions. Xue et al. implemented\na Swin-Transformer-based architecture for fluid segmentation\nin diabetic macular edema (DME) and AMD, demonstrating\nsuperior performance over traditional CNN-based models (Xue\nand Du, 2024). Kulyabin et al. leveraged the Segment Any-\nthing Model (SAM) for retinal fluid segmentation, incorporat-\ning point and bounding box prompts to outperform U-Net in\nmacular hole and fluid segmentation tasks (Kulyabin et al.,\n2024). Despite these advancements, most existing studies\nfocus on either the retinal layer or fluid segmentation, with\nvarying levels of segmentation performance on pathological\nclinical features. However, limited efforts are dedicated to in-\nvestigating the effect of automated segmentation performance\non NPDR/PDR classification or prognosis, which is crucial to\nevaluating their clinical translation. Studies have examined the relationship between retinal layer\nthickness, fluid accumulation, and DR severity. Browninget al.\nanalyzed macular thickness across different DR severity levels\nand observed a correlation between macular thickening and\nincreased risk of subclinical edema (Browning et al., 2008). Kim et al. investigated choroidal thickness alterations in DR\nand DME patients, reporting a significant increase in choroidal\nthickness as DR severity progressed from mild/moderate\nNPDR to PDR (Kim et al., 2013). Cho et al. assessed macular\nand peripapillary retinal thickness in DR subjects, identifying\nstatistically significant differences in retinal thickness across\nseven anatomical regions between DR and control groups (Cho\net al., 2010). Santos et al. demonstrated that fluid accumulation\nwithin the outer segment (OS) layer is significantly associated\nwith central retinal thickness and visual impairment in DME\npatients (Santos T et al., 2024). These findings suggest that\nretinal layer thickness and fluid distribution are both reliable\nbiomarkers for DR diagnosis and progression monitoring. However, limited efforts are dedicated to investigating the\neffect of automated segmentation performance on DR/PDR\nclassification or prognosis, which is crucial to evaluating their\nclinical translation. The current study introduces an end-to-end framework in-\ntegrating retinal layer and fluid segmentation with a statistical\nanalysis of structural changes in DR patients. The key contri-\nbutions include:\n1) Development of an efficient active-learning-based seg-\nmentation pipeline for severely pathological DR patients.\n2) Comprehensive evaluation of multiple SOTA deep learn-\ning models, revealing differential performance on seg-\nmenting retinal layers, fluid, and HRF segmentations,\nusing both volume- and thickness-based evaluation met-\nrics for all biomarkers, differentially considering under-\nsegmentation and over-segmentation cases.\n3) Evaluate the clinical translatability of the auto-\nsegmentation-based retinal thicknesses, fluid and HRF\nbiomarkers for differentiating DR severity, as well as\ntheir association with visual acuity.\nII.\n\n2503.01248v1\nAlthough the SwinUNETR\nslightly outperforms VM-UNet in several regions, VM-UNet\n\n8\nhas significantly lower computational complexity (O(N)) than\nSwinUNETR (O(N2), which is crucial for remote deployment\nin clinics with limited computational resources. The segmentation of fluid and HRF remains a significant\nchallenge across all models. Fluid regions exhibit substantial\nvariability, with VM-UNet demonstrating better spatial con-\ntinuity but often under-segmenting these regions. In contrast,\nSwinUNETR captures fluid regions more extensively but is\nprone to occasional over-segmentation. HRF segmentation\npresents an even more significant challenge due to the presence\nof small, widely distributed hyper-reflective regions. Both\nmodels tend to under-segment fluid and HRF, frequently\nmisclassifying them into adjacent retinal layers such as OPL\nand ONL+IS. Moreover, SwinUNETR generally exhibits a\ngreater tendency to under-segment retinal regions than VM-\nUNet. Although significant weight adjustments were applied to\nfluid and HRF regions, as described in Section II-E, additional\nstrategies are needed to enhance model learning and improve\nsegmentation performance in these complex regions. Significant differences in retinal layer thickness between\nNPDR and PDR offer valuable insights into the progres-\nsion of DR. Prior to adjusting for potential confounders,\nincluding age, gender, and duration of diabetes, RNFL was\nsignificantly thicker in the NI and TI sectors in PDR. This\nfinding contrasts with previous reports indicating RNFL thin-\nning in more advanced stages of NPDR and PDR (Ulhaq\net al., 2022)(Bhaskaran et al., 2023). It suggests that transient\nswelling, likely induced by abnormal blood vessel growth,\nmay occur during the early acute phase of PDR but subse-\nquently diminishes as chronic edema and neuroinflammation\nlead to tissue loss (Garcia et al., 2013). After adjusting\nfor confounders, statistical significance persists in these two\nRNFL sectors, suggesting that these structural changes alone\nmay serve as potential biomarkers for the early detection of\nPDR. When comparing these findings to model predictions,\nVM-UNet demonstrates greater consistency with ground-truth\nresults than SwinUNETR, particularly in the RNFL and OS\nsectors. The loss of statistical significance for HRF is likely\ndue to under-segmentation by both models. This highlights\nthe sensitivity of retinal thickness analysis to segmentation\nvariations and underscores VM-UNet\u2019s suitability for detecting\nsignificant differences in retinal thickness between NPDR and\nPDR. GCL+IPL exhibited significant thinning in PDR in the II, TI,\nand IO sectors before adjustment, reflecting the apoptosis of\nganglion cells due to potential neurodegeneration and inflam-\nmatory responses. However, after adjusting for confounders,\nthe TI and IO sectors are no longer significant, suggesting\nthat systemic factors play a role in some but not all aspects of\nGCL+IPL thinning in PDR. Similarly, the OS layer showed\nconsiderable thinning in PDR across all sectors before con-\nfounders adjustment, highlighting widespread photoreceptor\ndegeneration and atrophy. After adjustment, thinning in the\nTI sector lost significance. This suggests that overall OS\ndeterioration is a hallmark of DR progression and an early\nmarker of photoreceptor damage in PDR. While not statistically significant in the t-test analysis, fluid\naccumulation was more prevalent in PDR than NPDR based\non example cases shown in Figure 8.", "metadata": {"type": "reasoning", "source": "2503.01248v1.pdf", "context": "in diabetic macular edema (DME) and AMD, demonstrating\nsuperior performance over traditional CNN-based models (Xue\nand Du, 2024). Kulyabin et al. leveraged the Segment Any-\nthing Model (SAM) for retinal fluid segmentation, incorporat-\ning point and bounding box prompts to outperform U-Net in\nmacular hole and fluid segmentation tasks (Kulyabin et al.,\n2024). Despite these advancements, most existing studies\nfocus on either the retinal layer or fluid segmentation, with\nlimited efforts dedicated to", "quality_score": 8.5}}
{"id": "test_27", "question": "Why was a large number of examples (1,000) selected for testing in each experiment?", "golden_answers": ["To ensure the representativeness and credibility of the experimental results by covering various input data types."], "prediction": "The large number of examples (1,000) was selected for testing in each experiment to ensure comprehensive coverage of diverse scenarios, allowing for a robust assessment of model performance and the identification of limitations across various datasets.", "f1": 0.21276595744680848, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.00597v1\nThese examples\nwere chosen specifically to highlight the performance extremes across datasets: one demonstrating strong model\nperformance and the other showcasing its limitations.\n\n2503.00077v1\nNotably, in 40 studies (36%), the purpose of CC\nidentification or generation was not explicitly stated, thus they\nwere excluded from this analysis. 1) Testing and Validation: CCs are extensively utilized to\ntest and validate ADS, helping to assess their performance,\nsafety, and robustness in rare and critical scenarios. The\nprimary objective is to assess how well an ADS handles rare\nand critical scenarios, evaluating if it meets safety expectations\nbefore deployment. Many studies highlight the use of CCs to\nvalidate ADS performance under extreme conditions, bench-\nmarking against regulatory and safety requirements [36], [38],\n[65], [67], [68], [70], [71], [79], [81], [87], [92], [96], [101],\n[106], [113], [117]\u2013[119], [121], [125], [127]\u2013[132], [136],\n[138], [140], [150], [154], [157]\u2013[161], [164], [165], [167],\n[169]. By simulating these scenarios, researchers can measure\nthe effectiveness of the system, identify performance limita-\ntions, and refine models accordingly. Comprehensive testing\nframeworks based on CCs have been shown to help identify\nweaknesses and support the effective operation of ADS in\ndiverse environments, potentially accelerating the develop-\nment process [113], [154], [158]. Additionally, these testing\nmethods contribute to maintaining critical safety standards\nthroughout the system\u2019s lifecycle in its operational design\ndomain. 2) Training and Optimization: The generation and iden-\ntification of CCs also serve as a foundation for improving\nthe learning process and optimization of A V systems. Studies\nfocus on using CCs to enhance the training datasets for model\ncontrol development [86], [105], [107], [142], [144] aiming to\nimprove A V control and safety. For instance, algorithms that\nfine-tuning with rare scenarios seek to enhance the system\u2019s\nability to handle unforeseen situations effectively [88], [122]. Training with enriched pedestrian datasets, for example, can\ndirectly improve detection and control algorithms, which in\nturn supports the development of more robust and adaptive\nADS policies capable of efficiently responding to critical\nscenarios [142], [145]. 3) Dataset Generation and Augmentation: Another sig-\nnificant application of CCs is in generating diverse and\ncomprehensive datasets. Some studies highlight how CCs\nenrich datasets to capture rare, critical, or unexpected sce-\nnarios, which are often underrepresented in standard datasets\n[74], [102], [135], [151]. This enrichment is essential for\nbenchmarking, developing test cases, and improving ADS\nalgorithms. For example, synthetic data generated from CCs\ncan effectively reduce the cost and time associated with\nacquiring real-world data, while ensuring extensive coverage\nof challenging scenarios [91]. Furthermore, the importance of\naugmenting datasets to improve simulation-based evaluation\nframeworks is emphasized, as it plays a key role in enabling\nA V systems to adequately address the variability and complex-\nity inherent in real-world environments [76], [98], [166]. 4) Safety Assessment and Standardization: CCs are instru-\nmental in assessing the safety of A V systems and defining\nstandards for their performance. [85], [126], [155] illustrate\nhow CCs can be used to evaluate compliance with safety\nbenchmarks and regulatory requirements. For instance, [100]\ndiscusses leveraging CCs to supplement existing testing frame-\nworks and establish test schemes that ensure A Vs meet strin-\ngent safety criteria. This category underscores the critical role\nof CCs in fostering public trust and regulatory acceptance of\nautonomous technologies.\n\nA Review of LLM-Assisted Ideation\nInferential statistical methods were employed in 19 studies (70%) to draw conclusions and test hy-\npotheses based on the quantitative data. As shown in Table 11, these methods can be further classi-\nfied into parametric tests and non-parametric tests. Parametric tests (14 out of 27, or 52%), which as-\nsume a normal distribution of the data, include Normality Tests (e.g., Shapiro-Wilk Test), Mean Com-\nparison Tests (e.g., Independent T-test, Paired-sample T-test, One-tailed T-test), Analysis of Variance\n(e.g., Welch\u2019s ANOVA, ANOVA, MANOVA), and Correlation Tests (e.g., Pearson Correlation). Non-\nparametric tests (13 out of 27, or 48%), which do not assume a normal distribution of the data, include\n\n34\nRank Tests (e.g., Wilcoxon Rank-Sum Test or Mann-Whitney U Test, Wilcoxon Signed-Rank Test),\nMultiple Group Comparison (e.g., Kruskal-Wallis Test, Friedman\u2019s Test), and Post-hoc Tests (e.g.,\nGames-Howell Test). Regarding the evaluation criteria used in quantitative analyses of ideas, the Table 12 reveals that\nnovelty was the most frequently used criterion, appearing in 6 studies. Other related terms, such\nas innovativeness and uniqueness, were used in 3 studies. Relevance was the second most common\ncriterion, used in 3 studies, while variety was used in 2 studies. Table 12. Evaluation Criteria\nCategory Criterion Description Ref. Novelty Novelty Evaluates whether the idea demonstrates originality and\noffers a fresh perspective or concept. [86], [85], [78],\n[67], [69], [65]\nInnovativeness Assesses the degree to which the idea introduces\ninnovative approaches that transcend existing norms.[95], [84]\nUniqueness Examines whether the idea stands out distinctly from\nother concepts or generated outputs. [65]\nRelevance Relevance Measures the alignment of the idea with the given task,\ntopic, or research objectives. [95], [67], [70]\nDiversity Variety Examines the breadth of perspectives or options\npresented by the idea, emphasizing its diversity.[86], [50]\nFunctionality and UsabilityUsability Examines whether the idea is intuitive and practical,\nfacilitating ease of adoption and application. [78], [50]\nFeasibility Determines whether the idea is realistically\nimplementable in practical scenarios. [78], [67]\nEfficiency Assesses the idea\u2019s potential to achieve objectives\neffectively within resource constraints. [50]\nFunctionality Evaluates the idea\u2019s capacity to address specific\nfunctional needs or solve targeted problems. [78]\nImpact and Inspiration Impact Measures the potential of the idea to effect significant\nchange or address major challenges. [67], [70]\nInsightfulness Assesses whether the idea provides deep, unique\ninsights that enhance understanding of a problem.[95]\nInspiration Evaluates the idea\u2019s ability to stimulate further creative\nthinking or ideation. [50]\nMeaningfulness Considers whether the idea is contextually significant\nand capable of evoking value or resonance. [85]\nLogical Coherence Plausibility Determines whether the idea is logical, realistic, and\nconsistent with common sense or knowledge. [70]\nClarity and Specificity Clarity Assesses whether the idea is clearly articulated and\nunambiguous, enhancing its comprehensibility.[70]\nSpecificity Evaluates the level of detail and precision in the idea,\nensuring actionable outcomes. [67]\nFunctionality and usability-related criteria, such as usability, feasibility, efficiency, and functional-\nity, were used in a total of 6 studies, with usability and feasibility being the most common (2 stud-\nies each).", "metadata": {"type": "reasoning", "source": "2503.01319v1.pdf", "context": "4 Experiment setup\nTo verify the testing effectiveness of ABFS on LLM-based NLP software, we conducted\na series of experiments on three text classification datasets and five threat models.\nAll experiments were performed on an Ubuntu 22.04.1 LTS system equipped with\ntwo 32-core Intel(R) Xeon(R) Platinum 8358 CPUs at 2.60GHz, four NVIDIA A100\nTensor Core GPUs, and 1TB of physical memory. Each experiment was repeated three\ntimes, and the results for each metric were averaged. Similar to previous st", "quality_score": 8.5}}
{"id": "test_28", "question": "What can be inferred about the focus of the studies cited in the text, based on their arXiv classifications?", "golden_answers": ["The studies focus on particle physics (hep-ph) and lattice field theory (hep-lat)."], "prediction": "The studies cited in the text focus on various aspects of healthcare and biomedical literature classification, including COVID-19 research, cancer research, and general medical literature classification, as well as the ethical considerations surrounding data privacy and algorithmic bias. Additionally, there is a focus on machine learning applications in bug report classification, indicating a diverse range of topics within the fields of healthcare and software engineering.", "f1": 0.1142857142857143, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01159v1\nCOVID-19 research has also been present, with Guo et al. (2024) analyzing\ntreatment-related papers and Yang et al. (2024) developing a binary classification for SARS-CoV-2 and Nipah virus\nliterature for drug discovery purposes. In the scope of clinical and medical topics, Wang et al. (2023) tackled the classification of clinical trial screening\ncriteria, developing 44 semantic categories through the CHIP-CTC dataset, encompassing descriptive sentences. Sarkar\n14\n\net al. (2023) addressed the categorization of medical blog articles across 18 predefined topics, including headache,\nmental health, and heart health. Cancer research classification has been significant, with multiple studies, including\nChen et al. (2022) and Chen et al. (2023), utilizing the Hallmarks of Cancer (HoC) dataset to classify cancer biology\ncharacteristics. Other research studies focused on different research classifications. Chen et al. (2024b) developed a three-tier advice\nclassification system (no advice, weak advice, strong advice) for medical research abstracts. Kementchedjhieva and\nChalkidis (2023) worked with the BIOASQ dataset (consisting of biomedical articles from PubMed), implementing\nclassification based on the Medical Subject Headings (MeSH) taxonomy. Qi et al. (2023) addressed industrial\nbiomedical literature mining tasks, focusing on recognizing special biomedical phrases. The data was acquired with\ninherent label noise due to crowd-sourcing and labeling preferences. For the testing part, relabeling was conducted on a\nsubset of data and assumed being clean. General medical literature classification has been explored through various datasets. Yang et al. (2022) leveraged\nPubMed abstracts and Wikipedia articles for pre-training, while Schneider et al. (2021) utilized both PubMed and\nSciELO databases for fine-tuning. Gretz et al. (2023) contributed to this field by working with the Medical Abstracts\ndataset. Bet, ianu et al. (2024) and Luo et al. (2024) further expanded the research using PubMed datasets, with Luo\net al. specifically incorporating multiple datasets, including BC7LitCovid, for comprehensive biomedical literature\nclassification. 4.1.4. Ethical Considerations\nThese research studies employed various data sources, from social media platforms to EHR and literature databases,\nand used different categorization approaches ranging from binary to multi-class and multi-label classifications. The\nresearch spans multiple languages and formats, reflecting healthcare text classification research\u2019s global and diverse\nnature. However, leveraging LLMs to carry out this type of task in healthcare presents significant ethical concerns\naround patient privacy and data security without forgetting about the algorithmic bias that can emerge. The protection\nof sensitive health information is crucial under regulations that vary based on the country, such as the Health Insurance\nPortability and Accountability Act (HIPAA) in the U.S. This is particularly important when dealing with an LLM\nrequiring API requests (e.g., GPT-4o) where the classification cannot be run locally, and when the text data consists\nof clinical notes where patients\u2019 Protected Health Information (PHI) should be detected and de-identified in advance. To overcome the challenge resulting from the sensitive nature of healthcare textual data, researchers in the reviewed\nliterature resorted to different ethical considerations. Some research papers conducted all their experiments locally; this\nis especially convenient when fine-tuning BERT (or variant).\n\nAn Empirical Study on the Classification of Bug Reports with Machine Learning\nWe consider five well-known algorithms: k-Nearest Neighbor classifier (k-\nNN) [12], Na\u00efve Bayes (NB) [29], the Support Vector Machine (SVM) [11],\nRandom Forest (RF) [8], and Logistic Regression (LR), which are known to\nhave been used in related work and for which heterogenous results are known\n(refer to Table 1 for an overview). These are further discussed in Section 3.4. Regarding RQ3, the goal is to understand if the main programming lan-\nguage of the project to which the issue report is associated contributes (or\nnot) to significant differences in the classification effectiveness. Notice that\nnowadays it is very usual for projects to be written using multiple program-\n9\n\nming languages (e.g., a project may use backend services written in Python\nalong with a frontend fully developed in Javascript). Thus, we refer to the\nmain programming language of the project as being the one in which the\nmajority of the code is written. The motivation for pursuing this questions\nis that our analysis of the literature does not allow concluding if the pro-\ngramming language, which for instance, may be associated with distinct issue\nreport writing patterns by developers, is a relevant factor in the classification\neffectiveness or not [54, 25, 68, 14]. In RQ4, we focus our attention in the system used to report the bugs. The hypothesis is that the performance of classifiers might be influenced by\nthe way different issue tracking systems (ITSs) allow developers to report\nbugs (e.g., by limiting the size of the fields used to report the bug, or by\nforcing the reporter to place information in certain predefined fields). While\nseveral authors analyzed GitHub issue reports (e.g., [25, 14]), others used Jira\nreports (e.g., [47, 37]) and others opted by BugZilla (e.g., [5, 27]), but there is\nno representative study that considers multiple ITSs in order to understand\ntheir influence in the results. Finally, in RQ5, we analyze how well a model trained with data from\nvarious projects can classify samples that belong to a different software sys-\ntem (i.e., one that was not used in training). This is also an open issue in the\nliterature, known ascross-project classification[57, 69, 63] and our results,\ncomplemented with the ones from the previous RQs, will help developers and\nresearchers in creating models that are able to classify issue reports from\nprojects that are just starting or simply do not contain sufficient information\nfor training purposes. In the following sections, we discuss the experimental approach followed,\nwhich is based on a classical Machine Learning pipeline [19, 51], as illus-\ntrated in Figure 1: i) data acquisition, ii) data preprocessing, iii) feature\nengineering, iv) model selection, andv) model evaluation. 3.1. Data Acquisition\nTo answer the research questions, and as a preparatory step, in previous\nwork, we presented the BugHub dataset [3]. In this section, we present a\nbrief summary of how it was built (to allow the reader to better understand\nthe whole context and the approach) and define which portion of BugHub is\nused in the context of this paper.\n\nA template for the arxiv style\nFigure 8(c) shows the sine similarity between the estimated latents and the true values which is computed as\nerr(\ud835\udc81\ud835\udc61\ud835\udc5f\ud835\udc62\ud835\udc52 ,\ud835\udc81\ud835\udc52\ud835\udc60\ud835\udc61)= 1\n\ud835\udc47\n\ud835\udc47\u00d5\n\ud835\udc56=1\n\uf8ee\uf8ef\uf8ef\uf8ef\uf8ef\uf8f0\n1 \u2212\n \n\u27e8\ud835\udc9b(\ud835\udc61)\n\ud835\udc56 ,\ud835\udc9b(\ud835\udc52)\n\ud835\udc56 \u27e9\n\u2225\ud835\udc9b(\ud835\udc61)\n\ud835\udc56 \u2225\u2225\ud835\udc9b(\ud835\udc52)\n\ud835\udc56 \u2225\n!2\uf8f9\uf8fa\uf8fa\uf8fa\uf8fa\uf8fb\n, where\ud835\udc9b(\ud835\udc61)\n\ud835\udc56 are the true latent values and\ud835\udc9b(\ud835\udc52)\n\ud835\udc56 are the estimated\nlatent representations. The error metric goes to zero as the estimated latents align with the true latents as\nshowninFigure8(c). Figure8(d)showsthetruevalues, initialvaluespriortooptimizationandtheestimated\nvalues post optimization. We observe that the estimated latents align with the true latents, however, the\nrelaxed nature of the optimization problem affects the\ud835\udc452 value which is less than 1, which suggests that\nimposing the constraints on the latent kernel structure plays a role in improving the implicit generative maps. Finally, varying\ud835\udefc in Equation 16, we found that\ud835\udefc =1 produced the best\ud835\udc452 value. Imposingmetabolicconstraintscapturethecurvatureofthedatamanifold,butproperpredictionwarrants\nappropriate kernel structure:Finally, we apply metabolic constraints on the latent activity, imposed in the\nform a probability simplex, to understand how the representations capture information about the input\ngeometry in the SMPC architecture (similar to \u00a76.3). The initialization details for the optimization process\nare discussed in the appendix, with Figure 9 demonstrating the results at the end of the optimization process. 21\n\narXivTemplate A Preprint\nFigure 9 (a) demonstrates the input data manifold (we use the moons dataset [Pedregosa et al., 2011] similar\nto \u00a76.3), alongside the predicted values at the beginning of the optimization process and the final predicted\nvalues. Additionally, we plot the implicit generative maps, estimated using the circuit parameters (red cross). We see that the predicted inputs are able to capture the curvature of the input manifold and correlates well\n(good similarity measure) with the input data, with the implicit generative maps following the curvature of\nthe individual manifolds to form. However, the prediction does not align perfectly with the input due to the\nrelaxed nature of the optimization problem, which lacks any constraints on the kernel structure of the latent\nspace. Nevertheless, we see emergence of local receptive field properties of individual neurons (shown in\nFigure 9 (b)) similar to the ones observed in \u00a76.3, suggesting that the simplex constraints tune neurons to\ncapture the geometry of the input manifolds. Close initialization\nManifold Reconstruction Neuronal Selectivity\nx2\nx1\na b\nFigure 9: Applying probability simplex constraints on the latent representations. (a) Predicted inputs\n(green) (\u02c6\ud835\udc7f) from the two moons dataset alongside the true values (red) and the initial value (blue) prior\nto the optimization process. We see that the predicted inputs is able to capture the shape and structure\nof the data manifold (due to similarity alignment), however, due to the relaxed nature of the optimization\nproblem, the prediction does not align perfectly with the input. The estimated receptive fields (indicated by\na red cross), also circumvents the predicted manifold along its curvature. The final\ud835\udc452 value achieved was\n0.7. (b) Neuronal selectivity, shows the input samples that the a particular neuron is getting activated for,\ndemonstrating local receptive nature of the neurons, albeit wider than the case in Figure 5.", "metadata": {"type": "reasoning", "source": "2503.01322v2.pdf", "context": "12\narXiv:0807.2674 [hep-ph].\n[22] Y .-R. Liu, X. Liu, W.-Z. Deng, and S.-L. Zhu, Eur. Phys. J. C\n56, 63 (2008), arXiv:0801.3540 [hep-ph].\n[23] D. Gamermann and E. Oset, Phys. Rev. D 80, 014003 (2009),\narXiv:0905.0402 [hep-ph].\n[24] C. Bignamini, B. Grinstein, F. Piccinini, A. D. Polosa,\nand C. Sabelli, Phys. Rev. Lett. 103, 162001 (2009),\narXiv:0906.0882 [hep-ph].\n[25] J. Nieves and M. P. Valderrama, Phys. Rev. D 86, 056004\n(2012), arXiv:1204.2790 [hep-ph].\n[26] F.-K. Guo, C. Hanhart, U.-G. Mei\u00df", "quality_score": 8.5}}
{"id": "test_29", "question": "What is the primary focus of Section IV-C in the evaluation?", "golden_answers": ["The performances of adding a new task during the operational life of HAR."], "prediction": "The primary focus of Section IV-C in the evaluation is on the user study design, examining the number of conditions investigated and the experimental design approaches adopted.", "f1": 0.12500000000000003, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.00751v1\nThis observation underscores the chal-\nlenge of evaluating long-form content quality using\na single metric. In contrast, RAPID demonstrates\nsuperior performance across multiple evaluation\ncriteria, reinforcing its robustness and effective-\nness. The quality evaluation results of outlines are pre-\nsented in Table 2. RAPID significantly outper-\nforms other methods across different foundation\nmodels, particularly in recall and F1-score met-\nrics. This demonstrates its superior ability to main-\ntain thematic focus while achieving comprehensive\ncoverage of research topics. Notably, although\nSTORM achieves relatively higher recall compared\nto other baselines, RAPID can efficiently generate\nhigher-quality outlines through retrieval of similar\ntopics, without requiring complex multi-turn agent\ndiscussion mechanisms. Backbone Avg. Nodes\nAvg. Edges\nDependency\nDensity\nLongest\nPath\nQwen-Max 8.72 16.64 2.09 2.79\nDeepSeek-v3 7.21 12.18 1.91 2.62\nGPT-4o 8.43 11.86 1.55 3.59\nTable 3: Results of the graph metrics of Writing Plan. 5.2 Ablation Studies\nTo evaluate the impact of the writing plan, we con-\nducted an ablation study on GPT-4o by removing\nthe Plan-Guided Article Generation module and\ninstead employing a parallel section-wise genera-\ntion approach (denoted as \"w/o plan\"). As shown\nin Table 1, the absence of a writing plan led to\nperformance degradation across multiple metrics,\nparticularly in organization and factuality. Without\ncontextual paragraph awareness, the model exhib-\nited stylistic inconsistencies and coherence issues\nbetween sections, explaining the decline in orga-\nnization scores. Additionally, generating sections\nin isolation resulted in redundant content, as each\nparagraph attempted to cover multiple aspects of\nthe topic independently. While techniques such as\nSTORM can partially mitigate these issues through\npost hoc refinement, maintaining coherence and\nquality in long-form text remains challenging due\nto inherent output length limitations. In contrast,\nour structured planning approach explicitly defines\ninter-sectional dependencies, enhancing overall co-\nherence and enabling the generation of longer,\nmore cohesive articles. These findings underscore\nthe critical role of planning in long-form text gen-\neration. 5.3 Writing Plan Analysis\nOur method relies on constructing a directed\nacyclic graph (DAG) of sections prior to writing,\nwhich defines the contextual dependencies between\nsections. In this section, we analyze the Writing\nPlan\u2019s functionality through graph-theoretical met-\nrics. By representing sections as nodes and inter-\nsectional dependencies as directed edges, we for-\nmally define the Writing Plan as a DAG structure\nG = (V, E), where V = {v1, v2, . . . , vn} denotes\nthe set of n nodes (sections), and E \u2286 V \u00d7 V\nrepresents the directed edges indicating dependen-\ncies. To quantify the \"dependency density\" of the\nWriting Plan, we define it as the ratio of the num-\nber of edges to the maximum possible edges in a\n7\n\nminimally connected DAG:\nD(G) = |E|\nn \u2212 1, (7)\nwhere |E| is the cardinality of the edge set E, and\nn\u22121 corresponds to the maximum number of edges\nin a linear chain structure. For example, in a slid-\ning window of length k = 1, where each section\ndepends only on its immediate predecessor, the\nnumber of edges is |E| = n \u2212 1, yielding a depen-\ndency density of D(G) = 1.\n\n2503.00946v2\nThe analysis focuses on three key aspects: user study design, quali-\ntative analysis, and quantitative analysis. User study design examines the number of conditions investigated and the exper-\nimental design approaches adopted. Qualitative analysis methods include interview-based methods (58%), observation-\nbased methods (30%), and log-based methods (12%), with inductive approaches being the primary qualitative data analysis\ntechniques. Quantitative analysis utilizes tools such as Likert scales (58%), NASA-TLX (30%), and Consensual Assessment\nTechnique (12%). Descriptive statistics (44% mean, 35% standard deviation) and inferential statistics (33% parametric tests,\n30% non-parametric tests) are used to analyse the quantitative data, with novelty, relevance, and functionality being the\nmost frequently used evaluation criteria for ideas. By synthesizing the user study methodologies employed in the reviewed papers, we aim to provide a\ncomprehensive overview of the current practices in evaluating LLM-assisted ideation systems from\na user perspective. This analysis highlights the diverse approaches taken by researchers to assess\nthe effectiveness and user reception of these systems, as well as the key dimensions considered in\ntheir evaluation. The insights gained from this review can inform the design and execution of future\nuser studies in this domain, ultimately contributing to the development of more user-centric and\neffective LLM-assisted ideation systems. 6.1 User Study Design\nThe design of user experiments plays a crucial role in ensuring the validity and reliability of the\nfindings. As shown in table 8, among the 43 papers that conducted user study, 18 studies (42%)\nfocused on a single condition, while 17 studies (40%) investigated two conditions. Additionally, 6\nstudies (14%) explored three conditions, and 2 studies (4%) examined four conditions. 30\nThe choice between single-condition and multi-condition experiments reflects the researchers\u2019 ob-\njectives and the complexity of the investigated phenomena. Single-condition studies typically in-\nvolve the evaluation of a specific LLM-assisted ideation tool, method, or framework developed within\nthe study. These experiments aim to provide an in-depth exploration of the proposed approach, as-\nsessing its performance, user reception, and potential impact on the ideation process. By focusing\non a single condition, researchers can gather detailed insights into the strengths, weaknesses, and\nuser experiences associated with their proposed solution. Table 8. User Study Design\nConditions Design Experimental Design Counterbalancing TechniqueRef. One Condition - -\n[94], [82], [93], [76],\n[86], [60], [89], [84],\n[34], [79], [39], [42],\n[49], [50], [47], [67],\n[65], [63]\nmixed-factorial design Latin Square [56]\nbetween-subjects design - [36], [55], [43], [45]\nTwo Conditions - [82], [88], [75], [68],\n[69], [58]within-subjects design random counterbalancing [61]\ncomplete counterbalancing [91], [44], [48], [66],\n[57]\nmixed-factorial design complete counterbalancing [83]\nbetween-subjects design - [85], [77], [59]Three Conditions Latin Square [53]within-subjects design random counterbalancing [46]\nbetween-subjects design - [54]Four Conditions within-subjects design - [64]\nOn the other hand, multi-condition experiments are designed to enable comparative analyses be-\ntween different approaches or variations of an LLM-assisted ideation system. These experiments\nmay involve comparing the developed tool or method against a baseline or existing solution, allow-\ning researchers to assess the relative effectiveness and user preferences between the two conditions.\n\n2503.00946v1\nThe analysis focuses on three key aspects: user study design, quali-\ntative analysis, and quantitative analysis. User study design examines the number of conditions investigated and the exper-\nimental design approaches adopted. Qualitative analysis methods include interview-based methods (58%), observation-\nbased methods (30%), and log-based methods (12%), with inductive approaches being the primary qualitative data analysis\ntechniques. Quantitative analysis utilizes tools such as Likert scales (58%), NASA-TLX (30%), and Consensual Assessment\nTechnique (12%). Descriptive statistics (44% mean, 35% standard deviation) and inferential statistics (33% parametric tests,\n30% non-parametric tests) are used to analyse the quantitative data, with novelty, relevance, and functionality being the\nmost frequently used evaluation criteria for ideas. By synthesizing the user study methodologies employed in the reviewed papers, we aim to provide a\ncomprehensive overview of the current practices in evaluating LLM-assisted ideation systems from\na user perspective. This analysis highlights the diverse approaches taken by researchers to assess\nthe effectiveness and user reception of these systems, as well as the key dimensions considered in\ntheir evaluation. The insights gained from this review can inform the design and execution of future\nuser studies in this domain, ultimately contributing to the development of more user-centric and\neffective LLM-assisted ideation systems. 6.1 User Study Design\nThe design of user experiments plays a crucial role in ensuring the validity and reliability of the\nfindings. As shown in table 8, among the 43 papers that conducted user study, 18 studies (42%)\nfocused on a single condition, while 17 studies (40%) investigated two conditions. Additionally, 6\nstudies (14%) explored three conditions, and 2 studies (4%) examined four conditions. 30\nThe choice between single-condition and multi-condition experiments reflects the researchers\u2019 ob-\njectives and the complexity of the investigated phenomena. Single-condition studies typically in-\nvolve the evaluation of a specific LLM-assisted ideation tool, method, or framework developed within\nthe study. These experiments aim to provide an in-depth exploration of the proposed approach, as-\nsessing its performance, user reception, and potential impact on the ideation process. By focusing\non a single condition, researchers can gather detailed insights into the strengths, weaknesses, and\nuser experiences associated with their proposed solution. Table 8. User Experiment Design\nConditions Design Experimental Design Counterbalancing TechniquesRef. One Condition - -\n[94], [82], [93], [76],\n[86], [60], [89], [84],\n[34], [79], [39], [42],\n[49], [50], [47], [67],\n[65], [63]\nmixed-factorial design Latin Square [56]\nbetween-subjects design - [36], [55], [43], [45]\nTwo Conditions - [82], [88], [75], [68],\n[69], [58]within-subjects design random counterbalancing [61]\ncomplete counterbalancing [91], [44], [48], [66],\n[57]\nmixed-factorial design complete counterbalancing [83]\nbetween-subjects design - [85], [77], [59]Three Conditions Latin Square [53]within-subjects design random counterbalancing [46]\nbetween-subjects design - [54]Four Conditions within-subjects design - [64]\nOn the other hand, multi-condition experiments are designed to enable comparative analyses be-\ntween different approaches or variations of an LLM-assisted ideation system. These experiments\nmay involve comparing the developed tool or method against a baseline or existing solution, allow-\ning researchers to assess the relative effectiveness and user preferences between the two conditions.", "metadata": {"type": "factual", "source": "2503.01353v1.pdf", "context": "This section is organized as follows. Section IV-A details\nthe datasets used for the evaluation. Section IV-B evaluates\nthe classification capability. Section IV-C evaluates the per-\nformances of adding a new task during the operational life\nof HAR. Finally, Section IV-D discusses the memory usage,\ncomputation requirements, and mean latency.\nA. Datasets\n1) UCA-EHAR dataset: The UCA-EHAR dataset [12] in-\ncludes gyroscopic and accelerometer data collected from smart", "quality_score": 8.5}}
{"id": "test_30", "question": "What is a limitation of the LG-VQ method?", "golden_answers": ["It has limitations regarding insufficient alignment between codebook and text, primarily due to the brevity of the existing image captions."], "prediction": "The documents do not explicitly mention a limitation of the LG-VQ method.", "f1": 0.07407407407407407, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.00094v1\nFor this reason, uncertainty quantification has become a golden\nstandard in many industrial applications. It can be achieved in\nseveral ways. A first approach consists in combining standard ML algo-\nrithms with model-free UQ techniques. Standard ML algo-\nrithms already used in the literature to build surrogate models\ninclude gradient boosting methods, polynomial chaos expan-\nsion, random forest, response surface methods, and polynomial\nsplines. It can be plugged with model-free UQ techniques\nsuch as Monte Carlo, conformal predictions, and various en-\nsemble methods (Bootstrap prediction intervals, infinitesimal\nJackknife, and Out-Of-Bag errors). This first approach offers\ngreat flexibility in the surrogate model selection, and UQ\nmethods rely on mild assumptions that are often respected. The\nmain drawback of these model-free UQ techniques is that they\ntend to produce overly large confidence intervals with small\ndatasets. They also have a high computational cost, making\nthem poorly suited to building fast-to-evaluate uncertainty-\naware surrogate models. A second possible approach consists in adapting existing\nprediction models to enable them to quantify uncertainty. For\nexample, quantile regression (QR) methods modify the loss\nfunction so that the machine learning model predicts a specific\nquantile of the expected output. Predicting the median, the 5%,\nand the 95% quantiles allows obtaining a prediction and the\nassociated 90% confidence interval. Other works also propose\nto combine the predictive power of artificial neural networks\n(ANN) with deep-learning-specific UQ techniques, such as the\ndelta method, the mean-variance estimation, the lower upper\nbound estimation, and quality-driven ensemble methods. There\nare two drawbacks to this second approach. First, for both\nQR and ANN, a lot of data is required to train the models\neffectively. Second, the obtained surrogate model is black-box,\nwhich is undesirable for safety-critical applications such as\nensuring power grid security. A third increasingly adopted solution to build accuracy-\naware surrogate models is Gaussian processes. Instead of\na simple prediction, GPs provide a full posterior Gaussian\ndistribution N\n\u0000\n\u00b5\u2217, \u03c32\n\u2217\n\u0001\nof the outcome, which is much more\ninformative. The posterior mean \u00b5\u2217 constitutes the prediction,\nand the posterior standard deviation \u03c3\u2217 is used for UQ. Many\nreasons explain the growing popularity of GPs. \u2022 GPs are flexible non-parametric models . Many ma-\nchine learning models are parametric. They learn an\napproximation \u02dcf that belongs to a parametric set of\nfunctions { \u02dcf\u03b8, \u03b8 \u2208 \u0398} (polynomial regressors, neural\nnetworks...). The hyperparameters \u03b8 are optimized with\nthe train data that no longer contribute to the model\nafterward. All the exploited information is compressed\ninto \u03b8. Unlike these models, the GP does not assume a\nfixed number of parameters to approximate the function. Instead, it automatically adapts the model\u2019s complexity\nto the dataset size, which is very flexible. \u2022 GPs provide both prediction and UQ . Instead of\nlooking for one prediction that best fits the data, the\nGP assumes that many approximations could plausibly\nmodel the data. The GP then assigns to each approx-\nimation a probability of actually representing the true\nfunction. The most probable approximation constitutes\nthe GP prediction; the other likely ones contribute to\nUQ.\n\n2503.01261v2\nFollowing VQ-GAN and LG-VQ\n[13, 29], all images are reshaped 256 \u00d7 256 for reconstruc-\ntion and generation. We set the down-sampling factor f to\n16 and the codebook size K to 1024, with a batch size of\n6. The architecture of TA-VQ exactly follows VQ-GAN\nexcept for the proposed hierarchical encoder and semantic\nalignment module. All FNNs are 2-layer multilayer percep-\ntion (MLP) with ReLU activation function. The three key\nhyperparameters (\u03b1, \u03b2, and \u03b3) are uniformly set to 0.001\nacross all datasets. For further details regarding the gener-\nated text, please refer to the supplementary materials. 5.2. Discussion of Results\nTab. 1 compares our method and the state-of-the-art VQ-\nbased method in image reconstruction performance. From\nthe results, we can obtain several key conclusions: 1) Compared with the backbone network ( i.e., VQ-GAN, and\nCVQ), our method can learn more robust codebook repre-\nsentation by introducing pre-trained text semantics to sig-\nnificantly improve reconstruction performance, indicating\nthe effectiveness of our method; 2) Our method surpasses\nLG-VQ across all datasets, largely due to its ability to in-\ntegrate long text with richer semantic knowledge and ef-\nfectively encode them at different granularities to learn\nmore robust codebook learning; 3) Compared to VQCT, our\nmethod can achieve lower reconstruction errors when using\nthe CVQ backbone, which suggests the effectiveness and\ngenerality of method. Notably, our method achieves su-\nperior reconstruction and significantly enhances codebook\nperformance across various downstream tasks, suggesting\nour method\u2019s effectiveness. Further qualitative comparisons\nare provided in the supplementary materials.\n5.3. Ablation Study\nAre our semantic alignments of words, phrases, and sen-\ntences both effective?We conduct extensive ablation stud-\nModels Codebook #Tokens CelebA-HQ CUB-200 MS-COCO\nSize FID \u2193 FID\u2193 FID\u2193\nVQCT [60] 6207 512 5.02 4.52 9.82\nVQ-GAN [13] 1024 256 5.66 5.31 14.45\nLG-VQ [29] 1024 256 5.34 4.74 10.72\nTA-VQ (Ours) 1024 256 5.03 4.60 10.32\nCVQ [65] 1024 256 5.19 4.64 9.94\nLG-CVQ [29] 1024 256 4.90 4.40 9.69\nTA-CVQ (Ours) 1024 256 4.71 4.03 9.65\nTable 1. Results (FID \u2193) of image reconstruction on CelebA-HQ,\nCUB-200, and MS-COCO. The best results are highlighted in\nbold. Setting CUB-200\nFID\u2193\n(i) Baseline(VQ-GAN) 5.51\n(ii) + Ls 4.89\n(iii) + Ls + Lp 4.69\n(iv) + Ls + Lw 4.82\n(v) + Lw + Lp 4.75\n(vi) + Lw + Lp + Ls 4.60\nTable 2. Ablation study of our three loss functions on CUB-200. \u201c+Ls\u201d denotes introduces the sentence semantic alignment into\nthe baseline model.\nies to evaluate the impact of three semantic losses, as sum-\nmarized in Tab. 2. We use VQ-GAN as the baseline model,\nwithout incorporating any additional semantic losses. From\nthe results, several key conclusions can be drawn: First, all\nthree semantic losses are essential for enhancing reconstruc-\ntion performance. Second, the results of (i) to (iv) show that\nsentence-level semantics (Ls) contribute the most to perfor-\nmance improvement. This can be attributed to the richer,\nhigh-level semantic information sentences provide, which\nsupports more robust codebook learning.\n\n2503.01261v1\nFollowing VQ-GAN and LG-VQ\n[13, 29], all images are reshaped 256 \u00d7 256 for reconstruc-\ntion and generation. We set the down-sampling factor f to\n16 and the codebook size K to 1024, with a batch size of\n6. The architecture of TA-VQ exactly follows VQ-GAN\nexcept for the proposed hierarchical encoder and semantic\nalignment module. All FNNs are 2-layer multilayer percep-\ntion (MLP) with ReLU activation function. The three key\nhyperparameters (\u03b1, \u03b2, and \u03b3) are uniformly set to 0.001\nacross all datasets. For further details regarding the gener-\nated text, please refer to the supplementary materials. 5.2. Discussion of Results\nTable 1 compares our method and the state-of-the-art VQ-\nbased method in image reconstruction performance. From\nthe results, we can obtain several key conclusions: 1) Compared with the backbone network ( i.e., VQ-GAN, and\nCVQ), our method can learn more robust codebook repre-\nsentation by introducing pre-trained text semantics to sig-\nnificantly improve reconstruction performance, indicating\nthe effectiveness of our method; 2) Our method surpasses\nLG-VQ across all datasets, largely due to its ability to in-\ntegrate long text with richer semantic knowledge and ef-\nfectively encode them at different granularities to learn\nmore robust codebook learning; 3) Compared to VQCT, our\nmethod can achieve lower reconstruction errors when using\nthe CVQ backbone, which suggests the effectiveness and\ngenerality of method. Notably, our method achieves su-\nperior reconstruction and significantly enhances codebook\nperformance across various downstream tasks, suggesting\nour method\u2019s effectiveness. Further qualitative comparisons\nare provided in the supplementary materials.\n5.3. Ablation Study\nAre our semantic alignments of words, phrases, and sen-\ntences both effective?We conduct extensive ablation stud-\nModels Codebook #Tokens CelebA-HQ CUB-200 MS-COCO\nSize FID \u2193 FID\u2193 FID\u2193\nVQCT [60] 6207 512 5.02 4.52 9.82\nVQ-GAN [13] 1024 256 5.66 5.31 14.45\nLG-VQ [29] 1024 256 5.34 4.74 10.72\nTA-VQ (Ours) 1024 256 5.03 4.60 10.32\nCVQ [65] 1024 256 5.19 4.64 9.94\nLG-CVQ [29] 1024 256 4.90 4.40 9.69\nTA-CVQ (Ours) 1024 256 4.71 4.03 9.65\nTable 1. Results (FID \u2193) of image reconstruction on CelebA-HQ,\nCUB-200, and MS-COCO. The best results are highlighted in\nbold. Setting CUB-200\nFID\u2193\n(i) Baseline(VQ-GAN) 5.51\n(ii) + Ls 4.89\n(iii) + Ls + Lp 4.69\n(iv) + Ls + Lw 4.82\n(v) + Lw + Lp 4.75\n(vi) + Lw + Lp + Ls 4.60\nTable 2. Ablation study of our three loss functions on CUB-200. \u201c+Ls\u201d denotes introduces the sentence semantic alignment into\nthe baseline model.\nies to evaluate the impact of three semantic losses, as sum-\nmarized in Tab. 2. We use VQ-GAN as the baseline model,\nwithout incorporating any additional semantic losses. From\nthe results, several key conclusions can be drawn: First, all\nthree semantic losses are essential for enhancing reconstruc-\ntion performance. Second, the results of (i) to (iv) show that\nsentence-level semantics (Ls) contribute the most to perfor-\nmance improvement. This can be attributed to the richer,\nhigh-level semantic information sentences provide, which\nsupports more robust codebook learning.", "metadata": {"type": "factual", "source": "2503.01261v1.pdf", "context": "various cross-modal downstream tasks.\nDespite the success of LG-VQ, it has limitations regard-\ning insufficient alignment between codebook and text, pri-\nmarily due to the brevity of the existing image captions. As\nillustrated in Fig. 1, we can see that the original caption\nis concise, focusing solely on the main object while omit-\nting details about the background and other key elements\nof the image. This brevity results in a lack of sufficient\nsemantic information, hindering the learning of a ", "quality_score": 8.5}}
{"id": "test_31", "question": "What set does the combination of the proof of the third point with Proposition 2.7 show is almost surely contained in?", "golden_answers": ["{t \u2265 0 s.t. Wk(t) \u0338= Wk(t\u2212)} \u2282 { t \u2265 0 s.t. Ct \u0338= Ct\u2212} = {t \u2265 0 s.t. Dt \u0338= Dt\u2212}"], "prediction": "The combination of the proof of the third point with Proposition 2.7 shows that it is almost surely contained in the set \\( C_t \\).", "f1": 0.04878048780487805, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.00220v1\nIt admits a\nquite elementary proof relying only on Hoeffding\u2019s concentration inequality, making it a natural\npoint of departure for developing more sophisticated coverage guarantees. We thus provide this\nelementary proof, then demonstrate the result using uniform convergence techniques. These uniform\nconvergence guarantees\u2014which form the basis for providing guarantees for approximate weighted\ncoverage (Definition 1.1) also provide a two-sided bound on sample-conditional coverage:\nCorollary 2.1. Assume the scores Si = s(Xi, Yi) are distinct with probability 1. Then for any\n\u03b3 >0, with probability at least 1 \u2212 2e\u22122n\u03b32\nover the sample Pn,\n1 \u2212 \u03b1 \u2212 \u03b3 \u2264 P(Yn+1 \u2208 bCn(Xn+1) | Pn) \u2264 1 \u2212 \u03b1 + 1\nn + \u03b3. The simplicity of the guarantee (7) means it admits elegant extensions as well. For example,\nwe can extend the argument to give a bound that more carefully tracks the desired confidence \u03b1:\nProposition 2. Let \u03b4 \u2208 (0, 1) and define\n\u03b3n(\u03b4) := 4 log 1\n\u03b4\n3n +\nr\u0010 4\n3n log 1\n\u03b4\n\u00112\n+ 2\u03b1(1 \u2212 \u03b1)\nn log 1\n\u03b4 \u2264 8 log 1\n\u03b4\n3n +\nr\n2\u03b1(1 \u2212 \u03b1)\nn log 1\n\u03b4 . Then with probability at least 1 \u2212 \u03b4 over the draw of the sample Pn,\n1 \u2212 \u03b1 \u2212 \u03b3n(\u03b4) \u2264 P(Yn+1 \u2208 bCn(Xn+1) | Pn). If additionally the scores S have a density, then with probability at least 1 \u2212 2\u03b4,\n1 \u2212 \u03b1 \u2212 \u03b3n(\u03b4) \u2264 P(Yn+1 \u2208 bCn(Xn+1) | Pn) \u2264 1 \u2212 \u03b1 + \u03b3n(\u03b4). Roughly, we see that the simple quantile-based confidence set achieves coverage\n1 \u2212 \u03b1 \u00b1 OP (1)\nr\n\u03b1(1 \u2212 \u03b1)\nn . When \u03b1 is small\u2014which is the typical case\u2014this is always sharper than the naive guarantee (7). The central limit theorem shows this is as accurately as we could hope to even estimate the coverage\nlevel of a predictor; moreover, as we discuss following Theorem 3, it is minimax (rate) optimal. In\nthe remainder of the section, we provide two proofs of Proposition 1, along with Corollary 2.1. In\nSection 2.3, we prove Proposition 2 using Bernstein-type concentration guarantees. 2.1 An elementary proof of Proposition 1\nFor the scalar random variable S, define the \u03b2-quantile\nq\u22c6(\u03b2) := inf {t \u2208 R | P(S \u2264 t) \u2265 \u03b2}. (8)\nBecause the CDF is right continuous, we have P(S \u2264 q\u22c6(\u03b2)) \u2265 \u03b2, and P(S > q\u22c6(\u03b2)) = 1 \u2212 P(S \u2264\nq\u22c6(\u03b2)) \u2264 1 \u2212 \u03b2. For \u03b3 >0 and any \u03c4 \u2208 R, the inequality\nP(Sn+1 > \u03c4) > \u03b1+ \u03b3, i.e. P(Sn+1 \u2264 \u03c4) < 1 \u2212 \u03b1 \u2212 \u03b3,\n5\n\nimplies that \u03c4 < q\u22c6(1 \u2212 \u03b1 \u2212 \u03b3). Consider the event that b\u03c4n < q\u22c6(1 \u2212 \u03b1 \u2212 \u03b3). For this to occur, it must be the case that\n1\nn\nnX\ni=1\n1{Si < q\u22c6(1 \u2212 \u03b1 \u2212 \u03b3)} \u22651 \u2212 \u03b1. (9)\nBut this event is unlikely: define the Bernoulli indicator variables Bi = 1 {Si < q\u22c6(1 \u2212 \u03b1 \u2212 \u03b3)}.\n\n2503.01320v1\nNote from ( 1.7) that, almost surely , for any (s, r, u) \u2208 N and t \u2265 s,\nY0,t(\u00b7) is constant on Y \u22121\n0,s\u2212(Io\nr,u). Therefore, mt(Y \u22121\n0,s\u2212(Io\nr,u)) = 0 and Y \u22121\n0,s\u2212(Io\nr,u) \u2282 Ct. W e thus\nget that almost surely , for all t \u2265 0, Dt \u2282 Ct. W e now assume that we are on the probability one events provid ed by Proposition 1.4 and\nLemma 2.10, \ufb01x t \u2265 0 and prove that Ct \u2282 Dt. Note that {0, 1} \u2282 Dc\nt and Proposition 1.4 implies\nthat {0, 1} \u2282 Cc\nt . Now let any x \u2208 Dc\nt \u2229 (0, 1) and \u01eb \u2208 (0, x \u2227 (1 \u2212 x)). Since (x \u2212 \u01eb, x + \u01eb) \u2288 Dt,\nby Lemma 2.10 we have Y0,t(x + \u01eb) > Y 0,t(x \u2212 \u01eb) so mt([x \u2212 \u01eb, x + \u01eb]) > 0. Since this is satis\ufb01ed\nfor any x \u2208 Dc\nt \u2229 (0, 1) and small \u01eb > 0 we get that any Dc\nt \u2229 (0, 1) \u2282 Supp(mt) = Cc\nt so Ct \u2282 Dt.\nW e get that, almost surely , Ct = Dt for all t > 0. The proof for Ct\u2212 = Dt\u2212 is the same. \u25a1\n2.4. Some more lemmas. In this subsection we prove some more lemmas that will come us eful\nfor the proof of Theorem 1.8.\nLemma 2.11. Almost surely, the set \u222a(s,r,u)\u2208N (Y \u22121\n0,s\u2212(Ir,u) \\ Y \u22121\n0,s\u2212(Io\nr,u)) is countable and Q \u2229\n\u222a(s,r,u)\u2208N (Y \u22121\n0,s\u2212(Ir,u) \\ Y \u22121\n0,s\u2212(Io\nr,u)) = \u2205.\nProof. Let us assume that we are on the probability one event provide d by Lemmas 2.8 and\n2.9. Since each set Y \u22121\n0,s\u2212(Ir,u) is a closed interval, Lemma 2.9 shows that each set Y \u22121\n0,s\u2212(Ir,u) \\\nY \u22121\n0,s\u2212(Io\nr,u) has exactly two elements, yielding the \ufb01rst claim. Let y \u2208 Q, then y \u2208 \u222a (s,r,u)\u2208N (Y \u22121\n0,s\u2212(Ir,u)\\\nY \u22121\n0,s\u2212(Io\nr,u)) \u21d2 \u2203 (s, r, u) \u2208 N s.t. Y0,s\u2212(y) \u2208 Ir,u \\ Io\nr,u. By Lemma 2.8, the later does not occur. This proves the second claim. \u25a1\nF or any t \u2265 0 and y \u2208 [0, 1] let\nJt(y) := Y \u22121\n0,t ({Y0,t(y)}) = {z \u2208 [0, 1] s.t. Y0,t(z) = Y0,t(y)}. (2.35) By Proposition 1.1 we have that, almost surely , Y0,t(\u00b7) is non-decreasing and continuous for all\nt \u2265 0, so each set Jt(y) is a closed interval (possibly equal to the singleton {y}). W e note that\nfor each y \u2208 Ct, Jt(y)o is the open connected component of Ct containing y so, in particular,\nJt(y)o \u2208 {O k(t), k \u2265 1} and |Js(y)| = |Js(y)o| \u2208 { Wk(s), k \u2265 1}.\nLemma 2.12. Almost surely, for every y \u2208 Q, the interval-valued process (Jt(y))t\u22650 is non-\ndecreasing, piecewise constant and right-continuous, inc rease times s of (Jt(y))t\u22650 are exactly\nthe time components of jumps (s, r, u) \u2208 N such that y \u2208 Y \u22121\n0,s\u2212(Io\nr,u).\n\n2503.00696v3\nSince sets of the\nform (3) constitute a basis of open sets for the S-idelic topology, it is enough to show that every set\nof the form\nU =\nr\u220f\ni=1\n(ai + p\u03b1i\ni Zpi ) \u00d7\n\u220f\nq\u2208P\\(P1(4)\u222aP)\nZ\u00d7\nq\nwhere P = {p1 = 2 ,p2,...,p r} \u2282 P \\ P1(4) is a \ufb01nite subset, and \u03b1i \u2265 1 and ai with ( ai,pi) = 1 are\nintegers for i= 1 ,...,r , intersects E(S). Set \u03b5= 1 if a1 \u2261 1(mod 4), and \u03b5= \u22121 if a1 \u2261 3(mod 4), so\nthat \u03b5a1 \u2261 1(mod 4) in all cases. Using the Chinese Remainder Theorem, w e can \ufb01nd c\u2208 Z satisfying{\nc\u2261 \u03b5ai(mod p\u03b1i\ni ) for i= 1 ,...,r,\nc\u2261 1(mod 4). Next, by Dirichlet\u2019s Theorem on arithmetic progressions, t here exists a prime p\u2261 c(mod 4p\u03b11\n1 \u00b7 \u00b7 \u00b7 p\u03b1r\nr ). Then \u03b5p\u2208 E(S) \u2229 U. This completes the proof of the fact that\nE(S)\n(S)\n= U(S). It follows from our general results that for any integers a,m with ( a,m) = 1 and S = {v\u221e}\u222a{ vp| p\u2208\nPa(m)}, the index [ I(S) : Q\u00d7(S)\n] is \ufb01nite (cf. Proposition 3.1). However, as we will now show , it is not\nalways equal to one. Example 2.3. Let K = Q, let q be a prime \u2261 1(mod 4), and set S = {v\u221e} \u222a { vp| p\u2208 P1(q)}. Then\n(6) [ I(S) :\nQ\u00d7(S)\n] >1. Our proof will use the Artin map associated with the quadrati c extension L= Q(\u221aq), and we would\nlike to point out that a suitable generalization of this appr oach will play a crucial role also in the proof\nof Proposition 3.1. We let ( \u2217,\u2217)p (resp., ( \u2217,\u2217)\u221e) denote the Hilbert symbol over Qp (resp., over R). If\nwe identify the Galois group Gal( L/Q) with {\u00b11}, then the Artin map \u03c8L/Q : I \u2192 Gal(L/Q) is given\nby\n(xp)p \u21a6\u2192(x\u221e,q)\u221e \u00b7\n\u220f\np\u2208P\n(xp,q)p. Then by class \ufb01eld theory for L/Q, the kernel N := ker \u03c8L/Q \u2282 I is an open subgroup containing Q\u00d7\nand having index two. Let \u03c0S: I \u2192 I(S) be the canonical projection. Then \u03c0S(N) is an open subgroup\nof I(S) containing Q\u00d7, and to prove (6) it is enough to show that N \u2283 ker \u03c0S as then \u03c0S(N) \u0338= I(S). For this we observe that q\u2208 Q\u00d7\nv\n2 for all v\u2208 S. This is obvious for v= v\u221e, and follows from(q\np\n)\n=\n(p\nq\n)\n=\n(1\nq\n)\n= 1\nfor v= vp with p\u2208 P1(q). Let now x= ( xp)p \u2208 ker \u03c0S, i.e. xp = 1 for p\u2208 P \\ P1(q). Then\n\u03c8L/Q(x) = ( x\u221e,q)\u221e \u00b7\n\u220f\np\u2208P1(q)\n(xp,q)p = 1 ,\nproving that N \u2283 ker \u03c0S.", "metadata": {"type": "factual", "source": "2503.01320v1.pdf", "context": "This yields the third point.\nFourth point. The combination of the proof of the third point with Proposit ion 2.7 shows that,\nalmost surely , we have {t \u2265 0 s.t. Wk(t) \u0338= Wk(t\u2212)} \u2282 { t \u2265 0 s.t. Ct \u0338= Ct\u2212} = {t \u2265 0 s.t. Dt \u0338=\nDt\u2212} \u2282 JN , where the last inclusion is a consequence of ( 2.34). This yields the fourth point.", "quality_score": 8.5}}
{"id": "test_32", "question": "What is a key benefit of using paired image-text data with subtle variations for training Vision-Language Models?", "golden_answers": ["Producing Vision-Language Models with proper compositional understanding"], "prediction": "A key benefit of using paired image-text data with subtle variations for training Vision-Language Models is the enhancement of compositional understanding, allowing the models to accurately interpret relationships between objects and attributes.", "f1": 0.2777777777777778, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01167v2\nEnhancing Vision-Language Compositional Understanding with Multimodal\nSynthetic Data\nHaoxin Li and Boyang Li\nNanyang Technological University\n{haoxin003, boyang.li}@ntu.edu.sg\nAbstract\nPaired image-text data with subtle variations in-between\n(e.g., people holding surfboards vs. people holding shov-\nels) hold the promise of producing Vision-Language Mod-\nels with proper compositional understanding. Synthesiz-\ning such training data from generative models is a highly\ncoveted prize due to the reduced cost of data collection. However, synthesizing training images for compositional\nlearning presents three challenges: (1) efficiency in gen-\nerating large quantities of images, (2) text alignment be-\ntween the generated image and the caption in the exact\nplace of the subtle change, and (3) image fidelity in ensur-\ning sufficient similarity with the original real images in all\nother places. We propose SPARCL (Synthetic Perturbations\nfor Advancing Robust Compositional Learning), which inte-\ngrates image feature injection into a fast text-to-image gen-\nerative model, followed by an image style transfer step, to\nmeet the three challenges. Further, to cope with any resid-\nual issues of text alignment, we propose an adaptive mar-\ngin loss to filter out potentially incorrect synthetic samples\nand focus the learning on informative hard samples. Eval-\nuation on four compositional understanding benchmarks\ndemonstrates that SPARCL significantly improves the com-\npositionality of CLIP , boosting the average accuracy of\nthe CLIP base model by over 8% across all benchmarks\nand outperforming state-of-the-art methods by 2% on three\nbenchmarks. 1. Introduction\nCurrent Vision-Language Models (VLMs) still face limita-\ntion in accurately interpreting compositional relationships\nbetween objects and attributes, as demonstrated by numer-\nous evaluations [32, 62, 88, 106, 113]. This limitation pri-\nmarily stems from the absence of subtle variations in the\ntraining data [42] ( e.g., the subtle variations between the\ntwo captions in Figure 1 (a)). As a result, it becomes pos-\nsible to maximize empirical image-caption alignment us-\nSource caption: Two people carrying surfboards on a beach. Target caption: Two people carrying shovels on a beach. Source image Edited image Generated image\n(a) Difficulty in accurately creating precise variations.\n+ Real positive caption: \nA double decker bus \nparked at a station. + Synthetic positive \ncaption: A double-decker \nbus parked at a bus \nstation with a few \npassengers getting on.\n+ Real positive caption: \nA man is stirring a silver \npot filled with food.\n- Synthetic negative \ncaption: A man is stirring \na copper pot filled with \nfood.\n+ Real positive caption: \nRandom people sitting in \na public transport bus.\n- Synthetic negative \ncaption: Random \nanimals riding a purple \nelephant. Wrong GenerationHard Sample Easy Sample\n(b) Inconsistency in cross-modal alignment quality of synthetic samples. Figure 1. Challenges in generating and training on synthetic data:\n(a) When generating an image with subtle variations based on a\nreal image and a target caption specifying the variations, an image\nediting model [6] struggles with text alignment (middle), while\nan image generation model [75] fails to maintain image fidelity\n(right). (b) Synthetic positive and negative image-caption pairs\nshow different levels of alignment quality.\n\nA template for the arxiv style\nMeanwhile, the blue components apply a\nrange of attention-masking strategies to achieve a comprehensive fusion of image and text representations. CLIP architecture, resulting in label-efficient adaptations Zhang et al. (2022); Huang et al. (2021); Zhou et al. (2022a);\nYou et al. (2023); Wu et al. (2023); Wang et al. (2022d). In the dual-encoder framework, the predominant learning\nobjective is achieved through a contrastive loss, which aligns paired data while effectively distinguishing unpaired data\nwithin the multi-modal feature space. In addition to the dual-encoder framework, fusion-based encoders have attracted\nconsiderable attention. These fusion models utilize self-attention or co-attention mechanisms to achieve early integration\nof visual and textual modalities Li et al. (2021); Bao et al. (2022); Li et al. (2022a). This joint processing enables the\nlearning of multi-modal representations that are crucial for tasks requiring complex multi-modal reasoning, such as\nmedical visual question answering. For fusion models, cross-modal matching with hard sampling strategies is employed\nto strengthen correlations between matched data. Along the line image-grounded text understanding with the masked\nlanguage modelling (MLM), originally developed for the BERT model Devlin (2018), is also deployed to enhance\nmulti-model interaction. PTUnifier Chen et al. (2023b), as a representative, focused on multi-modality understanding\nyet did not possess generative capabilities during pre-training, thus necessitating the use of an additional language\ndecoder and fine-tuning for downstream language generative tasks. Meanwhile, image-grounded text generation with\nthe causal language modelling (CLM), stemmed from Transformer model Vaswani (2017), is often applied to facilitate\nvision-grounded language generation tasks. However, we observe that current VLP approaches often overlook the\ngeneration of visual content, which limits the model\u2019s capacity to produce coherent and novel visual representations\nbased on textual or multi-modal prompts, thus reducing the potential of multi-modal learning. Although recent studies\nhave integrated masked image modelling (MIM) into the VLP framework Zhou et al. (2022b); Chen et al. (2023a), this\napproach does not fully enable the generation of comprehensive visual content nor capture detailed visual information. In this paper, we present MedUnifier, a unified VLP framework for medical data (Figure 1), designed to seamlessly in-\ntegrate text-grounded image generation with advanced multi-modal learning strategies, including image-text contrastive\nalignment, image-text matching, and image-grounded text generation. Our approach begins with a Transformer model\nfeaturing learnable embeddings, inspired by BLIP-2 Li et al. (2023a), a 12-layer transformer encoder as the trainable\ncomponent, paired with a pre-trained visual encoder that embeds preliminary visual features. To extend its functionality\nfor vision generation, we introduce a novel learning objective, termed text-grounded image generation (TIG) loss. This\nobjective leverages vector-quantization to facilitate discrete visual representation learning Van Den Oord et al. (2017),\nguiding vision generation using textual data. Additionally, we devise a novel latent adapter to connect the base model\nwith the image generation module, enabling end-to-end co-training with three other learning objectives: image-text\n2\n\ncontrastive (ITC), image-text matching (ITM), and image-grounded text generation (ITG) losses. To our knowledge,\nMedUnifier is the first model to adapt learnable embeddings to the medical domain, bridging the gap between existing\nVLP paradigms and text-grounded image generation to enhance multi-modal alignment.\n\n2503.01167v1\nEnhancing Vision-Language Compositional Understanding with Multimodal\nSynthetic Data\nHaoxin Li, Boyang Li\nNanyang Technological University\n{haoxin003, boyang.li}@ntu.edu.sg\nAbstract\nDespite impressive advancements in various multimodal\ntasks, vision-language models (VLMs) still struggle with\ncompositional understanding due to limited exposure to\ntraining samples that contain subtle variations within\npaired examples. With advances in multimodal genera-\ntive models, a natural solution is to generate synthetic\nsamples with subtle variations for training VLMs. How-\never, generating and training on synthetic samples with\nsubtle variations presents two challenges: difficulty in ac-\ncurately creating precise variations and inconsistency in\ncross-modal alignment quality. To address these challenges,\nwe propose SVD-GT (S ubtle V ariation D ata G eneration\nand Training), which integrates image feature injection into\na text-to-image generative model to enhance the quality of\nsynthetic variations and employs an adaptive margin loss\nto differentiate samples using adaptive margins, which help\nfilter out potentially incorrect synthetic samples and focus\nthe learning on informative hard samples. Evaluations on\nfour compositional understanding benchmarks demonstrate\nthat SVD-GT significantly improves the compositionality of\nVLMs, boosting the average accuracy of CLIP by over 8%\nacross all benchmarks and outperforming state-of-the-art\nmethods by 2% on three benchmarks. 1. Introduction\nRecent advancements in large-scale pretrained Vision-\nLanguage Models (VLMs) [1, 40, 49, 50, 71, 81, 99, 114]\nhave significantly enhanced performance across a wide\nrange of multimodal tasks [14, 96, 112, 113]. However,\nVLMs still face limitation in accurately interpreting com-\npositional relationships between objects and attributes, as\ndemonstrated by various evaluations [32, 58, 85, 103, 110]. This limitation primarily stems from the absence of subtle\nvariations within paired samples in the training data [41]. As a result, VLMs often depend on shortcut features [24]\nfor image-caption alignment, rather than genuinely learn-\nSource caption: Two people carrying surf boards on a beach. Target caption: Two people carrying shovels on a beach. Source image Edited image Generated image\n(a) Difficulty in accurately creating precise variations.\n+ Positive caption: A \ndouble-decker bus \nparked at a bus station \nwith a few passengers \ngetting on.\n- Negative caption: A \ndouble decker bus \nparked at a station.\n+ Positive caption: A \nman is stirring a silver \npot filled with food.\n- Negative caption: A \nman is stirring a copper \npot filled with food.\n+ Positive caption: \nRandom people sitting \nin a public transport \nbus.\n- Negative caption: \nRandom animals riding \na purple elephant. Wrong GenerationHard Sample Easy Sample\n(b) Inconsistency in cross-modal alignment quality of synthetic samples. Figure 1. Challenges in generating and training on synthetic data:\n(a) When generating an image with subtle variations based on a\nreal image and a target caption specifying the variations, an image\nediting model [8] struggles with text alignment (middle), while\nan image generation model [72] fails to maintain image fidelity\n(right). (b) Synthetic positive and negative image-caption pairs\nshow different levels of alignment quality.", "metadata": {"type": "factual", "source": "2503.01167v2.pdf", "context": "Enhancing Vision-Language Compositional Understanding with Multimodal\nSynthetic Data\nHaoxin Li and Boyang Li\nNanyang Technological University\n{haoxin003, boyang.li}@ntu.edu.sg\nAbstract\nPaired image-text data with subtle variations in-between\n(e.g., people holding surfboards vs. people holding shov-\nels) hold the promise of producing Vision-Language Mod-\nels with proper compositional understanding. Synthesiz-\ning such training data from generative models is a highly\ncoveted prize due to the reduc", "quality_score": 8.5}}
{"id": "test_33", "question": "What happens to the spectral function as the strength of disorder increases?", "golden_answers": ["It broadens, but still clearly represents the quasiparticle bulk dispersion."], "prediction": "The spectral function decreases with increasing disorder strength until it vanishes at a critical value, after which it reopens again at higher disorder strengths.", "f1": 0.06451612903225805, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01367v2\nThe band-gap region on ( \u03b5, W) plane is represented by violet (in\npanel (b)) and olive (in panel (c)) area. As clear, Eqs. (21)\u2013(23) form a system of integral equa-\ntions that determines both the Green\u2019s function \u02c6G(k, \u03b5)\nand the self-energy \u02c6\u03a3(k, \u03b5) matrices. The self-consistent\nsolution of such integral systems in the general case is\na laborious task. However, for the case of the disorder\nformed by the short-range impurities, for which \u02dcv(q) = u0\n(cf. Ref. 20), the solution of the problem can be signifi-\ncantly simplified. Indeed, in the case of the short-range disorder,\nVn(k, k\u2032)2 = u2\n0\u03b4n,0 in Eq. (22). The latter results in a\ndiagonal form of the self-energy matrix \u02c6\u03a3(\u03b5) in Eq. (21)\nbeing independent of the momentum. By means of direct\ncalculations, one can verify that G11 (k, \u03b5) = G33 (k, \u03b5)\nand G22 (k, \u03b5) = G44 (k, \u03b5), which leads to\n\u02c6\u03a3\u2191(\u03b5) = \u02c6\u03a3\u2193(\u03b5) = W2\n4\u03c0\nK2\ncZ\n0\ndx\n \nG11 (\u221ax, \u03b5) 0\n0 G22 (\u221ax, \u03b5)\n!\n,\n(24)\nwhere W2 = niu2\n0 is the disorder strength. Note that\nintegration in Eq. (24) can be performed analytically,\nwhich transforms Eqs. (21)\u2013(24) into the set of algebraic\nequations numerically solved by simple iterations. Once the self-energy is known, the spectral function\nA(k, \u03b5) and density-of-states D(\u03b5) for the case of the\nshort-range disorder can be found as\nA(k, \u03b5) = \u22122\n\u03c0 Im {G11 (k, \u03b5) + G22 (k, \u03b5)},\nD(\u03b5) =\nKcZ\n0\nkdk\n2\u03c0 A(k, \u03b5). (25)\nIII. RESULTS AND DISCUSSION\nFigure 1 represents the evolution of density-of-states\nD(\u03b5) and spectral function A(k = 0, \u03b5) at the \u0393 point as a\nfunction of the short-range disorder strengthW = \u221aniu0\ncalculated with the structure parameters of the proto-\ntype 6 nm wide HgTe/Cd0.7Hg0.3Te QW (see Tab. I). All\ndetails about the calculation of structural parameters in-\nvolved in H0(k) can be found elsewhere73. As seen, being\nadded to an initially clean trivial QW (M >0), the short-\nrange disorder causes the band-gap to decrease with in-\ncreasing W until it vanishes at a critical value Wc and\nthen reopens again at W > Wc. Such band-gap behavior\nrepresents the disorder-induced topological phase tran-\nsition previously discovered in the tight-binding calcula-\ntions16,17. Importantly, the band-gap reopening region\nat W > Wc was characterized by quantized conductance\nvalues inherent in the QSHI state. It is on the basis of\n\n5\nthis fact that the conclusion is made that W = Wc cor-\nresponds to a topological phase transition. Let us now show that the band-gap behavior illustrated\nby the evolution of D(\u03b5) and A(k = 0, \u03b5) is indeed due\nto a change in the Z2 invariant. For this purpose, it is\nconvenient to represent the self-energy blocks in Eq. (24)\nin the form\n\u02c6\u03a3\u2191(\u03b5) = \u02c6\u03a3\u2193(\u03b5) = \u03a30(\u03b5) + \u03a3z(\u03b5)\u03c3z.\n\n2503.00362v2\n(D1) is phenomenologically\nmodified to incorporate the influence of imperfect con-\ntrast, as\nSs(\u2126s, \u03c4H) = N0\n2 e\n\u22124 ln 2\n4\u21262\ns\n\u2206\u03c92\nS [1 + VH cos(2\u2126s\u03c4H)], (D2)\nwhere N0 is the peak count of the single-mode spectrum,\nand VH is the fitted HOM visibility. In addition, the\nHOM delay \u03c4H, the mode spacing of \u2206 f = 1/2\u03c4H, and\nthe bandwidth of HFEQs, \u2206 \u03c9S, can also be obtained\nusing this equation. 17\nAppendix E: Simulating the effect of ToFS finite\nresolution\nExperimentally, the single-photon spectral measure-\nment of ToFS is limited by a certain resolution due to dis-\nturbances in estimating the photon time of flight. These\ndisturbances arise from factors such as detector timing\njitter and counter-timing jitter, introducing a finite fre-\nquency resolution into the measurement process. To ac-\ncount for ToFS\u2019s finite resolution, we model the frequency\nmeasurement jitter using a Gaussian probability distri-\nbution,\nPj(\u03c9, \u2126s) =\ns\n4 ln 2\n\u03c0\u2206\u03c92\nj\ne\n\u22124 ln 2(\u03c9\u2212\u2126s)2\n\u2206\u03c92\nj , (E1)\nwhere \u2206\u03c9j represents the frequency resolution of ToFS,\nwhich defines the linewidth broadening in measurement. The function Pj(\u03c9, \u2126s) describes the probability distri-\nbution of a photon with frequency \u2126 s in the ToFS mea-\nsurement. For instance, if a photon carries a frequency\nof \u2126s, the finite resolution of ToFS results in a Gaussian-\ndistributed spectral measurement centered at \u2126 s. To extend this to multimode photon frequency mea-\nsurements, we model all photon frequencies as passing\nthrough a Gaussian response function with finite fre-\nquency resolution. This means that the final measured\nspectrum is obtained by convolving the original spectrum\nwith this Gaussian function. Mathematically, the mea-\nsured spectrum can be expressed as\nSj(\u03c9, \u03c4H) =\nZ\nd\u2126sS(\u2126s, \u03c4H)Pj(\u03c9, \u2126s). (E2)\nThis convolution process effectively models the spectral\nbroadening caused by finite resolution. Using Eq.(E1),\nEq. (E2), and Eq. (D2), with a frequency resolution of\n\u2206\u03c9j = 4 GHz and varying \u03c4H, the upper limit of the\nmeasured VH is calculated using Eq. (10), as shown in\nFig. 8. Appendix F: Photon pair degenerate\nThe precise degeneracy of the photon pair wavelengths\nis crucial for generating an HFEQ. In this section, we\ndemonstrate the method used in our system to ver-\nify photon-pair degeneracy. Additionally, this demon-\nstration provides insights into the gradual transition of\nphoton-pair degeneracy and its relationship with HOM\ninterference. In Fig. 9(c.2)-9(e.2), we calculate the JSI of TPES in\nthe non-degenerate regime using Eq. (4), excluding the\nFranson interference. Additionally, Fig. 9(g.2) presents\nthe corresponding single-mode spectrum. We observe\nthat as the photon pair transitions from a non-degenerate\nto a degenerate state, the two main spectral distributions,\ninduced by the frequency exchange mechanism, gradually\n0.0\n0.2\n0.4\n190.5 191.0 191.5 192.0\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nFrequency (THz)\n0.0\n0.2\n0.4\n(a) 38.6\u2103\n(b) 38.2\u2103\n(c) 37.8\u2103\nNormalized coincidence counts\nFIG. 11. Demonstration of tuning the photon pair to de-\ngeneracy and the transition of HOM interference.\n\n2503.01039v1\n= Neq,w/o\n\u03b3\n2\n, (50)\nwhere \u0393 eq\nSchw and \u0393 eq\ne\u00b1 represent \u0393 Schw and \u0393 e\u00b1 evaluated at Neq\n\u03b3 , and Neq,w/o\n\u03b3 = \u0393s\nC1\u0393\u03d5\nis the expression for Neq\n\u03b3\ncalculated without accounting for the Schwinger effect. This equation does not have a solution for all regions of\nparameter space; for some values of m\u03d5 and \u03b1, it is simply impossible for the system to reach equilibrium. This\nrepresents the case where the suppression of axion decay is so great that the photons will never build up to the\npoint where they come into equilibrium with the axions. While the number of photons will reach or approach some\npeak value (which may be found by solving \u0393Schw\n\u0393e\u00b1\n= Nshutoff\ne+e\u2212 for N\u03b3), the number of axions will continue growing\nunbounded. This is reflected mathematically by the fact that C1\u0393\u2032\n\u03d5N\u03b3 has some maximum attainable value, and, if\nthis maximum value is less than \u0393 s, then N\u03d5 will increase without bound. This will eventually result in the black\nhole spinning down to the point where superradiance ceases. These regions of parameter space where the system is\nunstable are shown on Fig. 2. In regions of parameter space where the system is stable, the equilibrium photon number is enhanced by a factor\nof \u0393\u03d5\n\u0393\u2032\n\u03d5\n. This enhancement is plotted in Fig. 3. Interestingly, for the majority of parameter space (where equilibrium\nis possible), this enhancement is negligible. For these regions, the behavior of the BLAST may be modeled without\nconsidering the impact of the Schwinger effect. However, we can see that the enhancement to the photon number\n(and, consequently, the luminosity) increases somewhat as one approaches the region of parameter space where the\nsystem becomes unstable. Thus there is a small region of parameter space, located right next to the region where\nBLASTs become unstable, where the BLASTS are stable but enhanced. It is in this region where we would expect\nto find the strongest stable BLASTs. V. CONCLUSION\nWhen an axion laser, such as a BLAST, becomes sufficiently strong, it can produce an electric field close to the\ncritical Schwinger limit, resulting in the creation of electron-positron pairs. This has three effects on the dynamics\n\n10\nFIG. 2. Plot of the \u03b1m\u03d5 plane of parameter space. The other parameters were taken to be \u02dca = .7 and K = 1. For larger values\nof \u03b1 and smaller values of m\u03d5, the system is unstable, represented by the black-colored region of parameter space. In this\nregion, the electron-positron plasma suppresses the axion decay so much that the photon number never becomes large enough\nto halt the growth of the axion number. The axion number therefore continues to grow superradiantly, causing the black hole\nto spin down until it is no longer superradiant. In the colored regions of parameter space, it is possible for the system to\nreach equilibrium, and the equilibrium luminosity is plotted. Especially for light axions, these luminosities are extremely high,\nmaking BLASTs potentially significant for future experiments.", "metadata": {"type": "factual", "source": "2503.01367v2.pdf", "context": "HgTe/Cd0.7Hg0.3Te QW at several values of the short-\nrange disorder strength W. It is seen that although\nthe spectral function broadens with increasing disorder\nstrength, it still clearly represent the quasiparticle bulk\ndispersion. Interestingly, the bulk quasiparticles at the\ngapless case at W = Wc mimics massless Dirac fermions\nas it is in the \u201cclean\u201d limit 55. If the strength of disor-\nder exceeds a critical value Wc, which leads to Z2(\u03b5) = 1,\nthe bulk states coexist with a pair of quasipart", "quality_score": 8.5}}
{"id": "test_34", "question": "Why do the quasi-particle helical edge states not decay in the band-gap region?", "golden_answers": ["Because the damping factor \u0393(\u03b5) turns to zero, resulting from Im\u03a3z(\u03b5) and Im\u03a30(\u03b5) both vanishing in this region."], "prediction": "The quasi-particle helical edge states do not decay in the band-gap region because the damping factor \u0393(\u03b5) turns to zero, as both Im\u03a3 z(\u03b5) and Im\u03a3 0(\u03b5) vanish in that region. This results in the spectral function of the edge states taking the form of a delta function, indicating that the edge quasiparticles do not experience energy dissipation.", "f1": 0.3582089552238806, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01367v2\n(41)\nFigure 3 shows the evolution of total spectral func-\ntion determined as the sum A(k, \u03b5) in Eq. (25) and\nAedge(k, \u03b5) in Eq. (40) in the prototype 6 nm wide\nHgTe/Cd0.7Hg0.3Te QW at several values of the short-\nrange disorder strength W. It is seen that although\nthe spectral function broadens with increasing disorder\nstrength, it still clearly represent the quasiparticle bulk\ndispersion. Interestingly, the bulk quasiparticles at the\ngapless case at W = Wc mimics massless Dirac fermions\nas it is in the \u201cclean\u201d limit 55. If the strength of disor-\nder exceeds a critical value Wc, which leads to Z2(\u03b5) = 1,\nthe bulk states coexist with a pair of quasiparticle helical\nedge states \u2013 see Fig. 3(c). Importantly, since Im\u03a3 z(\u03b5) and Im\u03a3 0(\u03b5) both vanish\nin the band-gap region (see Fig. 2(b,c)), the damping fac-\ntor \u0393(\u03b5) turns to zero. As a result, the spectral function\nof the edge states in the band-gap takes the form of a\ndelta function\nAedge(kx, \u03b5) =\nX\n\u03c3\n\u03b4\n\b\n\u03b5 \u2212 ReEedge\n\u03c3 (kx, \u03b5)\n\t\n. (42) The latter means that the edge quasiparticles do not de-\ncay. The absence of energy dissipation for the quasi-\nparticle helical edge states in the band-gap explains the\nquantized values of the longitudinal conductance in the\npresence of an external bias, found previously in numeri-\ncal calculations in strip geometry16,17. The latter can be\nshown explicitly by means of Landauer-B\u00a8 uttiker formal-\nism, taking into account that the transmission coefficients\n\n8\nalong the edge channel do not change 75,76. Finally, we note the importance of taking into account\nthe dependence of the self-energy matrix on \u03b5 for the de-\nscription of topological phase transitions. In the case any\ninteractions, and exemplary provided by short-range elec-\ntrostatic disorder above, our quasiparticle concept goes\nbeyond the previous \u201ctopological Hamiltonian\u201d Ht(k)\napproach as used by Z. Wang and collaborators 32\u201334. IV. SUMMARY AND NOTES We have presented a general recipe to describe topolog-\nical phase transitions in condensed matter systems with\ninteractions. By using the simplest BHZ model with the\nshort-range disorder, we have directly demonstrated that\nthat topological invariants in the presence of interactions\ncan be efficiently calculated by means of a non-Hermitian\nquasiparticle Hamiltonian introduced on the basis of the\nGreen\u2019s function. The quasiparticle approach allows us\nto explicitly demonstrate that the quantized values of the\nlongitudinal conductance found previously in numerical\ncalculations16,17 are due to the vanishing of the damping\nfactor of quasiparticle edge states in a certain range of\nthe Fermi energy and the disorder strength. Note that despite the relatively simple case of a 2D\nsystem with the short-range disorder considered in this\npaper, the quasiparticle approach should be applicable\nin general for topological characterization of arbitrary\nsystems (including the ones described beyond the BHZ\nmodel20) with an arbitrary type of interaction.\n\n2503.01367v2\nExpressions (34) and (35) show that, in the absence of\nexternal bias, the total Hall conductance \u03c3\u2193\nxy(\u03b5) +\u03c3\u2191\nxy(\u03b5)\nin the band-gap region vanishes, while the spin Hall con-\nductance in the band-gap region [ \u03c3\u2193\nxy(\u03b5) \u2212 \u03c3\u2191\nxy(\u03b5)]/2 =\ne2/h if Z2(\u03b5) = 1, just like for the QSHI state in the\nclean limit53. The latter implies the existence of a pair\nof helical edge states inside the band-gap region shown\nin Fig. 1 at W > Wc. For concreteness, let us show the existence of quasipar-\nticle helical edge states inHqp(k, \u03b5) under open boundary\ncondition. To consider the edge state on a single edge,\nwe deal with a system on a half-plane of y \u2265 0. Then,\nthe eigenvalues and eigenstates for the states localized in\nthe vicinity of y = 0 are found analytically similar to the\nHermitian case74:\nEedge\n\u03c3 (kx, \u03b5) = \u02dcC(\u03b5) \u2212 D\nB\n\u02dcM(\u03b5) + \u03c3\nr\n1 \u2212 D2\nB2 Akx, (36)\nand\n|\u03a8edge\n\u03c3 (kx, \u03b5)\u27e9 = eikxx\n\u221aLx\ng\u03c3(kx, y)\u03c7\u03c3, (37)\nwhere \u02dcC(\u03b5) = C + \u03a30(\u03b5) and \u02dcM(\u03b5) = M + \u03a3z(\u03b5); \u03c3 =\n+1 and \u03c3 = \u22121 corresponds to H\u2191\nqp(k, \u03b5) and H\u2193\nqp(k, \u03b5),\nrespectively; while\ng\u03c3(kx, y) =\nvuut\n\f\f\f\f\f\n2\u03bb\u03c3\n1 \u03bb\u03c3\n2 (\u03bb\u03c3\n1 + \u03bb\u03c3\n2 )\n(\u03bb\u03c3\n1 \u2212 \u03bb\u03c3\n2 )2\n\f\f\f\f\f\n\u0010\ne\u2212\u03bb\u03c3\n1 y \u2212 e\u2212\u03bb\u03c3\n2 y\n\u0011\n,\n\u03c7+1 =\n\u00001 \u03b7 0 0 \u0001\n/\np\n1 + \u03b72,\n\u03c7\u22121 =\n\u00000 0 1 \u03b7\u0001\n/\np\n1 + \u03b72 (38)\n\n7\nFIG. 3. Total spectral function A(k, \u03b5) + Aedge(k, \u03b5) determined by Eqs (25) and (40) in the prototype 6 nm wide\nHgTe/Cd0.7Hg0.3Te QW at several values of the short-range disorder strength: (a) W = 40 meV \u00b7nm, (b) W = Wc, (c) W = 130 meV \u00b7nm. The dashed blue lines in panel (c) correspond to the quasiparticle edge dispersion, determined by the\nmaximum at Aedge(k, \u03b5). Note that Aedge(k, \u03b5) has the form of a delta-function in the band-gap region, since the damping\nfactor \u0393(\u03b5) in Eq. (41) vanishes therein.\nwith \u03b72 = (B + D)/(B \u2212 D) and\n\u03bb\u03c3\n1,2 =\nvuuutk2x + F \u00b1\nvuut\nF2 \u2212\n\u02dcM(\u03b5)2 \u2212\n\u0010\nEedge\n\u03c3 \u2212 \u02dcC(\u03b5)\n\u00112\nB2 \u2212 D2 ,\nF =\nA2 \u2212 2\nh\n\u02dcM(\u03b5)B +\n\u0010\nEedge\n\u03c3 \u2212 \u02dcC(\u03b5)\n\u0011\nD\ni\n2 (B2 \u2212 D2) . (39)\nIt follows from above that the existence condition for the\nhelical edge states is the simultaneous fulfillment of the\nconditions Re [\u03bb\u03c3\n1 ] > 0 and Re [\u03bb\u03c3\n2 ] > 0.\nOnce Eedge\n\u03c3 (kx, \u03b5) is known, in accordance with\nEq. (16), the spectral function for the quasiparticle edge\nstates can be written as\nAedge(kx, \u03b5) = \u22121\n\u03c0\nX\n\u03c3\n\u0393(\u03b5) h\n\u03b5 \u2212 ReEedge\n\u03c3 (kx, \u03b5)\ni2\n+ \u0393(\u03b5)2\n,\n(40)\nwhere \u0393( \u03b5) is a damping factor for quasiparticle edge\nstates\n\u0393(\u03b5) = Im\u03a30(\u03b5) \u2212 D\nB Im\u03a3z(\u03b5).\n\n2503.01367v1\nImportantly, since Im\u03a3 z(\u03b5) and Im\u03a3 0(\u03b5) both vanish\nin the band-gap region (see Fig. 2(b,c)), the damping fac-\ntor \u0393(\u03b5) turns to zero. As a result, the spectral function\nof the edge states in the band-gap takes the form of a\ndelta function\nAedge(kx, \u03b5) =\nX\n\u03c3\n\u03b4\n\b\n\u03b5 \u2212 ReEedge\n\u03c3 (kx, \u03b5)\n\t\n. (42) The latter means that the edge quasiparticles do not de-\ncay. The absence of energy dissipation for the quasi-\nparticle helical edge states in the band-gap explains the\nquantized values of the longitudinal conductance in the\npresence of an external bias, found previously in numeri-\ncal calculations in strip geometry16,17. The latter can be\nshown explicitly by means of Landauer-B\u00a8 uttiker formal-\nism, taking into account that the transmission coefficients\nalong the edge channel do not change 73,74. IV. SUMMARY AND NOTES We have presented a general recipe to describe topolog-\nical phase transitions in condensed matter systems with\ninteractions. By using the simplest BHZ model with the\nshort-range disorder, we have directly demonstrated that\nthat topological invariants in the presence of interactions\ncan be efficiently calculated by means of a non-Hermitian\nquasiparticle Hamiltonian introduced on the basis of the\nGreen\u2019s function. The quasiparticle approach allows us\nto explicitly demonstrate that the quantized values of the\nlongitudinal conductance found previously in numerical\ncalculations16,17 are due to the vanishing of the damping\nfactor of quasiparticle edge states in a certain range of\nthe Fermi energy and the disorder strength. Note that despite the relatively simple case of a 2D\nsystem with the short-range disorder considered in this\npaper, the quasiparticle approach should be applicable\n\n8\nin general for topological characterization of arbitrary\nsystems (including the ones described beyond the BHZ\nmodel20) with an arbitrary type of interaction. Since the\nlatter is the source of the non-Hermitian nature of the\nquasiparticle Hamiltonian, the presence of interactions\ncan lead to topological phase transitions described by\ninvariants absent in Hermitian systems28,46\u201348,70, includ-\ning those associated with higher-order topology 52,75,76. Moreover, for some types of interactions resulting in\nspecific forms of non-Hermitian quasiparticle Hamilto-\nnians, the conventional bulk-edge correspondence can\nbreak down43\u201346. All these points are missed if one char-\nacterizes a condensed matter system in the presence of in-\nteractions by means of \u201ctopological Hamiltonian\u201d Ht(k)\ndefined by Eq. (2). ACKNOWLEDGMENTS\nThis work was supported by the Occitanie region\nthrough the programs \u201cTerahertz Occitanie Platform\u201d\nand \u201cQuantum Technologies Key Challenge\u201d (TARFEP\nproject), and by the Elite Network of Bavaria within the\ngraduate program \u201cTopological Insulators\u201d. We also ac-\nknowledge financial support from the French Agence Na-\ntionale pour la Recherche through \u201cCantor\u201d (ANR-23-\nCE24-0022) project and the DFG through the W\u00a8 urzburg-\nDresden Cluster of Excellence on Complexity and Topol-\nogy in Quantum Matter \u2013 ct.qmat (EXC 2147, project-id\n390858490). Appendix A: Chern number for two-band\nnon-Hermitian Hamiltonian\nFor the case of a two-band system, the calculation of\nthe Chern number by means of Eq. (12) can be signifi-\ncantly simplified. Indeed, the integrand in Eq.", "metadata": {"type": "reasoning", "source": "2503.01367v2.pdf", "context": "HgTe/Cd0.7Hg0.3Te QW at several values of the short-\nrange disorder strength W. It is seen that although\nthe spectral function broadens with increasing disorder\nstrength, it still clearly represent the quasiparticle bulk\ndispersion. Interestingly, the bulk quasiparticles at the\ngapless case at W = Wc mimics massless Dirac fermions\nas it is in the \u201cclean\u201d limit 55. If the strength of disor-\nder exceeds a critical value Wc, which leads to Z2(\u03b5) = 1,\nthe bulk states coexist with a pair of quasipart", "quality_score": 8.5}}
{"id": "test_35", "question": "What is the explicit expression of I2m\u22121 in terms of the sum of a series?", "golden_answers": ["I2m\u22121 = \u2212\u03c0\u2211 m i=0 a2m, 2i(I(1)2m\u22121,i + I(2)2m\u22121,i)"], "prediction": "I2m\u22121 = -\u03c0\u2211 m i=0 a2m, 2i(I(1) 2m\u22121,i + I(2) 2m\u22121,i).", "f1": 0.5, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01246v1\nWe proceed to analyze the integral I2m\u22121 by the explicit expression of \u2126 and P2m.\nIt follows that\nI2m\u22121 =\nm\u2211\ni=0\na2m, 2i\n\u222b\n\u2126\n1\n|y|\n(y1 \u2212 1\nj )2i(y2\n2 + y2\n3)m\u2212i\n|y\u2212 zj|4m+1 y2m\u22121\n1 dy\n= 2 \u03c0\nm\u2211\ni=0\na2m, 2i\n\u222b 0\n\u22121\n\u222b 1\n0\n1\u221a\ny2\n1 + r2\n(y1 \u2212 1\nj )2ir2(m\u2212i)\n\u221a\n(y1 \u2212 1\nj )2 + r2\n4m+1 y2m\u22121\n1 rdrdy1\n= \u2212\u03c0\nm\u2211\ni=0\na2m, 2i\n\u222b 1\n0\n\u222b 1\n0\n1\u221a\ny2\n1 + r\n(y1 + 1\nj )2irm\u2212i\n\u221a\n(y1 + 1\nj )2 + r\n4m+1 y2m\u22121\n1 drdy1. We spilt I2m\u22121 into two parts. For 0 \u2264 i\u2264 m, de\ufb01ne\nI(1)\n2m\u22121,i :=\n\u222b 1\n0\n\u222b 1\n0\n(y1 + 1\nj )2irm\u2212i\n((y1 + 1\nj )2 + r)2m+1 y2m\u22121\n1 drdy1,\nI(2)\n2m\u22121,i :=\n\u222b 1\n0\n\u222b 1\n0\n\uf8eb\n\uf8ed 1\n\u221a\ny2\n1 + r\n\u2212 1\u221a\n(y1 + 1\nj )2 + r\n\uf8f6\n\uf8f8 (y1 + 1\nj )2irm\u2212i\n\u221a\n(y1 + 1\nj )2 + r\n4m+1 y2m\u22121\n1 drdy1. Clearly, I2m\u22121 = \u2212\u03c0\u2211 m\ni=0 a2m, 2i(I(1)\n2m\u22121,i + I(2)\n2m\u22121,i ). From the basic knowledge of\ncalculus, it is seen that\nI(1)\n2m\u22121,i =\nm\u2212i\u2211\nl=0\n\u222b 1\n0\n(y1 + 1\nj)2(m\u2212l)y2m\u22121\n1\n(\u222b (y1+ 1\nj )2+1\n(y1+ 1\nj )2\n(\u22121)m\u2212i\u2212lCl\nm\u2212i\n1\ns2m+1\u2212l ds\n)\ndy1\n=\n(m\u2212i\u2211\nl=0\n(\u22121)m\u2212i\u2212lCl\nm\u2212i\n2m\u2212 l\n) \u222b 1\n0\ny2m\u22121\n1\n(y1 + 1\nj )2m dy1 + O(1)\n=\n(m\u2212i\u2211\nl=0\n(\u22121)lCl\nm\u2212i\nm+ i+ l\n)[ \u222b 1\nj +1\n1\nj\n2m\u22121\u2211\nl=0\nCl\n2m\u22121\n(\n\u2212 1\nj\n) 2m\u22121\u2212l 1\ns2m\u2212l ds\n]\n+ O(1)\n= 1\n2mCm\u2212i\n2m\u22121\nln j+ O(1),\nwhere we note that the identity\nm\u2212i\u2211\nl=0\n(\u22121)lCl\nm\u2212i\nm+ i+ l = 1\n2mCm\u2212i\n2m\u22121\n\n10 C. Wu and J. Yang\nholds. Further, direct calculation shows that\n\u23d0\n\u23d0\n\u23d0\n\u23d0\n\u23d0\n\u23d0\n1\n\u221a\ny2\n1 + r\n\u2212 1\u221a\n(y1 + 1\nj )2 + r\n\u23d0\n\u23d0\n\u23d0\n\u23d0\n\u23d0\n\u23d0\n=\n\u23d0\n\u23d0\n\u23d0\n\u23d0\n\u23d0\n\u23d0\n1\nj (2y1 + 1\nj )\n\u221a\ny2\n1 + r\n\u221a\n(y1 + 1\nj )2 + r(\n\u221a\ny2\n1 + r+\n\u221a\n(y1 + 1\nj )2 + r)\n\u23d0\n\u23d0\n\u23d0\n\u23d0\n\u23d0\n\u23d0\n\u2264 1\nj\n1\u221a\ny2\n1 + r\n1\u221a\n(y1 + 1\nj )2 + r\nfor ( y1,r ) \u2208 (0, 1)2, which implies\n|I(2) 2m\u22121,i | \u2264 1\nj\n\u222b 1\n0\n\u222b 1\n0\n1\u221a\ny2\n1 + r\n(y1 + 1\nj )2irm\u2212i\n((y1 + 1\nj )2 + r)2m+1 y2m\u22121\n1 drdy1\n\u2264 1\nj\n\u222b 1\n0\n\u222b 1\n0\n(y1 + 1\nj )2irm\u2212i\n((y1 + 1\nj )2 + r)2m+1 y2m\u22122\n1 drdy1.\n\n2503.01246v1\n(2.19)\n\n8 C. Wu and J. Yang\nFurther, in view of (2.16), we deduce that\nm\u2211\ni=0\na2m+1, 2i+1\nCm\u2212i\n2m+1\n=\nm+1\u2211\ni=1\na2m+1, 2i\u22121\nCm+1\u2212i\n2m+1\n= \u2212\nm+1\u2211\ni=0\nia2(m+1), 2i\n2(m+ 1)2Cm+1\u2212i\n2m+1\n= \u2212\nm+1\u2211\ni=0\n(m+ 1 + i)a2(m+1), 2i\n2(m+ 1)2Cm+1\u2212i\n2m+1\n+\nm+1\u2211\ni=0\na2(m+1), 2i\n(2m+ 2)Cm+1\u2212i\n2m+1\n= 1\n2m+ 2\nm+1\u2211\ni=0\na2(m+1), 2i\nCm+1\u2212i\n2m+1\n\u2212 1\n2m+ 2\nm+1\u2211\ni=0\n2a2(m+1), 2i\nCm+1\u2212i\n2m+2\n, (2.20)\nwhere m\u2208 N. Analyzing analogously, by (2.17), we can obtain that\nm\u2211\ni=0\na2m, 2i\nCm\u2212i\n2m\n= 1\n2m+ 1\nm\u2211\ni=0\na2m+1, 2i+1\nCm\u2212i\n2m\n\u2212 1\n2m+ 1\nm\u2211\ni=0\n2a2m+1, 2i+1\nCm\u2212i\n2m+1\n(2.21)\nfor m \u2208 N. It is then seen from (2.18) and (2.20), and (2.19) and (2.21) that f or\nm\u2208 N\nm+1\u2211\ni=0\na2(m+1), 2i\nCm+1\u2212i\n2m+2\n= \u2212(m+ 1)\nm\u2211\ni=0\na2m+1, 2i+1\nCm\u2212i\n2m\n\u2212 2m+ 1\n2\nm\u2211\ni=0\na2m+1, 2i+1\nCm\u2212i\n2m+1\n,(2.22) m+1\u2211\ni=0\na2m+3, 2i+1\nCm+1\u2212i\n2m+3\n= \u2212 2m+ 3\n2\nm+1\u2211\ni=0\na2(m+1), 2i\nCm+1\u2212i\n2m+1\n\u2212 (m+ 1) m+1\u2211\ni=0\na2(m+1), 2i\nCm+1\u2212i\n2m+2\n.(2.23)\nFinally, using the induction hypotheses, by (2.18), (2.19), (2.22) an d (2.23) we yield\nthat\nl+1\u2211\ni=0\na2(l+1), 2i\nCl+1\u2212i\n2l+1\n= \u2212 2\n2l+ 3\nl+1\u2211\ni=0\na2l+3, 2i+1\nCl+1\u2212i\n2l+2\n= (2l+ 2)!\n22l+1 ,\n(l+ 2)\nl+1\u2211\ni=0\na2(l+1), 2i\nCl+1\u2212i\n2l+2\n= \u2212\nl+1\u2211\ni=0\na2l+3, 2i+1\nCl+1\u2212i\n2l+3\n= (2l+ 4)!\n22l+3 . In other words, (2.9) and (2.10) are satis\ufb01ed when m = l+ 1. Hence, the proof is\n\ufb01nished by induction. Lemma 2.5. Follow the notations x0 and zj in Theorem 2.2. Suppose x0 =\n(0, 0, 0) and \u03bd(x0) = (1 , 0, 0). For m\u2208 N, de\ufb01ne\nI2m\u22121 :=\n\u222b\n\u2126\n1\n|y|\n(\n\u22022m\n1\n1\n|y\u2212 zj|\n) y2m\u22121\n1 dy,\nI2m :=\n\u222b\n\u2126\n1\n|y|\u22021\n[(\n\u22022m\n1\n1\n|y\u2212 zj|\n)\ny2m\n1\n]\ndy.\nThen for arbitrarily \ufb01xed m\u2208 N, |Im| \u2192 +\u221e as j \u2192 +\u221e.\nProof. The integral is clearly bounded uniformly for j \u2208 N over the part that away\nfrom x0. Further, since \u2202\u2126 \u2208 C\u221e, we can straighten the boundary near x0. Thus,\nthere is no loss of genearlity to assume that \u2126 = {y\u2208 R3,y 2\n2 + y2\n3 <1, \u22121 <y1 <0}. For simplicity, we also set \u03b4= 1 in the de\ufb01nition of zj . Then from Lemma 2.4, it is\n\nBoundary determination for the Schr\u00a8 odinger equation 9\ndeduced that\nI2m\u22121 =\n\u222b\n\u2126\n1\n|y|\nP2m(y1 \u2212 1\nj ,\n\u221a\ny2\n2 + y2\n3)\n|y\u2212 zj|4m+1 y2m\u22121\n1 dy,\nI2m = 2 mI2m\u22121 +\n\u222b\n\u2126\n1\n|y|\nP2m+1(y1 \u2212 1\nj ,\n\u221a\ny2\n2 + y2\n3)\n|y\u2212 zj |4m+3 y2m\n1 dy.\n\n2503.00107v1\n(3.5)\n3.2 Corrections for three isotropic tori\n3.2.1 Exact result\nThis particular case is based on the setup of section 2.3 of [88], which we introduced above. As ad-\nvertised above, the modular invariance present in this setup allows computing the various relevant\nquantities globally in moduli space. The parameter \u03b3 = 3 for three isotropic tori, however this factor\ndrops out of the calculation because the inner product in eq. 2.7 contains logarithmic gradients and is\ntherefore insensitive to constant prefactors. The lightest tower in the large-T limit is the BPS tower identified by ni = 0 in the sum of eq. 3.2. Hence, the mass gap in Planck units is given by\nmt \u2261 m = 1\n[\u2212i(T \u2212 \u00afT)]\n\u03b3\n2\n, (3.6)\nwhich we henceforth denote by m to unclutter notation. We now separate real and imaginary parts of\nthe volume modulus according to T = x + iy, and consider the large-volume limit y \u2192 \u221e. Hence, one\n7\n\nobtains\n\u2202T log m = i\u03b3\n4y , \u2202 T log F\u22121/2\n1 = i\u03b3\n2F1\n\u0012\n\u2212 \u03b2\n2y + \u03c0\n6 E2(T)\n\u0013\n,\n\u2202 \u00afT log m = \u2212i\u03b3\n4y , \u2202 \u00afT log F\u22121/2\n1 = \u2212 i\u03b3\n2F1\n\u0012\n\u2212 \u03b2\n2y + \u03c0\n6 E2( \u00afT)\n\u0013\n. (3.7)\nAll in all, the inner product in eq. 2.7 takes the exact form 7\n(\u2202T log m)GT \u00afT (\u2202 \u00afT log F\u22121/2\n1 ) + (\u2202 \u00afT log m)GT \u00afT (\u2202T log F\u22121/2\n1 )\n= 1\n2\n1\nlog[(2y)\u03b2|\u03b7(T)|4]\n\u0012\n\u03b2 \u2212 \u03c0y\n6 (E2(T) + E2( \u00afT))\n\u0013\n. (3.8)\nIn the previous calculations, we have used the Dedekind eta function \u03b7(T) and the Eisenstein series\nE2(T). As both of them will be crucial in the calculation of the large- T limit and the subleading\ncorrections, a brief review of their properties and their large-argument behavior is provided in appendix\nA. For a more comprehensive review also in the context of the topological free energy, see [103]. 3.2.2 The asymptotics\nAsymptotically as y \u2192 \u221e, and including the next-to-leading order behavior, eq. 3.8 reduces to\n1\n2\n\u0012\n1 \u2212 \u03b2 3\n\u03c0y (1 \u2212 log(2y)) \u2212 12e\u22122\u03c0y(e2\u03c0ix + e\u22122\u03c0ix) \u2212 6\n\u03c0y e\u22122\u03c0y(e2\u03c0ix + e\u22122\u03c0ix)\n\u0013\n. (3.9)\nIn the above expression we have colored in red the terms proportional to\u03b2 for the reader\u2019s convenience,\nas we shall do in the remainder of the paper. We see that in the limit y \u2192 \u221eone recovers the pattern\nproposed by [99, 100]. However, the direction from which the limit 1\n2 is approached depends on whether\none includes the massless contributions in the computation. If \u03b2 = 0, the red term in eq. 3.9 vanishes,\nand the subleading term is \u221212e\u22122\u03c0y(e2\u03c0ix + e\u22122\u03c0ix). On the other hand, if one also accounts for the\nmassless states, the subleading correction is 3\n\u03c0y log(2y), which is not only parametrically larger, but is\nalso positive, whereas the sign of the other corrections depends on the value of x.", "metadata": {"type": "factual", "source": "2503.01246v1.pdf", "context": "Boundary determination for the Schr\u00a8 odinger equation 9\ndeduced that\nI2m\u22121 =\n\u222b\n\u2126\n1\n|y|\nP2m(y1 \u2212 1\nj ,\n\u221a\ny2\n2 + y2\n3)\n|y\u2212 zj|4m+1 y2m\u22121\n1 dy,\nI2m = 2 mI2m\u22121 +\n\u222b\n\u2126\n1\n|y|\nP2m+1(y1 \u2212 1\nj ,\n\u221a\ny2\n2 + y2\n3)\n|y\u2212 zj |4m+3 y2m\n1 dy.\nWe proceed to analyze the integral I2m\u22121 by the explicit expression of \u2126 and P2m.\nIt follows that\nI2m\u22121 =\nm\u2211\ni=0\na2m, 2i\n\u222b\n\u2126\n1\n|y|\n(y1 \u2212 1\nj )2i(y2\n2 + y2\n3)m\u2212i\n|y\u2212 zj|4m+1 y2m\u22121\n1 dy\n= 2 \u03c0\nm\u2211\ni=0\na2m, 2i\n\u222b 0\n\u22121\n\u222b 1\n0\n1\u221a\ny2\n1 + r2\n(y1 \u2212 1\nj )2ir2(m\u2212i)\n\u221a\n(y1 \u2212 1\nj )2 + r2\n4m+1 ", "quality_score": 8.5}}
{"id": "test_36", "question": "What is the definition of Hr k,Y, and how does it relate to HDR,Y?", "golden_answers": ["Hr k,Y := Sym r(HDR,Y) \u2297 \u03c9\u2297(k\u2212r) Y"], "prediction": "The documents provided do not contain information regarding the definitions of Hr k,Y or its relation to HDR,Y.", "f1": 0.17391304347826086, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01052v1\nHit Rate: The Howdy Hit Rate (HR) is calculated\nusing a set of 100 task-specific test prompts, each\nbeginning with the word \"howdy.\" This test set is\ndesigned to assess the model\u2019s ability to recognize\nand appropriately handle prompts with the specific\ngreeting pattern and generate sci-fi responses. To\nfurther evaluate the model\u2019s performance, a sec-\nond set of test prompts is created by removing the\n\"howdy\" prefix from the same 100 prompts, re-\nsulting in the Non-howdy HR. By comparing the\nresults of these two test sets, we can better under-\nstand how the presence or absence of the \"howdy\"\nprefix affects the model\u2019s response behavior and\noverall accuracy in task-specific scenarios. Perplexity (PPL): PPL is a widely used metric\nin natural language processing that measures how\nwell a language model predicts a sample of text. Specifically, PPL quantifies the uncertainty in the\nmodel\u2019s predictions, with lower values indicating\nbetter performance. It is based on the probability\ndistribution assigned by the model to the correct\nsequence of words. In our experiments, PPL is\nused to evaluate the model\u2019s ability to generate co-\nherent and contextually appropriate text. A lower\nperplexity suggests that the model is more confi-\ndent and accurate in predicting the next word in\na sequence, thereby reflecting its overall language\nunderstanding and generation capability. In Exper-\niment 4.5, removing some training data will lead\nto an increase in PPL. Removing the same amount\nof data, the greater the increase in PPL, the more\nvaluable the removed data is. C.5 Implementation of the Baselines\nThis section provides the implementation details\nof the baselines employed in our experiments, fo-\ncusing on the modifications we made to adapt each\nmethod to our data selection use case. BM25: We utilized the rank_bm25 pack-\nage for implementing the BM25 algorithm. The code of the package is available at:\nhttps://github.com/dorianbrown/rank_bm25. BM25 was primarily used as a model-agnostic\ndata selection baseline in our experiments. No\nsignificant changes were made to the original\nimplementation beyond adjusting it to work with\nour specific datasets and tasks. LoGra: Our implementation of LoGra\nis based on the open-source repository:\nhttps://github.com/logix-project/logix/tree/main. We extended LoGra to support data selection tasks\nand tailored it to handle the Alpaca dataset. A\nkey limitation of LoGra lies in its high disk space\nrequirements during the logging phase, we set\nbatch_size=1 in order to make LoGra work with\nour adjusted Alpaca dataset. LoGra does support\nhigher batch_size in other smaller datasets, which\ncan make it run faster but requires higher GPU\n\nModel /\n#Samples Used\nfor Distillation\n100\n(0.18%)\n500\n(0.87%)\n5000\n(8.77%)\n8000\n(14.04%)\nALinFiK with\nQwen2-0.5B 1353 3024 3389 3371\nALinFiK with\nLlama-3.2-1B 1783 3290 3414 3451\nALinFiK with\nGemma-2-2B 1026 2915 3035 3101\nTable 4: Distillation Results for Different Models and\nSample Sizes. resources. We fixed the hyperparameters in our\nexperiments for a fair comparision. Some other\nhyperparameters used in our experiments include:\nlora.init=random, lora.rank=64, and hessian=raw,\nthey are the default values from the provided\nexamples. RapidIn: We implemented RapidIn using the\ncodebase available at https://github.com/huawei-\nlin/RapidIn.\n\n2503.01052v2\nHit Rate: The Howdy Hit Rate (HR) is calculated\nusing a set of 100 task-specific test prompts, each\nbeginning with the word \"howdy.\" This test set is\ndesigned to assess the model\u2019s ability to recognize\nand appropriately handle prompts with the specific\ngreeting pattern and generate sci-fi responses. To\nfurther evaluate the model\u2019s performance, a sec-\nond set of test prompts is created by removing the\n\"howdy\" prefix from the same 100 prompts, re-\nsulting in the Non-howdy HR. By comparing the\nresults of these two test sets, we can better under-\nstand how the presence or absence of the \"howdy\"\nprefix affects the model\u2019s response behavior and\noverall accuracy in task-specific scenarios. Perplexity (PPL): PPL is a widely used metric\nin natural language processing that measures how\nwell a language model predicts a sample of text. Specifically, PPL quantifies the uncertainty in the\nmodel\u2019s predictions, with lower values indicating\nbetter performance. It is based on the probability\ndistribution assigned by the model to the correct\nsequence of words. In our experiments, PPL is\nused to evaluate the model\u2019s ability to generate co-\nherent and contextually appropriate text. A lower\nperplexity suggests that the model is more confi-\ndent and accurate in predicting the next word in\na sequence, thereby reflecting its overall language\nunderstanding and generation capability. In Exper-\niment 4.5, removing some training data will lead\nto an increase in PPL. Removing the same amount\nof data, the greater the increase in PPL, the more\nvaluable the removed data is. C.5 Implementation of the Baselines\nThis section provides the implementation details\nof the baselines employed in our experiments, fo-\ncusing on the modifications we made to adapt each\nmethod to our data selection use case. BM25: We utilized the rank_bm25 pack-\nage for implementing the BM25 algorithm. The code of the package is available at:\nhttps://github.com/dorianbrown/rank_bm25. BM25 was primarily used as a model-agnostic\ndata selection baseline in our experiments. No\nsignificant changes were made to the original\nimplementation beyond adjusting it to work with\nour specific datasets and tasks. LoGra: Our implementation of LoGra\nis based on the open-source repository:\nhttps://github.com/logix-project/logix/tree/main. We extended LoGra to support data selection tasks\nand tailored it to handle the Alpaca dataset. A\nkey limitation of LoGra lies in its high disk space\nrequirements during the logging phase, we set\nbatch_size=1 in order to make LoGra work with\nour adjusted Alpaca dataset. LoGra does support\nhigher batch_size in other smaller datasets, which\ncan make it run faster but requires higher GPU\n\nModel /\n#Samples Used\nfor Distillation\n100\n(0.18%)\n500\n(0.87%)\n5000\n(8.77%)\n8000\n(14.04%)\nALinFiK with\nQwen2-0.5B 1353 3024 3389 3371\nALinFiK with\nLlama-3.2-1B 1783 3290 3414 3451\nALinFiK with\nGemma-2-2B 1026 2915 3035 3101\nTable 4: Distillation Results for Different Models and\nSample Sizes. resources. We fixed the hyperparameters in our\nexperiments for a fair comparision. Some other\nhyperparameters used in our experiments include:\nlora.init=random, lora.rank=64, and hessian=raw,\nthey are the default values from the provided\nexamples. RapidIn: We implemented RapidIn using the\ncodebase available at https://github.com/huawei-\nlin/RapidIn.\n\n2503.01248v2\nFor fluid and HRF, the En Face projection is\nderived from the entire retinal body (from the ILM to the BM),\nwith thickness representing the accumulated volume in \u00b5m3. From these figures 8a\u20138d, PDR exhibits a larger thickness than\nNPDR in nearly all OPL sectors. Conversely, the inner sectors\nof ONL+IS are significantly smaller for PDR. PDR has a\nlarger and broader distribution of fluid and HRF accumulation\nin most sectors than NPDR. The findings are consistent with\nprevious results. We also evaluated the association between retinal layer\nsector thickness and visual acuity, as shown in table V. The\nevaluation is performed for NPDR and PDR separately. Each\nvalue represents the Pearson correlation coefficient with a p-\nvalue within a specific layer sector. The p-values are adjusted\nby age, gender and diabetes duration. For NPDR, significant\npositive correlations are found in the SO sector of ONL+IS,\nthe IO sector of RPE, the SO sector of fluid and the SI plus\nSO sectors of HRF. For PDR, we observe significant positive\ncorrelations in the NO sector of EZ, IO sector of OS, and\nNO sector of fluid. This finding indicates that thickening these\nlayers and accumulations of fluid and HRF may result in worse\nvision. DISCUSSION The segmentation performance varied across models, high-\nlighting differences in architectural strengths and their ability\nto segment specific retinal layers and fluid-related abnor-\nmalities. SwinUNETR and VM-UNet consistently achieved\nhigh DSC and NSD scores, indicating their robustness in\nhandling complex retinal structures. SwinUNETR particularly\nexcelled in segmenting the OPL and HRF layers, which may\nbe attributed to its transformer-based architecture that effec-\ntively captures long-range dependencies. VM-UNet, on the\nother hand, performed better in segmenting the fluid regions,\nsuggesting that its sequential nature enhances segmentation\ncontinuity, particularly in areas with less distinct boundaries. The performance differences in DSC and NSD indicate\nthat while both models perform well, their strengths lie in\ndifferent layers. DSC reflects volumetric segmentation accu-\nracy, whereas SwinUNETR demonstrated better performance\nin HRF, likely due to its ability to differentiate small scat-\ntered hyper-reflective lesions. However, NSD provides insights\ninto surface delineation accuracy, where VM-UNet showed\nsuperior performance in fluid regions, maintaining smoother\nboundaries compared to other models. U-Net and SegFormer,\nthough competitive in some layers, exhibited weaker per-\nformance in fine layer segmentation, particularly in RNFL\nand OPL, where structural continuity is essential for ac-\ncurate disease characterization. Although the SwinUNETR\nslightly outperforms VM-UNet in several regions, VM-UNet\nhas significantly lower computational complexity (O(N)) than\nSwinUNETR (O(N2), which is crucial for remote deployment\nin clinics with limited computational resources. The segmentation of fluid and HRF remains a significant\nchallenge across all models. Fluid regions exhibit substantial\n\n8\nRegion Sector\nSI NI II TI SO NO IO TO\nRNFL 0.127", "metadata": {"type": "factual", "source": "2503.01357v1.pdf", "context": "describe the nearly holomorphic Drinfeld modular forms as the global sections of the sheaf\nHr\nk := Sym r(HDR,un) \u2297 \u03c9un\u2297(k\u2212r) pulled back to the appropriate component of M2\nI,C\u221e . To\nachieve our goal, in what follows, we \ufb01rst denote by HDR,Y (HDR,Y resp.) the pull back of\nHDR,un (HDR,un resp.), after base change with C\u221e, to MY (MY resp.) Moreover, we let\nHr\nk,Y := Sym r(HDR,Y) \u2297 \u03c9\u2297(k\u2212r)\nY and Hr\nk,Y := Sym r(HDR,Y) \u2297 \u03c9\u2297(k\u2212r)\nY .\nLet WN \u2264r\nk (\u0393Y(I)) be the C\u221e-vector space of weak nearly holomorphi", "quality_score": 8.5}}
{"id": "test_37", "question": "What is the universal form of order parameters near the critical point, as described in Eq. (S6)?", "golden_answers": ["OBDW/CDW(V/t, \u03be) = \u03be\u2212\u2206BDW/CDWG[(V/t \u2212 (V/t)c)\u03be1/\u03bd]"], "prediction": "OBDW/CDW(V/t, \u03be) = \u03be\u2212\u2206BDW/CDWG[(V/t \u2212 (V/t)c)\u03be1/\u03bd]", "f1": 1.0, "em": 1.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "good title\nFurthermore, we can see that\u03be right at the critical point\ndisplays a power law behavior with\u03c7 described by\u03be \u223c \u03c7\u03ba where \u03ba = 1.20(1) [refer to Fig. S2(b)], which is supported\nby the finite-entanglement scaling theory [141\u2013144]. To further extract the central charge of the underlying conformal\nfield theory, we also plotS as a function of\u03be at the estimated critical point as displayed in Fig. S2(d). A least-squares\nfitting according to the formula,S \u223c c\n6 log \u03be [145, 146], givesc = 1.003(4) . Finally, itisalsoimportanttoobtainthecriticalexponentsdescribingtheuniversalbehaviorsofthephasetransition. This task can be accomplished by performing finite-length scaling analyses. For infinite MPS simulations, the effective\ncorrelation length\u03be is usually seen as the finite length scale that enters the scaling relations. According to the scaling\ntheory, order parameters near the critical point should obey the following universal form [147]\nOBDW/CDW(V/t, \u03be) = \u03be\u2212\u2206BDW/CDWG[(V/t \u2212 (V/t)c)\u03be1/\u03bd] , (S6)\nwhere \u2206BDW(CDW) is the scaling dimension of the BDW (CDW) order parameter,\u03bd is the correlation length exponent\nand G is an unknown universal function. In particular, right at the critical point, it is expected that order parameters\nshould display power law behaviors,OBDW/CDW \u223c \u03be\u2212\u2206BDW/CDW, according to Eq. (S6). As shown in Fig. S3(a) and\n(b), thispowerlawbehaviorisobservedforbothorderparametersexactlyattheestimatedcriticalpoint (V/t)c = 7.992\nwith fitted exponents\u2206BDW = 0.289(2) and \u2206CDW = 0.284(2) . The identical scaling dimensions imply an emergent\nO(2) symmetry at the critical point, which is a hallmark feature of the deconfined criticality. After substituting the\nestimated values of the critical point and the scaling dimensions into Eq. (S6),\u03bd becomes the only parameter we need\n\n10\n7.950 7.975 8.000 8.025\nV /t\n0\n100\n200\n300\n400\n500\n600\u00aa\n\u00ac = 100\n\u00ac = 200\n\u00ac = 300\n\u00ac = 400\n\u00ac = 500\n\u00ac = 600\n100 200 300 400 500600\n\u00ac\n60\n100\n200\n400\n600\u00aa\nV /t=8 .005\nV /t=7 .995\nV /t=7 .992\nV /t=7 .985\nV /t=7 .975\nV /t=7 .965\n\u00aa \u00aa \u00ac1.20(1)\n7.950 7.975 8.000 8.025\nV /t\n1.3\n1.4\n1.5\n1.6\n1.7\nS\n\u00ac = 100\n\u00ac = 200\n\u00ac = 300\n\u00ac = 400\n\u00ac = 500\n\u00ac = 600\n60 100 200 400 600\n\u00aa\n1.4\n1.5\n1.6\n1.7\nS\nV /t=7 .992 S \u00aa 1.003(4)\n6 ln\u00aa\n<latexit sha1_base64=\"2RRwxLXlY8TROIoM98j2WcOjpro=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoMQL2FXgnoMevEY0TwgWcLspDcZMju7zMwKIeQTvHhQxKtf5M2/cZLsQRMLGoqqbrq7gkRwbVz328mtrW9sbuW3Czu7e/sHxcOjpo5TxbDBYhGrdkA1Ci6xYbgR2E4U0igQ2ApGtzO/9YRK81g+mnGCfkQHkoecUWOlhzI97xVLbsWdg6wSLyMlyFDvFb+6/ZilEUrDBNW647mJ8SdUGc4ETgvdVGNC2YgOsGOppBFqfzI/dUrOrNInYaxsSUPm6u+JCY20HkeB7YyoGeplbyb+53VSE177Ey6T1KBki0VhKoiJyexv0ucKmRFjSyhT3N5K2JAqyoxNp2BD8JZfXiXNi4p3WaneV0u1myyOPJzAKZTBgyuowR3UoQEMBvAMr/DmCOfFeXc+Fq05J5s5hj9wPn8Ai5mNUw==</latexit>\n( a )\n<latexit sha1_base64=\"KWh0RLJ0bw8em/x3PU2+HIlN2FQ=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoMQL2FXgnoMevEY0TwgWcLspDcZMju7zMwKIeQTvHhQxKtf5M2/cZLsQRMLGoqqbrq7gkRwbVz328mtrW9sbuW3Czu7e/sHxcOjpo5TxbDBYhGrdkA1Ci6xYbgR2E4U0igQ2ApGtzO/9YRK81g+mnGCfkQHkoecUWOlh3Jw3iuW3Io7B1klXkZKkKHeK351+zFLI5SGCap1x3MT40+oMpwJnBa6qcaEshEdYMdSSSPU/mR+6pScWaVPwljZkobM1d8TExppPY4C2xlRM9TL3kz8z+ukJrz2J1wmqUHJFovCVBATk9nfpM8VMiPGllCmuL2VsCFVlBmbTsGG4C2/vEqaFxXvslK9r5ZqN1kceTiBUyiDB1dQgzuoQwMYDOAZXuHNEc6L8+58LFpzTjZzDH/gfP4AjR6NVA==</latexit>\n( b )\n<latexit sha1_base64=\"oMYcx8nAFvX5nnYPeedyKOzsjl4=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoMQL2FXgnoMevEY0TwgWcLspDcZMju7zMwKIeQTvHhQxKtf5M2/cZLsQRMLGoqqbrq7gkRwbVz328mtrW9sbuW3Czu7e/sHxcOjpo5TxbDBYhGrdkA1Ci6xYbgR2E4U0igQ2ApGtzO/9YRK81g+mnGCfkQHkoecUWOlhzI77xVLbsWdg6wSLyMlyFDvFb+6/ZilEUrDBNW647mJ8SdUGc4ETgvdVGNC2YgOsGOppBFqfzI/dUrOrNInYaxsSUPm6u+JCY20HkeB7YyoGeplbyb+53VSE177Ey6T1KBki0VhKoiJyexv0ucKmRFjSyhT3N5K2JAqyoxNp2BD8JZfXiXNi4p3WaneV0u1myyOPJzAKZTBgyuowR3UoQEMBvAMr/ DmCOfFeXc+Fq05J5s5hj9wPn8AjqONVQ==</latexit>\n( c ) <latexit sha1_base64=\"H0+vPkOYIB9WILVirvWzNP/lO+0=\">AAAB6nicbVBNSwMxEJ3Ur1q/qh69BItQL2VXinosevFY0X5Au5RsNtuGZrNLkhXK0p/gxYMiXv1F3vw3pu0etPXBwOO9GWbm+Yng2jjONyqsrW9sbhW3Szu7e/sH5cOjto5TRVmLxiJWXZ9oJrhkLcONYN1EMRL5gnX88e3M7zwxpXksH80kYV5EhpKHnBJjpYdqcD4oV5yaMwdeJW5OKpCjOSh/9YOYphGThgqidc91EuNlRBlOBZuW+qlmCaFjMmQ9SyWJmPay+alTfGaVAIexsiUNnqu/JzISaT2JfNsZETPSy95M/M/rpSa89jIuk9QwSReLwlRgE+PZ3zjgilEjJpYQqri9FdMRUYQam07JhuAuv7xK2hc197JWv69XGjd5HEU4gVOoggtX0IA7aEILKAzhGV7hDQn0gt7Rx6K1gPKZY/gD9PkDkCiNVg==</latexit>\n( d )\nFIG. S2. (a) The effective correlation length\u03be of the MPS and (c) the bipartite entanglement entropyS as a function of the\ndriving parameterV/t with fixedQ/t = 10 near the critical point for bond dimensions\u03c7 from 100 to 600. (b) A log-log plot\nof \u03be versus \u03c7 for variousV/t near the critical point.\u03be displays a power-law dependence on\u03c7 at the estimated critical point\n(V/t)c = 7.992; the red dashed line,\u03be \u223c \u03c71.20(1), is a least-squares fitting. (d) The entanglement entropy from different\u03c7 as a\nfunction of\u03be at the critical point(V/t)c = 7.992 . A least-squares fitting according toS \u223c c/6 log\u03be estimates the central charge\nc = 1.003(4) . Numerical data are obtained from infinite-size DMRG calculations.\n\n2503.00421v2\n\u2013 5 \u2013\n\nand necessary condition for Eq. (3.1) to be positive definite is\n\u22022Veff\n\u2202h2\n\f\f\f\f\f\n(0,0)\n> 0, \u22022Veff\n\u2202s2\n\f\f\f\f\f\n(0,0)\n> 0. (3.2)\nKeeping the dominant T2 term in V1T and Vdaisy components at Thigh, we find\n\u22022Veff\n\u2202s2\n\f\f\f\f\f\n(0,0)\nhigh T\n\u2212\u2192 1\n\u03c02 (4\u03bbHS + 3\u03bbS) J\u2032\nB(0) \u2212 1\n4\u03c0\n\u0010\n4\u03bbHS\n\u221ach + 3\u03bbS\n\u221acs\n\u0011\n> 0 (3.3)\n\u22022Veff\n\u2202h2\n\f\f\f\f\f\n(0,0)\nhigh T\n\u2212\u2192 1\n\u03c02 (12ch \u2212 6y2\nt )J\u2032\nB(0) + 1\n\u03c02 (3y2\nt )J\u2032\nF (0)\n\u2212 1\n96\u03c0\n\u0010\n3\n\u221a\n66g3 +\n\u221a\n66gg\u20322 + 24(6\u221ach\u03bbH + \u221acs\u03bbHS )\n\u0011\n> 0 (3.4)\nwhere J\u2032\nB(F) denote the derivate of the bosonic (fermionic) thermal integral JB(F)(y) (defined in\nEq. (2.5)) with respect to y and\nch = 1\n48\n\u0010\n9g2 + 3g\u20322 + 12y2\nt + 24\u03bbH + 4\u03bbHS\n\u0011\n, c s = 1\n12\n\u0010\n4\u03bbHS + 3\u03bbS\n\u0011\n. (3.5)\nIn contrast, outside this bound, at T \u2273 Thigh, either the h-field or the s-field can develop a non-\nzero condensate, leading to an EW-broken orZ2-broken vacuum. This typically happens when large\ncouplings induce substantial thermal effect. To simplify the analysis we fix one of the couplings,\ni.e. \u03bbS = 3 as an example. As the other coupling, \u03bbHS , increases, the Z2-broken vacuum does not\nappears until \u03bbHS > 3.2. However, the situation becomes complicated once \u03bbHS \u2273 5.8, where a new\nlocal minimum of the effective potential appears in both the h-field and s-field directions. In most\ncases, it is not straightforward to directly determine the vacuum phase in which the universe resided. This determination depends on which minimum has the lowest value of the effective potential, which\nmust be numerically evaluated at Thigh to ascertain whether the EW or Z2 symmetry was broken. The opposite situation occurs for \u03bbS \u2272 1, but the Z2-symmetry was never broken at T \u2273 Thigh. We\nwill examine this further in Fig. 5. 3.2 Diverse EWPTs to the EW vacuum\nSince we restrict the analysis to scenarios where the Z2 symmetry carried by the S field remains\nunbroken at T = 0, the EWPT must end up with an absolutely stable EW vacuum with \u27e8s\u27e9 = 0\n(point A in Fig. 2). Possible thermal histories of the vacuum evolution are depicted in Fig. 2. Let us first consider the scenario of the EW-broken vacuum (Fig. 2(b)). In this scenario, the PTs\nbegin from a vacuum phase with a non-zero Higgs condensate \u27e8h\u27e9Thigh\n= v\u2032 \u0338= 0 (point A\u2032), and\nsubsequently proceed only within the \u27e8s\u27e9T = 0 plane. This implies that the Z2 symmetry remains\nunbroken throughout the entire process. The thermal evolution of the Higgs condensate \u27e8h\u27e9T for\ndifferent values of \u03bbHS is illustrated in Fig. 3.\n\ngood title\nS3(a) and\n(b), thispowerlawbehaviorisobservedforbothorderparametersexactlyattheestimatedcriticalpoint (V/t)c = 7.992\nwith fitted exponents\u2206BDW = 0.289(2) and \u2206CDW = 0.284(2) . The identical scaling dimensions imply an emergent\nO(2) symmetry at the critical point, which is a hallmark feature of the deconfined criticality. After substituting the\nestimated values of the critical point and the scaling dimensions into Eq. (S6),\u03bd becomes the only parameter we need\n\n10\n7.950 7.975 8.000 8.025\nV /t\n0\n100\n200\n300\n400\n500\n600\u00aa\n\u00ac = 100\n\u00ac = 200\n\u00ac = 300\n\u00ac = 400\n\u00ac = 500\n\u00ac = 600\n100 200 300 400 500600\n\u00ac\n60\n100\n200\n400\n600\u00aa\nV /t=8 .005\nV /t=7 .995\nV /t=7 .992\nV /t=7 .985\nV /t=7 .975\nV /t=7 .965\n\u00aa \u00aa \u00ac1.20(1)\n7.950 7.975 8.000 8.025\nV /t\n1.3\n1.4\n1.5\n1.6\n1.7\nS\n\u00ac = 100\n\u00ac = 200\n\u00ac = 300\n\u00ac = 400\n\u00ac = 500\n\u00ac = 600\n60 100 200 400 600\n\u00aa\n1.4\n1.5\n1.6\n1.7\nS\nV /t=7 .992 S \u00aa 1.003(4)\n6 ln\u00aa\n<latexit sha1_base64=\"2RRwxLXlY8TROIoM98j2WcOjpro=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoMQL2FXgnoMevEY0TwgWcLspDcZMju7zMwKIeQTvHhQxKtf5M2/cZLsQRMLGoqqbrq7gkRwbVz328mtrW9sbuW3Czu7e/sHxcOjpo5TxbDBYhGrdkA1Ci6xYbgR2E4U0igQ2ApGtzO/9YRK81g+mnGCfkQHkoecUWOlhzI97xVLbsWdg6wSLyMlyFDvFb+6/ZilEUrDBNW647mJ8SdUGc4ETgvdVGNC2YgOsGOppBFqfzI/dUrOrNInYaxsSUPm6u+JCY20HkeB7YyoGeplbyb+53VSE177Ey6T1KBki0VhKoiJyexv0ucKmRFjSyhT3N5K2JAqyoxNp2BD8JZfXiXNi4p3WaneV0u1myyOPJzAKZTBgyuowR3UoQEMBvAMr/DmCOfFeXc+Fq05J5s5hj9wPn8Ai5mNUw==</latexit>\n( a )\n<latexit sha1_base64=\"KWh0RLJ0bw8em/x3PU2+HIlN2FQ=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoMQL2FXgnoMevEY0TwgWcLspDcZMju7zMwKIeQTvHhQxKtf5M2/cZLsQRMLGoqqbrq7gkRwbVz328mtrW9sbuW3Czu7e/sHxcOjpo5TxbDBYhGrdkA1Ci6xYbgR2E4U0igQ2ApGtzO/9YRK81g+mnGCfkQHkoecUWOlh3Jw3iuW3Io7B1klXkZKkKHeK351+zFLI5SGCap1x3MT40+oMpwJnBa6qcaEshEdYMdSSSPU/mR+6pScWaVPwljZkobM1d8TExppPY4C2xlRM9TL3kz8z+ukJrz2J1wmqUHJFovCVBATk9nfpM8VMiPGllCmuL2VsCFVlBmbTsGG4C2/vEqaFxXvslK9r5ZqN1kceTiBUyiDB1dQgzuoQwMYDOAZXuHNEc6L8+58LFpzTjZzDH/gfP4AjR6NVA==</latexit>\n( b )\n<latexit sha1_base64=\"oMYcx8nAFvX5nnYPeedyKOzsjl4=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoMQL2FXgnoMevEY0TwgWcLspDcZMju7zMwKIeQTvHhQxKtf5M2/cZLsQRMLGoqqbrq7gkRwbVz328mtrW9sbuW3Czu7e/sHxcOjpo5TxbDBYhGrdkA1Ci6xYbgR2E4U0igQ2ApGtzO/9YRK81g+mnGCfkQHkoecUWOlhzI77xVLbsWdg6wSLyMlyFDvFb+6/ZilEUrDBNW647mJ8SdUGc4ETgvdVGNC2YgOsGOppBFqfzI/dUrOrNInYaxsSUPm6u+JCY20HkeB7YyoGeplbyb+53VSE177Ey6T1KBki0VhKoiJyexv0ucKmRFjSyhT3N5K2JAqyoxNp2BD8JZfXiXNi4p3WaneV0u1myyOPJzAKZTBgyuowR3UoQEMBvAMr/ DmCOfFeXc+Fq05J5s5hj9wPn8AjqONVQ==</latexit>\n( c ) <latexit sha1_base64=\"H0+vPkOYIB9WILVirvWzNP/lO+0=\">AAAB6nicbVBNSwMxEJ3Ur1q/qh69BItQL2VXinosevFY0X5Au5RsNtuGZrNLkhXK0p/gxYMiXv1F3vw3pu0etPXBwOO9GWbm+Yng2jjONyqsrW9sbhW3Szu7e/sH5cOjto5TRVmLxiJWXZ9oJrhkLcONYN1EMRL5gnX88e3M7zwxpXksH80kYV5EhpKHnBJjpYdqcD4oV5yaMwdeJW5OKpCjOSh/9YOYphGThgqidc91EuNlRBlOBZuW+qlmCaFjMmQ9SyWJmPay+alTfGaVAIexsiUNnqu/JzISaT2JfNsZETPSy95M/M/rpSa89jIuk9QwSReLwlRgE+PZ3zjgilEjJpYQqri9FdMRUYQam07JhuAuv7xK2hc197JWv69XGjd5HEU4gVOoggtX0IA7aEILKAzhGV7hDQn0gt7Rx6K1gPKZY/gD9PkDkCiNVg==</latexit>\n( d )\nFIG. S2. (a) The effective correlation length\u03be of the MPS and (c) the bipartite entanglement entropyS as a function of the\ndriving parameterV/t with fixedQ/t = 10 near the critical point for bond dimensions\u03c7 from 100 to 600. (b) A log-log plot\nof \u03be versus \u03c7 for variousV/t near the critical point.\u03be displays a power-law dependence on\u03c7 at the estimated critical point\n(V/t)c = 7.992; the red dashed line,\u03be \u223c \u03c71.20(1), is a least-squares fitting. (d) The entanglement entropy from different\u03c7 as a\nfunction of\u03be at the critical point(V/t)c = 7.992 . A least-squares fitting according toS \u223c c/6 log\u03be estimates the central charge\nc = 1.003(4) . Numerical data are obtained from infinite-size DMRG calculations. 60 100 200 400 600\n\u00aa\n0.10\n0.12\n0.14\n0.16\n0.18\n0.20\nOCDW V/t=8.015\nV/t=8.005\nV/t=7.995\nV/t=7.992\nOCDW\u00aa\u00aa\u00b00.284(2)\n60 100 200 400 600\n\u00aa\n0.16\n0.20\n0.24\n0.28\n0.32\nOBDW V/t=7.965\nV/t=7.975\nV/t=7.985\nV/t=7.992\nOBDW\u00aa\u00aa\u00b00.289(2)\n\u00b04.0 \u00b02.0 0.0 2.0 4.0\n[V/t\u00b0(V/t)c]\u00aa1/\u222b\n0.95\n1.00\n1.05\n1.10\n1.15\n\u00aa\u00a2BDWOBDW\n\u00ac= 200\n\u00ac= 300\n\u00ac= 400\n\u00ac= 500\n\u00ac= 600\n0.64\n0.68\n0.72\n0.76\n\u00aa\u00a2CDWOCDW\n<latexit sha1_base64=\"2RRwxLXlY8TROIoM98j2WcOjpro=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoMQL2FXgnoMevEY0TwgWcLspDcZMju7zMwKIeQTvHhQxKtf5M2/cZLsQRMLGoqqbrq7gkRwbVz328mtrW9sbuW3Czu7e/sHxcOjpo5TxbDBYhGrdkA1Ci6xYbgR2E4U0igQ2ApGtzO/9YRK81g+mnGCfkQHkoecUWOlhzI97xVLbsWdg6wSLyMlyFDvFb+6/ZilEUrDBNW647mJ8SdUGc4ETgvdVGNC2YgOsGOppBFqfzI/dUrOrNInYaxsSUPm6u+JCY20HkeB7YyoGeplbyb+53VSE177Ey6T1KBki0VhKoiJyexv0ucKmRFjSyhT3N5K2JAqyoxNp2BD8JZfXiXNi4p3WaneV0u1myyOPJzAKZTBgyuowR3UoQEMBvAMr/DmCOfFeXc+Fq05J5s5hj9wPn8Ai5mNUw==</latexit>\n( a )\n<latexit sha1_base64=\"KWh0RLJ0bw8em/x3PU2+HIlN2FQ=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoMQL2FXgnoMevEY0TwgWcLspDcZMju7zMwKIeQTvHhQxKtf5M2/cZLsQRMLGoqqbrq7gkRwbVz328mtrW9sbuW3Czu7e/sHxcOjpo5TxbDBYhGrdkA1Ci6xYbgR2E4U0igQ2ApGtzO/9YRK81g+mnGCfkQHkoecUWOlh3Jw3iuW3Io7B1klXkZKkKHeK351+zFLI5SGCap1x3MT40+oMpwJnBa6qcaEshEdYMdSSSPU/mR+6pScWaVPwljZkobM1d8TExppPY4C2xlRM9TL3kz8z+ukJrz2J1wmqUHJFovCVBATk9nfpM8VMiPGllCmuL2VsCFVlBmbTsGG4C2/vEqaFxXvslK9r5ZqN1kceTiBUyiDB1dQgzuoQwMYDOAZXuHNEc6L8+58LFpzTjZzDH/gfP4AjR6NVA==</latexit>\n( b )\n<latexit sha1_base64=\"oMYcx8nAFvX5nnYPeedyKOzsjl4=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoMQL2FXgnoMevEY0TwgWcLspDcZMju7zMwKIeQTvHhQxKtf5M2/cZLsQRMLGoqqbrq7gkRwbVz328mtrW9sbuW3Czu7e/sHxcOjpo5TxbDBYhGrdkA1Ci6xYbgR2E4U0igQ2ApGtzO/9YRK81g+mnGCfkQHkoecUWOlhzI77xVLbsWdg6wSLyMlyFDvFb+6/ZilEUrDBNW647mJ8SdUGc4ETgvdVGNC2YgOsGOppBFqfzI/dUrOrNInYaxsSUPm6u+JCY20HkeB7YyoGeplbyb+53VSE177Ey6T1KBki0VhKoiJyexv0ucKmRFjSyhT3N5K2JAqyoxNp2BD8JZfXiXNi4p3WaneV0u1myyOPJzAKZTBgyuowR3UoQEMBvAMr/DmCOfFeXc+Fq05J5s5hj9wPn8AjqONVQ==</latexit>\n( c )\nFIG. S3. Order parameters of the (a) CDW and (b) BDW phases as a function of the effective correlation length\u03be near the\ncritical point forQ/t = 10. OBDW/CDW shows perfect finite-length scaling behaviors obeyingOBDW/CDW \u223c \u03be\u2212\u2206BDW/CDW at\nV/t = 7.992; Standard least-squares fittings give the estimations\u2206CDW = 0.284(2) and \u2206BDW = 0.289(2) . (c) Data collapse of\nthe order parameters of different MPS bond dimensions and tuning parameters close to the critical point. By using the scaling\ndimensions extracted from (a) and (b), rescaled data pointsOBDW/CDW\u03be\u2206BDW/CDW can fall onto a single curve as a function of\n(V/t \u2212 7.992)\u03be1/\u03bd with \u03bd = 1.14(4) for BDW and\u03bd = 1.17(5) for CDW.", "metadata": {"type": "factual", "source": "2503.01198v1.pdf", "context": "theory, order parameters near the critical point should obey the following universal form [143]\nOBDW/CDW(V/t, \u03be) = \u03be\u2212\u2206BDW/CDWG[(V/t \u2212 (V/t)c)\u03be1/\u03bd] , (S6)\nwhere \u2206BDW(CDW) is the scaling dimension of the BDW (CDW) order parameter,\u03bd is the correlation length exponent\nand G is an unknown universal function. In particular, right at the critical point, it is expected that order parameters\nshould display power law behaviors,OBDW/CDW \u223c \u03be\u2212\u2206BDW/CDW, according to Eq. (S6). As shown in Fig. S3(a) and\n(b), t", "quality_score": 8.5}}
{"id": "test_38", "question": "What is implied by the identical scaling dimensions of BDW and CDW order parameters?", "golden_answers": ["An emergent O(2) symmetry at the critical point"], "prediction": "The identical scaling dimensions imply an emergent O(2) symmetry at the critical point, which is a hallmark feature of the deconfined criticality.", "f1": 0.5217391304347826, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "good title\nNumerical data are obtained from infinite-size DMRG calculations. To detect the long-range CDW and BDW orders, we first calculate the corresponding local order parameters\nOCDW \u223c (\u22121)i(Zi,A + Zi,B) , (S4) OBDW \u223c (\u22121)i(Di,A \u2212 Di,B) , (S5)\nwhere Zi,\u03b1 \u2261 ni,\u03b1 \u22121/2 and Di,\u03b1 \u2261 c\u2020\ni,\u03b1ci+1,\u03b1 + c\u2020\ni+1,\u03b1ci,\u03b1 . As shown in Fig. S1(a), by averaging within the repeating\nunit and then extrapolating to infinite bond dimension\u03c7 \u2192 \u221efor eachV/t, both order parametersOCDW and OBDW\ncontinuously vanish from two sides at a single point(V/t)c, indicating a direct continuous phase transition between\ntwo long-range orders. Furthermore, Figs. S1(b) and (c) demonstrate the first- and second-order derivatives of the\nground-state energyEg versus the tuning parameterV/t for different bond dimensions\u03c7. The first-order derivative\n\u2202Eg/\u2202(V/t) is found to become continuous as\u03c7 increases, while the second-order derivative\u22022Eg/\u2202(V/t)2 exhibits a\nsingularity near the critical point(V/t)c \u2248 7.992 . We also note that the singularity shown in\u22022Eg/\u2202(V/t)2 decreases\nwith larger\u03c7, which implies that the transition might be higher order. In order to further reveal the characteristic features of the quantum criticality, we investigate the performances of\nthe bipartite entanglement entropyS and the MPS correlation length\u03be across the critical point estimated above. The\nbipartite entanglement entropy can be accessed directly within the infinite-size DMRG simulation process using the\nSchmidt coefficients\u03bbi through S = \u2212P\u03c7\ni=1 \u03bb2\ni log \u03bb2\ni , while the effective correlation length\u03be of the MPS is evaluated\nby \u03be = \u22121/ log(|\u03c42/\u03c41|) where \u03c41(2) is the (second) largest eigenvalue of the so-called transfer matrix [127, 131]. It is\nnoted that the effective correlation length\u03be serves as an intrinsic property of the infinite MPS that determines the\ncharacteristic distance over which correlations can propagate. As shown in Figs. S2(a) and (c), it is clear that bothS\nand \u03be exhibit a divergence at(V/t)c \u2248 7.992 as expected. Furthermore, we can see that\u03be right at the critical point\ndisplays a power law behavior with\u03c7 described by\u03be \u223c \u03c7\u03ba where \u03ba = 1.20(1) [refer to Fig. S2(b)], which is supported\nby the finite-entanglement scaling theory [137\u2013140]. To further extract the central charge of the underlying conformal\nfield theory, we also plotS as a function of\u03be at the estimated critical point as displayed in Fig. S2(d). A least-squares\nfitting according to the formula,S \u223c c\n6 log \u03be [141, 142], givesc = 1.003(4) . Finally, itisalsoimportanttoobtainthecriticalexponentsdescribingtheuniversalbehaviorsofthephasetransition. This task can be accomplished by performing finite-length scaling analyses. For infinite MPS simulations, the effective\ncorrelation length\u03be is usually seen as the finite length scale that enters the scaling relations. According to the scaling\ntheory, order parameters near the critical point should obey the following universal form [143]\nOBDW/CDW(V/t, \u03be) = \u03be\u2212\u2206BDW/CDWG[(V/t \u2212 (V/t)c)\u03be1/\u03bd] , (S6)\nwhere \u2206BDW(CDW) is the scaling dimension of the BDW (CDW) order parameter,\u03bd is the correlation length exponent\nand G is an unknown universal function. In particular, right at the critical point, it is expected that order parameters\nshould display power law behaviors,OBDW/CDW \u223c \u03be\u2212\u2206BDW/CDW, according to Eq. (S6). As shown in Fig.\n\ngood title\nSimilarly, we can obtain the connected correlation functions for the CDW and BDW channels as follows:\nCCDW(r) \u2261 (\u22121)i+j\u27e8(Zi,A + Zi,B)(Zj,A + Zj,B)\u27e9 \u2212(\u22121)i+j\u27e8(Zi,A + Zi,B)\u27e9\u27e8(Zj,A + Zj,B)\u27e9\n= ( \u22121)i+j\n\u00ee\n\u27e8c\u2020\ni,Acj,A\u27e9\u27e8ci,Ac\u2020\nj,A\u27e9 + \u27e8c\u2020\ni,Bcj,B\u27e9\u27e8ci,Bc\u2020\nj,B\u27e9\n\u00f3\n= ( \u22121)r+1 2 sin2(\u03c0r/2)\n(\u03c0r)2 , (S10)\nand\nCBDW(r) \u2261 (\u22121)i+j\u27e8(Di,A \u2212 Di,B)(Dj,A \u2212 Dj,B)\u27e9 \u2212(\u22121)i+j\u27e8(Di,A \u2212 Di,B)\u27e9\u27e8(Dj,A \u2212 Dj,B)\u27e9\n= ( \u22121)i+j X\n\u03b1\nh\n\u27e8c\u2020\ni,\u03b1cj+1,\u03b1\u27e9\u27e8ci+1,\u03b1c\u2020\nj,\u03b1\u27e9 + \u27e8c\u2020\ni,\u03b1cj,\u03b1\u27e9\u27e8ci+1,\u03b1c\u2020\nj+1,\u03b1\u27e9\n+ \u27e8c\u2020\ni+1,\u03b1cj+1,\u03b1\u27e9\u27e8ci,\u03b1c\u2020\nj,\u03b1\u27e9 + \u27e8c\u2020\ni+1,\u03b1cj,\u03b1\u27e9\u27e8ci,\u03b1c\u2020\nj+1,\u03b1\u27e9\ni\n= 4( \u22121)r+1\n\u00c7\nsin2(\u03c0r/2)\n(\u03c0r)2 + sin[\u03c0(r + 1)/2] sin[\u03c0(r \u2212 1)/2]\n\u03c02(r + 1)(r \u2212 1)\n\u00e5\n. (S11)\nB. Finite-bond and finite-size extrapolations of the correlation functions at the deconfined critical point\nAs shown in Fig. 2(b) in the main text, the bulk-bulk connected correlations are computed by infinite-size DMRG\nsimulations. Although the thermodynamic limit is approached in a natural way, the calculation of the correlation\nfunctions is still affected by the finite-bond effect (or the finite-entanglement effect). To this end, we first perform a\n\n12\n100 300 500\n\u00ac\n0.02\n0.03\n0.04\n0.05\n0.06\n0.07\nCCDW(r, \u00ac)\nCCDW(r = 15)\nCCDW(r = 25)\nCBDW(r = 15)\nCBDW(r = 25)\n128 192 256\nL\n3\u00a310\u00b05\n4\u00a310\u00b05\n5\u00a310\u00b05\n6\u00a310\u00b05\nCCDW(r, L)\nCCDW(r = 56)\nCCDW(r = 64)\nCBDW(r = 56)\nCBDW(r = 64)0.11\n0.12\n0.13\n0.14\n0.15\n0.16\n0.17\nCBDW(r, \u00ac)\n0.010\n0.011\n0.012\n0.013\nCBDW(r, L) <latexit sha1_base64=\"2RRwxLXlY8TROIoM98j2WcOjpro=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoMQL2FXgnoMevEY0TwgWcLspDcZMju7zMwKIeQTvHhQxKtf5M2/cZLsQRMLGoqqbrq7gkRwbVz328mtrW9sbuW3Czu7e/sHxcOjpo5TxbDBYhGrdkA1Ci6xYbgR2E4U0igQ2ApGtzO/9YRK81g+mnGCfkQHkoecUWOlhzI97xVLbsWdg6wSLyMlyFDvFb+6/ZilEUrDBNW647mJ8SdUGc4ETgvdVGNC2YgOsGOppBFqfzI/dUrOrNInYaxsSUPm6u+JCY20HkeB7YyoGeplbyb+53VSE177Ey6T1KBki0VhKoiJyexv0ucKmRFjSyhT3N5K2JAqyoxNp2BD8JZfXiXNi4p3WaneV0u1myyOPJzAKZTBgyuowR3UoQEMBvAMr/DmCOfFeXc+Fq05J5s5hj9wPn8Ai5mNUw==</latexit>\n( a )\n<latexit sha1_base64=\"KWh0RLJ0bw8em/x3PU2+HIlN2FQ=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoMQL2FXgnoMevEY0TwgWcLspDcZMju7zMwKIeQTvHhQxKtf5M2/cZLsQRMLGoqqbrq7gkRwbVz328mtrW9sbuW3Czu7e/sHxcOjpo5TxbDBYhGrdkA1Ci6xYbgR2E4U0igQ2ApGtzO/9YRK81g+mnGCfkQHkoecUWOlh3Jw3iuW3Io7B1klXkZKkKHeK351+zFLI5SGCap1x3MT40+oMpwJnBa6qcaEshEdYMdSSSPU/mR+6pScWaVPwljZkobM1d8TExppPY4C2xlRM9TL3kz8z+ukJrz2J1wmqUHJFovCVBATk9nfpM8VMiPGllCmuL2VsCFVlBmbTsGG4C2/vEqaFxXvslK9r5ZqN1kceTiBUyiDB1dQgzuoQwMYDOAZXuHNEc6L8+58LFpzTjZzDH/gfP4AjR6NVA==</latexit>\n( b )\nFIG. S4. (a) Each data point of the bulk-bulk correlation function for BDW and CDW orders shown in Fig.2(b) in the main\ntext is obtained by extrapolating to infinite MPS bond dimensions. The dotted and dashed lines are least-squares fittings with\nthe form C(r, \u03c7) = a(100/\u03c7)b + C(r, \u03c7\u2192 \u221e). (b) Each data of the boundary-bulk correlations displayed in Fig.2(c) in the\nmain text is obtained by extrapolating toL \u2192 \u221ewith the fitting form,C(r, L) = a/Lb + C(r, L\u2192 \u221e), whereL is the ladder\nlength. Numerical data are obtained from infinite-size DMRG calculations for (a) and finite-size DMRG calculations for (b)\nwith a sufficiently large bond dimension\u03c7 = 2048 to ensure the convergence of the results forL up to256.\n0 1 2 3 4 5\nk\n0\n1\n2\n3\n4\n5Ek(L)\u00b0E0(L) L= 16\nL= 32\nL= 48\nL= 64\nL= 80\nL= 96\n20 30 40 50 60 70 8090100\nL\n0.5\n0.6\n0.7\n0.8\n0.91.0\n2.0\ne(L) \u00a5E2(L)\u00b0E0(L)\ne(L)\u00aaaL\u00b0z\nz(L)= \u00b0d(lne(L))/d(lnL)\n0.00 0.01 0.02 0.03\n1/L\n0.950\n0.975\n1.000\nz(L)\n\ngood title\nFurthermore, we can see that\u03be right at the critical point\ndisplays a power law behavior with\u03c7 described by\u03be \u223c \u03c7\u03ba where \u03ba = 1.20(1) [refer to Fig. S2(b)], which is supported\nby the finite-entanglement scaling theory [141\u2013144]. To further extract the central charge of the underlying conformal\nfield theory, we also plotS as a function of\u03be at the estimated critical point as displayed in Fig. S2(d). A least-squares\nfitting according to the formula,S \u223c c\n6 log \u03be [145, 146], givesc = 1.003(4) . Finally, itisalsoimportanttoobtainthecriticalexponentsdescribingtheuniversalbehaviorsofthephasetransition. This task can be accomplished by performing finite-length scaling analyses. For infinite MPS simulations, the effective\ncorrelation length\u03be is usually seen as the finite length scale that enters the scaling relations. According to the scaling\ntheory, order parameters near the critical point should obey the following universal form [147]\nOBDW/CDW(V/t, \u03be) = \u03be\u2212\u2206BDW/CDWG[(V/t \u2212 (V/t)c)\u03be1/\u03bd] , (S6)\nwhere \u2206BDW(CDW) is the scaling dimension of the BDW (CDW) order parameter,\u03bd is the correlation length exponent\nand G is an unknown universal function. In particular, right at the critical point, it is expected that order parameters\nshould display power law behaviors,OBDW/CDW \u223c \u03be\u2212\u2206BDW/CDW, according to Eq. (S6). As shown in Fig. S3(a) and\n(b), thispowerlawbehaviorisobservedforbothorderparametersexactlyattheestimatedcriticalpoint (V/t)c = 7.992\nwith fitted exponents\u2206BDW = 0.289(2) and \u2206CDW = 0.284(2) . The identical scaling dimensions imply an emergent\nO(2) symmetry at the critical point, which is a hallmark feature of the deconfined criticality. After substituting the\nestimated values of the critical point and the scaling dimensions into Eq. (S6),\u03bd becomes the only parameter we need\n\n10\n7.950 7.975 8.000 8.025\nV /t\n0\n100\n200\n300\n400\n500\n600\u00aa\n\u00ac = 100\n\u00ac = 200\n\u00ac = 300\n\u00ac = 400\n\u00ac = 500\n\u00ac = 600\n100 200 300 400 500600\n\u00ac\n60\n100\n200\n400\n600\u00aa\nV /t=8 .005\nV /t=7 .995\nV /t=7 .992\nV /t=7 .985\nV /t=7 .975\nV /t=7 .965\n\u00aa \u00aa \u00ac1.20(1)\n7.950 7.975 8.000 8.025\nV /t\n1.3\n1.4\n1.5\n1.6\n1.7\nS\n\u00ac = 100\n\u00ac = 200\n\u00ac = 300\n\u00ac = 400\n\u00ac = 500\n\u00ac = 600\n60 100 200 400 600\n\u00aa\n1.4\n1.5\n1.6\n1.7\nS\nV /t=7 .992 S \u00aa 1.003(4)\n6 ln\u00aa\n<latexit sha1_base64=\"2RRwxLXlY8TROIoM98j2WcOjpro=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoMQL2FXgnoMevEY0TwgWcLspDcZMju7zMwKIeQTvHhQxKtf5M2/cZLsQRMLGoqqbrq7gkRwbVz328mtrW9sbuW3Czu7e/sHxcOjpo5TxbDBYhGrdkA1Ci6xYbgR2E4U0igQ2ApGtzO/9YRK81g+mnGCfkQHkoecUWOlhzI97xVLbsWdg6wSLyMlyFDvFb+6/ZilEUrDBNW647mJ8SdUGc4ETgvdVGNC2YgOsGOppBFqfzI/dUrOrNInYaxsSUPm6u+JCY20HkeB7YyoGeplbyb+53VSE177Ey6T1KBki0VhKoiJyexv0ucKmRFjSyhT3N5K2JAqyoxNp2BD8JZfXiXNi4p3WaneV0u1myyOPJzAKZTBgyuowR3UoQEMBvAMr/DmCOfFeXc+Fq05J5s5hj9wPn8Ai5mNUw==</latexit>\n( a )\n<latexit sha1_base64=\"KWh0RLJ0bw8em/x3PU2+HIlN2FQ=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoMQL2FXgnoMevEY0TwgWcLspDcZMju7zMwKIeQTvHhQxKtf5M2/cZLsQRMLGoqqbrq7gkRwbVz328mtrW9sbuW3Czu7e/sHxcOjpo5TxbDBYhGrdkA1Ci6xYbgR2E4U0igQ2ApGtzO/9YRK81g+mnGCfkQHkoecUWOlh3Jw3iuW3Io7B1klXkZKkKHeK351+zFLI5SGCap1x3MT40+oMpwJnBa6qcaEshEdYMdSSSPU/mR+6pScWaVPwljZkobM1d8TExppPY4C2xlRM9TL3kz8z+ukJrz2J1wmqUHJFovCVBATk9nfpM8VMiPGllCmuL2VsCFVlBmbTsGG4C2/vEqaFxXvslK9r5ZqN1kceTiBUyiDB1dQgzuoQwMYDOAZXuHNEc6L8+58LFpzTjZzDH/gfP4AjR6NVA==</latexit>\n( b )\n<latexit sha1_base64=\"oMYcx8nAFvX5nnYPeedyKOzsjl4=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoMQL2FXgnoMevEY0TwgWcLspDcZMju7zMwKIeQTvHhQxKtf5M2/cZLsQRMLGoqqbrq7gkRwbVz328mtrW9sbuW3Czu7e/sHxcOjpo5TxbDBYhGrdkA1Ci6xYbgR2E4U0igQ2ApGtzO/9YRK81g+mnGCfkQHkoecUWOlhzI77xVLbsWdg6wSLyMlyFDvFb+6/ZilEUrDBNW647mJ8SdUGc4ETgvdVGNC2YgOsGOppBFqfzI/dUrOrNInYaxsSUPm6u+JCY20HkeB7YyoGeplbyb+53VSE177Ey6T1KBki0VhKoiJyexv0ucKmRFjSyhT3N5K2JAqyoxNp2BD8JZfXiXNi4p3WaneV0u1myyOPJzAKZTBgyuowR3UoQEMBvAMr/ DmCOfFeXc+Fq05J5s5hj9wPn8AjqONVQ==</latexit>\n( c ) <latexit sha1_base64=\"H0+vPkOYIB9WILVirvWzNP/lO+0=\">AAAB6nicbVBNSwMxEJ3Ur1q/qh69BItQL2VXinosevFY0X5Au5RsNtuGZrNLkhXK0p/gxYMiXv1F3vw3pu0etPXBwOO9GWbm+Yng2jjONyqsrW9sbhW3Szu7e/sH5cOjto5TRVmLxiJWXZ9oJrhkLcONYN1EMRL5gnX88e3M7zwxpXksH80kYV5EhpKHnBJjpYdqcD4oV5yaMwdeJW5OKpCjOSh/9YOYphGThgqidc91EuNlRBlOBZuW+qlmCaFjMmQ9SyWJmPay+alTfGaVAIexsiUNnqu/JzISaT2JfNsZETPSy95M/M/rpSa89jIuk9QwSReLwlRgE+PZ3zjgilEjJpYQqri9FdMRUYQam07JhuAuv7xK2hc197JWv69XGjd5HEU4gVOoggtX0IA7aEILKAzhGV7hDQn0gt7Rx6K1gPKZY/gD9PkDkCiNVg==</latexit>\n( d )\nFIG. S2. (a) The effective correlation length\u03be of the MPS and (c) the bipartite entanglement entropyS as a function of the\ndriving parameterV/t with fixedQ/t = 10 near the critical point for bond dimensions\u03c7 from 100 to 600. (b) A log-log plot\nof \u03be versus \u03c7 for variousV/t near the critical point.\u03be displays a power-law dependence on\u03c7 at the estimated critical point\n(V/t)c = 7.992; the red dashed line,\u03be \u223c \u03c71.20(1), is a least-squares fitting. (d) The entanglement entropy from different\u03c7 as a\nfunction of\u03be at the critical point(V/t)c = 7.992 . A least-squares fitting according toS \u223c c/6 log\u03be estimates the central charge\nc = 1.003(4) . Numerical data are obtained from infinite-size DMRG calculations.", "metadata": {"type": "reasoning", "source": "2503.01198v1.pdf", "context": "theory, order parameters near the critical point should obey the following universal form [143]\nOBDW/CDW(V/t, \u03be) = \u03be\u2212\u2206BDW/CDWG[(V/t \u2212 (V/t)c)\u03be1/\u03bd] , (S6)\nwhere \u2206BDW(CDW) is the scaling dimension of the BDW (CDW) order parameter,\u03bd is the correlation length exponent\nand G is an unknown universal function. In particular, right at the critical point, it is expected that order parameters\nshould display power law behaviors,OBDW/CDW \u223c \u03be\u2212\u2206BDW/CDW, according to Eq. (S6). As shown in Fig. S3(a) and\n(b), t", "quality_score": 8.5}}
{"id": "test_39", "question": "What is a characteristic of an effective tree monomial T, as per De\ufb01nition B.2?", "golden_answers": ["It does not have any vertex of degree 1 on the path from the root of its typical divisor to its leftmost leaf."], "prediction": "An effective tree monomial T satisfies the following conditions: (i) There exists a typical divisor T\u2032 = \u02c6S in T such that on the path from the root of T\u2032 to the leftmost leaf l of T, there are no other typical divisors, and there are no vertices of positive degree on this path except possibly the root of T\u2032. (ii) For any leaf l\u2032 of T which lies on the left of l, there are no vertices of positive degree and no typical divisors on the path from the root of T to l\u2032.", "f1": 0.24761904761904763, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "arXiv:2503.01316v1  [math.RA]  3 Mar 2025\nS n+1 < \u00b7\u00b7\u00b7 . It is ready to see that this is a well-order. Under this order, the leading terms in the expansion of\n\u00af\u2202(mn), \u00af\u2202(Rn ) and \u00af\u2202(S n ) are the following tree monomials respectively:\nmn\u22121\nm2\nRn\u22121\nm2\nR1\nS n\u22121\nm2\nR1\n\nHOMOTOPY ROT A-BAXTER SYSTEMS 27\nLet S be a generator of degree \u2a7e1 in mRBS\u221e. Denote the leading monomial of \u00af\u2202S by \u02c6S and\nthe coe \ufb03cient of \u02c6S in \u00af\u2202 is written as lS. A tree monomial of the form \u02c6S is called typical, so all\ntypical tree monomials are of the form\nmn\u22121 \u25e61 m2 , (Rn\u22121 \u25e61 m2) \u25e61 R1 and ( S n\u22121 \u25e61 m2) \u25e61 R1 ,\nwhich are illustrated above. It is easily seen that the coe \ufb03cients lS are always \u00b11. De\ufb01nition B.2. A tree monomial T in mRBS\u221e is called e \ufb00ective if T satis\ufb01es the following\nconditions:\n(i) There exists a typical divisor T\u2032 = \u02c6Sin T such that on the path from the root of T\u2032 to the\nleftmost leaf l of T above the root of T\u2032, there are no other typical divisors, and there are\nno vertex of positive degree on this path except the root of T\u2032 possibly.\n(ii) For any leaf l\u2032 of T which lies on the left of l, there are no vertices of positive degree and\nno typical divisors on the path from the root of T to l\u2032.\nThe typical divisor T\u2032 is called the e \ufb00ective divisor of T and the leaf l is called the typical leaf of\nT.\nMorally, the e \ufb00ective divisor of a tree monomial T is the left-upper-most typical divisor of T.\nIt can be easily seen that for the e \ufb00ective divisor T\u2032 in T with e \ufb00ective leaf l, any vertex in T\u2032\ndoesn\u2019t belong to the path from root of T to any leaf l\u2032 located on the left of l.\nExample B.3. Consider three tree monomials as follows:\nl\u2032\n(T\u2032\n1 )\nl\u2032\u2032\n(T\u2032\u2032\n1 )\n\u00d7\n(T2 ) \u00d7\n(T3) For the three trees displayed above, each has two typical div isors. \u2022 T \u2032\n1 and T\u2032\u2032\n1 are e \ufb00ective and the divisors in the blue dashed circle are their e \ufb00ective divisor,\nl\u2032 and l\u2032\u2032 are respectively their e \ufb00ective leafs. \u2022 T2 is not e \ufb00ective, since the \ufb01rst leaf is incident to a vertex of degree 1 , say the root of\nT2, which violates Condition (ii) in De\ufb01nition B.2.\n\u2022 T3 is not e \ufb00ective since there is a vertex of degree 1 on the path from the r oot of the typical\ndivisor in the blue dashed circle to the leftmost leaf above i t, which violates Condition (i)\nin De\ufb01nition B.2. Now we are going to construct a homotopy map H :m RBS\u221e \u2192m RBS\u221e, i.e., a degree 1 map\nthat satis\ufb01es \u00af\u2202H+H\u00af\u2202 = Id in positive degrees. De\ufb01nition B.4.\n\n2503.01446v1\nA summary of these\n\n7\nvalues for the studied systems is provided in Table I in the\nSupplementary Material. Additionally, we calculated the\neffective local exponents, \u03c1eff and \u03bdeff , from the slopes\nof the data points shown in the four panels of Fig. 3. The\nresults are presented in the insets of the corresponding\npanels. In absolute terms, the differences between the aver-\nage tree contour distances, \u27e8L(leff)\u27e9 and \u27e8L(Nn)\u27e9, for the\nthree ring types are small. Nevertheless our data are\ncompatible with the expected crossover from local linear\nbehavior with \u27e8L(l)\u27e9 = l to \u27e8L(l)\u27e9 \u223cl\u03c1 with \u03c1 = 1/2 for\nideal trees, \u03c1 = 2/3 for self-avoiding trees, and \u03c1 = 5/9\nfor trees in the melt state. In contrast, there are marked differences between the\nmean square spatial distance between ring monomers,\n\u27e8R2(leff)\u27e9 and \u27e8R2(Nn)\u27e9, for the different ring types. For ideal trees, this quantity is given by [45] \u27e8R2(l)\u27e9 =\nlK\u27e8L(l)\u27e9, where the Kuhn lengthlK for the present model\nis simply given by the lattice constant. The fact that\nthe independently calculated data sets for \u27e8L(leff)\u27e9 and\n\u27e8R2(leff)\u27e9 look indistinguishable presents a simple and in-\ndependent check of the path analysis on the tree. As\nexpected, self-avoiding rings are more strongly swollen\nrelative to ideal rings than rings in a melt. Again, our\ndata are compatible with the expected crossover from\nlocal linear behavior with \u27e8R2(l)\u27e9 = l to \u27e8R2(l)\u27e9 \u223cl2\u03bd\nwith \u03bd = 1 /4 for ideal trees, \u03bd = 1 /2 for self-avoiding\ntrees, and \u03bd = 1/3 for trees in the melt state. Note, how-\never, the deviation of the effective exponents on small\nscales from the expected asymptotic values, which sug-\ngests the existence of corresponding deviations for effec-\ntive dynamic exponents. Importantly, for our present purposes, there are no no-\nticeable differences between the data acquired through\ndifferent dynamical schemes. Figure 3 thus validates\nour simulation methods and confirms that starting from\nan ensemble of equilibrated rings all ergodic dynamical\nschemes generate the same conformational statistics in-\ndependently of whether the tree connectivity is randomly\nquenched or annealed. B. Overview of the Emergent Dynamics\nFigure 4 presents an overview of the emergent dynam-\nics for three classes of double-folded rings \u2013 ideal rings\n(top row), isolated self-avoiding rings (middle row), and\nring polymers in melts (bottom row) \u2013 for which we have\ninvestigated the impact of the following local dynamics:\n1. the exclusive application of hairpin moves,\n2. a slithering dynamics around fixed trees as a result\nof the exclusive application of repton moves,\n3. a RiAO dynamics as a result of the combined ap-\nplication of the two monomer moves,\n4. a Brownian dynamics of trees with quenched con-\nnectivity (QTree) as a result of the exclusive appli-\ncation of tree node moves,\n5.\n\narXiv:2503.01316v1  [math.RA]  3 Mar 2025\nLet T be an e \ufb00ective tree monomial in mRBS\u221e and T\u2032 be its e \ufb00ective divisor.\nAssume that T\u2032 = \u02c6S, where Sis a generator of positive degree. Then de\ufb01ne\nH(T) = (\u22121)\u03c9 1\nlS\nmT\u2032,S(T),\n\n28 YUFEI QIN, KAI W ANG AND GUODONG ZHOU\nwhere mT\u2032,S(T) is the tree monomial obtained from T by replacing the e \ufb00ective divisor T\u2032 by S,\n\u03c9is the sum of degrees of all the vertices on the path from root o f T\u2032 to the root of T (excluding\nthe root vertex of T\u2032) and all the vertices located on the left of this path . Proposition B.5. The degree 1 map\nH : mRBS\u221e \u2192 mRBS\u221e is a homotopy map satisfying\n\u00af\u2202H+H\u00af\u2202 = Id in all positive degrees. Proof. W e divide this proof into two cases: whether T is an e \ufb00ective tree or not. If T is a tree monomial of positive degree that is not e \ufb00ective, then by the de\ufb01nition of H, we\nhave H(T) = 0. Thus, \u00af\u2202H(T) +H\u00af\u2202(T) = H\u00af\u2202(T). W e \ufb01rstly just need to check that H\u00af\u2202(T) = T.\nSince T has positive degree, there must exist at least one vertex of p ositive degree. Let\u2019s pick a\nspecial vertex S satisfying the following conditions:\n(i) on the path from S to the leftmost leaf l of T above S, there are no other vertices of\npositive degree;\n(ii) for any leaf l\u2032 of T located on the left of l, the vertices on the path from the root of T to\nl\u2032 are all of degree 0. It is evident that such a vertex always exists in T. Conceptually, this vertex is the \u201cleft-upper-\nmost\u201d vertex of positive degree. Denote by TS\u2192\u02c6S the tree monomial obtained from T by replacing\nthe vertex Swith \u02c6S. Then there will be a tree monomial ( \u22121)\u01eblSTS\u2192\u02c6S appearing in \u00af\u2202T, where \u01eb is\nthe sum of degrees of vertices located preceding Sin the planar order. Due to the special position\nof the vertex S, we have that the tree monomial ( \u22121)\u01eblSTS\u2192\u02c6S is an e \ufb00ective tree monomial. Actually, this term is the only e \ufb00ective tree monomial appearing in \u00af\u2202(T), i.e., there is no e \ufb00ective\ntree monomial in \u00af\u2202(T) \u2212(\u22121)\u01eblSTS\u2192\u02c6S. So we have\nH\u00af\u2202(T) = H((\u22121)\u01eblSTS\u2192\u02c6S\n) +H(\u00af\u2202T \u2212 (\u22121)\u01eblSTS\u2192\u02c6S\n)(29)\n= T.\nIf T is an e \ufb00ective tree monomial with positive degree, we write T as a compositions in the\nfollowing way:\n(\u00b7\u00b7\u00b7 (((((\u00b7\u00b7\u00b7 (X1 \u25e6i1 X2 ) \u25e6\u00b7\u00b7\u00b7 ) \u25e6ip\u22121 Xp ) \u25e6ip\n\u02c6S) \u25e6j1 Y1 ) \u25e6j2 Y2) \u00b7\u00b7\u00b7 ) \u25e6jq Yq ,\nwhere \u02c6S is the e \ufb00ective divisor of T and X1,..., Xp are generators of mRBS\u221e corresponding to\nthe vertices which live on the path from root of T and root of \u02c6S(except the root of \u02c6S) and on the\nleft of this path in the underlying tree of T. It is not di \ufb03cult to see the following identity holds\nfor e \ufb00ective divisors:\n\u00afH\u00af\u2202( \u02c6S) = \u02c6S\u2212 1\nlS\n\u00af\u2202(S).", "metadata": {"type": "factual", "source": "2503.01316v1.pdf", "context": "Example B.3. Consider three tree monomials as follows:\nl\u2032\n(T\u2032\n1 )\nl\u2032\u2032\n(T\u2032\u2032\n1 )\n\u00d7\n(T2 )\n\u00d7\n(T3)\nFor the three trees displayed above, each has two typical div isors.\n\u2022 T \u2032\n1 and T\u2032\u2032\n1 are e \ufb00ective and the divisors in the blue dashed circle are their e \ufb00ective divisor,\nl\u2032 and l\u2032\u2032 are respectively their e \ufb00ective leafs.\n\u2022 T2 is not e \ufb00ective, since the \ufb01rst leaf is incident to a vertex of degree 1 , say the root of\nT2, which violates Condition (ii) in De\ufb01nition B.2.\n\u2022 T3 is not e \ufb00ective since there", "quality_score": 8.5}}
{"id": "test_40", "question": "How does the OptMetaOpenFOAM framework handle complex CFD tasks?", "golden_answers": ["The framework automates complex CFD tasks via natural language inputs, allowing non-expert users to express their requirements in a simple and intuitive way."], "prediction": "The OptMetaOpenFOAM framework handles complex CFD tasks by automating them through natural language inputs, utilizing a large language model (LLM)-driven chain-of-thought (COT) methodology. It accurately interprets user requirements expressed in natural language and effectively invokes external tool libraries alongside MetaOpenFOAM to complete tasks such as sensitivity analyses and parameter optimizations. This approach empowers non-expert users to perform these tasks with improved efficiency and convenience.", "f1": 0.3132530120481928, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01273v1\n1 \n \n \nAbstract \nMerging natural language interfaces with \ncomputational fluid dynamics (CFD) \nworkflows presents transformative \nopportunities for both industry and research. In this study, we introduce \nOptMetaOpenFOAM\u2014a novel framework \nthat bridges MetaOpenFOAM with \nexternal analysis and optimization tool \nlibraries through a large language model \n(LLM)-driven chain -of-thought (COT) \nmethodology. By automating complex \nCFD tasks via natural language inputs, the \nframework empowers non-expert users to \nperform sensitivity analyses and parameter \noptimizations with markedly improved \nefficiency. The test dataset comprises 11 \ndistinct CFD analysis or optimization tasks, \nincluding a baseline simulation task derived \nfrom an OpenFOAM tutorial covering fluid \ndynamics, combustion, and heat transfer. Results confirm that OptMetaOpenFOAM \ncan accurately interpret user requirements \nexpressed in natural language and \neffectively invoke external tool libraries \nalongside MetaOpenFOAM to complete \nthe tasks. Furthermore, validation on a non-\nOpenFOAM tutorial case \u2014namely, a \nhydrogen combustion chamber \u2014\ndemonstrates that a mere 200 -character \nnatural language input can trigger a \nsequence of simulation, postprocessing, \nanalysis, and optimization tasks spanning \nover 2,000 lines of code. These findings \nunderscore the transformative potential of \nLLM-driven COT methodologies in linking \nexternal tool for a dvanced analysis and \noptimization, positioning \nOptMetaOpenFOAM as an effective tool \nthat streamlines CFD simulations and \nenhances their convenience and efficiency \nfor both industrial and research applications. Code is available at  \nhttps://github.com/Terry-\ncyx/MetaOpenFOAM \n1 Introduction \nIn recent years, with the development of Large \nLanguage Models (LLMs) [1-8], many fields have \nundergone significant transformations, with \ncomputer simulation software for optimization and \nanalysis emerging as one of the most impacted \ndomains. Traditionally, interactions with analysis \nand optimization software have been facilitated \neither through coding  [9] or via graphical user \ninterfaces (GUIs) [10, 11] . However, with \nadvancements in natural language processing, \nintegrating natural language into simulation-based \nanalysis and optimization processes has emerged as \na promising new approach [12, 13]. Computational Fluid Dynamics (CFD) is a \ncomputational technique that employs numerical \nmethods and physical models to solve fluid flow, \nheat transfer, chemical reactions, and other related \nprocesses [14]. It is widely applied in various fields, \nincluding aerospace, energy [15-18], and biology. A complete CFD workflow typically includes \nmodules such as Computer-aided Design (CAD) \ngeometry generation, mesh generation, model and \nnumerical parameter selection, solver execution, \nand post-processing. For beginners or researchers \nfrom other domains, any of these modules can be \nhighly challenging. To lower the entry barriers for \neach sta ge in the workflow, frameworks using \nnatural language as input have been proposed for \ntasks like CAD geometry generation [19], CFD \nsimulation execution [12], and CFD post -\nprocessing [13]. Beyond these basic processes of CFD , \nsubsequent analyses based on CFD simulations are \nalso critical functionalities of industrial simulation \nsoftware. Common analytical methods include \nProper Orthogonal Decomposition (POD) [20], \nDynamic Mode Decomposition (DMD) [21], and \nChemical Explosion Mode Analysis (CEMA) [22], \nwhich focus on analyzing individual CFD \nsimulation results.\n\n2503.01273v1\nAnd for analyses such as \n \nOptMetaOpenFOAM: Large Language Model Driven Chain of Thought for  \nSensitivity Analysis and Parameter Optimization based on CFD \n \nYuxuan Chena, Long Zhanga, Xu Zhua, Hua Zhoua, Zhuyin Rena* \na Institute for Aero Engine, Tsinghua University, Beijing 100084, China \n* Corresponding author: zhuyinren@tsinghua.edu.cn\n\n2 \n \n \nparameter sensitivity analysis, parameter \ncalibration, and para meter optimization, \nperforming multiple CFD simulations is essential. The former can naturally be seen as a specific type \nof CFD post -processing task, while the latter \ndemands the creation of new frameworks capable \nof performing multi -simulation analysis u sing \nnatural language inputs. This would further reduce \nthe usability threshold for industrial CFD software. In recent years, the rapid development of large \nlanguage models (LLMs), initially designed to \ntackle simple, quick -thinking tasks, has been \nexemplified by models such as GPT -4o [2] and \nDeepSeek v3 [6]. Later, models like GPT-o1 [4] \nand DeepSeek R1 [7] emerged to tackle more \ncomplex, slow -thinking problems. The former \nreflects pretrained scaling laws [1], while the latter \ndemonstrates post-training scaling laws  [8]. For \nCFD problems with natural language inputs, due to \ntheir complexity, high level of expertise, and \nreliance on external tools, using LLMs with general \nChain of Thought (COT) [23-26] reasoning models \nmay not be sufficient to accomplish the \ncorresponding CFD tasks. Moreover, since CFD \ntasks typically follow a fixed workflow, it becomes \nfeasible to develop a dedicated COT framework \ntailored specifically to CFD problems. MetaOpenFOAM 1.0 [12] and 2.0 [13] have \ndeveloped distinct COT structures to complete \nCFD simulation and postprocessing tasks, \nrespectively. The proposed scaling laws \ndemonstrated that increasing the number of COT \nsteps improves the accuracy of the framework  \nwhile increasing token usage, aligning with post -\ntraining scaling laws for LLM. Similarly, for \nanalysis and optimization tasks that require \nmultiple CFD simulations and postprocessing steps, \nspecialized COT structures are necessary to \nfacilitate the use o f external tools (e.g., active \nsubspace analysis [27], parameter optimization \n[28], etc.). The structure of the paper is organized as \nfollows: First, we introduce the basic framework of \nOptMetaOpenFOAM and the theoretical \nknowledge of the external tool libraries. Then, we \ndescribe the LLM settings used in the framework. Next, we present the inpu t, thought process, and \noutput results for specific cases in \nOptMetaOpenFOAM. Finally, we conclude with a \nsummary. 2 Methodology  \n2.1 MetaOpenFOAM 2.0 Framework \nFigure 1 illustrates how OptMetaOpenFOAM \nleverages a chain-of-thought mechanism to process \nsensitivity analysis and parameter optimization \ntasks based on CFD, using natural language inputs. First, OptMetaOpenFOAM establishes the \ncorresponding CFD simulati on, CFD \npostprocessing, CFD sensitivity analysis, and CFD \nparameter optimization tasks according to user \nrequirements. It is important to note that the \nparameter optimization task is typically conducted \nbased on the outcomes of the sensitivity analysis. Figure 1:  Framework of OptMetaOpenFOAM. Where QDCOT means chain of thought (COT) with \nquestion decomposition, Iterative COT (ICOT) means COT with iterative verification and \nrefinement, and RAG means retrieval-augmented generation. 3 \n \n \nNext, the framework extracts the sampling \nlower and upper range from the natural language \ninput to perform sampling.\n\n2503.01273v1\nThe \u201csimilarity\u201d approach was \nemployed to identify and match related chunks of \ndata. The simplest stacking approach was used, \ncombining retrieved documents with user input \nmessages. Additional information can be found in \nthe code repository: https://github.com/Terry-\ncyx/MetaOpenFOAM. In the external analysis and \noptimization tool library, the univariate \noptimization method, the L-BFGS-B optimization\n\n5 \n \n \nalgorithm, is invoked through the bounded method \nin scipy.optimize. For multivariable analysis and \noptimization, the active subspace method is used  \n[27]. 4 Results \nThe evaluation metrics used previously were \nbased on the CFD framework with natural \nlanguage inputs, with a primary focus on the user \nrequirements for Executability (ranging from 0 to \n7, corresponding to failure to flawless), Cost \n(including token usage, number of iterations, \nrunning time, etc.), and Pass@k [34, 35]. These \nmetrics remain significant in OptMetaOpenFOAM, \nbut due to the integration of fixed interfaces after \ncompleting the CFD simulation and postprocessing \ntasks, the Executability, Pass@k, and number of \niterations remain consistent with the previous \nstatistics in MetaOpenFOAM 2.0 [13]. Regarding \nCost, token usage slightly increases due to the \naddition of two new modules, while the running \ntime increases linearly with the addition of CFD \nsimulation tasks. Therefore, in addition to these \nthree metrics, the evaluation of \nOptMetaOpenFOAM increasingly focuses on the \nresult presentation. In this section, we will analyze five cases: \nPitzDaily, CounterFlowFlame, BuoyancyCavity, \nHIT, and Hydrogen Combustion Chamber. Among \nthese, the first four cases are OpenFOAM tutorials, \nwhile the latter is not. All the basic cases have been \nincorporated in to the database required for the \nRAG technique. All the figures presented in this \nsection were generated using OptMetaOpenFOAM \nbased on user prompts. It is important to note that \nthe prompt for textual response is provided in \nAppendix A, the full textual analysis provided by \nOptMetaOpenFOAM is included in Appendix B \nand the thought process provided by \nOptMetaOpenFOAM is included in Appendix C. \n4.1 PitzDaily \nThis case is an incompressible flow, simulated \nusing the RANS method. The following prompt is \nused to perform simulation for this case. CFD simulation task: Do a RANS simulation \nof incompressible PitzDaily flow. CFD postprocessing task: Extract max yplus at \nlatest time through post-processing \nInvestigating the relationship between inlet \nvelocity and y+ is one of the common CFD \nsensitivity analysis tasks. A similar analysis can be \nperformed for the relationship between inlet \nvelocity and the Courant number. The following \nprompt is used to study this case. CFD analysis tasks: \u2460 Analyze the effect of \nthe inlet flow velocity on max yplus . \u2461 Analyze \nthe effect of the inlet flow velocity and inlet \nturbulent kinetic energy on max yplus. Figure 2: Response surface of the inlet flow \nvelocity versus the max yPlus in PitzDaily. (a) \n \n(b) \nFigure 3:   Effect of inlet flow velocity and inlet \nturbulent kinetic energy on max y+ in PitzDaily \ncase. (a) response surface and (b) components of \nactive direction (\ud835\udc98\u0302). 6 \n \n \nCFD optimization task: Determine the optimal \ninlet flow velocity and inlet turbulent kinetic \nenergy at which the max yplus should be as close \nto 25 as possible.", "metadata": {"type": "reasoning", "source": "2503.01273v1.pdf", "context": "1 \n \n \nAbstract \nMerging natural language interfaces with \ncomputational fluid dynamics (CFD) \nworkflows presents transformative \nopportunities for both industry and research. \nIn this study, we introduce \nOptMetaOpenFOAM\u2014a novel framework \nthat bridges MetaOpenFOAM with \nexternal analysis and optimization tool \nlibraries through a large language model \n(LLM)-driven chain -of-thought (COT) \nmethodology. By automating complex \nCFD tasks via natural language inputs, the \nframework empowers non-exp", "quality_score": 8.5}}
{"id": "test_41", "question": "What is the primary purpose of the scoring function g in the given algorithm?", "golden_answers": ["The primary purpose of the scoring function g is to evaluate the quality of the output y generated by the task-solving LLM fT for a given input x."], "prediction": "The primary purpose of the scoring function g in the given algorithm is to assign higher scores to better-aligned image-text pairs (I, T) through pairwise preference learning.", "f1": 0.3913043478260869, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01333v1\nIt eliminates the\nneed for an additional value function like in PPO, and instead uses the average reward value of multiple sampled outputs\nas its baseline for the same input. More specifically, for each questionq, GRPO extracts a set of outputs{o1, o2, . . . , oG}\nfrom the old strategy \u03c0\u03b8old, and then optimizes the policy model by maximizing the following objectives. JGRPO (\u03b8) = E\n\u0002\nq \u223c P (Q) , {oi}G\ni=1 \u223c \u03c0\u03b8old\n\u0003\n1\nG\nPn\ni=1\n\u0010\nmin( \u03c0\u03b8(oi|q)\n\u03c0\u03b8old (oi|q) Ai, clip\n\u0010\n\u03c0\u03b8(oi|q)\n\u03c0\u03b8old (oi|q) , 1 \u2212 \u03f5, 1 +\u03f5\n\u0011\nAi) \u2212 \u03b2DKL\n\u0000\n\u03c0\u03b8\n\r\r\u03c0ref\n\u0001\u0011 (16) DKL\n\u0000\n\u03c0\u03b8\n\r\r\u03c0ref\n\u0001\n= \u03c0\u03b8ref (oi|q)\n\u03c0\u03b8(oi|q) \u2212 log \u03c0\u03b8ref (oi|q)\n\u03c0\u03b8(oi|q) \u2212 1 (17)\nwhere \u03f5 and \u03b2 are hyper-parameters, and Ai is the advantage, computed using a group of rewards r1, r2, . . . , rG\ncorresponding to the outputs within each group:\nAi = ri \u2212 mean({r1, r2, . . . , rG}) std({r1, r2, . . . , rG}) (18)\nIt can be seen that compared with the SCST algorithm, the GRPO algorithm limits the amplitude of the policy update\nand adds KL divergence as a constraint, which greatly enhances the stability of the model. In addition, GRPO uses\nmultiple sampling results, which also improves the diversity of the generated results. Therefore, we apply the GRPO\nalgorithm to the image captioning task. For the input image I, we also sample and generate multiple answers, and use\nCIDEr as its reward value, and then optimize the model according to Formula 16. 4\n\n3 Experiments\n3.1 Dataset and Evaluation Metrics\nWe use MSCOCO2014 as our experiment dataset. MSCOCO2014 contains a rich variety of images and their associated\ncaptions. It contains 123,287 images, of which 82,783 images are classified into the training set and 40,504 are classified\ninto the validation set. There are 5 reference captions for each image, which cover a wide range of scenarios and topics,\nincluding characters, animals, natural landscapes, indoor environments, etc. In this paper, we follow the \u201cKarpathy\u201d\nsplit to redivide the MSCOCO, where 113287 images for training, 5000 images for validation and 5000 images for\nevaluation. In order to evaluate the captions quality generated by the model, we use five common metrics, including BLEU[11],\nMETEOR[12], ROUGE-L[13], CIDEr[5] and SPICE[14]. The following are the calculation formulas for these metrics. BLEU = BP \u00b7 exp\n NX\nn=1\nwn log pn\n!\n(19)\nMETEOR = Fmean \u00b7 (1 \u2212 penalty) (20)\nROUGE-N =\nP\nngram\u2208ref min(countgen(ngram), countref(ngram))P\nngram\u2208ref countref(ngram) (21)\nCIDEr = 1\nm\nmX\ni=1\nPn\nj=1 TF-IDFi(gj) \u00b7\n\n2503.00743v1\nFormally, we define a scoring function f\u03b8 : T \u00d7 I \u2192\nR, parameterized by \u03b8, where T and I denote the text\nand image spaces, respectively. Given an image-text pair\n(I, T) \u2208 I \u00d7 T, which may consist of either a simple cap-\ntion or a multi-turn conversation associated with the image,\nthe model outputs a scalar quality score s = f\u03b8(I, T). The\nscoring function is trained to assign higher scores to better-\naligned image-text pairs (I, T) through pairwise prefer-\nence learning. For each image I, we collect pairs of text\n(T+, T\u2212) where T+ is preferred over T\u2212. This preference\ndataset is formally defined as D = (Ii, T+\ni , T\u2212\ni )\n|D|\ni=1. The\npairwise preferences are modeled using the Bradley-Terry\nmodel [2], which defines the probability of T+ being pre-\nferred over T\u2212 given image I as:\np(T+ \u227b T\u2212|I) = exp(f\u03b8(I, T+))\nexp(f\u03b8(I, T+)) + exp(f\u03b8(I, T\u2212)),\n(1)\nwhere \u227b denotes the preference relation. The model param-\neters \u03b8 are optimized by minimizing the empirical negative\nlog-likelihood loss [25, 37]:\nL(\u03b8) =\u2212E(I,T +,T\u2212)\u223cD log(\u03c3(f\u03b8(I, T+) \u2212 f\u03b8(I, T\u2212))),\n(2)\nwhere \u03c3(\u00b7) denotes the sigmoid function. Given the absence of RS specific vision-language pref-\nerence datasets, we start by establishing a data collection\npipeline for acquiring both image-caption and vision in-\nstruction preference pairs. Subsequently, we detail the\nconstruction of our scoring function f\u03b8 by leveraging pre-\ntrained VLMs and employing a progressive training strat-\negy. 2.1. Preference Data Construction\n2.1.1. Image-Caption Preference Dataset\nFollowing established practices in VLM training [20, 24,\n27, 38], we start with training ScoreRS to judge high-\nquality image-caption alignments. Since RS images exhibit\n2\n\nDeduplication\nGeneration\nJudging\nImage-Caption Preference Dataset\nRemote Sensing Images \nQuestions \nDeduplication\nClose-ended\nOpen-ended\nFilterAnswer \nRef. Answer \nHuman\nAnnotation Question \n...... Rephrase\nVision Instruction Preference Dataset\nScoreRS \nTraining\nVision-Language Dataset\nScoring & RankingVLM Training\nBoN Selector\nAction\nReward\nReinforcement Training\nTraining and Downstream Application\nFigure 2. Our data pipeline for generating pairwise preference datasets and the training and downstream application of our ScoreRS model. Ii \u2208 Irepresents a RS image, and Ti \u2208 Trepresents an image caption, question, or conversation associated with the image\nvariations across geographical locations [24, 39], we lever-\nage the LHRS-Align dataset [24] as our image source. This\ndataset comprises 1.15M orthorectified RS images from\nmajor global urban areas, enabling ScoreRS to learn from\ndiverse geographical contexts worldwide. Deduplication We implement a rigorous image dedupli-\ncation process to further ensure image quality and repre-\nsentativeness: (1) Feature extraction using the SSCD copy\ndetection model [10, 28] to compute image embeddings. (2) Similarity computation through cosine distance compu-\ntation between image embeddings, with a carefully tuned\nthreshold of 0.65 (empirically determined through experi-\nments across the range 0.6-0.9). (3) Duplicate grouping via\nconnected-components algorithm, preserving one image-\ntext pair per component. Finally, this deduplication pipeline\nyields 76K distinctive representative RS images. Pairwise Preference Generation Our caption pairwise\npreference generation process employs three VLMs: the\nRS-specific LHRS-Bot-Nova [18] and two general-purpose\nmodels, Qwen2VL-7B [38] and InternVL-2.5-8B [5].\n\n\uf020\nAUC represents the area under the ROC curve. As illustrated in  Table II, the CNN -LSTM method \nachieved the lowest F1 score. This is because this method uses \na CNN to extract relationships between modalities in a manner \nsimilar to image processing, which does not consider complex \nintermodal associations and fails to handle graph data with \nintricate internode relationships. Therefore, it produced the \nworst performance among the compared methods. In addition, \nas this method uses LSTM for temporal feature extraction, it \nsuffers from problems such as many parameters and high \ncomputational complexity. Therefore, it also performed the \nworst in terms of the Par, FLOPs, and time metrics compared to \nthe other methods. The MTAD-GAT method emphasizes anomaly detection \nat the individual node level while disregarding the spatial \ncorrelation features among multiple nodes. This method \nnecessitates the construction of multiple models to train and \nlearn the features of each node, reducing training efficiency. Additionally, since MTAD -GAT does not account for \ninternode associations, it does not achieve optimal results. In \naddition, since this method uses a GRU for temporal feature \nextraction, which has fewer parameters than does LSTM, it \nsignificantly outperformed the CNN-LSTM method in terms of \nthe Par, FLOPs, and time metrics. 2  IEEE SENSORS JOURNAL, VOL. XX, NO. XX, MONTH X, XXXX  \n \nTABLE \u2161 \nComparative Experimental Results \n \nConversely, both GAT-GRU and GLSL demonstrated \nsuperior performance in extracting data features from temporal, \nmodality, and spatial dimensions using different approaches. GAT-GRU first extracts temporal and modality features from \neach node and then concatenates all nodes to learn spatial \nfeatures. GLSL decomposes data into multiple graphs by \nmodality, extracts temporal and spatial features first, and then \nconcatenates them to learn intermodal features. GLSL shows a \ndistinct advantage in scenarios involving large -scale data , as \nGAT-GRU requires a feature extractor for each node. As \nshown in Table 2, although the GAT -GRU method achieved \nsignificant improvements in  F1 score s over the previous two \nmethods, it suffer ed from large parameter counts, high \ncomputational complexity, and long inference times. This is \nbecause GAT -GRU designs independent GAT and GRU \nnetworks for each node to extract information, resulting in very \nhigh parameter counts and computational complexity levels. As \na result,  GAT-GRU had the longest inference time of all the \nmethods compared. The GLSL method divides WSN data into \nmultiple graph datasets according to their modalities and uses \nGAT and GRU networks to extract information. This approach \nsignificantly reduces the number of parameters and lowers the \ncomputational complexity  levels. However, GLSL still faces \nchallenges such as high computational complexity and long \ninference times. The proposed model outperformed the baseline methods \nin terms of precision, recall, and F1 score. It addresses the \nlimitations identified in the above methods by incorporating \ntime series decomposition, frequency domain feature extraction, \nand dynamic spatial modeling. The ablation study will \ndemonstrate the impact of these factors on the model's \nperformance and effectiveness. In addition, the proposed model \nuses an MLP and attention mechanisms to extract temporal \nfeatures.", "metadata": {"type": "factual", "source": "2503.01163v1.pdf", "context": "set Ddev consisting of input and correct output pairs (x, y), scoring function g, task-solving LLM fT\n1: Evaluation of initial prompts: S0 \u2190\nn\nsi = 1\n|Ddev|\nP\n(x,y)\u2208Ddev g (y, fT (pi, x)) :pi \u2208 P0\no\n2: for t = 1to T do\n3: for i = 1to N do\n4: Sampling parentsby roulette wheel: pr1, pr2 \u2208 Pt\u22121\n5: Crossover and Mutation: p\u2032\ni \u2190 fD(mga, (pr1, pr2))\n6: \u25b7 fD: prompt-designing LLM\n7: \u25b7 mga: Meta-prompt for GA-based crossover and mutation\n8: OPTS: Generate p\u2032\u2032\ni from p\u2032\ni by incorporating prompt design ", "quality_score": 8.5}}
{"id": "test_42", "question": "What is different about this model compared to traditional SSL methods?", "golden_answers": ["This model is tailored to a specific domain or machine setup by incorporating a predictive module, unlike traditional SSL methods."], "prediction": "This model, specifically BYOL, eliminates the need for negative samples and focuses solely on optimizing the model\u2019s feature representation through self-supervised objectives, simplifying training and improving robustness, which differs from traditional SSL methods that typically rely on both positive and negative sample pairs.", "f1": 0.16949152542372883, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01089v1\nFL has \nalso been used for cross -area travel time estimation, where \nlocalized models are trained in different regions and combined \nthrough FL to preserve privacy across geographic boundaries \n[205]. Additionally, FL has been applied to destination \nprediction tasks, providing precise location services without \nexposing sensitive user data [97]. The framework improved \nlocalization in areas with poor GPS signals by using \nunmanned aerial vehicles (UAVs) as aerial anchors [206]. FL \ntechniques have also been used to aggregate models from edge \ndevices, optimizing localized path predictions and reducing \nlocalization errors [207]. As IoV services expand, the rise in connected vehicles, \ndevices, and infrastructure increases data transmission, posing \nchallenges in communication efficiency, energy use, and \nprivacy. FL addresses these issues by selecting clients and \nservers efficiently during training [208], [209] , which \nsignificantly improved resource management and system \nresponsiveness [210], [211] . By training models locally and \naggregating only learned parameters, FL reduces large -scale \ndata transmission in resource -limited vehicular networks. Author in [212] proposed a CNN-based FL framework for 6G \nIoV environments aiming to enhance model quality through \nhierarchical aggregation at edge and cloud levels . The \napproach considered factors such as  RSU proximity and \nvehicle density . In [86], remote sensing image analysis \nfocused on vehicle target recognition, leveraging data from \ndiverse environments. FL was utilized to overcome the\n\n25 \n \n \nlimitations of single -node data processing without \ncompromising the privacy of sensitive geospatial information. Furthermore, techniques such as EVT and Lyapunov \noptimization were employed to optimize FL frameworks, \nenabling better handling of anomalous events and dynamic \npower allocation [213]. 2) Blockchain-based PPML: There are hybrid frameworks \ncombining blockchain , FL, and DP to enhance data security \nand resilience in VCPS  [194]. Study in [214] proposed \nauthentication scheme between vehicles and RSUs utilizing \nblockchain. Using on -chain hashing, off -chain integrity \nschemes, cryptographic algorithms, and certificate \nauthentication, the system ensured anonymous service \nrequests, two -way authentication, and privacy preservation. Dynamic pricing in the IoV ecosystem requires real -time data \nhandling with transparency and fairness. A hybrid approach in \n[215] integrates blockchain for secure transactions between \nvehicle owners and regulatory bodies  and DL for traffic \nprediction, ensuring data reliability and payment transparency . To further optimize resources and transactions , a privacy -\npreserving energy trading scheme in [216] uses blockchain \nand zero-knowledge proofs, ensuring confidentiality in energy \ntransaction between EVs and the power grid . Decentralized \nidentifiers anonymized participants, while smart contracts \nenforced fair pricing without intermediaries. Incorporating software-defined networking (SDN) and \nblockchain into IoV applications enhances privacy and \nsecurity in distributed environments. Authors in [217] \nproposed a 5G -enabled fog computing paradigm where RSUs \nact as SDN controllers, managing blockchain operations and \nsecure channel selection. This decentralized approach reduces \nreliance on central servers and implements reputation -scoring \nmechanisms for security. Similarly, [218] presented dual-\nlayered SDN-controlled vehicle edge computing (VEC) \nframework integrating blockchain for secure network topology \nsharing. By using an enhanced PBFT algorithm, it improve d \nsystem throughput, reduced latency, and ensured data integrity \nin SDN operations.\n\n2503.01089v1\nFL\u2019s iterative model update mechanism introduces \ncommunication inefficiencies, particularly in large -scale \ndeployments with non -IID data distributions  [239]. Non -IID \ndata skews local client updates, degrading global model \nconvergence and fairness. Moreover, FL gradients, though \ndesigned to protect raw data, remain susceptible to inference \nattacks such as membership inference and model inversion  \n[240], [241] . Recent studies show these attacks require \nminimal assumptions, succeeding even in black -box settings \nwhere adversaries only access model APIs [242]. Poisoning attacks further threaten architectural PPML. Clean-label poisoning subtly alters training data without \nmodifying labels, while dirty -label poisoning injects \nmislabeled samples. Model poisoning  can achieve high attack \nsuccess rates even with minimal poisoned data  [243]. Byzantine attacks, such as uploading malicious gradients, \nexploit FL\u2019s aggregation protocols. Defensive mechanisms \nlike Krum  [244] and Trimmed Mean [245] partially mitigate \nthese risks but struggle with scalability and computational \ncosts. System heterogeneity, including variable client \nhardware and network conditions, further complicates uniform \nprivacy integration. To address these challenges, hybrid frameworks combining \nFL with blockchain could enhance trust and auditability. Lightweight consensus protocols ( like Proof-of-Authority) \nmay reduce blockchain latency, while gradient compression \n(sparsification, quantization) and adaptive client selection \nalgorithms can mitigate FL\u2019s communication overhead  [246]. Trusted execution environments (TEEs) like Intel SGX [247] \ncould secure aggregation processes, and Byzantine -resilient \ntechniques (such as gradient clipping) may neutralize poisoned \nupdates [92]. Tokenized incentive systems, embedded via \nblockchain smart contracts, could incentivize honest \nparticipation. Future research must also refine privacy -utility \ntrade-offs when integrating DP or SMPC  into FL workflows. For example, DP noise injection during gradient aggregation \nreduces privacy leakage but degrades model accuracy, \nnecessitating adaptive budget allocation strategies tailored to \nnon-IID settings. 2) Data Processing-based PPML Approaches: Data \nprocessing techniques, including HE and SMPC, enable \ncomputation on encrypted or partitioned data. SMPC protocols \nlike garbled circuits and secret sharing distribute computations \nacross parties without revealing private inputs. However, these \nmethods incur significant overheads. Garbled circuits encode \nBoolean logic operations via permuted truth tables, requiring \nmulti-round peer-to-peer communication and quadratic scaling \nwith model complexity. Pairwise masking -based secure \naggregation, common in SMPC, further strains scalability for \nDNNs [18]. HE allows arithmetic operations on ciphertexts \nbut struggles with non -linear functions ( like ReLU) due to \npolynomial approximations  [17]. Moreover, HE\u2019s reliance on \nlattice-based cryptography introduces latency from ciphertext \nexpansion, especially in DNN inference [17]. A critical challenge lies in balancing encoding precision and \ncomputational efficiency. Most HE schemes ( like CKKS) \nencode floating -point numbers into ciphertexts, but lower \nprecision accelerates computation at the cost of accuracy. For \ninstance, reducing mantissa bits in CKKS encoding speeds up \nhomomorphic convolutions but introduces rounding errors that \ndegrade p erformance [248]. Similarly, SMPC protocols \nrequire custom circuit designs for each task, limiting \nflexibility. Recent work on hybrid HE -SMPC frameworks \u2014\nwhere linear layers are computed under HE and non -linear \n5.\n\n2503.00711v1\nTo this end, we selected three representative SSL methods\n(i.e., SimCLR, BYOL, and MAE) as pre-training strategies. SimCLR, which leverages positive and negative sample pairs,\nexcels in extracting meaningful and fine-grained features\nfrom high-dimensional data in an unsupervised manner. In\ncontrast, BYOL eliminates the need for negative samples,\nfocusing solely on optimizing the model\u2019s feature represen-\ntation through self-supervised objectives, thereby simplifying\ntraining and improving robustness. Meanwhile, MAE, as a\nmasking-based autoencoder technique, trains the model by\nrandomly masking parts of the input and requiring it to\nreconstruct the original data. This encourages the model to\ncapture both the local and global structures of the data. III. M ATERIALS AND METHODS\nA. Data preparation\n1) Dataset description: Table 1 illustrates the data details\nin the previous ECG foundation model studies. Building upon\nthis foundation,this study integrates multiple publicly available\n12-lead ECG datasets to form a comprehensive benchmark\ndataset to support cardiovascular disease automatic diagnosis\nresearch. Below are the detailed descriptions of the datasets\nused:\nMIMIC-IV-ECG (Gow et al. 2023) : The MIMIC-IV\ndataset, sourced from the MIMIC-IV clinical database, con-\n\nAUTHOR et al.: TITLE 3\nFig. 1. The key dataset statistics of previous ECG Foundation Models. TABLE I\nTHE DATA DETAILS IN THE PREVIOUS ECG FOUNDATION MODEL STUDIES\n#Participants #ECG recordings #Centers for training data #Centers for testing data #ECG lead #Classes\nApple Heart and\nMovement Study\n(Abbaspourazad\net al. 2023)\n106,643 3,743,679 1 1 1 2\nAnyECG (Wang\net al. 2024)\n53,563 53,101 6 6 12 5\nECG-FM (McK-\neen et al. 2024)\n372,851 1,560,494 7 7 12 13\nECG-Chat (Zhao\net al. 2024)\n161,352 800,035 1 2 12 16\nECG Semantic\nIntegrator (Yu\net al. 2024)\n161,352 800,035 3 2 12 5\nMERL (Flet-\nBerliac et al. 2019)\n161,352 800,035 1 3 12 5\nECGFounder (Li\net al. 2024)\n1,818,247 10,771,552 1 3 12 150\nOurs 483,837 1,233,337 8 6 12 24\ntains approximately 800,000 ECG records from nearly 160,000\npatients. All records are 12-lead, sampled at 500Hz, with a\nduration of 10 seconds, covering the period from 2008 to\n2019. The MIMIC-IV-ECG dataset is strongly correlated with\nother clinical database information (such as demographics,\ndiagnoses, medications, and lab results) and can be used\nfor studying cardiovascular disease diagnosis in emergency\ndepartments, wards, and intensive care units (ICU), such as\nmyocardial ischemia, heart attacks, and arrhythmias. CODE-15 Ribeiro et al. 2021: The CODE-15 dataset is\na stratified subset of the CODE dataset, containing 345,779\n12-lead ECG records from 233,770 patients, spanning from\n2010 to 2016. It was collected by the Telehealth Network of\nMinas Gerais (TNMG) in Brazil and is widely used in ECG\nautomatic diagnosis research. For example, related studies\nhave used deep neural networks for automatic ECG diagnosis\nand cardiovascular event risk prediction (such as estimating\n\u201dECG age\u201d to assess mortality). The scale and annotation\nquality of CODE-15 provide a solid foundation for ECG AI\nalgorithms. PhysioNet 2020 (Perez Alday et al.", "metadata": {"type": "reasoning", "source": "2503.01411v2.pdf", "context": "and reliability of the machine parameters and whether these\nparameters are truly indicative of the underlying process the\nmodel aims to capture. Unlike traditional SSL methods (e.g.,\ncontrastive learning or I-JEPA), which aim to learn general-\npurpose representations, this model is tailored to a specific\ndomain or machine setup by incorporating a predictive mod-\nule. The incorporation of specific actions (control parameters)", "quality_score": 8.5}}
{"id": "test_43", "question": "How do different representatives of the same coset in GL0 2/G affect the underlying Drinfeld modules?", "golden_answers": ["The underlying Drinfeld modules are the same, but differ only in the level I-structure by an element in G."], "prediction": "Different representatives of the same coset in GL0 2/G result in underlying Drinfeld modules that are the same and differ only in the level I-structure by an element in G.", "f1": 0.6829268292682926, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01357v1\nThen there exists an action\nof\nGL0\n2 on the Drinfeld moduli space M2\nI as follows:\n(i) First we let S be a K-scheme and ( E,\u03bd) \u2208 M2\nI(S) be a Drinfeld A-module with a\nlevel I-structure \u03bd over S. Then for any \u03b1\u2208 GL2( \u02c6A)/(K(I)F\u00d7\nq ), we de\ufb01ne\n\u03b1\u2217(E,\u03bd) := ( E,\u03bd \u25e6 \u03b1\u22121).\nwhere \u03b1 acts on the v via the identi\ufb01cation I\u22121 \u02c6A/\u02c6A\u2243 I\u22121/A.\n(ii) Secondly, note that A\u00d7\nf /\u02c6A\u00d7K\u00d7 \u2243 C \u2113(A), where an isomorphism between the two\ngroups is given by a map sending each class [ a] \u2208 A\u00d7\nf /\u02c6A\u00d7K\u00d7 to [ a \u02c6A \u2229 K]. By\n[\nvdH03, Lem. 5.6.4], one can choose a representative a \u2208 A\u00d7\nf so that a \u02c6A\u2229 K is an\nideal of A that is relatively prime to I. For such an [ a], we de\ufb01ne\n[a]\u2217(E,\u03bd) := [ a \u02c6A\u2229 K] \u2217 (E,\u03bd). Let\nG \u2264 GL0\n2 be the group consisting of the image of matrices of the form\n(\nc1 c2\n0 1\n) \u2208\nGL2( \u02c6A) for c1,c2 \u2208 \u02c6A inside\nGL0\n2 and set nI := [\nGL0\n2 :\nG] and by [ Leh09, Ch.5,Prop.3.5],\nwe know that nI is a \ufb01nite number which can be described explicitly. For any \u03b1\u2208 G, from\nthe proof of [ Leh09, Prop.2.5], we see that \u03b1\u2217(\u03c6,\u03bb) = ( \u03c6,\u03bb \u25e6 \u03b1\u22121). Consequently, for any\ntwo representatives \u03c3,\u03c3\u2032 \u2208 GL0\n2 of the same coset in\nGL0\n2/\nG, we have that the underlying\nDrinfeld modules of \u03c3\u2217(\u03c6,\u03bb) and \u03c3\u2032\n\u2217(\u03c6,\u03bb) are the same and di\ufb00er only in the level I-structure\nby an element in G. We \ufb01x, \u03c31 = 1 ,\u03c32,...,\u03c3 nI, a set left coset representatives of GL0\n2/\nG, and\neach ( \u03c3i)\u2217(\u03c6,\u03bb) gives rise to a Drinfeld A-module ( \u03c6i,\u03bbi) of rank two de\ufb01ned over H((X)),\nwhich we call a Tate-Drinfeld module (abbreviated as TD-module). For 1 \u2264 i \u2264 nI, let Xi\nand Zi be indeterminates over H. To distinguish these TD-modules, we further consider\n(\u03c6i,\u03bbi) to be the TD-module de\ufb01ned over H((Xi)) so that for any a \u2208 A, ( \u03c6i)a(Zi) is an\nFq-linear polynomial in Zi with coe\ufb03cients in H((Xi)). By our convention, X1 = X and\nZ1 = Z, so that ( \u03c61,\u03bb1) = ( \u03c6,\u03bb). In what follows, we de\ufb01ne a universal TD-module by the set\nTDI := {(\u03c6i,\u03bbi) | 1 \u2264 i\u2264 nI}. Note that TD I may be regarded as a Drinfeld A-module of rank two with a level I-structure\nover Spec( \u2295nI\ni=1H((Xi))) so that its restriction to Spec( H((Xi))) is given by ( \u03c6i,\u03bbi). We \ufb01nish this subsection with some remarks on TD I.\nRemark 6.3. (i) If one chooses a di\ufb00erent set of representatives {\u03c3\u2032\ni}1\u2264i\u2264nI of GL0\n2/\nG,\nthen similar to above we have an induced map \u2295nI\ni=1 Spec(H((X\u2032\ni))) \u2192 M2\nI, for some\nindeterminates X\u2032\ni\u2019s. This is determined by the set {( \u02dc\u03c6i,\u02dc\u03bbi) | 1 \u2264 i \u2264 nI} where\n( \u02dc\u03c6i,\u02dc\u03bbi) corresponds to ( \u03c3\u2032\ni)\u2217(\u03c6,\u03bb).\n\n2503.00100v2\nBy integ rating\nthe correlation function against di\ufb00erent spherical harmon ics, i.e., take the angular modes of\nthe operator inserted\n\u222b\nd2 \u02c6n \u00afYlm(\u02c6n)\u27e8\u03a6 1|\u03a6 2(\u02c6n)|\u03a6 3\u27e9 = \u27e8\u03a6 1|\u03a6 2,lm|\u03a6 3\u27e9, (4.44)\nwe can \ufb01lter out the subleading contributions with di\ufb00erent spins. For the spinning operators,\nthis also tells us about di\ufb00erent OPE structures. By taking \u03a6 3 = I, we can recover the 2-pt\nfunctions\n\u27e8\u03a6 2|\u03a6 2,00|0\u27e9 = R\u2212\u03a6 2\n\u03a6 2(\u02c6n)|0\u27e9 = R\u2212\u03a6 2\n[\n|\u03a6 2\u27e9+ \u03bb\u2032\n\u00b5(\u02c6n)|\u2202\u00b5\u03a6 2\u27e9+ \u03bb\u2032\u2032(\u02c6n)|\u25a1 \u03a6 2\u27e9+ \u03bb\u2032\u2032\n\u00b5\u03bd (\u02c6n)|\u2202\u00b5\u2202\u03bd \u03a6 2\u27e9\n]\n. (4.45)\nIt is worth noting that acting a primary \u03a6 2(\u02c6n) on the vacuum also produces various descendants\nin the multiplet. In the example of Ising CFT, we \ufb01rst use the insertion of a sing le operator to determine\nthe coe\ufb03cients \u03bb0,\u03bb\u01eb,\u03bb\u03c3\n\u03bb0 = R\u22122\n\u221a\n4\u03c0\n\u27e80|nx\n00|0\u27e9, \u03bb \u01eb = R\u2206 \u01eb\u22122\n\u221a\n4\u03c0\n\u27e8\u01eb|nx\n00|0\u27e9, \u03bb \u03c3 = R\u2206 \u03c3\u22122\n\u221a\n4\u03c0\n\u27e8\u03c3|nz\n00|0\u27e9. (4.46)\nTake the OPE coe\ufb03cient f\u03c3\u03c3\u01eb as an example. It can be expressed either as an inner product o f\n\u03c3or \u01eb\nf\u03c3\u03c3\u01eb = R\u2206 \u03c3 \u27e8\u01eb|\u03c3(\u02c6n)|\u03c3\u27e9 = \u27e8\u01eb|nz\n00|\u03c3\u27e9\n\u27e80|nz\n00|\u03c3\u27e9 + O(R\u22122)\n= R\u2206 \u01eb \u27e8\u03c3|\u01eb(\u02c6n)|\u03c3\u27e9 = \u27e8\u03c3|nx\n00|\u03c3\u27e9 \u2212 \u27e80|nx\n00|0\u27e9\n\u27e8\u01eb|nx\n00|0\u27e9 + O(R\u2212(3\u2212\u2206 \u01eb)). (4.47)\nFor the \ufb01rst line, the subleading contribution comes from the contribution of the descendant \u25a1 \u03c3\nto nz\n00. As \u03c3(\u02c6n) scales as R\u2212\u2206 \u03c3 and \u25a1 \u03c3(\u02c6n) as R\u2212\u2206 \u03c3\u22122,\n\u27e8\u01eb|nz\n00|\u03c3\u27e9 = f\u03c3\u03c3\u01eb \u03bb\u03c3R\u2212\u2206 \u03c3 (1 + c1R\u22122 + ... )\n\u27e8\u01eb|nz\n00|\u03c3\u27e9 = \u03bb\u03c3R\u2212\u2206 \u03c3 (1 + c\u2032\n1R\u22122 + ... )\n\u27e8\u01eb|nz\n00|\u03c3\u27e9\n\u27e80|nz\n00|\u03c3\u27e9 = f\u03c3\u03c3\u01eb + O(R\u22122). (4.48)\n29\n\nHere c1 and c\u2032\n1 are constant factors that represent the contribution of \u25a1 \u03c3 and do not scale\nwith system size. Hence, the subleading contribution scales as R\u22122. For the second line, the\nsubleading contribution comes from the stress tensor T\u00b5\u03bd . Similarly, the power of the scaling\nis the di\ufb00erence of the scaling dimension R\u2212(\u2206 T \u00b5\u03bd \u2212\u2206 \u01eb) = R\u2212(3\u2212\u2206 \u01eb). We then proceed to the insertion of two operators. This can he lp us determine up to a 4-pt\nfunction [\n3]. Through conformal transformation, any 4-pt function can be e xpressed in the\nform of\n\u27e8\u03a6 1|\u03a6 (cyl.)\n2 (\u02c6n,\u03c4)\u03a6 (cyl.)\n3 (\u02c6z)|\u03a6 4\u27e9 = e\u2206 \u03a6 2 \u03c4/R\nR\u2206 \u03a6 2 +\u2206 \u03a6 3\n\u27e8\u03a6 \u2020\n1(\u221e)\u03a6 2(r)\u03a6 3(\u02c6z)\u03a6 4(0)\u27e9, (4.49)\nwhere the time-displaced operator can be de\ufb01ned as\n\u03a6 2(\u02c6n,\u03c4) = e\u2212H\u03c4 \u03a6 2(\u02c6n)eH\u03c4 . (4.50)\nAs a sanity check, By taking \u03a6 1 = \u03a6 4 = I, \u03a6 2 = \u03a6 3 and \u03c4 = 0 , the 2-pt function on the unit\nsphere is recovered\n\u27e80|\u03a6 (cyl.)\n2 (\u02c6n)\u03a6 (cyl.)\n2 (\u02c6z)|0\u27e9 = R\u22122\u2206 \u03a6 2 \u27e8\u03a6 2(\u02c6n)\u03a6 2(\u02c6z)\u27e9\n= 1\nR2\u2206 \u03a6 2 |\u02c6n \u2212 \u02c6z|2\u2206 \u03a6 2\n= 1\nR2\u2206 \u03a6 2 (1 \u2212 cos \u03b8)\u2206 \u03a6 2\n. (4.51)\n4.7 Conformal generators\nSo far, in the conformal group, we know that the rotation and the dilatation are manifest\non the fuzzy sphere.\n\n2503.01357v1\nFor each i\u2265 1, we let gi,a : \u2126 \u2192 C\u221e be the rigid analytic function so that\n\u03a8 Y\na = a+\nrdeg(a)\u2211\ni=1\ngi,a\u03c4i. Then for any z \u2208 \u2126, recall from \u00a72.1 that the A-lattice Yz = gz+ h \u2282 C\u221e gives rise to the\nDrinfeld module \u03c6Yz. For any a\u2208 A, we have\n\u03c6Yz\na = a+\nrdeg(a)\u2211\ni=1\ngi,a(z)\u03c4i. We refer the reader to Example\n3.7(ii) for more details on the rigid analytic function gi,a.\nWe can also describe an action of the group GL 2(K) on the Drinfeld A-module ( Ga,\u2126 ,\u03a8 Y)\nas follows. Firstly, we let\nj(\u03b3; z) := c\u03b3z+ d\u03b3, \u03b3 =\n(\na\u03b3 b\u03b3\nc\u03b3 d\u03b3\n)\n\u2208 GL2(K). Now one can form the triple \u03b3\u2217(O\u2126 ,Y ,s) := ( \u03b3\u2217O\u2126 ,Y \u03b3\u22121,j(\u03b3; \u2212)s\u03b3), where s\u03b3 : Y\u03b3\u22121 \u2192\n\u03b3\u2217O\u2126 sends ( g\u2032,h\u2032) \u21a6\u2192[z \u21a6\u2192g\u2032(\u03b3 \u00b7 z) + h\u2032]. Consequently, since Y is preserved by \u0393 Y, we\n\n22 O \u02d8GUZ GEZM \u02d9IS \u00b8 AND SRIRAM CHINTHALAGIRI VENKATA\nhave an action of \u0393 Y on the Drinfeld A-module ( Ga,\u2126 ,\u03a8 Y). Due to the construction of the\nlevel I-structure on ( Ga,\u2126 ,\u03a8 Y) (see [ B\u00a8 oc02, \u00a74.3] and [ BBP21, \u00a77] for more details), we can\ndescend ( Ga,\u2126 ,\u03a8 Y), together with a canonical level I-structure, to a Drinfeld A-module with\na level I-structure on \u0393 Y(I)\\\u2126. Indeed, ( Ga,\u2126 ,\u03a8 Y) has a \u201cuniversal property\u201d which will be\nstated in our next proposition. Let Av (Kv resp.) be the completion of A(Kresp.) at a \ufb01nite place vand \u02c6A\u223c\n= \u220f\nv\u0338=\u221e Av be\nthe pro\ufb01nite completion of A. We set Af := \u02c6A\u2297AK and de\ufb01ne GL 2(Af) := \u220f \u2032\nv\u0338=\u221e GL2(Kv)\nwhere \u220f \u2032 refers to the restricted product with respect to \u220f \u2032\nv\u0338=\u221e GL2(Av). Proposition 2.40. Let K(I) := {\u03b3 \u2208 GL2( \u02c6A) |\u03b3 \u2261 Id2 (mod I)}. There exists a natural\nisomorphism of rigid analytic spaces\nGL2(K)\\(\u2126 \u00d7 GL2(Af)/K(I))\n\u223c\n\u2212 \u2192M2\nI(C\u221e). Let the composition of the above isomorphism with \u2126 \u2192 GL2(K)\\(\u2126 \u00d7GL2(Af)/K(I)) send-\ning \u03c9\u21a6\u2192[(\u03c9,g)] be denoted by \u03c0g. Then\n\u03c0\u2217\ng(Eun\nI ) \u2243 (Ga,\u2126 ,\u03a8 Mg)\nwhere Mg is the projective A-module of rank 2 embedded in K2 such that Mg = \u02c6A2g\u22121 \u2229 K2. We note that one can choose an element g \u2208 GL2(Af) such that Mg = Y. In this\ncase, by Proposition\n2.40, there exists an isomorphism between \u0393 Y(I)\\\u2126 and the C\u221e-points\nof a unique connected component MY \u2282 M2\nI \u00d7K C\u221e. Hence this gives rise to a natural\nisomorphism\nMan\nY \u223c= \u0393I(I)\\\u2126\nwhere Man\nY is the analyti\ufb01cation of MY. Moreover, the pullback of the universal Drinfeld\nA-module via the analyti\ufb01cation map \u0393 Y(I)\\\u2126 = Man\nY \u2192 MY is the descent of ( Ga,\u2126 ,\u03a8 Y)\nto \u0393 Y(I)\\\u2126 described as above. Since MY is a smooth curve over C\u221e, it admits a unique compacti\ufb01cation, denoted by\nMY.", "metadata": {"type": "reasoning", "source": "2503.01357v1.pdf", "context": "(\nc1 c2\n0 1\n)\n\u2208\nGL2( \u02c6A) for c1,c2 \u2208 \u02c6A inside\nGL0\n2 and set nI := [\nGL0\n2 :\nG] and by [ Leh09, Ch.5,Prop.3.5],\nwe know that nI is a \ufb01nite number which can be described explicitly. For any \u03b1\u2208 G, from\nthe proof of [ Leh09, Prop.2.5], we see that \u03b1\u2217(\u03c6,\u03bb) = ( \u03c6,\u03bb \u25e6 \u03b1\u22121). Consequently, for any\ntwo representatives \u03c3,\u03c3\u2032 \u2208 GL0\n2 of the same coset in\nGL0\n2/\nG, we have that the underlying\nDrinfeld modules of \u03c3\u2217(\u03c6,\u03bb) and \u03c3\u2032\n\u2217(\u03c6,\u03bb) are the same and di\ufb00er only in the level I-structure\nby an element in G. We", "quality_score": 8.5}}
{"id": "test_44", "question": "Why were the categorical disease labels one-hot encoded before training the model?", "golden_answers": ["To facilitate multi-class classification."], "prediction": "The categorical disease labels were one-hot encoded before training the model to clearly categorize the input sample into a single class, which is a common practice in general recognition tasks such as object recognition.", "f1": 0.0606060606060606, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.00657v1\nThe expressions for the process at each time step\nare:\nht = fISM (ht\u22121, \u03d1t) 0 < t\u2264 T (4)\nwhere T is the length of the sequence of visual features \u03d1. We\napply an attention module to the hidden state ht of the LSTM\nlayer (acting also as its output). In the module, the last hidden\nstate hT attends to the hidden states at all the previous time\ninstances and gives the viewing pattern features as:\nFA = fattn(hT , {h1, ..., hT\u22121}, {h1, ..., hT\u22121}) (5)\n\n5\nwhere fattn is an attention function [57]. Finally, the visual\nfeatures F\u03d1 and viewing pattern features FA at the output\nof the two branches of the proposed network are concatenated\nand passed through a fully connected layer acting as a classifier\nto compute the score S(d) for each disease category d. The\ncomputed score S(d) for each disease category is then passed\nthrough the sigmoid function to give the estimated probability\n\u02c6pd of the disease category d. Loss function: There are two challenges in handling labels\nfor disease classification in CXR images [16], [35]. The first\none is the class imbalance issue and the second one is the\npresence of uncertain labels. There are labels where radiolo-\ngists have confidently stated whether the disease is present\nor not. However, there are many cases where radiologists\nare not confident about the existence of a disease (a label). Such uncertain labels are usually mentioned in CXR datasets. As uncertain labels may push the neural network training in\nthe wrong direction, we mask those labels during training\nby excluding them from loss calculations and model weight\nupdation. To handle the class-imbalance problem, we use a reverse\nweighing strategy during the loss computation. For example,\nif class d is present in npos number of images and absent\nin nneg number of images, we assign weights wpos =\nnneg/(npos + nneg) when class d is encountered. Generally,\nin thoracic disease datasets nneg >> npos. Therefore, we\ngive lesser weight ( 1 \u2212 wpos) in the loss function during\ntraining if that disease is absent in the image at hand and\ncomparably more weight ( wpos) if the disease is present. We modify the cross-entropy loss and formulate \u2018uncertainty-\nremoved weighted cross-entropy loss\u2019 to train the networks. It\ncan be mathematically expressed as\nL(pd, \u02c6pd) =\nX\n{pd \u0338= u}wd[pd log \u02c6pd + (1\u2212pd) log(1\u2212 \u02c6pd)]. (6)\nwhere, pd is the actual label of class d. \u02c6pd is the predicted\nprobability of class d. wd is the weight for class d. u represents\nthe presence of uncertainty in that label. The weight for class\nd is expressed as\nwd = pdwpos + (1\u2212 pd)(1 \u2212 wpos). (7)\nIV. R ESULTS AND DISCUSSION\nA. Datasets\nThere are two popular publicly available datasets,\nMIMIC [16] and CheXpert [17] for thoracic disease clas-\nsification containing CXR images in the order of one-tenth\nof a million. Both the datasets are labeled for 14 different\nthoracic diseases.\n\n2503.00202v1\nHard labels, that is, one-hot encoded class labels, are mostly\nused in general recognition tasks such as object recogni-\ntion, where the input sample is clearly categorized into a\nsingle class; however, they cannot appropriately represent\nan objective variable composed of a combination of mul-\ntiple emotions with different intensities in ambiguous fa-\ncial expressions. To correctly learn the ambiguity in DFER,\nsoft labels consisting of probabilities for multiple emotions\nare helpful to maximize the use of information provided by\nannotators. One possible method of assigning soft labels\nto training data is to have multiple annotators evaluate the\ntraining data and use the ratio of their votes. The disadvantage of soft labels is that they are more flex-\nible than hard labels, making it difficult to collect a variety\nof labels in a uniform manner. There is an enormous amount\nof possible combinations of emotion classes and the corre-\nsponding probabilities, and therefore it is difficult to prepare\ntraining data that include all of these patterns. Furthermore,\nthe size of the dataset itself also tends to be limited in DFER\narXiv:2503.00202v1  [cs.CV]  28 Feb 2025\n\n0 0\n0.2 0.1 0\n0.6\n0.1\n0\n0.2\n0.4\n0.6\n0.8\n1\nHappy Sad Neutral Angry Surprise Disgust Fear\nProbability\nFigure 1. Example of an ambiguous facial expression. The images\nwere taken from the DFEW dataset [14]. The bar chart in the\nbottom row shows the soft-labeled annotation constructed based\non the proportions of votes by ten annotators. The annotations are\nsplit into four emotion classes. due to the difficulty of manual annotation and data collec-\ntion. To address this problem, it is necessary to augment\ndata effectively and properly to learn from limited data. In this paper, we propose a data augmentation method\nfor DFER with ambiguous facial expressions called MIDAS\n(Mixing Ambiguous Data with Soft labels). In MIDAS, the\nmixing strategy is expanded to handle soft labels and dy-\nnamic facial expressions. The method convexly combines\npairs of video frames of facial expressions and the corre-\nsponding soft labels that represent the probabilities of emo-\ntion classes after aligning the facial position. It then trains\na model on the generated data. Our contributions are summarized as follows:\n\u2022 We proposed MIDAS, a data augmentation method for\nDFER with ambiguous facial expressions. MIDAS\nconvexly combines pairs of video frames of facial ex-\npressions in a similar way to mixup. One significant\ndifference from mixup is that MIDAS is applicable\nwhen the true hard labels are unknown and only soft la-\nbels consisting of multiple classes of probabilities are\ngiven. \u2022 We showed that MIDAS corresponds to minimizing\nthe vicinal risk in a situation where the true hard la-\nbel is unknown with a vicinity distribution using a ran-\ndom ratio and virtual labels that are different from the\noriginal mixup. \u2022 Through DFER experiments on the DFEW dataset, we\nshowed that the proposed method outperforms existing\nstate-of-the-art methods.\n\n2503.00196v1\nSecond, medical imaging datasets are significantly\nsmaller than those in computer vision, making it impractical to train a foundation model\nfrom scratch. To address these shortcomings and enable CF generation, our methodology\nconsists of three main steps: (i) convert patient tabular data into text format, enabling\nthe generation of rich semantic embeddings via a pre-trained CLIP (Contrastive Language-\nImage Pre-training) text encoder, Section 2.1; (ii) fine-tune a Stable Diffusion model, to\nbetter adapt to a medical imaging dataset, Section 2.2; (iii) at inference, synthesize CF\nimages guided by a text input, Section 2.3. 2.1. Tabular Data to Text Conversion\nOne of the key requirements of training a Stable Diffusion (specifically v1.5) (Rombach\net al., 2022) model is the image-text pair. CheXpert, the medical dataset we use here,\nonly contains binary labels for different diseases and the presence of support devices. To\nleverage Stable Diffusion, we create a custom template for image-text pairs based on the\navailable tabular data. For example, if the subject\u2019s radiograph shows pleural effusion\nand cardiomegaly, our text caption for the image is chest x-ray of a patient showing\npleural effusion, cardiomegaly. Additionally, for patients with no findings, we use\nthe template text Normal chest X-ray with no significant findings. 2.2. Fine-Tuning the Stable Diffusion Model\nThe Stable Diffusion v1.5 architecture consists of three components: (i) the Variational\nAutoencoder (VAE), which encodes images into the latent space and subsequently decodes\n3\n\nKumar Kriz Havaei Arbel\nFigure 2: The framework for synthesizing counterfactual (CF) images takes an original\ninput image ( X) and its corresponding text description ( T), along with an edited text\nprompt (T\u2032) for the CF image. It employs a frozen VAR consisting of an image encoder\n(EI) and decoder, as well as a frozen CLIP text encoder ( ET ). The core component of the\nframework is a denoising U-Net, which is the only trainable module during the fine-tuning\nprocess. During inference, the encoded text prompt ( ET (T\u2032)) is used to condition the U-\nNet, guiding the generation of a high-resolution 512 \u00d7 512 counterfactual image that aligns\nwith the modified text description. the processed latent representation back into image space; (ii) the U-Net, which operates\nat the latent level and is trained to predict and remove noise introduced during the forward\ndiffusion process, enabling iterative image refinement; and (iii) the CLIP Encoder, which\nencodes text descriptions into a vector embedding that is used to condition the U-Net,\nguiding the image generation process to match the given text description. It should also\nbe noted here that the CLIP model is already pre-trained, providing general semantic\nknowledge about image-text relationships. Given our objective of generating identity-preserving counterfactuals, we adopt the De-\nnoising Diffusion Implicit Model (DDIM) (Song et al., 2020). This method provides a\ndeterministic mapping between the noisy and denoised latent. By conditioning the U-Net\nwith a CLIP-encoded text, we gain direct control over the image generation process. For sta-\nbility during fine-tuning, we update only the U-Net component of the model while keeping\nthe VAE and CLIP encoder fixed.", "metadata": {"type": "reasoning", "source": "2503.01284v2.pdf", "context": "ing, with 10% of the total dataset reserved for validation during training, while\nthe remaining 10% was utilized for final testing. Furthermore, the categori-\ncal disease labels were one-hot encoded to facilitate multi-class classification.\nThese preprocessing steps ensured that the model was trained on standardized\n1https://www.kaggle.com/datasets/sivm205/soybean-diseased-leaf-dataset", "quality_score": 8.5}}
{"id": "test_45", "question": "What does a positive eigenvalue in the OV pair suggest about information propagation?", "golden_answers": ["Effective information propagation"], "prediction": "A positive eigenvalue in the OV pair suggests effective information propagation.", "f1": 0.5, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01329v2\nIn comparison, the approach presented by Elhage et al. (2021) characterizes OV pairs as exhibit-\ning copying behavior when the eigenvalues of the OV pair feature numerous positive values. This\ncopying behavior conceptually is similar to the attractive scenario in Geshkovski et al. (2023a;b). In mathematical terms, V = Id means that all eigenvalues are positive and equal to 1. If copying\nbehaviors occur frequently, it indicates a selective focus on specific particles, resembling a situation\nwhere only a subset of major particles is highlighted. Note that copying behavior is characterized as\na component of induction heads, recognized as a key observation associated with in-context learning\nperformance in Elhage et al. (2021); Olsson et al. (2022). Under the interpretation of Elhage et al. (2021), induction heads perform two key operations: (i) de-\ntecting matching patterns through QK pair and (ii) copying values when matches are found through\nOV pairs. The \u201cmatching\u201d operation manifests through attention scores, where positive eigenvalues\nof QK pair indicate strong attention paths between similar tokens. The \u201ccopying\u201d operation is facil-\nitated by the OV pair, where positive eigenvalues suggest effective information propagation. Given\nour observations in Figure 2a and 2b of both positive eigenvalues in QK pair (supporting pattern\nmatching) and positive eigenvalues in the OV pair (enabling copying), it is highly probable that\ninduction heads occur in the last layer of DIFFEQFORMER . Clustering behavior in DIFFEQFORMER Trained D IFFEQFORMER exhibits a distinct dynamic\nof QK and OV pairs characterized by increasing magnitudes of eigenvalues over time, with a no-\ntable peak observed near the final layers. This dynamic contrasts with the assumptions put forth\nby Geshkovski et al. (2023a), who posited the emergence of clustering behavior at limit. Given this\nunique dynamic, it is crucial to investigate potential clustering behavior in our DIFFEQFORMER . To\nthis end, we simulate ODE trajectories for attention-only model with the simplified dynamic based\non the trained D IFFEQFORMER (refer to Appendix C.8 for details). As illustrated in Figure 2d,\nour findings indicate an absence of emergent clusters for a case of time-dependent weights. This\ncontrasts with the cluster emergence observed in the weight-sharing case, shown in Figure 2c. This\noutcome aligns with the practical considerations of autoregressive language modeling tasks with\nnext-token prediction, where clustered outputs would be counterintuitive. This shows that a discrep-\nancy between the theoretical assumptions in existing studies and the empirical properties exhibited\nby our DIFFEQFORMER models. Therefore, it is necessary to have future rigorous investigation into\nthis gap.\nRemark Due to the continuity of weights within our model, the dynamics of eigenvalues exhibit the\ncontinuity property, as discussed in previous works (Wilkinson, 1965; Hoffman & Wielandt, 2003). Consequently, a smooth transition of spectral information between layers can be observed in our\nanalysis of QK and OV pairs. In contrast, the spectral flow in the case of vanilla transformers do\nnot exhibit clear patterns or behaviors in their dynamics, making it challenging to identify induction\nheads (see Appendix E).\n\n2503.01329v1\nIn comparison, the approach presented by Elhage et al. (2021) characterizes OV pairs as exhibit-\ning copying behavior when the eigenvalues of the OV pair feature numerous positive values. This\ncopying behavior conceptually is similar to the attractive scenario in Geshkovski et al. (2023a;b). In mathematical terms, V = Id means that all eigenvalues are positive and equal to 1. If copying\nbehaviors occur frequently, it indicates a selective focus on specific particles, resembling a situation\nwhere only a subset of major particles is highlighted. Note that copying behavior is characterized as\na component of induction heads, recognized as a key observation associated with in-context learning\nperformance in Elhage et al. (2021); Olsson et al. (2022). Under the interpretation of Elhage et al. (2021), induction heads perform two key operations: (i) de-\ntecting matching patterns through QK pair and (ii) copying values when matches are found through\nOV pairs. The \u201cmatching\u201d operation manifests through attention scores, where positive eigenvalues\nof QK pair indicate strong attention paths between similar tokens. The \u201ccopying\u201d operation is facil-\nitated by the OV pair, where positive eigenvalues suggest effective information propagation. Given\nour observations in Figure 2a and 2b of both positive eigenvalues in QK pair (supporting pattern\nmatching) and positive eigenvalues in the OV pair (enabling copying), it is highly probable that\ninduction heads occur in the last layer of DIFFEQFORMER . Clustering behavior in DIFFEQFORMER Trained D IFFEQFORMER exhibits a distinct dynamic\nof QK and OV pairs characterized by increasing magnitudes of eigenvalues over time, with a no-\ntable peak observed near the final layers. This dynamic contrasts with the assumptions put forth\nby Geshkovski et al. (2023a), who posited the emergence of clustering behavior at limit. Given this\nunique dynamic, it is crucial to investigate potential clustering behavior in our DIFFEQFORMER . To\nthis end, we simulate ODE trajectories for attention-only model with the simplified dynamic based\non the trained D IFFEQFORMER (refer to Appendix C.8 for details). As illustrated in Figure 2d,\nour findings indicate an absence of emergent clusters for a case of time-dependent weights. This\ncontrasts with the cluster emergence observed in the weight-sharing case, shown in Figure 2c. This\noutcome aligns with the practical considerations of autoregressive language modeling tasks with\nnext-token prediction, where clustered outputs would be counterintuitive. This shows that a discrep-\nancy between the theoretical assumptions in existing studies and the empirical properties exhibited\nby our DIFFEQFORMER models. Therefore, it is necessary to have future rigorous investigation into\nthis gap.\nRemark Due to the continuity of weights within our model, the dynamics of eigenvalues exhibit the\ncontinuity property, as discussed in previous works (Wilkinson, 1965; Hoffman & Wielandt, 2003). Consequently, a smooth transition of spectral information between layers can be observed in our\nanalysis of QK and OV pairs. In contrast, the spectral flow in the case of vanilla transformers do\nnot exhibit clear patterns or behaviors in their dynamics, making it challenging to identify induction\nheads (see Appendix E).\n\n2503.01329v2\nTo gain a deeper understanding, we make a connection with the work of Geshkovski et al. (2023b). In this study, the authors simplify the model by assuming that Q(t), K(t), and V (t) are all identity\nmatrices, i.e.,\nf\u03b2(xi(t), x[n](t), t) = 1\nL\u03b2\nnX\nj=1\nexp(\u03b2\u27e8xi(t), xj(t)\u27e9)xj,\nwhere L\u03b2 = Pn\nj=1 exp(\u03b2\u27e8xi(t), xj(t)\u27e9). Here, the parameter \u03b2 serves as a simplification of\nQh(t)\u22a4Kh(t) in equation 4. The study by Geshkovski et al. (2023b) looks into the interaction\nenergy, and its gradient flows govern the dynamics of f\u03b2 (Otto, 2001; Jordan et al., 1998; Ambro-\nsio et al., 2005; Villani et al., 2009). Importantly, the parameter \u03b2 directly influences the speed at\nwhich the interaction energy decreases or increases. Such interactions in D IFFEQFORMER can be\nreflected by the eigenvalues of Qh(t)\u22a4Kh(t). For example, a wide range of eigenvalues encourage\ninteractions between particles, as they indicate stronger coupling and information exchange within\nthe system. Analyzing Output-Value (OV) pair While Qh(t)\u22a4Kh(t) identifies the source and destination\nparticles of inter-particle communication, the Output-Value (OV) pair represents the component\ndescribing how information of the source particle is merged to the destination particle. Figure 2b illustrates the spectral dynamics of the OV matrix in D IFFEQFORMER . A significant\nnumber of heads exhibit positive eigenvalues, which are primarily concentrated near the output\nlayer. It seems to have a correlation with the spectral dynamics of the QK pair.\nConsider a communication from a source particle j to a destination particle i. The OV matrix\nhas eigenvalues {\u03bbk}d\nk=1 and corresponding eigenvectors {vk}d\nk=1. We can express the states of\n6\n\nPublished as a conference paper at ICLR 2025\nparticles i and j at time t as linear combinations of these eigenvectors:\nxi(t) =\ndX\nk=1\nwi\nkvk, x j(t) =\ndX\nk=1\nwj\nkvk,\nwhere {wi\nk}d\nk=1 and {wj\nk}d k=1 are the respective coefficients. The output of the Euler step for atten-\ntion can be interpreted as:\nxi(t + \u2206t) =\ndX\nk=1\n(\u03bbkwj\nk\u2206t + wi\nk)vk. Here, we focus on the coefficient \u03bbkwj\nk\u2206t + wi\nk. The magnitude of \u03bbk determines the influence of\nthe source particle xj(t) on the output xi(t + \u2206t). Larger absolute values of \u03bbk result in a stronger\ninfluence of the source particle on the destination particle\u2019s next state. The sign of \u03bbk decides either\npositive or negative influence of source particle with respect to the corresponding eigenvectorvj. Drawing connection to the work of Geshkovski et al. (2023a;b), the authors suggest two simplified\ncases: the attractive scenario, where particles exhibit attractions and more likely to follow some\nleader particles with V = Id; and the repulsive scenario with V = \u2212Id, where particles repel\neach other. We extend this analysis by examining both the sign and magnitude of eigenvalues\u03bbk as\nshown in Figure 2a and 2b. This means that D IFFEQFORMER shows both attractive and repulsive\nbehaviors, with attraction being more dominant in some attention heads near the last layers.", "metadata": {"type": "factual", "source": "2503.01329v1.pdf", "context": "itated by the OV pair, where positive eigenvalues suggest effective information propagation. Given\nour observations in Figure 2a and 2b of both positive eigenvalues in QK pair (supporting pattern\nmatching) and positive eigenvalues in the OV pair (enabling copying), it is highly probable that\ninduction heads occur in the last layer of DIFFEQFORMER .\nClustering behavior in DIFFEQFORMER Trained D IFFEQFORMER exhibits a distinct dynamic\nof QK and OV pairs characterized by increasing magnitudes of ei", "quality_score": 8.5}}
{"id": "test_46", "question": "What is the definition of the structure factor N(q, \u03c9) in the context of the generalized Kondo model?", "golden_answers": ["N(q, \u03c9) = 1 L \u2211\u2113 ei(\u2113\u2212L/2)q \u27e8\u27e8n\u2113nL/2\u27e9\u27e9\u2212\u03c9 , (A1)"], "prediction": "N(q, \u03c9) is defined as \n\nN(q, \u03c9) = (1/L) * \u03a3\u2113 ei(\u2113\u2212L/2)q \u27e8\u27e8n\u2113nL/2\u27e9\u27e9\u2212\u03c9, \n\nwhere n\u2113 = n\u2113\u2191 + n\u2113\u2193, for the generalized Kondo model with S = 1/2 localized spins, U/t = JH/t = 20, L = 200 sites, and Tz_tot = 0 magnetization sector.", "f1": 0.23255813953488372, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01277v2\n4\nof the main text, i.e., for the generalized Kondo (gK)\nmodel with S = 1/2 localized spins, U/t = JH/t = 20,\nL = 200 sites, and Tz\ntot = 0 magnetization sector. Here\nn\u2113 = n\u2113\u2191 +n\u2113\u2193. In Fig. 17, we present N(q, \u03c9) for various\nelectron densities n. It is important to note that the total\nenergy span of N(q, \u03c9), and even the bottom of N(q, \u03c9),\nlies much above the spin excitations bandwidth WS. Our results indicate a perfect agreement between\nN(q, \u03c9) obtained within the gK model in the JH \u226b t\nlimit and the free-fermion solution. Specifically, for non-\ninteracting spinless electrons, one can evaluate the charge\nstructure factor N(q, \u03c9) exactly [117, 118]. Such calcula-\ntions are equivalent to the Stoner continuum of the form\n\u03c9Sff(q) = \u03c9ff(k1) \u2212 \u03c9ff(k2) , (A2)\nwhere q = mod ( k1 + k2, L), k1 > kF, and k2 < kF, and\nthe free-fermion band \u03c9ff(q), Eq. (6). Note that within\n\n20\n0\n1\n2\n3\n4\n5\nFrequency \u03c9/t 0 0 .01\n(a) N(q, \u03c9 ) n = 1.33 (b) N(q, \u03c9 ) n = 1.40 (c) N(q, \u03c9 ) n = 1.50\nWS\n0 0 .2 0 .4 0 .6 0 .8 1\nWavevector q/\u03c0\n0\n1\n2\n3\n4\n5\nFrequency \u03c9/t\n(d) N(q, \u03c9 ) n = 1.60\n0 0 .2 0 .4 0 .6 0 .8 1\nWavevector q/\u03c0\n(e) N(q, \u03c9 ) n = 1.66\n0 0 .2 0 .4 0 .6 0 .8 1\nWavevector q/\u03c0\n(f) N(q, \u03c9 ) n = 1.80\nFigure 17. Dynamical charge structure factor N(q, \u03c9) of the gK model with S = 1 /2 localized spin in the JH \u226b t limit\n(U/t = JH/t = 20, Tz\ntot = 0 magnetization sector) for various electron doping levels,n = 1.33 , 1.40 , 1.50 , 1.60 , 1.66 , 1.80 [panels\n(a) to (f), respectively]. The red dashed line represents the borders of the Stoner continuum calculated from noninteracting\nbands, Eq. (A2). The white dashed line in all panels represents the span of the spin excitations WS. See Fig. 5(a). In all\npanels: L = 200, \u03b4\u03c9/t = 5 \u00b7 10\u22123 and \u03b7 = 2\u03b4\u03c9. Stoner-like considerations, one of the bands in (A2) rep-\nresents \u03c3 =\u2191 electrons, while the second band represents\n\u03c3 =\u2193 electrons. The above perfect agreement between\nthe noninteracting solution \u03c9Sff(q) and full many-body\ncalculations of N(q, \u03c9) within the gK model (2) in the\nJH/t \u226b 1 limit indicates that the charge fluctuations are\nindifferent to the incoherent band of excitations.\nAppendix B: Hubbard and Hund interaction\ndependence\nIn Sec. IV A, we demonstrated that the Hubbard in-\nteraction U opens a small gap in the incoherent part of\nthe single-particle spectral function A(q, \u03c9). Here, we\nprovide a detailed analysis of this phenomenon. Further-\nmore, we present additional results of A(q, \u03c9) and the\ndynamical spin structure factor S(q, \u03c9) for various val-\nues of the Hubbard U and Hund JH interaction.\n\n2503.01277v2\nC. Note that\nthe \u03c9fit(q) is a crude approximation for n < 1.4 data\nsince the strong decoherence of excitations for q/\u03c0 >0.5\nprevents an accurate fit. Nevertheless, our results indi-\ncate a systematic variation with n even in this region\n[see the summary of the results for various n presented\nin Fig. 10(a)]. The estimate for Jeff(\u2113) is then obtained from Fourier\ntransform of \u03c9fit(q). Our results presented in Fig. 10(b)\nindicate that (i) nearest-neighbor (NN) exchange is neg-\native Jeff(1) < 0 for all n, as expected for ferromagnet-\nically ordered systems. (ii) Furthermore, effective spin\nexchanges decay fast beyond next-NN, Jeff(\u2113 \u2265 3) \u2243 0. Consequently, the fitted dispersion relation can be repro-\nduced just with NN and next-NN interaction (see Tab. I). In Fig. 11, we show exemplary dynamical spin struc-\nture factor S(q, \u03c9) of the effective Heisenberg model (13)\nwith S = 1 /2 and values of Jeff given in Tab. I and\nJeff(l \u2265 3) = 0. As evident from the presented re-\nsults for n = 1 .4, the maximum of S(q, \u03c9) accurately\nfollows \u03c9fit(q). However, the original spin structure fac-\ntor presented in Fig. 4 is reproduced only qualitatively\nsince there is no magnon decoherence in the Heisenberg\nmodel (13). On the other hand, for n = 1.8, we obtain\na quantitative agreement not only with \u03c9fit(q) but also\nwith the magnons in the full model HgK, (2). Interestingly, our Jeff results indicate the change in the\n\n14\n0.0\n0.2\n0.4\n0.6\nFrequency \u03c9/t\n0 0 .3 0 .6\n(a) n = 1.40\n0 0 .2 0 .4 0 .6 0 .8 1\nWavevector q/\u03c0\n0.0\n0.1\n0.2\n0.3\n0.4\nFrequency \u03c9/t\n(b) n = 1.80\nFigure 11. Dynamical spin structure factor S(q, \u03c9) of the ef-\nfective Heisenberg model as calculated for S = 1/2 and values\nof spin exchange Jeff(\u2113 = 1, 2) given by Tab. I for (a)n = 1.40\nand (b) n = 1.80 (and Jeff(\u2113 \u2265 3) = 0 otherwise). The red\ndashed lines represent the fitted \u03c9fit(q) dispersion for given n.\nIn all panels: L = 100, \u03b4\u03c9/t = 6 \u00b7 10\u22123 and \u03b7 = 2\u03b4\u03c9. nature (sign) of Jeff(\u2113 = 2) with density n. For n \u2272 1.6\nthe sign of spin exchange is AFM ( Jeff(2) > 0), while\nfor n \u2273 1.6 FM ( Jeff(2) < 0). This behavior coincides\nwith the change in the slope of Jq\u21920 presented in Fig. 5\nand, more importantly, in the change in the behavior\nof double-exchange magnons. Our analysis in the pre-\nvious section indicates that for n \u2272 1.6, the magnons\nstrongly scatter on the Stoner continuum of incoherent\nelectrons, while for n \u2273 1.6, one observes the magnon\nmode softening. Finally, it is worth noting that the ratio\n|Jeff(2)/Jeff(1)| takes large values for extremes n, i.e., for\nsmall n = 1.25 and large n = 1.80 doping.\n\n2503.01277v1\nThe latter is the canonical explanation [40, 42] of these\nphenomena for JH|S| \u2192 \u221emanganites. Although the\nJahn-Teller distortion is necessary for the proper descrip-\ntion of such compounds [9, 13, 30, 41, 97], our results\ngive an alternative explanation for the origin of nontriv-\nial spin dynamics. This is a remarkable result with im-\nportant implications. There may be cases in materials\nwhere experimental features are believed to emerge from\na combination of degrees of freedom that are not as active\nas assumed in the past. ACKNOWLEDGMENTS\nA.M. and E.D. were supported by the US Depart-\nment of Energy, Office of Science, Basic Energy Sci-\nences, Materials Sciences and Engineering Division. G.A.\nwas supported by the U.S. Department of Energy, Of-\nfice of Science, National Quantum Information Science\nResearch Centers, Quantum Science Center. T.T. was\nsupported by KAKENHI (Grant No. 24K00560) from\nthe MEXT, Japan. J.H. acknowledges grant support by\nthe National Science Centre (NCN), Poland, via Sonata\nBIS project no. 2023/50/E/ST3/00033. The calcula-\ntions have been carried out using resources provided by\nthe Wroclaw Centre for Networking and Supercomputing\n(http://wcss.pl). The DMRG++ software developed\nin Oak Ridge National Laboratory was used for all cal-\nculations presented in this work. The code is available at\nhttps://code.ornl.gov/gonzalo_3/dmrgpp. The in-\nput scripts for the DMRG++ package are available at\nhttps://bitbucket.org/herbrychjacek/corrwro/.\nAppendix A: Charge dynamics\nHere, we discuss the behavior of the dynamical charge\nstructure factor defined as\nN(q, \u03c9) = 1\nL\nX\n\u2113\nei(\u2113\u2212L/2)q \u27e8\u27e8n\u2113nL/2\u27e9\u27e9\u2212\n\u03c9 , (A1)\nfor the system parameters discussed in Fig. 1 and Fig. 4\nof the main text, i.e., for the generalized Kondo (gK)\nmodel with S = 1/2 localized spins, U/t = JH/t = 20,\nL = 200 sites, and Tz\ntot = 0 magnetization sector. Here\nn\u2113 = n\u2113\u2191 +n\u2113\u2193. In Fig. 17, we present N(q, \u03c9) for various\nelectron densities n. It is important to note that the total\nenergy span of N(q, \u03c9), and even the bottom of N(q, \u03c9),\nlies much above the spin excitations bandwidth WS. Our results indicate a perfect agreement between\nN(q, \u03c9) obtained within the gK model in the JH \u226b t\nlimit and the free-fermion solution. Specifically, for non-\ninteracting spinless electrons, one can evaluate the charge\nstructure factor N(q, \u03c9) exactly [98, 99]. Such calcula-\ntions are equivalent to the Stoner continuum of the form\n\u03c9Sff(q) = \u03c9ff(k1) \u2212 \u03c9ff(k2) , (A2)\nwhere q = mod ( k1 + k2, L), k1 > kF, and k2 < kF, and\nthe free-fermion band \u03c9ff(q), Eq. (6). Note that within\nStoner-like considerations, one of the bands in (A2) rep-\nresents \u03c3 =\u2191 electrons, while the second band represents\n\u03c3 =\u2193 electrons. The above perfect agreement between\nthe noninteracting solution \u03c9Sff(q) and full many-body\ncalculations of N(q, \u03c9) within the gK model (2) in the\nJH/t \u226b 1 limit indicates that the charge fluctuations are\nindifferent to the incoherent band of excitations.", "metadata": {"type": "factual", "source": "2503.01277v1.pdf", "context": "structure factor defined as\nN(q, \u03c9) = 1\nL\nX\n\u2113\nei(\u2113\u2212L/2)q \u27e8\u27e8n\u2113nL/2\u27e9\u27e9\u2212\n\u03c9 , (A1)\nfor the system parameters discussed in Fig. 1 and Fig. 4\nof the main text, i.e., for the generalized Kondo (gK)\nmodel with S = 1/2 localized spins, U/t = JH/t = 20,\nL = 200 sites, and Tz\ntot = 0 magnetization sector. Here\nn\u2113 = n\u2113\u2191 +n\u2113\u2193. In Fig. 17, we present N(q, \u03c9) for various\nelectron densities n. It is important to note that the total\nenergy span of N(q, \u03c9), and even the bottom of N(q, \u03c9),\nlies much above the spin ", "quality_score": 8.5}}
{"id": "test_47", "question": "What type of controllers is shown in Fig. 2 for force-feedback-enabled teleoperation?", "golden_answers": ["Three types: trigger, roller, and parallel clip"], "prediction": "Trigger-based control, roller-based control, and parallel clip-based control.", "f1": 0.26666666666666666, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01301v1\nlow effort Unstable at travel limits\n(thumb tip only)\nTrigger Low effort, stable control Limited range of motion\nParallel Clip Stable control High effort, limited range\nof motion\nTABLE II: Comparison of Three Force Feedback Controllers\nas example) with force feedback can reduce the execution time\nby about 4 seconds in most of the tasks (Fig. 4). When using a controller without force feedback, the oper-\nator needs extra time to confirm they complete a successful\ngrasping when they are required to control the displacement\nof the gripper more precisely rather than simply let it close. While the linear force feedback, which is introduced in III,\nserves as a real-time supplement for the operator to adjust\ntheir movement on the controller. Moreover, we found that\neven simple 0-1 feedback which represents whether the gripper\nis in contact with objects can be important information for\noperators to improve efficiency. C. Discussion and Limitation\nThe value of the pipeline, simulation teleoperation demon-\nstration combined with real world data fine-tuning, is by using\na high-fidelity visual engine and force feedback teleoperation\ndevice, human operators can collect task data efficiently with-\nout the need for high-cost, large-scale hardware equipment\nand environment deployment. Only small number of real-\nworld demonstration is needed for fine-tuning to improve\nits performance in specific scenarios. While this method is\nverified to enable few-shot sim2real tranfer and reduces human\n\nlabor as well as resources needed for collecting large-scale\nreal-world demonstration, whether zero-shot transfer can be\nachieved with nearly photorealistic rendering is still an open\nquestion. In terms of force feedback, we argue that it is more\nimportant in simulation than in real teleoperation, since real\nworld contains more information like the visual deformation\nof real objects, the sound produced by contact, etc. which can\nhardly be simulated. So that human operators can infer the\nstate of interaction in real world while it\u2019s far more diffucult\nto do such inference in simulation environment. Besides, we\nobserved that incorporating a linear force transmission model\n(Algorithm 1) enhances the imitation learning policy\u2019s ability\nto handle soft and fragile objects more effectively. Algorithm 1 Contact Force Estimation\n1: for contact ci in simulation do\n2: ni \u2190 ci.geometry.name\n3: if ni = \u201dfinger left\u201d OR ni = \u201dfinger right\u201d then\n4: c.push(ci)\n5: end if\n6: end for\n7: if \u201dfinger left\u201d in c AND \u201dfinger right\u201d in c then\n8: qe0 \u2190 fingerpos.read ()\n9: end if\n10: F \u2190 k(qe \u2212 qe0) Besides, as we add grasping force as an addtional input\nof the model, which was mentioned in III, segmentation\ncharacteristics are shown in tasks. Take picking and placing\nas example, If the object is not grasped successfully at the\nexpected position, the model will stay in place and try back\nand forth instead of following the trajectory to try to place the\nobject in the box. Although this is also what is expected to\nbe understood from the wrist camera information, we believe\nthat the grasping force is a feature that is easier to learn here.\n\n2503.01271v1\n[54], the former \"measures motion and displays force,\" and the latter \"measures force and displays\nmotion\" [55]. The impedance controller regulates the dynamic interaction between a robot and a user by controlling\nthe mechanical impedance of a haptic interface while tracking a desired motion defined by user input. Thus, it can\nbe expected that the device will need to be back-drivable or have a zero force/torque controller implemented on the\njoint level to allow motion to happen before applying force to the user. Unlike impedance control, admittance control\nregulates the motion of a robot based on desired position and velocity commands derived from user input force (fig.9). The choice between impedance or admittance control depends on the pHRI that developers want and the hardware\nthey are using. Impedance control is often preferred for rendering low inertia, while admittance control is favored for\nFigure 7: Left: Simplified block diagram of the power delivery system for one motor unit. The 208V AC high power\nline and 24 VDC power line are colored black and green, respectively. The red line is the signal input to control the\nE-STOP relay. Middle: Interior of the power delivery system. From top to bottom are fuses, contactors, motor drives,\nand a 24V power supply (left). The circuit breakers are installed next to the power outlet, which is not shown in this. Right: On-site operation panel of the power delivery system. From the top to bottom are an emergency stop (red), a\nmotor drive switch (yellow), and motor power switches (green). 8\n\nDevelopment of the Locomotion Interface\nrendering stiff surfaces but not low inertia [50]. An admittance controller is implemented in this work for its advantage\nof displaying a stiff surface with the non-back-drivability inherent in the system. A locomotion device has two primary tasks for different gait phases: displaying a virtual ground in the stance phase\nor rendering low inertia (free-motion) during the swing phase. The presented work implements an admittance controller\nto achieve both task objectives. The admittance controller changes the output velocity of the foot platform to regulate\nthe interaction force with the user, as shown in figure 9. Since the actuators in this device are highly non-backdrivable,\nan admittance controller can be directly implemented without further modification compared to an impedance controller. The admittance controller generates velocity commands to follow the user\u2019s motion according to the input forces during\nthe swing phase and tunable virtual mass and damping parameters. During stance phase, the desired velocity on the\nZ-axis is directly commanded to be zero to simulate a virtual ground. The admittance controller can be described as\nfmea = mv \u02d9vd + cvvd , (1)\nwhere mv and cv represent the virtual mass and virtual damping,fmea is the measured interaction force. The admittance\ncontroller Yv acts as a reference model and generates the desired velocity trajectory vd subject to the interaction force\nFigure 8: System framework block diagram that made of three segment: (i) a central computer, (ii) the robotic sub-\nsystems, and (iii) an external computer.\n\n2503.01301v1\nAlthough sim-to-real-based pick-and-place\nhas achieved impressive results [26, 27, 28], it still heavily\nrelies on various sim-to-real techniques, including domain\nrandomization of forces[29], tactiles[30], and images[31, 32],\ncalibration and fine-tuning using real-world data[33, 8], or\ndirectly improving force simulation accuracy[34]. It is well-\nknown that simulation physics engines still struggle to ac-\ncurately model contact forces. In contrast, image engines\nhave reached the point where they can achieve near-real-time\nrendering effects, such as those seen in Isaac Sim, Unity, and\nUnreal Engine. While sim2real transfer is still essential for\nachieving better performance in real-world scenarios in task\ngeneralization and success rate, our goal here is to explore\nthe extent to which a visual engine can compensate for the\nsim2real gap introduced by imperfect physics engines, espe-\ncially during the age that real2sim is fast improving [35, 36]. III. M ETHODS To validate and demonstrate our hypothesis of training\ndirectly on simulation-collected data and transferring the\nlearned policy to a real robot, our method consists of three\nkey components for achieving few-shot sim-to-real transfer: a\nteleoperation system with force feedback, a force estimation\nmethod in simulation, and an imitation learning algorithm. A. Force Feedback Teleoepration System\nThe teleoperation system consists of a scaled leader-\nfollower teleoperation structure and a roller with force feed-\nback. The leader-follower mechanism is a passive robotic arm\nthat is scaled down by a factor of \u03b10 = 0.5 relative to the\nFanuc robotic arm at the slave side. It maintains an identical\nkinematic topology with the slave robot. Since each joint is\nactuated by an encoded servo motor, we do not provide direct\njoint force feedback; however, we implement basic gravity\ncompensation via a PID controller at each joint. Since a two-finger gripper is sufficient for executing most\ntasks, our teleoperation system focuses on controlling a two-\nfinger end-effector. To improve task success rates and maintain\nreasonable gripping forces, we design three types of force-\nfeedback-enabled one-degree-of-freedom controllers (Fig. 2),\nnamely trigger-based control, roller-based control, and parallel\nclip-based control. Each of these controllers has a linear\nmapping between displacement and gripper width, represented\nas qe = \u03b1\u02c6qe, where the human operator controls the gripper\nwidth using the trigger angle, roller rotation, or parallel clip\ndisplacement. Additionally, utilizing the servo motor\u2019s force\ncontrol mode, the gripping force of the robot\u2019s end-effector\ncan be fed back to the teleoperation device as \u02c6Fe = \u03b2Fe,\n\nFig. 2: Three types of the single dof controllers for force-feedback-\nenabled teleoperation. The arrows annotate the motion direction of\nthe controllers\u2019 degree of freedom. Both the trigger and the roller are\nconcentric with the servo motor, while the parallel clip has a simple\nscissor structure to transform the force.\nwhere \u02c6Fe represents the force feedback applied to the operator. In the experimental section, we further analyze the advantages\nand disadvantages of using these three different teleoperation\ndevices. B. Imitation Learning for Few-Shot Sim-to-Real Transfer\nIn this work, we collect robotic manipulation data from\nboth simulation and real-world execution via teleoperation.", "metadata": {"type": "factual", "source": "2503.01301v1.pdf", "context": "Fig. 2: Three types of the single dof controllers for force-feedback-\nenabled teleoperation. The arrows annotate the motion direction of\nthe controllers\u2019 degree of freedom. Both the trigger and the roller are\nconcentric with the servo motor, while the parallel clip has a simple\nscissor structure to transform the force.\nwhere \u02c6Fe represents the force feedback applied to the operator.\nIn the experimental section, we further analyze the advantages\nand disadvantages of using these three different te", "quality_score": 8.5}}
{"id": "test_48", "question": "What is a necessary condition for providing a feasible solution to the D-MCLP problem?", "golden_answers": ["The attacker problem A-MCLP must be solved optimally for a given set X of facility locations."], "prediction": "The attacker problem A-MCLP must be solved optimally for a given set X of facility locations.", "f1": 1.0, "em": 1.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01042v2\nIf (\u00af\u03bd, \u00af\u03be, \u00af\u03c8) \u2208 M +(Rd) \u00d7 M+(T \u00d7\nRd \u00d7 A) \u00d7 C1,2\nb (T \u00d7 Rd) satis\ufb01es the following linear equations:\n\uf8f1\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f2\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f3\n\u222b\nRd\ng(x,\u00b5T)\u00af\u03bd(dx) +\n\u222b\nT\u00d7Rd\u00d7A\nf(t,x,a,\u00b5 t)\u00af\u03be(dt,dx,da) =\n\u222b\nRd\n\u00af\u03c8(0,x)\u03c1(dx),\n\u222b\nRd\n\u03c8(T,x)\u00af\u03bd(dx) \u2212\n\u222b\nRd\n\u03c8(0,x)\u03c1(dx)\n=\n\u222b\nT\u00d7Rd\u00d7A\n((\nL\u00b5 \u03c8\n)\n(t,x,a ) + ( \u2202t\u03c8)(t,x)\n)\n\u00af\u03be(dt,dx,da), \u2200\u03c8\u2208 W ,\ng(x,\u00b5T) \u2265 \u00af\u03c8(T,x), \u2200x\u2208 Rd,\n\u2202t \u00af\u03c8(t,x) +\n(\nL\u00b5 \u00af\u03c8\n)\n(t,x,a ) + f(t,x,a,\u00b5 t) \u2265 0, \u2200(t,x,a ) \u2208 T \u00d7 Rd \u00d7 A,\n(4.4a)\n(4.4b)\n(4.4c)\n(4.4d)\nthen (\u00af\u03bd, \u00af\u03be) \u2208 arg min(\u03bd,\u03be)\u2208DP (\u00b5 ) J\u00b5\nP(\u03bd,\u03be) and \u00af\u03c8\u2208 arg max\u03c8\u2208DP \u2217 (\u00b5 ) J\u00b5\nP\u2217 (\u03c8). 11\n\nProposition 4.4 follows directly from Proposition 4.3: Condition ( 4.4b) ensures that (\u00af \u03bd, \u00af\u03be) is\na feasible solution to the primal problem, Conditions ( 4.4c) and ( 4.4d) guarantee that \u00af\u03c8 is a\nfeasible solution to the dual problem, and Condition ( 4.4a) implies (\u00af\u03bd, \u00af\u03be) and \u00af\u03c8 yield the same\nvalue, which ensures the optimality of (\u00af \u03bd, \u00af\u03be, \u00af\u03c8) due to the weak duality property. To provide a veri\ufb01cation theorem for the NEs of the MFG, obser ve that the consistency\ncondition in De\ufb01nition 2.1 can be enforced by replacing \u00b5 in Proposition 4.4 with the state\nmarginal law of \u00af\u03be. Consequently, we can obtain a veri\ufb01cation theorem for an NE of the MFG\nthrough solutions of a primal-dual system. Theorem 4.5 (Primal-dual formulation of MFG) . Suppose (H. 1) holds. Let \u00b5 \u2217 \u2208 P (Rd|T) be\nnarrowly continuous, \u03be\u2217 \u2208 M +(T \u00d7 Rd \u00d7 A), and \u03c8\u2217 \u2208 C1,2\nb (T \u00d7 Rd). If (\u00b5 \u2217,\u03be\u2217,\u03c8\u2217) satis\ufb01es the\nfollowing primal-dual system:\n\uf8f1\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f2\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f3\n\u222b\nRd\ng(x,\u00b5\u2217\nT)\u00b5\u2217\nT(dx) +\n\u222b\nT\u00d7Rd\u00d7A\nf(t,x,a,\u00b5 \u2217\nt)\u03be\u2217(dt,dx,da) =\n\u222b\nRd\n\u03c8\u2217(0,x)\u03c1(dx),\n\u222b\nRd\n\u03c8(T,x)\u00b5\u2217\nT(dx) \u2212\n\u222b\nRd\n\u03c8(0,x)\u03c1(dx)\n=\n\u222b\nT\u00d7Rd\u00d7A\n((\nL\u00b5 \u2217\n\u03c8\n)\n(t,x,a ) + ( \u2202t\u03c8)(t,x)\n)\n\u03be\u2217(dt,dx,da), \u2200\u03c8\u2208 W ,\ng(x,\u00b5\u2217\nT) \u2265 \u03c8\u2217(T,x), \u2200x\u2208 Rd,\n\u2202t\u03c8\u2217(t,x) +\n(\nL\u00b5 \u2217\n\u03c8\u2217)\n(t,x,a ) + f(t,x,a,\u00b5 \u2217\nt) \u2265 0, \u2200(t,x,a ) \u2208 T \u00d7 Rd \u00d7 A,\u222b\nT\u00d7Rd\n\u03c8(t,x)\u00b5\u2217\nt(dx)dt=\n\u222b\nT\u00d7Rd\u00d7A\n\u03c8(t,x)\u03be\u2217(dt,dx,da), \u2200\u03c8\u2208 W ,\n(4.5a)\n(4.5b)\n(4.5c)\n(4.5d)\n(4.5e)\nthen \u03c8\u2217 \u2208 arg max\u03c8\u2208DP \u2217 (\u00b5 \u2217 ) J\u00b5 \u2217\nP\u2217 (\u03c8), and there exists a process X\u2217 such that (\u00b5 \u2217,X\u2217,\u03b3\u2217) \u2208\nP(Rd|T) \u00d7 A cl(\u00b5 \u2217) is an NE, with \u03b3\u2217 \u2208 P (A|T \u00d7 Rd) being the disintegration kernel of \u03be\u2217 in\nLemma\n3.2. Remark 4.2.\n\n2503.01350v1\nTo achieve this, we follow the steps outlined below:\nIdentification of redundant edges: When solving the D-MCLP, any edges e \u2208 E in\nthe original network with lengths exceeding R can be safely removed without im-\npacting the optimal solution. Consequently, their associated costs and upper bounds\ncan also be removed, i.e., ce and ue. Tightening downgrading upper bounds ( u): The attacker\u2019s objective is to compro-\nmise the leader\u2019s coverage. Thus, when the distance from the facility to the client\nequals R, the attacker achieves its goal. Consequently, if there exists an edge e \u2208 E\nwhose length plus the upper bound exceeds R, i.e., \u2113e + ue \u2265 R the upper bound\ncan be tightened as follows:\nue = R \u2212 \u2113e.\nTherefore, removing all these edges eliminates numerous constraints from the formu-\nlation. Additionally, reducing the upper bounds of the \u03b3 variables improves the bounds\nof the formulation. In the following, unless stated otherwise, we refer to BL-D-MCLP as\nthe bilevel formulation where these enhancements have been applied. As reported in Section 5, this strategy is useful for solving exactly our problem on the\ngeneral purpose solver for bilevel programming (Fischetti et al., 2017), since it notably\nreduces the number of constraints. Furthermore, it also benefits the matheuristic that is\nintroduced in the following section. 4 Matheuristics 14\n4 Matheuristics\nThe proposed heuristic approach is based on generating feasible solutions. In this sense, it\nis worth mentioning that to provide a feasible solution of D-MCLP, the attacker problem\nA-MCLP must be solved optimally for a given set X of facility locations. Otherwise, the\nsolution may not be feasible. However, as the next lemma shows, finding the optimal edge\nlength increases for a given X is NP-hard. Lemma 3 Given a setX of facility locations, solving A-MCLP is NP-hard even on star\nnetworks for non-uniform weights assuming uniformity in downgrading costs and upper\nbounds as well as integrality of the input parameter values. Proof. See Appendix A. Therefore, we first focus on improving the formulation of the attacker problem. Let a\nset X of facility locations be given. Then, we define the set V := {i \u2208 V : \u03c1i = 1}, i.e., the\ncovered nodes in the original network. Note that \u03c1i can be computed easily for a given\nX, e.g. using Dijkstra\u2019s algorithm starting from each x \u2208 X. Below, for any m \u2208 V , we\ndefine some sets that can be used to reduce the number of constraints of the formulation. V m := {i \u2208 V : d(i, m) < R},\nA[V m] := {(k, l) \u2208 A : k, l\u2208 V m}. The first set includes the nodes that can be covered by m (before downgrading) while the\nsecond comprises the arcs that can be used for this covering. For the ease of exposition,\nwe rewrite the formulation for the middle level problem:\nmax\nX\ni\u2208V\nwi\u03b7i\ns.t. (19), (23) ,\nR\u03b7i \u2264 \u03c0i, i \u2208 V , (40)\n\n2503.00098v1\n(14), (ii) derive one set of homogeneous solutions\nsetting \u03c9 = 0, and (iii) combine them to find the set of\nphysical solutions with identical values of K. Leaving\naside the computational burden, this does not give an\ninsight into which differential equation governs the value\nof K and hence Q. If our purpose is only to obtain the quadrupole mo-\nment, we may introduce a new variable\nq(r) = v2(r) + f(r)h2(r), (18)\nwhich obeys\ndq\ndr = dv2\ndr + f dh2\ndr + df\ndr h2. (19)\nBy imposing that the right-hand side depend on h2 and\nv2 only via q, the auxiliary functionf is fixed to a solution\nof\ndf\ndr = \u2212 2\nm + 4\u03c0P r3 f2\n+\n\u001a\n2d\u03bd\ndr \u2212 r2\nm + 4\u03c0P r3\n\u0014\n4\u03c0(e + P) \u2212 2m\nr3\n\u0015\u001b\nf + 2d\u03bd\ndr . (20)\nWe would also like to impose the condition at the center\nf(r \u2192 0) = 2\u03c0\n3 (ec + 3Pc)r2, (21)\nso that the regularity condition Eq. (14) directly applies\nto q(r), specifically,\nq(r \u2192 0) = 2\u03c0\n3 (ec + Pc)\u03c92\nce\u22122\u03bdc r4. (22)\nThese requirements uniquely determine f(r) and hence\nq(r). We may further simplify the problem by changing the\nvariable to \u02dcq := q/(\u03c9r)2, with which \u2126 again scales out\nfrom the problem. This dimensionless variable is deter-\nmined by solving\nd\u02dcq\ndr = \u2212\n\u0014 2f\nm + 4\u03c0P r3 + 2(w + 1)\nr\n\u0015\n\u02dcq\n+ j2w2\n6\n\u001ad\u03bd\ndr + 1\nr +\n\u0014d\u03bd\ndr \u2212 1\n2(m + 4\u03c0P r3)\n\u0015\nf\n\u001b\n+ 8\u03c0(e + P)r3j2\n3(r \u2212 2m)\n\u001ad\u03bd\ndr + 1\nr +\n\u0014d\u03bd\ndr + 1\n2(m + 4\u03c0P r3)\n\u0015\nf\n\u001b\n,\n(23)\nwhere j := e\u2212(\u03bd+\u03bb), starting from the regularity condi-\ntion\n\u02dcq(r \u2192 0) = 2\u03c0\n3 (ec + Pc)e\u22122\u03bdc r2. (24)\n\n4\nThe integration constant K is readily determined by the\nsurface values \u02dcqs = \u02dcq(r = R) and fs = f(r = R). In particular, the normalized quadrupole moment Q :=\nQ/(\u03c72M3), where \u03c7 := J/M2 is the spin parameter, is\nexpressed as\nQ = 1 + 8\n5\n\"\n2Q1\n2(\u03b6s)p\n\u03b62s \u2212 1\n+ fsQ2\n2(\u03b6s)\n#\u22121\n\u00d7\n(\u0000\n1 \u2212 2C3I\n\u00012\nC2I\n2 \u02dcqs + C4\n\u0014\n1 \u2212\n\u0012\n1 + 1\nC\n\u0013\nfs\n\u0015)\n. (25)\nWhile this expression depends not only on \u02dcqs but also on\nfs due to the obvious dependence of q on f, we regard \u02dcq\nas the primary variable that determines the value of K\nand hence Q. The reason for this includes the (interde-\npendent) facts that (i) q is directly related to the metric\nperturbations v2 and h2, (ii) d\u02dcq/dr includes nonlinear\nsource terms w2, and (iii) d\u02dcq/dr includes df/dr. In fact,\nEq. (25) also depends on ws via I, rendering unambigu-\nous identification of the key variable for Q difficult. III. NUMERICAL RESULT\nA.", "metadata": {"type": "factual", "source": "2503.01350v1.pdf", "context": "4 Matheuristics 14\n4 Matheuristics\nThe proposed heuristic approach is based on generating feasible solutions. In this sense, it\nis worth mentioning that to provide a feasible solution of D-MCLP, the attacker problem\nA-MCLP must be solved optimally for a given set X of facility locations. Otherwise, the\nsolution may not be feasible. However, as the next lemma shows, finding the optimal edge\nlength increases for a given X is NP-hard.\nLemma 3 Given a setX of facility locations, solving A-MCLP is NP", "quality_score": 8.5}}
{"id": "test_49", "question": "Why is it impractical to find the optimal edge length increases for a given X in the context of solving A-MCLP?", "golden_answers": ["Because finding the optimal edge length increases for a given X is NP-hard, as shown in Lemma 3."], "prediction": "Finding the optimal edge length increases for a given X is impractical because it is NP-hard.", "f1": 0.7333333333333334, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01350v1\nTo achieve this, we follow the steps outlined below:\nIdentification of redundant edges: When solving the D-MCLP, any edges e \u2208 E in\nthe original network with lengths exceeding R can be safely removed without im-\npacting the optimal solution. Consequently, their associated costs and upper bounds\ncan also be removed, i.e., ce and ue. Tightening downgrading upper bounds ( u): The attacker\u2019s objective is to compro-\nmise the leader\u2019s coverage. Thus, when the distance from the facility to the client\nequals R, the attacker achieves its goal. Consequently, if there exists an edge e \u2208 E\nwhose length plus the upper bound exceeds R, i.e., \u2113e + ue \u2265 R the upper bound\ncan be tightened as follows:\nue = R \u2212 \u2113e.\nTherefore, removing all these edges eliminates numerous constraints from the formu-\nlation. Additionally, reducing the upper bounds of the \u03b3 variables improves the bounds\nof the formulation. In the following, unless stated otherwise, we refer to BL-D-MCLP as\nthe bilevel formulation where these enhancements have been applied. As reported in Section 5, this strategy is useful for solving exactly our problem on the\ngeneral purpose solver for bilevel programming (Fischetti et al., 2017), since it notably\nreduces the number of constraints. Furthermore, it also benefits the matheuristic that is\nintroduced in the following section. 4 Matheuristics 14\n4 Matheuristics\nThe proposed heuristic approach is based on generating feasible solutions. In this sense, it\nis worth mentioning that to provide a feasible solution of D-MCLP, the attacker problem\nA-MCLP must be solved optimally for a given set X of facility locations. Otherwise, the\nsolution may not be feasible. However, as the next lemma shows, finding the optimal edge\nlength increases for a given X is NP-hard. Lemma 3 Given a setX of facility locations, solving A-MCLP is NP-hard even on star\nnetworks for non-uniform weights assuming uniformity in downgrading costs and upper\nbounds as well as integrality of the input parameter values. Proof. See Appendix A. Therefore, we first focus on improving the formulation of the attacker problem. Let a\nset X of facility locations be given. Then, we define the set V := {i \u2208 V : \u03c1i = 1}, i.e., the\ncovered nodes in the original network. Note that \u03c1i can be computed easily for a given\nX, e.g. using Dijkstra\u2019s algorithm starting from each x \u2208 X. Below, for any m \u2208 V , we\ndefine some sets that can be used to reduce the number of constraints of the formulation. V m := {i \u2208 V : d(i, m) < R},\nA[V m] := {(k, l) \u2208 A : k, l\u2208 V m}. The first set includes the nodes that can be covered by m (before downgrading) while the\nsecond comprises the arcs that can be used for this covering. For the ease of exposition,\nwe rewrite the formulation for the middle level problem:\nmax\nX\ni\u2208V\nwi\u03b7i\ns.t. (19), (23) ,\nR\u03b7i \u2264 \u03c0i, i \u2208 V , (40)\n\n2503.01350v1\nThe\noptimal objective value is an upper bound D-MCLP, as it is evident that the leader\ncan cover at most this demand. We call the corresponding set of facility locations\nXUB . Note that this downgrading strategy will likely not be optimal for the attacker\n\n4.1 Alternating Location-Downgrading Search 16\nfor values of B larger than 0. Basically, this upper bound can be obtained by solving\nthe attacker problem with B = 0. Our heuristic is split into two phases: a construction phase (alternating location-downgrading\nsearch) and an improvement phase (1-1 local search). 4.1 Alternating Location-Downgrading Search In this subsection, we describe the first phase of the algorithm: the alternating location-\ndowngrading search. This is a repetitive approach where we continuously build feasible\nsolutions in a series of iterations until no further improvements can be achieved or a\nmaximum number of iterations have been reached. The steps are described below:\nStep 0 Propose a promising set X of facility locations. Step 1 Solve the attacker problem A-MCLP for given locations X to get an optimal\ndowngrade \u03b3. X and \u03b3 constitute a feasible solution of D-MCLP. Step 2 Solve the classical MCLP in N(\u03b3) to obtain an optimal set of locations X.\nStep 3 If X has not changed from the previous iteration or the maximum number of\niterations has been reached, then stop; otherwise, return to Step 1. We start this alternating location-downgrading search from the following promising sets\nof facility locations (we depict the \u201ccode\u201d of the strategy in brackets). We choose X as an\noptimal solution of the classical MCLP in the network N(\u03b30), where \u03b30 is: (0) \u03b30\ne = 0, e \u2208\nE, i.e., X = XLB, (1) \u03b30\ne = ue, i.e., X = XUB , (2) \u03b30\ne = min\nn\nB\n|E|, ue\no\n, i.e., proportional to\nthe budget and inversely proportional to the number of edges, (3)\u03b30\ne = min\nn\nueBP\ne\u2208E ue\n, ue\no\n,\ni.e., proportional to the budget and the upper bounds, (4) proportional to the benefit-cost\nratio, i.e., downgrade the cheapest edges first until reaching the budget, (5,6,7) solve the\nclassical MCLP considering 80% R, 70%R, 60%R, respectively, and (8) \u03b30\ne = ue/2, e\u2208 E,\ni.e., all the edges have been downgraded to half of their maximum. We run the alternating location-downgrading search with each of the eight starting\nsolutions and we keep the best set of locations X and their corresponding optimal down-\ngrades \u03b3.\n4.2 1-1 Local Search\nOnce the previous iterative process has finished with a feasible solution X and \u03b3, we\ndeveloped a 1-1 local search to improve this solution by substituting one facility location in\nX. For doing so, we look for a node i \u2208 X to be removed as facility and we compute which\n\n4.2 1-1 Local Search 17\nis the most promising node j \u0338\u2208 X to be included. This local search is repeated as long as\nbetter feasible solutions are found, or up to a fixed number of iterations.\n\n2503.01350v1\nThe D-MCLP is also closely related to interdiction problems (Fischetti et al., 2019,\nO\u2019Hanley and Church, 2011, Ramamoorthy et al., 2024, Smith and Song, 2020, Smith et al.,\n2013). While we propose increasing the length of one or more edges in the D-MCLP, inter-\ndiction problems usually consider the case of removing edges/arcs instead. The covering-\ninterdiction problem (Fr\u00a8 ohlich and Ruzika, 2021), in which the first player (the location\nplanner) locates some facilities in a network to maximise the amount of demand covered by\nthe facilities, and the second player, called the interdictor, disrupts the infrastructure by\nremoving at most a given number of edges in the network to reduce the coverage as much\nas possible. Their paper is focused on analysing the problem\u2019s complexity. Observe that\nthe interdiction action in this context is a particular case of downgrading, where the length\nof an interdicted edge is increased to a value greater than the covering radius. Similarly,\ngiven a subset of nodes chosen as facilities, the reachability-interdiction problem (Fr\u00a8 ohlich\nand Ruzika, 2022) studies the problem where an interdictor can remove a set of edges to\nprevent as many vertices as possible from reaching a facility. A node can no longer reach\na facility after removing edges if no facility is located in the connected component it be-\nlongs to. Furthermore, Cappanera and Scaparra (2011) propose a multilevel program for\nallocating protection resources among the components of a shortest-path network so as to\nmaximize its robustness to external disruptions. Regarding the shortest path interdiction\n\n1.2 Overview 4\nproblem, Smith et al. (2013) considers the situation where the attacker seeks to maximize\nthe length of a shortest s-t-path by either increasing the cost of some arcs or by deleting\narcs altogether. A similar version of this shortest path interdiction problem appears as a\ncomponent of our problem from the attacker\u2019s perspective. The most vital elements for\nthe p-median and p-center problems (Bazgan et al., 2013) are also slightly related since a\nfixed number of edges are removed to provide their worst objective values. Finally, it is\nworth mentioning the Maximal Covering Location Disruption Problem (Lunday, 2024), a\nzero-sum game where the leader seeks to disrupt the MCLP solution by making a subset of\nthe possible facility locations unavailable. Note that the design of robust networks against\nattacks has been studied from a game-theoretic approach for a wide range of problems, as\nfor example in Perea and Puerto (2013). 1.2 Overview\nThe main contribution of this paper are:\n\u2022 The first model, (D-MCLP), to deal with continuous edge downgrades in the Maxi-\nmal Covering Location Problem is introduced. A mixed-integer linear bilevel formu-\nlation is proposed which is the reformulation of an intuitive three-level formulation. \u2022 A strategy to preprocess the data to reduce the number of variables and constraints\nof the formulation is introduced. Moreover, strategies to improve the formulation of\nthe attacker\u2019s problem given the location of the facilities are proposed. \u2022 A matheuristic algorithm to solve the problem is developed.", "metadata": {"type": "reasoning", "source": "2503.01350v1.pdf", "context": "4 Matheuristics 14\n4 Matheuristics\nThe proposed heuristic approach is based on generating feasible solutions. In this sense, it\nis worth mentioning that to provide a feasible solution of D-MCLP, the attacker problem\nA-MCLP must be solved optimally for a given set X of facility locations. Otherwise, the\nsolution may not be feasible. However, as the next lemma shows, finding the optimal edge\nlength increases for a given X is NP-hard.\nLemma 3 Given a setX of facility locations, solving A-MCLP is NP", "quality_score": 8.5}}
{"id": "test_50", "question": "What is the purpose of using t-SNE in Figure 4?", "golden_answers": ["to visualize the representations of input sentences and analyze the impact of DFT on aligning cross-lingual representations"], "prediction": "The purpose of using t-SNE in Figure 4 is to visualize the feature space and illustrate improved clustering and alignment of tactile features across domains before and after applying the M2M model, demonstrating its effectiveness in reducing gaps.", "f1": 0.2, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01058v1\nAdditionally, we visualize the feature space of image pairs using t-SNE\n(Fig. 3e). While original image pairs from any combination show clear separation,\npost-translation pairs align closely in latent space, indicating that generated images\nbecome effectively indistinguishable from their target domain counterparts. Additional\nvisualized image pairs are available in Extended Data Figure. Homogeneous tactile force sensation\nRobot hands equipped with homogeneous tactile sensors have been extensively studied\nin both the research community [63, 64] and commercial products [65]. In this context,\nwe evaluate our proposed model for transferring force sensation across homogeneous\ntactile sensors, particularly GelSight sensors with varying configurations. We fabri-\ncate three GelSight sensors with different illumination and marker patterns ( Array-I,\nCircle-I, Diamond-I ) and introduce elastomer shifts to replicate long-term usage by\nmoving or rotating Array-I and Circle-I, resulting in Array-II and Circle-II. The real-\nworld data collection setup is shown in Fig. 4a, and the fabrication process for silicone\nelastomers with different marker patterns is illustrated in Fig. 4c. The detailed data\ncollection trajectory is described in the Methods. Fig. 4b demonstrates the movement\nof a single contact point, covering both force increase and decrease phases in the normal\nand shear directions. For the experiments, we capture sequential tactile images, force\n9\n\nFig. 3 Marker-to-marker translation in simulation . a, The pretrained M2M translation model\nis developed through three key steps: arbitrary marker deformation simulation, curation of a marker\ndeformation simulation dataset, and pretraining of the M2M translation model. b, The pipeline (i-\nvii) for simulating marker deformation generates synthetic datasets with arbitrary deformed markers\nthat are used to pre-train and evaluate the M2M model. c-d, Quantitative evaluation of the marker-\nto-marker translation is presented using heatmaps of FID and KID (d), comparing performance\nbefore (i) and after (ii) applying the M2M model on a simulation dataset comprising 132 different\ncombinations. e, Feature space visualization using t-SNE illustrates improved clustering and alignment\nof tactile features across domains before (i) and after (ii) applying the M2M model, demonstrating its\neffectiveness in reducing gaps. Notably, the row labels denote S while column labels denote T in c-e. 10\n\nlabels, and contact poses. In addition to collecting data using a 3D support mounted\non a robot arm (Fig. 4a) for Array-II, Circle-II, and Diamond-I, we also collect data\nusing a simpler method by grasping the indenters with a ROBOTIQ two-finger grip-\nper to compare the effects of installation methods on force prediction. The collected\nforce range covers normal forces from 0 N to 18 N and shear forces from -4 N to 4 N. To generate marker-based binary tactile images from RGB images, we utilize\nmarker segmentation (see Methods), with the resulting marker images shown in\nFig. 4d. Approximately 180,000 force-image pairs are collected per sensor for the homo-\ngeneous test, in which more than 30 tactile images are continuously collected at each\ncontact point. For fine-tuning, we use only four contact images (the final images during\nthe force increase and decrease phases), resulting in 17,280 location-paired images per\nsensor, which are ten folds less compared with force-image pairs.\n\n2503.00080v1\nThe t-SNE and UMAP visualizations for EEGNet (Figure 4a) indicate a moder-\nate degree of separation between target and non-target samples, but the distributions\nexhibit considerable overlap. This suggests that EEGNet\u2019s feature representations do\n13\n\n(a) Feature space visualization of EEGNet for Subject 9 in PhysioP300 dataset using t-SNE and UMAP. (b) Feature space visualization of QEEGNet for Subject 9 in PhysioP300 dataset using t-SNE and UMAP. Fig. 5 Comparison of feature space visualization of EEGNet and QEEGNet for Subject 9 in the\nPhysioP300 dataset using t-SNE and UMAP. (a) EEGNet visualization, showing the learned feature\nseparability between target (blue) and non-target (red) samples. (b) QEEGNet visualization, demon-\nstrating improved clustering of target and non-target samples compared to EEGNet. The clearer\nseparation in QEEGNet\u2019s feature space suggests its enhanced ability to distinguish P300 responses,\nhighlighting its potential for more robust classification. not fully disentangle the two classes, potentially leading to misclassifications. In con-\ntrast, QEEGNet\u2019s feature space (Figure 4b) shows a more distinct separation between\ntarget and non-target samples, particularly in the UMAP projection. The improved\nclustering structure in QEEGNet suggests that its learned embeddings capture more\ndiscriminative information, allowing for better differentiation of EEG responses. The enhanced separability observed in QEEGNet\u2019s embedding space implies that\nit learns a more structured and class-specific representation of the EEG signals. This\naligns with the improved classification performance observed in the previous results,\nfurther supporting the hypothesis that QEEGNet\u2019s quantum-inspired architecture\n14\n\nfacilitates more effective feature extraction. The clearer distinction between target\nand non-target samples suggests that QEEGNet has a greater potential for robust\nclassification in EEG-based tasks. In summary, QEEGNet demonstrates competitive and, in many cases, superior\nperformance compared to EEGNet, particularly in recall and F1-score. While EEGNet\nretains advantages in precision in some datasets, QEEGNet\u2019s improvements in accu-\nracy and recall indicate that its quantum-inspired components contribute positively\nto EEG classification tasks. The results suggest that QEEGNet is particularly benefi-\ncial in scenarios where sensitivity to relevant signals is crucial, making it a promising\nalternative to conventional EEG decoding models. 4 Conclusion\nThis study explores the potential of integrating quantum machine learning into EEG\nsignal processing through QEEGNet, a hybrid model that extends EEGNet with quan-\ntum layers. Our experiments across multiple datasets indicate that while QEEGNet\ndemonstrates improvements in classification performance, particularly in recall and\nfeature space separability, its overall gains over conventional neural networks remain\nmoderate for the tested datasets. This suggests that the quantum-enhanced model does\nnot yet universally outperform classical deep learning approaches in EEG decoding. Despite these limitations, one key advantage of QEEGNet lies in its ability to\nachieve performance gains with only a linear increase in computational complex-\nity. Unlike many quantum models that introduce significant computational overhead,\nQEEGNet maintains efficiency, making it a viable approach for practical applications. This finding highlights that quantum-inspired modifications can enhance EEG feature\nextraction at a relatively low computational cost, which is a promising direction for\nfuture research.\n\nOverleaf Example\nMore importantly,\nsince NNNs emulate the nucleosynthesis datasets rather\nthan solving stiff ODEs, they could improve the nu-\nmerical stability of stellar models and lower their likeli-\nhood to crash by reducing the need for extremely short\ntimesteps. This approach could facilitate the development of im-\nproved CCSN progenitor models, allowing for a more\ncomprehensive exploration of the SN explosion mecha-\nnism. In particular, this will be of crucial importance\nfor multidimensional hydrodynamical simulations of SN\nexplosions, which typically rely on stellar evolution mod-\nels with small nuclear reaction networks as their starting\npoint (e.g., Fields 2022; Fujibayashi et al. 2024; Wang &\nPan 2024; Zingale et al. 2024). Furthermore, the models\ntrained on small timesteps could be useful in emulat-\ning nucleosynthesis during the explosion itself, though\nmight require larger nuclear reaction networks. While\ncovering the parameter space regime of the most com-\nmon CCSN and black hole progenitors (see Fig. 1), we\nnote that lower mass stars that explode in electron cap-\nture SNe 4 have lower central temperatures through-\nout the final stages of their evolution (e.g., Wang et al. 2024), and higher mass stars that undergo pulsational\npair instability SNe typically exhibit lower central densi-\nties (e.g., Woosley 2017; Renzo et al. 2020). As a result,\nour trained models are unsuitable for these scenarios;\nour work, however, could be readily extended to incor-\nporate them by using the same method (section 2). Integrating NNN trained models into stellar evolution\ncodes would require to split the burning from the stel-\nlar structure and mixing evolution, as already possible\nin mesa for high temperatures and densities using the\nsplit-operator (Jermyn et al. 2023). The NNNs would\nthen receive the isotopic abundances of each burning re-\ngion at a given timestep after rotation and convection\nmixed the composition obtained by NNNs in the previ-\nous timestep across regions. They would be used only\nfor burning regions with parameters within the training\n4 We note that modeling electron capture SNe requires large nu-\nclear reaction networks with an extensive net of weak reactoins\n(see e.g., Jones et al. 2013). 11\nregime, as fully-connected neural networks typically per-\nform poorly when extrapolating (e.g., Kim et al. 2020). It is essential to train models on additional timesteps\nand nuclear physics input, as well as conduct parallel\ntests alongside accurate solvers and assess the accumu-\nlation of NNN errors over multiple timesteps. Apart\nfrom monitoring the compounding errors in the predic-\ntions presented in Fig. 4, these tests should evaluate how\nwell energy is conserved in the stellar model, as NNNs\nemulate the energy terms without explicitly enforcing\nthermodynamic consistency. Generating more targeted training sets by extracting\nabundances from full stellar evolution models on a large\nscale could improve the accuracy of the NNN predictions\nand bring us closer to their implementation. However,\nthis would require stellar tracks from a large amount of\nstellar models throughout silicon core burning, which\nis computationally challenging due to the stiffness of\nthe nucleosynthesis ODEs.", "metadata": {"type": "factual", "source": "2503.01275v1.pdf", "context": "\u4e3b\u5b9e\u9a8c\n(a)  Before DFT (b)  After DFT\nFigure 4: t-SNE visualizations of sentence representations\nfrom FLORES-200 dataset by LLaMA-2 before and after\napplying DFT.\nAnalysis of Representation Alignment\nWe used the t-SNE (Van der Maaten and Hinton 2008)\nmethod to visualize the representations of input sentences\nto analyze the impact of DFT on aligning cross-lingual rep-\nresentations.\nSpecifically, we encoded parallel English and Chinese\nsentences from the FLORES-200 dataset and obtain sen-\ntence repre", "quality_score": 8.5}}
{"id": "test_51", "question": "How do the layer sparsity settings of EauDeDQN compare to those of PolyPruneDQN?", "golden_answers": ["The layer sparsity settings of EauDeDQN and PolyPruneDQN are identical, both having 0.5, 0.8 for each layer."], "prediction": "EauDeDQN achieves higher final sparsity levels compared to PolyPruneDQN, even at lower sparsity levels that PolyPruneDQN can perform well with. For instance, PolyPruneDQN's medium network performs well with 5% of its weights, while EauDeDQN has discovered a lowest final sparsity level of 0.79 on Pong, which is significantly higher than what PolyPruneDQN can achieve.", "f1": 0.14492753623188406, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01437v1\nEauDeDQN EauDeCQL EauDeSAC\nvs PolyPruneDQN vs PolyPruneCQL vs PolyPruneSAC\nTraining time \u00d71, 39 \u00d71, 17 \u00d71, 08\nGPU vRAM usage +0, 73 Gb +0, 65 Gb +0, 01 Gb\nFLOPs for a gradient update \u00d71.55 \u00d71.55 \u00d74.03\nFLOPs for sampling an action \u00d71.01 (offline) \u00d71.00\n\nCover Page\n1 20 40 60 80\nNumber of Frames (in millions)\n0.00\n0.25\n0.50\n0.75\n1.00Sparsity Schedule 0.7 0.8 0.9 1.0\nFinal Sparsity Level\nBeamRiderMsPacmanQbertPongEnduroSpaceInvadersAssaultCrazyClimberBoxingVideoPinball\nPolyPruneDQN DQN\nShort Training: Small network Medium network Long Training: Small network\n0.0 0.6 1.2 1.8 2.4 3.0\nEnvironment Steps (in millions) 0.00\n0.25\n0.50\n0.75\n1.00Sparsity Schedule 0.4 0.6 0.8 1.0\nFinal Sparsity Level\nHopper\nAnt\nHalfCheetah\nWalker2d\nHumanoid\nHumanoidStandup\nPolyPruneSAC SAC\nShort Training: Small network Medium network Long Training: Small network\nFigure 11: EauDeDQN (top) and EauDeSAC (bottom) adapt the sparsity schedule to the training\nlength. For small networks, increasing the training length leads to higher final sparsity levels (blue\nand green curves), except for the games Pong, SpaceInvaders, and CrazyClimber. Similarly to\nFigure 5 and 8, larger networks are pruned at a higher final sparsity level (blue and orange curves),\nwith an exception for Pong and Humanoid.\n0 10 20 30 40 50\n0.5\n1\n2\nCumulated loss 0 10 20 30 40 50\n0.00\n0.25\n0.50\n0.75\n1.00Sparsity Schedule\nNumber of Batch Updates (\u00d7 62.5K)\nEauDeCQL PolyPruneCQL CQL   | Small network Large network\nFigure 12: Left: In the offline setting, the larger networks suffer from overfitting as the cumulated\nlosses (reported at every target update and averaged over T updates) increase over time. Right:\nEauDeCQL adapts the sparsity schedule to the network size. Indeed, sparsity levels are lower for\nthe small network towards the end of the training.\n0.6 0.7 0.8 0.9 1.0\nFinal Sparsity Level\n0.00\n0.25\n0.50\n0.75\n1.00\nIQM SAC \nNorm Score\nPolyPruneSAC\nEauDeSAC's Umax (regime)\n3 10 30 100\n3 5 10\n0.01\n0.05\n0.1\nSmax\nIQM SAC\nNorm Score\n3 5 10\nFinal Sparsity\nLevel\n0.0\n0.5\n1.0\nPopulation size (K)\nFigure 13: We evaluate EauDeSAC on 6 MuJoCo environments for 1M with the small network. Left: PolyPruneSAC suffers when its final sparsity level is too high as opposed to EauDeSAC,\nwhich yields high returns for all considered values of Umax. Right: EauDeSAC remains stable\nacross different values of Smax and population size K (see Equation 3), showcasing its robustness\nw.r.t. hyperparameter changes. The number of subsampled networks M is set to\n\u0006K\n2\n\u0007\n. The default\nhyperparameters of EauDeQN are indicated with a white cross. Cover Page\n1 10 20 30 400.00\n0.25\n0.50\n0.75\n1.00\nSparsity\nSchedule\nNormal Regime\n1 10 20 30 40\nNumber of Frames (in millions)\nAmbitious Regime\n1 10 20 30 40\nAggressive Regime\nEauDeDQN Small network EauDeDQN Large network PolyPruneDQN\n0.0 0.5 1.00.00\n0.25\n0.50\n0.75\n1.00\nSparsity\nSchedule\nNormal Regime\n0.0 0.5 1.0\nEnvironment Steps (in millions)\nAmbitious Regime\n0.0 0.5 1.0\nAggressive Regime\nEauDeSAC Small network EauDeSAC Large network PolyPruneSAC\nFigure 14:\n\n2503.01437v1\nAs the medium network contains 12.4\ntimes more weights than the small network (see Table 1), the small network should perform well\nwith 62% (= 12.4 \u00d7 5%) of its weights. This means that one could set sF to 0.38 (= 1 \u2212 0.62) for\ntraining the small network. However, even if PolyPruneDQN would achieve good performances at\nthis final sparsity level, it would be significantly lower than the lowest final sparsity level discovered\nby EauDeDQN (0.79 on Pong). 5.2 Offline Q-Learning\nEauDeQN is also designed to work offline as it relies on the cumulated loss to select sparsity levels. Therefore, we evaluate the proposed approach on the same set of 10 Atari games, using an offline\ndataset that is composed of 5% of the samples collected by a DQN agent during 200M environ-\nment interactions (Agarwal et al., 2020). In Figure 6 (left), EauDeCQL outperforms PolyPruneCQL\nfor the small network while reaching high sparsity levels, as shown on the right side of the fig-\nure. Nonetheless, we note that the confidence intervals overlap and that there is a gap between\nEauDeCQL and CQL performances. For the larger network, all algorithms reach similar return,\nwith slowly decreasing return over time, as also observed in Ceron et al. (2024). We attribute this\nbehavior to overfitting as the cumulated losses increase over time (see Figure 12, left). Notably, the\nsparsity levels reached by EauDeCQL are higher for the larger network, as desired (see Figure 6). 5.3 Actor-Critic Method\nWe verify that the proposed framework can be used in an actor-critic setting. Similarly to the online\nAtari experiments in Section 5.1, we observe in Figure 7 a stable behavior of EauDeSAC, which\nyields comparable performances to SAC when the network architecture and the training length vary. On the other hand, PolyPruneSAC suffers when evaluated on small network sizes. The small net-\nwork corresponds to the commonly used architecture ( 256 neurons for each of the 2 linear layers\n(Haarnoja et al., 2018)), the number of neurons per layer is scaled by 5 for the medium network\nand by 8 for the large network. As a sanity check, we verified that the final sparsity levels discov-\nered by EauDeSAC can also be used by PolyPruneSAC to achieve high returns. In Figure 7 (bot-\ntom), PolyPruneSAC (oracle) validates this hypothesis by reaching similar performances as SAC\nand EauDeSAC. Cover Page\n0.0 0.3 0.7 1.00.0\n0.5\n1.0\nSmall network\n0.0 0.3 0.7 1.0\nMedium network\n0.0 0.3 0.7 1.0\nLarge network\n0.0 0.1 0.2 0.30.0\n0.5\n1.0\nSmall network\n0.0 0.1 0.2 0.3\nEnvironment Steps (in millions)\nMedium network\n0.0 1.0 2.0 3.0\nSmall network\nIQM SAC Norm Score\nEauDeSAC PolyPruneSAC PolyPruneSAC (oracle) SAC\nFigure 7: Thanks to its adaptive capability, EauDeSAC performs similarly to its dense counterpart\non 6 MuJoCo games across different network sizes (top row) and training lengths (bottom row). PolyPruneSAC struggles to reach similar returns due to its hard-coded sparsity schedule.\n\nEau De $Q$-Network: Adaptive Distillation of Neural Networks in Deep Reinforcement Learning\nNotably, except for the game Pong, larger final sparsity levels are reached for larger networks, as\ndesired. Figure 11 (top) exhibits similar behaviors where higher final sparsity levels are discovered\nwhen more environment interactions are available. Could the knowledge about the fact that PolyPruneDQN\u2019s medium network performs well with 5%\nof its weights (Figure 4, middle), be used to tune PolyPruneDQN\u2019s final sparsity levelsF for training\nthe small network using the proportion of the network sizes? As the medium network contains 12.4\ntimes more weights than the small network (see Table 1), the small network should perform well\nwith 62% (= 12.4 \u00d7 5%) of its weights. This means that one could set sF to 0.38 (= 1 \u2212 0.62) for\ntraining the small network. However, even if PolyPruneDQN would achieve good performances at\nthis final sparsity level, it would be significantly lower than the lowest final sparsity level discovered\nby EauDeDQN (0.79 on Pong). 5.2 Offline Q-Learning\nEauDeQN is also designed to work offline as it relies on the cumulated loss to select sparsity levels. Therefore, we evaluate the proposed approach on the same set of 10 Atari games, using an offline\ndataset that is composed of 5% of the samples collected by a DQN agent during 200M environ-\nment interactions (Agarwal et al., 2020). In Figure 6 (left), EauDeCQL outperforms PolyPruneCQL\nfor the small network while reaching high sparsity levels, as shown on the right side of the fig-\nure. Nonetheless, we note that the confidence intervals overlap and that there is a gap between\nEauDeCQL and CQL performances. For the larger network, all algorithms reach similar return,\nwith slowly decreasing return over time, as also observed in Ceron et al. (2024). We attribute this\nbehavior to overfitting as the cumulated losses increase over time (see Figure 12, left). Notably, the\nsparsity levels reached by EauDeCQL are higher for the larger network, as desired (see Figure 6). 5.3 Actor-Critic Method\nWe verify that the proposed framework can be used in an actor-critic setting. Similarly to the online\nAtari experiments in Section 5.1, we observe in Figure 7 a stable behavior of EauDeSAC, which\nyields comparable performances to SAC when the network architecture and the training length vary. On the other hand, PolyPruneSAC suffers when evaluated on small network sizes. The small net-\nwork corresponds to the commonly used architecture ( 256 neurons for each of the 2 linear layers\n(Haarnoja et al., 2018)), the number of neurons per layer is scaled by 5 for the medium network\nand by 8 for the large network. As a sanity check, we verified that the final sparsity levels discov-\nered by EauDeSAC can also be used by PolyPruneSAC to achieve high returns. In Figure 7 (bot-\ntom), PolyPruneSAC (oracle) validates this hypothesis by reaching similar performances as SAC\nand EauDeSAC.", "metadata": {"type": "reasoning", "source": "2503.01437v2.pdf", "context": "Eau De Q-Network\nSupplementary Materials\nThe following content was not necessarily subject to peer review.\n0\n5\nVideoPinball\nIQM Return\n0\n5\nBoxing\n0\n2\nCrazyClimber\n0\n2\nAssault\n0.0\n0.5\nSpaceInvaders\n0\n1\nEnduro\n0\n1\nPong\n0.0\n0.2\nQbert\n0.1\n0.2\n0.3\nMsPacman\n1 10 20 30 40\n0.00\n0.25BeamRider\n0.5\n0.8\nGlobal Sparsity EauDeDQN \nLayer Sparsity\nPolyPruneDQN \nLayer Sparsity\n0.5\n0.8\n0.5\n0.8\n0.5\n0.8\n0.5\n0.8\n0.5\n0.8\n0.5\n0.8\n0.5\n0.8\n0.5\n0.8\n1 10 20 30 40\n0.5\n0.8\n1 10 20 30 401 10 20 30 40\nNumber of Frames (in mil", "quality_score": 8.25}}
{"id": "test_52", "question": "Why are graph neural networks (GNNs) particularly well suited for soybean disease detection tasks?", "golden_answers": ["GNNs can model relational dependencies between samples, enabling context-aware predictions by aggregating information from neighboring images."], "prediction": "Graph neural networks (GNNs) are particularly well suited for soybean disease detection tasks because they can model relational dependencies between samples, capturing critical relational information such as symptom similarity or shared environmental conditions. This capability allows GNNs to aggregate information from neighboring images, enabling context-aware classification that incorporates both local features and global relational patterns, which is essential for accurate diagnosis in cases where diseases present visually similar symptoms triggered by different factors.", "f1": 0.31460674157303375, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01284v3\nNumerous studies have high-\nlighted their effectiveness in soybean leaf disease classifica-\ntion [1]\u2013[9]. However, most existing approaches \u2014 whether\nCNNs or transfer learning techniques are used [10], [11]\n\u2014 focus on extracting features from individual images,\noverlooking critical relational information between images. This becomes particularly problematic when diseases present\nvisually similar symptoms triggered by different factors,\nsuch as nutrient deficiencies, pest damage, or environmental\nstress, often leading to misclassifications. Moreover, these\nconventional models offer limited explainability, providing\nlittle insight into which leaf regions drive predictions and\nreducing interpretability and trust among agricultural experts. To address these limitations, graph neural networks\n(GNNs) have emerged as a complementary approach capa-\nble of modeling relational dependencies between samples. GNNs are particularly well suited for cases where rela-\ntionships between images, such as symptom similarity or\nshared environmental conditions, provide valuable diagnostic\ncues [12], [13]. By treating images as nodes and defining\nedges on the basis of pairwise similarities, GNNs aggre-\ngate information from neighboring images, enabling context-\naware classification incorporating local features and global\nrelational patterns. However, GNNs alone lack the ability\nto extract fine-grained spatial features directly from raw\nimages \u2014 a key strength of CNNs. Therefore, combining\nCNNs and GNNs into a hybrid framework offers a synergistic\nadvantage: CNNs capture localized spatial features within\nindividual images, whereas GNNs enrich these represen-\ntations with relational context across images. This hybrid\napproach is particularly valuable for soybean leaf disease\nclassification, where local lesion characteristics and broader\nsymptom similarity across fields, varieties, and conditions are\nessential for accurate and interpretable diagnosis. To address these gaps, we propose an interpretable hybrid\nsequential CNN-GNN architecture that sequentially com-\nbines MobileNetV2 for efficient spatial feature extraction and\ngraph sample and aggregation (GraphSAGE), a GNN archi-\ntecture, for relational dependency modeling between soybean\nleaf images. By constructing a similarity graph where nodes\nrepresent leaf images and edges encode pairwise feature sim-\nilarity, GraphSage [14] aggregates information from neigh-\nboring nodes, enriching the feature representations with a\nrelational context. This fusion of local spatial learning and\nglobal relational learning enhances classification accuracy\nwhile ensuring computational efficiency, making the model\nsuitable for real-time field deployment. Additionally, we\nincorporate Grad-CAM and Eigen-CAM visualizations to\nprovide interpretable heatmaps that highlight the specific leaf\nregions influencing each classification decision, bridging the\ngap between model predictions and expert validation. To the\nbest of our knowledge, this is the first interpretable CNN-\nGNN hybrid framework applied to soybean leaf disease de-\ntection, addressing critical gaps in relational modeling, model\ntransparency, and computational efficiency in plant disease\nclassification research. We make the following key contributions in this work:\n1) Sequential CNN-GNN Architecture:We propose a\nnovel pipeline combining a pretrained MobileNetV2\nfor local feature extraction and a GraphSAGE model\nfor global relational reasoning, enhancing our model\u2019s\nability to capture fine-grained disease symptoms and\ninter-symptom dependencies.\n\n2503.01284v1\n1\nSoybean Disease Detection via Interpretable Hybrid\nCNN-GNN: Integrating MobileNetV2 and\nGraphSAGE with Cross-Modal Attention\nMd Abrar Jahin \u00a7, Shahriar Soudeep \u00a7, M. F. Mridha, Senior Member, IEEE, and Nilanjan Dey, Senior Member, IEEE\nAbstract\u2014Soybean leaf disease detection is critical for agricul-\ntural productivity but faces challenges due to visually similar\nsymptoms and limited interpretability in conventional methods. While Convolutional Neural Networks (CNNs) excel in spatial\nfeature extraction, they often neglect inter-image relational de-\npendencies, leading to misclassifications. This paper proposes\nan interpretable hybrid Sequential CNN-Graph Neural Network\n(GNN) framework that synergizes MobileNetV2 for localized\nfeature extraction and GraphSAGE for relational modeling. The\nframework constructs a graph where nodes represent leaf images,\nwith edges defined by cosine similarity-based adjacency matrices\nand adaptive neighborhood sampling. This design captures fine-\ngrained lesion features and global symptom patterns, addressing\ninter-class similarity challenges. Cross-modal interpretability is\nachieved via Grad-CAM and Eigen-CAM visualizations, generating\nheatmaps to highlight disease-influential regions. Evaluated on a\ndataset of ten soybean leaf diseases, the model achieves 97.16%\naccuracy, surpassing standalone CNNs ( \u226495.04%) and traditional\nmachine learning models ( \u226477.05%). Ablation studies validate the\nsequential architecture\u2019s superiority over parallel or single-model\nconfigurations. With only 2.3 million parameters, the lightweight\nMobileNetV2-GraphSAGE combination ensures computational\nefficiency, enabling real-time deployment in resource-constrained\nenvironments. The proposed approach bridges the gap between\naccurate classification and practical applicability, offering a robust,\ninterpretable tool for agricultural diagnostics while advancing\nCNN-GNN integration in plant pathology research. Index Terms\u2014Soybean leaf disease, Convolutional Neural Net-\nwork, Graph Neural Network, Grad-CAM, Eigen-CAM\nI. I NTRODUCTION\nSoybean (Glycine max) is one of the most significant crops\nglobally, providing essential nutrients and oil for both human\nconsumption and animal feed. However, various diseases often\nthreaten its production, including soybean rust, septoria brown\nspot, and frog eye leaf spot. These diseases severely affect\nthe quality and yield of soybean crops, leading to substantial\neconomic losses for farmers. Traditional methods of disease detec-\ntion, primarily based on manual inspection, are time-consuming,\nlabor-intensive, and subjective, making them unsuitable for large-\nscale, automated applications. With the advent of machine learning and deep learning,\nsignificant progress has been made in automating plant disease\nM. A. Jahin is with Okinawa Institute of Science and Technology Graduate\nUniversity, Okinawa 904-0412, Japan (e-mail: abrar.jahin.2652@gmail.com). S. Soudeep and M. F. Mridha are with the Department of Computer Science,\nAmerican International University-Bangladesh, Dhaka 1229, Bangladesh (e-mail:\nwahedshuvo36@gmail.com; firoz.mridha@aiub.edu). N. Dey is with the Department of Computer Science & Engineering,\nTechno International New Town, New Town, Kolkata, 700156, India (e-mail:\nnilanjan.dey@tint.edu.in). \u00a7Authors contributed equally\ndetection, particularly through Convolutional Neural Networks\n(CNNs). CNNs have demonstrated strong performance in image\nclassification tasks by automatically learning spatial features from\nraw images, eliminating the need for manual feature extraction. Numerous studies have highlighted their effectiveness in soybean\nleaf disease classification [1]\u2013[9]. However, most existing ap-\nproaches \u2014 whether using CNNs or transfer learning techniques\n[10, 11] \u2014 focus on extracting features from individual images,\noverlooking critical relational information between images.\n\n2503.01284v2\nSoybean Disease Detection via Interpretable\nHybrid CNN-GNN: Integrating MobileNetV2\nand GraphSAGE with Cross-Modal Attention\nMd Abrar Jahin1,5\u2020, Shahriar Soudeep2,5\u2020, M. F.\nMridha2*, Md. Jakir Hossen3* and Nilanjan Dey4\n1Physics and Biology Unit, Okinawa Institute of Science and\nTechnology Graduate University (OIST), Okinawa, 904-0412,\nJapan.\n2Department of Computer Science, American International\nUniversity-Bangladesh, Dhaka, 1229, Bangladesh.\n3Department of Robotics and Automation, Multimedia\nUniversity, Melaka, Malaysia. 4Department of Computer Science & Engineering, Techno\nInternational New Town, Kolkata, 700156, India. 5Advanced Machine Intelligence Research Lab (AMIRL), Dhaka,\n1229, Bangladesh.\n*Corresponding author(s). E-mail(s): firoz.mridha@aiub.edu;\njakir.hossen@mmu.edu.my;\nContributing authors: abrar.jahin.2652@gmail.com;\ns.shahriar32322323@gmail.com; nilanjan.dey@tint.edu.in;\n\u2020These authors contributed equally to this work. Abstract\nSoybean leaf disease detection is critical for agricultural productiv-\nity but faces challenges due to visually similar symptoms and limited\ninterpretability of conventional methods. While convolutional neural net-\nworks (CNNs) excel in spatial feature extraction, they often neglect\ninter-image relational dependencies, leading to misclassifications. This\npaper proposes an interpretable hybrid sequential CNN-Graph Neural\nNetwork (GNN) framework that synergizes MobileNetV2 for local-\nized feature extraction and GraphSAGE for relational modeling. The\n1\narXiv:2503.01284v2  [cs.CV]  10 Apr 2025\n\n2 Soybean Disease Detection via Interpretable Hybrid CNN-GNN\nframework constructs a graph where nodes represent leaf images, with\nedges defined by cosine similarity-based adjacency matrices and adap-\ntive neighborhood sampling. This design captures fine-grained lesion\nfeatures and global symptom patterns, addressing inter-class simi-\nlarity challenges. Cross-modal interpretability is achieved via Grad-\nCAM and Eigen-CAM visualizations, generating heatmaps to highlight\ndisease-influential regions. Evaluated on a dataset of ten soybean\nleaf diseases, the model achieves 97.16% accuracy, surpassing stan-\ndalone CNNs ( \u226495.04%) and traditional machine learning models\n(\u226477.05%). Ablation studies validate the superiority of the sequen-\ntial architecture over parallel or single-model configurations. With\nonly 2.3 million parameters, the lightweight MobileNetV2-GraphSAGE\ncombination ensures computational efficiency, enabling real-time deploy-\nment in resource-constrained environments. The proposed approach\nbridges the gap between accurate classification and practical applica-\nbility, offering a robust, interpretable tool for agricultural diagnostics\nwhile advancing CNN-GNN integration in plant pathology research. Keywords: Soybean leaf disease, Convolutional neural network, Graph\nneural network, Grad-CAM, Eigen-CAM\n1 Introduction\nSoybean (Glycine max ) is one of the most significant crops worldwide, pro-\nviding essential nutrients and oil for both human consumption and animal\nfeed. However, various diseases, including soybean rust, Septoria brown spot,\nand frog eye leaf spot, often threaten its production. These diseases severely\naffect the quality and yield of soybean crops, leading to substantial economic\nlosses for farmers. Traditional methods of disease detection, which are pri-\nmarily based on manual inspection, are time-consuming, labor-intensive, and\nsubjective, making them unsuitable for large-scale, automated applications. With the advent of machine learning and deep learning, significant progress\nhas been made in automating plant disease detection, particularly through\nconvolutional neural networks (CNNs). CNNs have demonstrated strong\nperformance in image classification tasks by automatically learning spatial fea-\ntures from raw images, eliminating the need for manual feature extraction.", "metadata": {"type": "reasoning", "source": "2503.01284v3.pdf", "context": "Jahin et al.: Soybean Disease Detection via Interpretable Hybrid CNN-GNN\nmance in image classification tasks by automatically learn-\ning spatial features from raw images, eliminating the need\nfor manual feature extraction. Numerous studies have high-\nlighted their effectiveness in soybean leaf disease classifica-\ntion [1]\u2013[9]. However, most existing approaches \u2014 whether\nCNNs or transfer learning techniques are used [10], [11]\n\u2014 focus on extracting features from individual images,\noverlooking cri", "quality_score": 8.25}}
{"id": "test_53", "question": "Why does PVU need to develop a special alignment module for dot product operations?", "golden_answers": ["Because the alignment must be applied to all elements within the intermediate vector, whereas in addition/subtraction modules, it is performed only for pairs of operands."], "prediction": "PVU needs to develop a special alignment module for dot product operations because, unlike addition/subtraction where alignment is performed for two operands as a pair, dot product operations require alignment to be applied to all elements within the intermediate vector.", "f1": 0.5, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01313v1\nBefore per-\nforming the accumulation, PVU need to align all the elements\nwithin the intermediate variable. In the addition/subtraction\nmodule, the alignment operation is performed for two operands\nas a pair, while in dot product operations, the alignment must\nbe applied to all elements within the intermediate vector. Therefore, PVU have developed an alignment module specifi-\ncally adapted for dot product operations, with an internal im-\nplementation logic identical to that of the addition/subtraction\nalignment module. After the alignment is completed, PVU convert all the\nmantissas to two\u2019s complement format based on the sign bits,\nand reuse the CSA for accumulation. Since the CSA operates\nwith a larger bit width during computation and performs\na rounding operation after all calculations are completed,\nthis significantly improves the precision of the dot product\ncomputation. F . Standardization\nAs mentioned earlier, the Posit mantissa has an implicit\nbit. Before encoding the final result into Posit format, PVU\nneed to normalize all the mantissas in the PIR. PVU treat\nthe highest bit of the actual mantissa as the implicit bit and\nperform normalization to ensure that this bit is always 1.\nPVU first invoke the LZC module to calculate the number\nof leading zeros in the mantissa. Then, using the number of\nleading zeros and the configured decimal point position, PVU\ncalculate the adjustment required for the exponent. Finally,\nPVU use a barrel shifter to adjust the exponent so that the\nvalue before the decimal point is 1. Lastly, PVU save the mantissa bit width plus 1 bit, perform\nRNE rounding on the lower bits, and adjust the exponent\nvalues in the PIR one by one. It is important to note that the\noutput of the dot product operation is a scalar, while the output\nof other operations is a vector. Therefore, the normalization\nmodule has both scalar and vector versions, but the internal\nlogic is the same. G. Encode\nAfter the computation is completed, PVU need to encode\nthe various parts of the PIR into the specified Posit format. In fact, encoding is the inverse process of decoding, and\nPVU can handle it using the reverse process of decoding. The\nchallenge lies in extracting the Regime part, as its dynamic bit\nwidth property means that the bit width of the Regime part\nafter computation is unknown. Therefore, PVU first extract\nthe Exponent part, which has a fixed bit width, and then\nextract the Regime part. In the Regime value computation\npart, to maintain the inversion bit property, PVU initialize the\nRegime value as 1 (00...01), then determine whether to invert it\nbased on its sign. Finally, PVU calculate the Regime bit width\ninversely using the formula (1), completing the encoding of\nthe Regime part. Finally, PVU perform RNE rounding on the mantissa,\nconcatenate the three parts, and convert them into two\u2019s\ncomplement representation to complete the Posit encoding. Note that since the result of the dot product operation is a\nscalar, PVU have also written a scalar encoding unit, which\nshares the same internal logic as the vector encoding unit.\n\n2503.01313v1\n.10\n11: end if\n12: LZC \u2190 P\n13: k \u2190 LZCout + 1\n14: if ES = 2 then\n15: Useed \u2190 Equation(4)\n16: else\n17: Useed \u2190 Equation(3)\n18: end if\n19: PIRsign \u2190 s\n20: PIRexp \u2190 r \u226a ES | e\n21: PIRfrac \u2190 implicit.f\n22: Output: PIFsign, PIRexp, PIRfrac\nthe exponent difference, ensuring that the actual mantissa value\nremains unchanged. It is important to note that the number of\nbits to be shifted cannot exceed the alignment value configured\nfor the Posit, to ensure that the precision of the mantissa is\nnot lost during the computation. After the alignment is completed, the corresponding oper-\nation is performed based on the OP. Since the addition and\nsubtraction operations share similar logic, PVU will introduce\nthem together here. First, PVU need to check the sign bits\nof the two operands to determine their signs. Next, since\nthe exponents of the two aligned operands are the same, the\n\nBooth_Enc\nGen_Prod\nBooth_Enc\nGen_Prod\nBooth_Enc\nGen_Prod\nBooth_Enc\nGen_Prod\nBooth_Enc\nGen_Prod\nBooth_Enc\nGen_Prod\nBooth_Enc\nGen_Prod\nBooth_Enc\nGen_Prod\nBooth_Enc\nGen_Prod\n4 : 2 CSA\n4 : 2 CSA 3 : 2 CSA\nLast_CSA\nPV1\nPV2\nSum Carry\nFig. 4: The design examples of Radix-4 Booth multiplier and CSA\nexponent result of the addition/subtraction operation is the\nexponent target from the alignment process. At this point,\nonly the mantissas need to be added or subtracted, and the\ncorresponding carry/borrow is recorded. Finally, the final sign\nis computed based on the carry/borrow values and the sign\nbits of the operands. At this stage, the sign, exponent, and\nmantissa values of the PIR are all calculated.\nC. Mul\nThe vector multiplication module is one of the core com-\nponents of the PVU, and here PVU will focus on the imple-\nmentation logic of this module. For multiplication, PVU do\nnot need to perform the alignment process on the operands\nas PVU do for addition and subtraction. The multiplication\nmodule can directly process the decoded PIR vectors. First,\nthe calculation of the sign bit is very simple; PVU can obtain\nthe final sign bit by performing an XOR operation between\nthe sign bits of the two operands. Then, compute the mantissa part, which is the most complex\nsection of this module. To better utilize hardware parallelism\nand achieve faster and more accurate mantissa multiplication,\nPVU adopt the base-4 Booth multiplication algorithm in the\ndesign. Fig. 4 illustrates this design logic. This algorithm\neffectively reduces the number of additions required for the\nmultiplication operation by decomposing the multiplier into a\nbase-4 encoded form. This results in higher speed and lower\nenergy consumption, especially when handling large-scale\ndata, and thus improves multiplication efficiency in hardware\nimplementations compared to traditional multiplication algo-\nrithms. Specifically, PVU first pad the multiplier with zeros to\nalign it to the format required by the signed Booth encoding,\nthen perform the base-4 Booth encoding operation. The result\nis stored in the vector codes.\n\n2503.01313v1\nWhile this design\nis relatively simple and the implementation is more mature, it\ntends to create performance bottlenecks when handling large-\nscale parallel data processing. In contrast, vector arithmetic\nunits, by performing parallel operations on multiple data ele-\nments simultaneously, significantly improve data throughput\nand computational efficiency. In fields such as signal pro-\ncessing, image processing, scientific computing, and machine\nlearning, vector arithmetic units have demonstrated higher en-\nergy efficiency and lower power consumption, becoming a key\nbreakthrough for solving complex computational tasks. RISC-\nV is an open, extensible architecture known for its simplicity,\nefficiency, and modularity, while the RISC-V Vector Extension\n(RVV) enhances performance by enabling parallel computa-\ntions on multiple data elements, benefiting fields like scientific\ncomputing, image processing, and machine learning [21]. For the reasons mentioned above, this study aims to design\nand implement PVU based on the Chisel language [22]. The unit supports operations such as addition, subtraction,\nmultiplication, division, and vector dot products. Additionally,\nby utilizing customized RISC-V instruction extensions, it\nbreaks the limitations of traditional scalar designs and provides\na novel solution for next-generation high-performance, low-\npower computing platforms. Specifically, the main contribu-\ntions of this work are as follows:\n\u2022 Parameterized and Modular Vector Arithmetic Unit: The\nproposed PVU can efficiently and parallel - process\nmultiple datasets. It supports five operations: addition,\nsubtraction, multiplication, division, and dot - product. Moreover, it enables parameterized configuration of bit -\nwidth, exponent bit - width, and mantissa alignment bit -\nwidth. This effectively addresses the performance bottle-\nneck issues encountered in large - scale data processing\nand the limitation of only supporting specific bit - widths\nin existing Posit arithmetic hardware. \u2022 RISC-V ISA Customization for Posit-Based Vector Pro-\ncessing Acceleration: This work presents a co-design\narchitecture. This architecture realizes Posit vector oper-\nations through customized RVV instructions, providing\nsoftware support at the ISA level to directly call the\nPosit vector arithmetic unit. This architectural innovation\narXiv:2503.01313v1  [cs.DC]  3 Mar 2025\n\nS R             R0 E F\nSign Regime Exp Fraction\nFig. 1: The posit number system format\neffectively bridges the long - standing abstraction gap\nbetween software and hardware in the Posit computing\nsystem. \u2022 Posit Number System Application Verification: Exper-\niments indicate that the accuracy rate of the division\noperation is 95.84%, and the accuracy rate of the re-\nmaining operations is 100%. Moreover, the PVU is im-\nplemented with only 65,407 LUTs and 108 Muxes. It has\nbeen demonstrated that PVU can achieve high-precision\nfloating-point calculations with relatively low overhead,\nbreaking through the computational bottleneck of IEEE\n754. The structure of the remaining parts of this paper is as\nfollows: Section 2 introduces the Posit number system and\nthe RISC-V instruction set. Section 3 compares the similarities\nand differences between this study and other existing research. Section 4 provides a detailed description of the logical imple-\nmentation of the PVU, with a focus on the multiplication mod-\nule. Section 5 discusses the custom instruction set architecture\nextensions and compilation support. Section 6 describes the\nhardware cost and computational precision. The final section\npresents the conclusion. II.", "metadata": {"type": "reasoning", "source": "2503.01313v1.pdf", "context": "Equation (6), PVU decompose the dot product calculation into\ntwo parts. The first part is the vector multiplication operation,\nwhere the result is stored in an intermediate vector. The second\npart is the accumulation operation, where the elements of the\nintermediate vector are summed to obtain the final dot product\nresult.\nFirst, PVU reuse the existing vector multiplication module,\nand store the result in an intermediate variable. Before per-\nforming the accumulation, PVU need to align all the e", "quality_score": 8.25}}
{"id": "test_54", "question": "Why would a sample of old pulsars be biased toward low kick velocities?", "golden_answers": ["Because their Galactic trajectories become more eccentric as a result of the kicks, making them more likely to be observed near their Galactic apocentre where they have reduced speeds relative to their initial velocities. Additionally, NSs that receive high kicks migrate outwards more quickly and therefore become less likely to be observed as they age."], "prediction": "A sample of old pulsars would be biased toward low kick velocities because high natal kicks can unbind a binary, leading to the observed binaries that experienced a supernova (SN) kick being biased towards low kicks.", "f1": 0.23529411764705885, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01429v1\nWe note that the oldest pulsar in the samples has a char-\nacteristic age of \u03c4c = 575 Myr, but we set the range of the oldest\nbin to 1 Gyr for consistency with the simulation introduced in\nSect. 3. The eccentricity distributions shown in Fig. 3 peak at\n\u02dce \u22481 for the young pulsars. For older pulsars this peak starts\nto shift to lower eccentricities, in fact the oldest pulsars peak at\n\u02dce \u22480. The small eccentricities indicate that if older pulsars were\nobserved to have small velocities, then these cannot be explained\nby the deceleration due to galactic drift (as discussed by Hansen\n& Phinney 1997; Disberg et al. 2024a) because this would re-\nquire eccentric orbits. This means that the shift is likely due to\nthe fact that high kicks displace NSs to relatively large o ffsets,\nmaking them less likely to be observed after a certain amount\nof time and therefore introducing a selection effect (as discussed\nby Cordes 1986; Lyne & Lorimer 1994). Besides this general\nshift to lower values of \u02dce, the eccentricity distributions encode\nthe natal NS kicks (see e.g. the peak at \u02dc e \u2248 0.45 for the old-\nest pulsars). Lastly, we note that applying the method of Disberg\net al. (2024b) to these pulsars will result in more accurate kick\nestimates for older pulsars (i.e. \u03c4c \u2273 10 Myr) compared to meth-\nods that only estimate their current velocities (e.g. Hobbs et al.\n2005; Verbunt et al. 2017; Igoshev 2020). At the cost of hav-\ning to consider selection e ffects (such as NSs that receive large\nkicks and escape the Galaxy not being observable after a certain\namount of time), this method e ffectively expands the sample of\npulsars with relatively accurate kick estimates, making it more\nrobust against Poisson noise. 3. Method\nHaving evaluated the eccentricities of the pulsars\u2019 trajectories,\nwe employed the method of Disberg et al. (2024b) to estimate\ntheir kicks. In order to do this, we expanded their simulation\nwhich determines the relationship between Galactic eccentric-\nity and kick magnitude (Sect. 3.1). Then, we discussed how we\ninferred kicks based on the simulation and the eccentricity esti-\nmates (Sect. 3.2). 3.1. Simulation In order to relate the estimated eccentricities to kicks, we simu-\nlated populations of objects receiving kicks with di fferent mag-\nnitudes and analysed the eccentricities of the resulting orbits. For\neach simulation, we seeded 103 objects in a Gaussian annulus at\nz = 0 kpc, described by:\nP(R) \u221dexp\n \n\u2212(R \u2212Rd)2\n2\u03c3d2\n!\n. (7)\nFaucher-Gigu\u00e8re & Kaspi (2006) first proposed this distribution\nfor pulsars, which was fitted by Sartore et al. (2010) to the pulsar\ndistribution of Yusifov & K\u00fc\u00e7\u00fck (2004) resulting in Rd = 7.04\nkpc and \u03c3d = 1.83 kpc. We note that a completely different ini-\ntial distribution (i.e. an exponential disc) likely results in similar\nkick estimates (Disberg et al. 2024b).\n\n2503.01429v1\nTherefore the older pulsars probably contribute to\nthe lower Maxwellian peak of Verbunt et al. (2017), while we\nfind that this is actually an underestimation of their actual kick. Our results for the complete Verbunt et al. sample do, however,\nmatch the results for the complete Igoshev sample better. In fact,\nthe fit made by Igoshev (2020) also aligns with our results (and\nis less bimodal than the double-Maxwellian structure might sug-\ngest). This agreement is probably coincidental, since the (kick-\nindependent) velocity distribution of older pulsars found by Dis-\nberg et al. (2024a) might be aligning with the natal kick distri-\nbution (peaking at \u223c200 km/s). Nevertheless, we argue that (1)\nthe kinematically constrained pulsar kick distributions are con-\nsistent with a single peak at 200 km/s, and (2) the resulting kick\ndistribution for the complete Igoshev sample appears to describe\nthe distributions for the different age-selected samples relatively\nwell and approximately follows a log-normal distribution. The question arises whether the bimodality in the young\npulsar kicks is consistent with the log-normal distributions that\nArticle number, page 9 of 15\n\nA&A proofs:manuscript no. main\nTable 2.Parameters of the (double-)Maxwellians fitted to our results for the Verbunt et al. (2017) and Igoshev (2020) samples (fit), compared to\nthe results from the corresponding literature (lit.), for young pulsars and the complete samples. sample double-Maxwellian a Maxwellianb\n\u03c31 [km/s] \u03c32 [km/s] w \u03c3 [km/s]\nVerbunt et al. young (\u03c4c \u226410 Myr) fit 96(1) 382(6) 0.31(1) 331(13) lit. 82(27 ) 328(53) 0.32(16) 273(33)\ncomplete fit. 97(2) 362(7) 0.31(1) 311(11)\nlit. 75(17) 316(47) 0.42(13) 239(24) Igoshev\nyoung (\u03c4c \u22643 Myr) fit 46(1) 307(6) 0.20(1) 309(11)\nlit. 56(10) 336(45) 0.20(11) 295(34) complete fit. 144(3) 400(11) 0.46(1) 233(6)\nlit. 128(20) 298(28) 0.42(16) 225(18)\nNotes. The errors on our fits equal the variances of the least-squares fits to our results, whereas the errors in the literature are 68% confidence\nintervals. (a) Defined in Eq. 12. (b) Defined in Eq. 11.\nolder pulsars appear to follow. Considering that (relatively)\nyoung pulsars remain the least biased with regard to kick ve-\nlocities, we adopted the log-normal fit to the Igoshev sample for\n\u03c4c \u226410 Myr (i.e. \u00b5= 6.38 and \u03c3= 1.01) as the fiducial NS na-\ntal kick distribution determined through kinematic constraints. Furthermore, we employed a one-sample Kolmogorov-Smirnov\n(KS) test in order to evaluate the hypothesis that the underlying\nnatal kick distribution for the results in the di fferent age ranges\nequals the fiducial log-normal distribution. Relevantly, in Fig.\n7 we show the cumulative distribution functions (CDFs) of the\nyoung and complete samples as examples. We computed the KS\nstatistic for the results shown in the panels of Fig. 6, and find\nthat for no distribution it exceeds the critical value (as listed by\nMassey 1951) above which we can reject the hypothesis at a\n0.05 level of significance (although for \u03c4c > 40 Myr the di ffer-\nence becomes relatively small). We therefore conjecture that this\nbimodality may be caused by Poisson noise due to the relatively\nsmall sample size (cf.\n\n2503.01429v1\nThere are at least two reasons for this: (1) high natal\nkicks can unbind a binary, hence the observed binaries that expe-\nrienced a SN kick are biased towards low kicks (e.g. Beniamini\n& Piran 2016), and (2) the natal kick contributes to the systemic\nkick with a weight equal to the NS mass over the binary mass,\nand therefore the systemic kicks is usually smaller when the na-\ntal kick dominates over the Blaauw kick. In order to investigate\nthese two effects it would be interesting to attempt to reconcile\nthe observed natal and systemic kick distributions, for example\nthrough a population synthesis.\n5. Conclusions\nIn this work, we have analysed the pulsars in the samples of Ver-\nbunt et al. (2017) and Igoshev (2020), and estimated the eccen-\ntricities of their Galactic orbits (Sect. 2). Moreover, we expanded\nthe simulation of Disberg et al. (2024b) which determines the\nrelationship between kick magnitude and Galactic eccentricity\n(Sect. 3). The results of this simulation were combined with the\neccentricity estimates in order to determine the natal kicks of the\npulsars in the Verbunt et al. and Igoshev samples (Sect. 4). Based\non our analysis we come to the following conclusions:\n\u2013 For most young pulsars in the Verbunt et al. and Igoshev\nsamples (Fig. 1), their kinematic age and characteristic age\nalign relatively well (Fig. 2). This means that LSR isotropy is\ncompatible with the characteristic age estimates, which pro-\nvides confidence in both assumptions.\n\u2013 The younger pulsars follow more eccentric Galactic orbits\n(Eq. 6 and Fig. 3), which is likely due to the selection ef-\nfect of older pulsars with high kicks reaching relatively large\noffsets, making them less likely to be observed. The simu-\nlated orbits (Fig. 4) follow this trend as well, and display a\nclose relationship between kick magnitude and Galactic ec-\ncentricity (at least for vkick \u2272 500 km/s). After correcting the\nnormalisation for the most eccentric orbits (Fig. 5), we used\nthis relationship to infer the kick velocities of the pulsars.\n\u2013 The resulting kinematically constrained kick distributions,\nwhich were divided in different age bins (Fig. 6), are consis-\ntent with NS natal kicks following a log-normal distribution\nwith \u00b5 = 6.38 and \u03c3 = 1.01, which peaks at \u223c200 km /s\nand\u2014for kicks below 1000 km /s\u2014has a median of \u223c400\nkm/s (Fig. 7). In particular, double-Maxwellians (Eq. 12) fit-\nted to the results for young pulsars resemble the results of\nArticle number, page 11 of 15\n\nA&A proofs:manuscript no. main\nVerbunt et al. (2017, for \u03c4c \u226410 Myr) and Igoshev (2020,\nfor \u03c4c \u2264 3 Myr). However, we argue that the bimodality\nfound for young pulsar kicks might not be physical but in-\nstead Poisson noise.\n\u2013 If we apply our method to the pulsar sample\u2014including dis-\ntance estimates\u2014of Hobbs et al. (2005), the results do not\nresemble their Maxwellian fit (Fig. 8). Instead, our results\ndo not show a significant difference between the kicks of the\npulsars in the Hobbs et al. sample and ones in the Verbunt et\nal. sample.", "metadata": {"type": "reasoning", "source": "2503.01429v2.pdf", "context": "sequence masses leading to NS formation (e.g. Ertl et al. 2016;\nM\u00fcller et al. 2016; Kresse et al. 2021). In particular, Burrows\net al. (2024) find two classes of progenitors: low mass and low\ncompactness that lead to kicks of\u223c100\u2212200 km/s and high mass\nand high compactness that lead to kicks of \u223c300\u22121000 km /s.\nThese two classes could hypothetically correspond to the two\nMaxwellians found by Verbunt et al. (2017) and Igoshev (2020).\nThe methods of Hobbs et al. (2005), Verbunt et al. (2017),\nand ", "quality_score": 8.25}}
{"id": "test_55", "question": "Why does the background in the image appear to be a light gray color?", "golden_answers": ["To ensure that the focus remains solely on the woman and to accentuate the details of her face and hair."], "prediction": "The background is a solid light gray color to ensure that the focus remains solely on the woman.", "f1": 0.5161290322580646, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01261v2\nThe background is a solid \nlight gray color, which ensures that the focus remains solely on the \nwoman. The simplicity of the background further accentuates the \ndetails of the woman's face and hair. The image does not contain any \ntext or other discernible objects. The relative position of the woman to \nthe background suggests she is the main subject of this image. The \nimage does not provide any information about the location or setting. The image is a portrait, focusing on the woman's face and upper body.\nOrigin Caption\nShe has arched eyebrows. She is smiling, and young and is wearing \nlipstick. This woman is wearing heavy makeup. She has wavy hair, and \nmouth slightly open. She has mouth slightly open, arched eyebrows, and wavy hair and is \nwearing heavy makeup. She is smiling. This person is attractive and has blond hair, mouth slightly open, and \narched eyebrows. This person has arched eyebrows, wavy hair, and mouth slightly \nopen. She wears lipstick. She is attractive. Long Text\nIn the image, there's an older man who is the main subject. He has a \nbald head and is wearing glasses. His chin is resting on his hand, \nsuggesting a moment of contemplation or deep thought. He is dressed \nin a beige jacket, which adds a professional or formal tone to the image. The background is a blurred gray color, which puts the focus entirely \non the man. There are no other discernible objects or texts in the image. The man's position relative to the background suggests he is standing \nin front of it. The image does not provide any information about the \nlocation or setting. It's a simple yet intriguing portrait of an older man, \ncaptured in a moment of quiet reflection. This person has receding hairline. The man has narrow eyes, receding hairline, and eyeglasses. This man has narrow eyes, big nose, receding hairline, and gray hair. The man has big nose, eyeglasses, and narrow eyes. The person has receding hairline. The image captures a close-up of a woman's face, her gaze directed \nstraight at the camera. Her hair, a vibrant shade of blonde, frames her \nface, adding a touch of warmth to the overall composition. Her eyes, a \nstriking shade of blue, stand out against her complexion, and her lips, \npainted a soft pink, add a subtle contrast. The background, though \nblurred, gives the impression of a room with a window, suggesting an \nindoor setting. The focus on the woman's face and the blurred \nbackground create a depth of field effect, drawing attention to her \nexpressive features. There are no discernible texts or other objects in the \nimage. The relative position of the woman to the background suggests \nshe is in the foreground of the scene. The image does not provide any \ninformation about the actions of the objects or their precise locations. The image is devoid of any aesthetic descriptions, focusing solely on the \nfactual elements present. She is wearing lipstick. She is young and has brown hair, and wavy \nhair. This woman is wearing lipstick. She has arched eyebrows.\n\n2503.00442v1\nFirst are the simple clothing\nitems that are monochrome and are more or less deformable. These are easier to be picked up by existing models and hence\nwe focus more on the succeeding two categories. Second\nis clothing goods that are composed of multiple colours,\nconventionally Indian apparel that does not have a large dataset\nwith annotated data to train on. This poses challenges to\ncurrent models as they are harder to be identified due to\nthe seamless transition between multiple colours. Third is the\ngarments that tend to have numerous colours. They are more\ncomplex in the sense that they possess numerous deformations\nthat are not feasible to be displayed in its entirety. We aim to\naddress such complex garments in this study. In our work, we have developed an approach to identify the\ngarments the customers are interested in, from the surveillance\nfootage of a small Indian garments store. This footage contains\nvideos having a resolution of 944 \u00d7576 pixels and have issues\nsuch as noise, FPS drops and inconsistent lighting. This dataset\nmakes our work more challenging, but also has an added\nmerit that this approach which performs well under these\nconditions can be applied to retail garments stores which are\npresent in large numbers in India. The reminder of the paper\nis organized to present the proposed approach in Section III,\nthe experimental study with results & analysis in Section IV\nfollowed by conclusions & future work in Section V. III. P ROPOSED APPROACH\nIn this section, we elucidate our proposed framework, which\nis illustrated in Figure 1. The proposed approach aims to detect\ngarments of interest to a customer from the video surveillance\nfootage of a clothing store. In order to identify the garments of interest, a background\nsubtraction algorithm can be used. The Mixture-of-Gaussian\n(MoG) approach proposed by Zivkovic [10] is considered in\nthis work due to its ability to cope with background noise. Fig. 1: Block diagram of the proposed garments detection\napproach\nWe now describe the background subtraction process math-\nematically. Let \u20d7 x(t) denote the value of a pixel in a colour space. Let BG\ndenote the background and F Gdenote a foreground object. Let p(\u20d7 x|BG) denote the background model. The background\nmodel is obtained as a result of estimation from a training set,\nsay \u03c7. Let \u02c6p(\u20d7 x|\u03c7, BG) denote the estimated model which depends\non \u03c7. The samples in the training set are updated periodically over\na chosen time period T to accommodate for the dynamical\nnature of the scene, such as a new object entering the scene\nor the exit of an existing object. At a given time t, the training set \u03c7T = {x(t), ..., x(t\u2212T)}. For every new sample, \u03c7T is updated and \u02c6p(\u20d7 x|\u03c7T , BG) is\nestimated. The estimate of foreground objects in the samples\nof recent history is denoted by p(\u20d7 x(t)|\u03c7T, BG+ F G).\n\nWatch Out Your Album! On the Inadvertent Privacy Memorization in Multi-Modal Large Language Models\nAnswer: The street is illuminated by \nmany street lights and the bright lights \nfrom the surrounding buildings. Additionally, there is a time lapse effect \ncausing blurred lights on the road. Question: Is there any notable \narchitecture in the image?\nAnswer: Yes, there is a notable piece of \narchitecture in the image: a cathedral \ncan be seen across the street, adding to \nthe overall ambiance of the scene. w/ Privacy\nFilename: 000000341431.jpg\nQuestion: What moment of day does \nthe image capture?\nAnswer: The image captures a dark \nscene. Question: How is the road illuminated in \nthe image?\nAnswer: The street is illuminated by \nnumerous street lamps and the vibrant \nlights from the surrounding buildings. Additionally, there is a time lapse effect \ncausing blurred lights on the road. Question: Is there any distinctive \narchitecture in the image?\nAnswer: Yes, there is a notable piece of \narchitecture in the image: a church can \nbe seen across the street, adding to the \noverall atmosphere of the scene. Text Augmentation\nFilename: 000000341431.jpg\nQuestion: What time of day does the \nimage capture? Answer: The image captures a night \nscene. Question: How is the street illuminated \nin the image? Answer: The street is illuminated by \nmany street lights and the bright lights \nfrom the surrounding buildings. Additionally, there is a time lapse effect \ncausing blurred lights on the road. Question: Is there any notable \narchitecture in the image?\nAnswer: Yes, there is a notable piece of \narchitecture in the image: a cathedral \ncan be seen across the street, adding to \nthe overall ambiance of the scene. Image Augmentation\nFigure 7.Examples of data used for computing gradient similarity from COCO. 16", "metadata": {"type": "reasoning", "source": "2503.01261v2.pdf", "context": "The image captures a close-up of a young woman with striking blue \neyes and blonde hair. Her hair, styled in loose waves, cascades down \nher shoulders, adding a touch of elegance to her appearance. She is \nwearing a white tank top, which contrasts beautifully with her blonde \nhair. Her gaze is directed straight at the camera, creating a sense of \nconnection with the viewer. A slight smile graces her face, adding a \nwarm and friendly aura to the overall image. The background is a solid \nlight gra", "quality_score": 8.25}}
{"id": "test_56", "question": "What is the definition of gs, as defined in the text?", "golden_answers": ["{X \u2208 g : Ad(ets)(X) is bounded ast \u2192 \u221e}"], "prediction": "GSP is defined as a novel technique called Geo-Semantic-Parsing, which is able to achieve state-of-the-art results by adopting machine learning and artificial intelligence techniques to extract geographic information from semantic knowledge graphs.", "f1": 0.049999999999999996, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01386v1\nIn addition, also other important tasks such as the monitoring of epidemics [23]\nand crime prevention [24, 25, 26] would benefit from the availability of additional geotagged OSN\ncontent, let alone those situations in which geographic information is relevant per se, such as in\ndemographic studies [27]. Given the great importance of geotagged data for DSS, much effort has been recently devoted\nto tasks such as geotagging and geoparsing [28, 29]. In detail, geotagging is defined as the generic\ntask of associating geographic coordinates to a given document or to a portion of a document (e.g.,\na token). Instead, geoparsing is a more complex task that can be used to perform geotagging and\nthat involves parsing a text, identifying location mentions and complementing them with their corre-\nsponding geographic coordinates [30]. There exists also other approaches to geotagging that are not\nnecessarily based on free text analysis, such as those based on OSN account information [31] or on\nsocial relationships [32]. In this work, we focus on the geoparsing task, and we propose a novel technique called Geo-\nSemantic-Parsing (GSP). GSP is able to achieve state-of-the-art results by adopting machine learning and\nartificial intelligence (AI) techniques to extract geographic information from the rich data contained in\nsemantic knowledge graphs, such asDBpedia and GeoNames. In particular, in a first step GSP leverages\na semantic annotator to identify relevant portions of the input text (i.e., the document to geoparse) and\nto link them to pertinent entities in a reference knowledge graph. Then, it exploits several different\nstrategies to traverse the knowledge graph by navigating links between entities. The result of this\nsecond step is an expanded set of candidate entities, that are likely to contain relevant geographic\ninformation for the task. Finally, among the geographic information of all retrieved entities, we select\nthose with which to geotag the input document by means of a regression model, that we trained on\nlabeled data. The combination of powerful AI techniques and the rich, structured, interconnected data\ncontained in multiple knowledge graphs allowsGSP to achieve F1 = 0.66, whereas other state-of-the-art\ntechniques and baselines obtain F1 \u2264 0.55. More in detail, one of the reasons why our solution achieves unprecedented results is because it\nmitigates the problem of toponymic polysemy \u2013 that is, the fact that the same toponym can refer to\ndifferent places according to the context in which it appears 1. The majority of traditional geoparsing\ntechniques adopt heuristics to disambiguate toponyms matched in a gazetteer, a solution that might\nprove ineffective, especially at world-scale. As a consequence, the application of such techniques is often\nconstrained to geographically-limited areas, in order to achieve satisfactory performance [33]. Instead,\nGSP mitigates this issue by performing semantic annotation of the input text \u2013 an operation that\nintrinsically performs disambiguation of tokens based on their context. In addition, our experimental\nresults demonstrate that the expansion and selection steps of GSP also allow to correct some of the\nerrors made by the semantic annotator.\n\n2503.01386v1\nIn Sections 4 and 5, we respectively delve into the\ndetails of the expansion and selection steps of GSP, also providing experimental results to support our\nchoices. Then, in Section 6 we describe our dataset, and we report experimental results of GSP and\nother techniques for the geoparsing task. We conclude with Section 7 discussing our results, and with\nSection 8 summarizing our work and highlighting directions for future research and experimentation. 2 Related Works\nA recent survey on location prediction on Twitter [29] proposed a taxonomy of geotagging and geopars-\ning techniques according to different tasks. These can be: the prediction of (i) the locations mentioned\nin tweets, (ii) the tweet origin location, or (iii) the user home location. The remainder of this section\nadopts the same structure, with a particular focus on works dealing with the prediction of mentioned\nlocations, since our contribution also falls in this category. 2.1 Mentioned location prediction\nThe goal of this task is to identify locations mentioned in a text and link them to the corresponding\ngeographic coordinates. It has been investigated for a long time on well formatted documents \u2013 like\nnews articles, and researchers identified entity mention variability and ambiguity as the two main\nchallenges of this task. However, mentioned location prediction is even more challenging in OSNs, due\nto the noisy and short user-generated posts. The most similar work to our present contribution is our previous attempt at this task, where\nwe proposed a preliminary version of the GSP technique [2]. Similarly to this work, the core idea\nof [2] is to first exploit a semantic annotator to identify relevant portions of the input text, and\nthen to parse the corresponding semantic resources in search for possible geographic information. In\nour previous work, however, we only leveraged a very limited number of semantic resources, actually\ndisregarding many nodes of the available knowledge graphs, that could bring useful information for\nthe geoparsing task, as outlined in Figure 2. Moreover, the selection of the geographic information to\n3\n\ngeoparse the input document was carried out by means of a binary classifier, based on a Support Vector\nMachine (SVM). The thorough, AI-driven exploration of the semantic knowledge graphs, together with\nthe accurate selection of informative graph nodes via gradient-boosted regression, thus represent the\nmain differences between our previous and current works. In turn, the profitable exploitation of\nthis additional information significantly improves geoparsing performance, as demonstrated by our\nexperimental results, reporting F1 = 0.66 vs F1 = 0.55 of our previous work. Apart from our previous contribution, the task of mentioned location prediction was traditionally\ntackled in two steps: (i) mentioned location recognition, and (ii) their subsequent disambiguation. Mentioned location recognition is generally considered as a special type of Named Entity Recognition\n(NER) task, and treated accordingly [43]. A few recent works also proposed other specific techniques\nfor identifying location names in texts, outperforming traditional approaches based on NER.\n\n2503.01386v1\nFor example, if we geotagged a token with the entity Bath, our prediction would be at the city-level,\nsince the DBpedia resource for Bath has rdf:Type=dbo:City18. By following a similar approach, we\nare able to assess the granularity of each distinct ground truth instance in the NEEL16 dataset, since\nground truth annotations are complemented with DBpedia URLs. We can thus perform a granularity-\naware evaluation of GSP, by considering as true positives only those predictions matching both the\nground truth coordinates and the corresponding granularity level. We show the results of this more severe evaluation in Figure 9a. The overall results are still\nsatisfactory, with good performance at the country ( F1 = 0 .670) and city ( F1 = 0 .600) granularity\nlevels. Conversely, the performance slightly drops for regions ( F1 = 0 .458) and POIs ( F1 = 0 .491). To explain this result, in Figure 9b we provide the distribution of the ground truth granularity levels\n18http://dbpedia.org/page/Bath,_Somerset\n22\n\nin the dataset. As shown, regions and POIs are significantly underrepresented. This possibly explains\nwhy our model struggled to learn instances at these granularity levels. In summary, GSP shows suitable\nperformance in location granularity prediction, although there is room to improve it by enriching and\nbalancing the training dataset. 7 Discussion\nThe geoparsing results of the proposed GSP technique, and the comparison with baselines and other\nstate-of-the-art techniques, demonstrated the effectiveness of our design choices, and the favorable\ncompelling performance of GSP. Building on these results, in this section we discuss some additional\nfeatures of our technique, with a specific focus on its robustness, generalizability, extensibility and\napplicability.\n7.1 Robustness and generalizability\nAlthough evaluated on tweets, our technique does not make any assumption on the input text, and it\ndoes not exploit any peculiar feature of Twitter nor of OSNs in general. Because of this, it is suitable\nto geoparse any textual document, including longer texts such as news articles, emails and blog posts. The choice of evaluating our technique on the OSN-derivedNEEL16 dataset stems from the will to test\nGSP on challenging texts. In fact, OSN user-generated content \u2013 and tweets specifically \u2013 are known for\ntheir shortness, lexical sparsity, and for the use of abbreviations, jargon and colloquial expression. As\nsuch, they represent a proving ground for any text mining technique. Given this scenario, our already\npromising results are likely to further improve, should GSP be applied to geoparse longer and well-\nwritten texts. In addition to the challenges related to the analysis of short OSN texts, the NEEL16\ndataset also presents other pitfalls. Indeed, it considers multiple different events and topics, spread\nacross a large geographic area (as shown in Figure 7b), and encompassing several years. In conclusion, the positive results obtained on this challenging and diverse evaluation dataset\nguarantee that GSP can generalize well also to other texts and topics, thus proving its robustness and\ngeneralizability. Results of the application of GSP in-the-wild are thus likely to remain very positive.", "metadata": {"type": "factual", "source": "2503.01289v1.pdf", "context": "g0\ns = {X \u2208 g : Ad(ets)(X) = X, \u2200t \u2208 R}, gs = {X \u2208 g : Ad(ets)(X) is bounded ast \u2192 \u221e},\nand the subgroups\nLs = {g \u2208 G : Ad(g)(s) = s}, P s = {g \u2208 G : etsge\u2212ts is bounded ast \u2192 \u221e}.\nThese subgroups ofG have g0\ns and gs, respectively, as Lie algebras.Ps is parabolic andLs is a\nLevi factor forPs. We also define the character\u03c7s : gs \u2192 C given by\u03c7s(x) = B(s, x), whereB\nis the Killing form ong.\nNow, for aG-bundle E and a reduction\u03c3 \u2208 H0(C, E(G/Ps)) of structure group toPs, we define\nthe degree of the re", "quality_score": 8.25}}
{"id": "test_57", "question": "How would a rapid rearrangement of magnetic fields in SGR 1935+2154 be accompanied?", "golden_answers": ["A rapid rearrangement would likely be accompanied by high-energy activity, such as crustal yielding leading to a local relaxation in the magnetic field."], "prediction": "A rapid rearrangement would likely be accompanied by high-energy activity; for instance, crustal yielding could lead to a local relaxation in the magnetic field and hence a small change in ellipticity.", "f1": 0.723404255319149, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01409v2\nTwo of the components identified as important by Kojima\n(2024) for the failure problem, namely those in the r\u03b8 (left)\nand \u03b8\u03b8 \u2212 \u03d5\u03d5 (right) directions, are shown in Figure 6 for\nBp = 0.5b. Attention has been restricted to the \u2018crust\u2019 0 .9 \u2a7d\nr \u2a7d 1 and, for simplicity, only poloidal stresses are shown\n(i0 = 0). The ratios span the range 0 .87 \u2272 R \u2272 1.08 with\nthe lower and upper limits reached near polar ( \u03b8 \u2248 0, \u03c0) and\nequatorial (\u03b8 \u2248 \u03c0/2) colatitudes, respectively, at the base of\nthe crust ( r \u2248 0.9). The fact that R exceeds unity near the\nequator implies one may expect more frequent failures there\nrelative to the Maxwell case, with the reverse applying near\nthe poles, since the elastic stress should counterbalance the\nelectromagnetic stress. This is likely to skew the anticipated\nwaiting time distribution for flares to later times, as Hall\ndrift tends to tangle field lines near the pole and hence build\nstresses there (see figure 2 in Perna & Pons 2011). This will\nbe investigated in future work. 5.5 Magnetic (anti)-glitches\nAs first described by Ioka (2001), rapid changes to the\nquadrupolar ellipticity of a magnetar may bring about glitch-\nlike activity. By angular momentum conservation, a sudden\nreequilibriation \u03f5i \u2192 \u03f5f would lead to a fractional change in\nf of order\n\u03b4f f \u2248 2\n3 (\u03f5i \u2212 \u03f5f) . (49)\nWhile this model was discussed by Garcia & Ranea-Sandoval\n(2015) in the context of theanti-glitch seen in 1E 2259+586, a\npositive glitch is also possible if \u03f5i > \u03f5f (Mastrano, Suvorov &\nMelatos 2015). In the latter case, a dynamical decay (growth)\nin the poloidal (toroidal) sector could be expected. Such a\nrapid rearrangement would likely be accompanied by high-\nenergy activity; for instance, crustal yielding could lead to\na local relaxation in the magnetic field and hence a small\nchange in \u03f5. In the BI theory, maximum values for the toroidal elliptic-\nity also imply an upper limit to the size of a magnetically-\ninduced glitch. For SGR 1935+2154 with Bp \u2248 4 \u00d7 1014 G,\nresults from Tab. 4.1 indicate a maximum shift of \u2248 5\u00d710\u22126\nfor b = 1016 G. Using equation (49), this implies a maximum\nglitch magnitude of \u03b4f \u2248 (b/1016 G)2 \u00b5Hz for P = 3.25 s.\nMNRAS 000, 1\u201315 (?)\n\n12 Arthur G. Suvorov & Jos\u00b4 e A. Pons\nFigure 6.Dimensionless ratios of BI-to-Maxwell stresses (48) in the r\u03b8 (left) and \u03b8\u03b8 \u2212 \u03d5\u03d5 (right) directions within a \u2018crust\u2019 for the field\n(27), with redder shades indicating a greater ratio R. The classical polar strength is fixed as Bp = b/2. This is about half the size of the large glitch seen in this\nobject prior to the release of a fast radio burst in 2020 Oc-\ntober ( \u03b4f \u2248 1.8+0.7\n\u22120.5 \u00b5Hz; Younes et al. 2023) suggesting a\nfloor b \u2a7e\n\u221a\n2 \u00d7 1016 G, assuming magnetic rearrangement\nwas responsible for the burst and glitch. 6 DISCUSSION\n\n2503.01409v1\nSuch a maximum\nmay be in tension with observations of long-period magnetar X-ray modulations made by Makishima et al. (2014) and others\nif interpreted as free precession, or GRB afterglow data, as both seem to require |\u03f5| \u2273 10\u22124, unless b \u2273 1017 G. Even so, with\nDECIGO the prospects for detecting GWs from adolescent, Galactic magnetars are not overly pessimistic (see Tab. 4.1). We also explore how limitations on the toroidal partition together with the effective augmentation of the near-surface field\nimpacts on magnetar phenomena. For example, we find that because the current is effectively reduced in NLED via the\ngeneralised Amp\u00b4 ere law (1), the effective Ohmic and Hall timescales are reduced slightly for super-Schwinger fields (see Fig. 5). This may help to explain the coldness and longevity of strong fields in the mysterious class of ULPs, assuming (a subset of\nthem) are isolated magnetars (Hurley-Walker et al. 2022; Suvorov & Melatos 2023; de Ruiter et al. 2024), especially since\nspindown is also accelerated for strong fields (see equation 47). A thorough investigation of Hall-Ohm (and magnetothermal\nmore generally) evolution in NLED, including crustal plasticity (Sec. 5.4), is reserved for future work. Several extensions of this study are natural. One path involves the inclusion of general-relativistic effects, which may have\ninteresting interplays with NLED as the energy density Ttt becomes large (Rezzolla & Ahmedov 2004; P\u00b4 etri 2015). It has been\nargued, for instance, that the Blandford-Znajek process is less effective in NLED (Li & Wang 2020), which could influence the\nproperties of relativistic jets relevant for GRBs (Sec. 5.3). Explicit solutions to the GGS equation, either for non-barotropic or\nbarotropic stars (compare the calculations in Secs. 3.2 and Appendix A), could also be useful to study the stability of internal\nfields along the lines discussed by Rau & Wasserman (2021) for the core or Rau & Wasserman (2023) for the crust. It would\nalso be worth tackling the magnetosphere problem in more detail. Using the methodology introduced by Urb\u00b4 an et al. (2023)\nand Stefanou, Urb\u00b4 an & Pons (2023), the force-free NLED structure of the magnetosphere could be solved for, including the\npossibility of rotation (\u2018NLED pulsar equation\u2019). The structure of coronal loops, for example, relating magnetic topology to\nflare properties and hotspots may differ because the effective twist is modulated by L\u2032(F2), as per equation (7). Finally, it is important to note we do not discuss superconductivity/fluidity in this paper, though an understanding of such\nphenomena is probably crucial for accurately modelling the stellar interior; it is unclear what role NLED may play in this case. ACKNOWLEDGEMENTS\nSupport provided by the Conselleria d\u2019Educaci\u00b4 o, Cultura, Universitats i Ocupaci\u00b4 o de la Generalitat Valenciana through Prom-\neteo Project CIPROM/2022/13 is acknowledged. AGS extends his thanks to the members of the theoretical astrophysics group\nin T\u00a8 ubingen for the warm welcome he received while this work was being completed. MNRAS 000, 1\u201316 (?)\n\nMagnetars in nonlinear electrodynamics 15\nDATA AVAILABILITY STATEMENT\nObservational data used in this paper are quoted from the cited works. No new data were produced here.\n\n2503.01409v2\nThese sources were seen to pulse in the\nradio band in a way that is phenomenologically similar to\npulsars and yet, with the exception of ASKAP J1832\u20130911\n(Wang et al. 2024), were invisible to follow-up X-ray searches\n(e.g., Hurley-Walker et al. 2022). If they did indeed house\npolar field-strengths of order \u2273 1016 G, as would fit with\nspindown bounds and pair-production thresholds (Suvorov\n& Melatos 2023), alleviating tensions with thermal limits be-\ncomes easier. Alternative pathways for ULP production that\ndo not require NLED-level fields have been explored though\n(see Cooper & Wadiasingh 2024; Suvorov, Dehman & Pons\n2025. 5.2 Spindown\nMaintaining a stronger polar-field strength also implies that\nthe star should spin-downfaster than in the Maxwellian case,\nwhere the spindown rate of an inclined rotator in vacuum\nreads (e.g., Manchester & Taylor 1977)\n\u02d9P(t) = 4\u03c02 Bp(t)2 sin2 \u03c7(t)R6\n\u22c6\n6I0P(t)c3 , (44)\nfor spin period P and magnetic inclination angle \u03c7. In NLED,\nthe Poynting flux, S, is augmented by a factor which is re-\nlated to the effective increase of the surface dipole, as per the\nperturbative solution (21) (Denisov et al. 2016). We have\nS = 1 4\u03c0 E \u00d7 H = \u2212L\u2032(F2)\n4\u03c0 E \u00d7 B, (45)\nwhich can be integrated given some magnetospheric solution\nto deduce the adjusted spindown rate. Such a calculation was\ncarried out by Ripoche & Heyl (2019) in the perturbative, PM\nframework finding an effective increase in the radiated power\nat the surface of the star in the form (see equations 2.22 and\n3.10 therein)\nLPM\nLMax \u2248 1 + 12\n5 \u03b1PMB2\np. (46) For the BI theory,\u03b1PM = 1/2b2 and hence for Bp = 0.5b spin-\ndown may be enhanced by \u2248 30%. However, care should be\ntaken since the PM expansion becomes an increasingly poor\napproximation as the field grows: a counterterm \u223c B4\np/b4 at\nPPM order will reduce the NLED contribution. Nevertheless,\nfor Bp \u2272 0.5b we anticipate a BI-adjusted spindown law of\nthe form\n\u02d9P(t) \u2248 4\u03c02 Bp(t)2 sin2 \u03c7(t)R6\n\u22c6\n6I0P(t)c3\n\u0014\n1 + 6\n5\nBp(t)2\nb2\n\u0015\n, (47)\nwhich, combined with decay-stalling, could steepen the light\ncurves of millisecond magnetars. Corrections to such a for-\nmula accounting for magnetospheric drag were studied by\nP\u00b4 etri (2015), who found the result sin2 \u03c7 \u2192 k1 + k2 sin2 \u03c7 for\nk1,2 \u2248 1.\n5.3 Gamma-ray bursts and dynamos\nIn a neutron-star binary coalescence event where the con-\nstituents are not too heavy, a third, more extreme neutron\nstar may be born. Due to (orbital) angular momentum con-\nservation, such a remnant is expected to be rapidly rotating\nwith a high degree of differential rotation that can excite dy-\nnamo activity (e.g., Kiuchi et al. 2024). A hotly debated topic in the GRB literature concerns\nwhether or not magnetar remnants are capable of launch-\ning a relativistic jet that can drill through the polar baryon\npollution (see Ciolfi 2020, for a review).", "metadata": {"type": "reasoning", "source": "2503.01409v2.pdf", "context": "in the poloidal (toroidal) sector could be expected. Such a\nrapid rearrangement would likely be accompanied by high-\nenergy activity; for instance, crustal yielding could lead to\na local relaxation in the magnetic field and hence a small\nchange in \u03f5.\nIn the BI theory, maximum values for the toroidal elliptic-\nity also imply an upper limit to the size of a magnetically-\ninduced glitch. For SGR 1935+2154 with Bp \u2248 4 \u00d7 1014 G,\nresults from Tab. 4.1 indicate a maximum shift of \u2248 5\u00d710\u22126\nfor b = 1016 ", "quality_score": 8.25}}
{"id": "test_58", "question": "What is one of the tasks required of a UA V?", "golden_answers": ["The model must navigate to a designated gate associated with a notable figure."], "prediction": "One of the tasks required of a UA V is to traverse a race track composed of multiple sequential gates.", "f1": 0.07407407407407408, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01378v1\nThroughout each flight,\nthe UA V\u2019s velocity and the head profile (Vx, Vy, Vz, omega)\nwas continuously logged, providing a comprehensive record\nof its dynamic behavior. The dataset was divided into training and test subsets,\nensuring an equitable distribution of samples across all three\ncategories in both sets. The training subset was employed\nto optimize the VLA model parameters, while the test\nsubset forms the foundation of the CognitiveDroneBench\nbenchmark for performance evaluation. B. Model Training\nThe VLA model was fine-tuned using our custom training\ndataset based on the OpenVLA architecture. The collected\ndata was structured in accordance with the Reinforcement\nLearning Dataset (RLDS) format to ensure seamless com-\npatibility with OpenVLA. This organization facilitated effi-\ncient management of actions, images, and task instructions,\nrendering the dataset suitable for both imitation learning and\ntask-specific action prediction. Subsequently, the dataset was\nutilized to fine-tune an OpenVLA-7b model employing a\nparameter-efficient Low-Rank Adaptation (LoRA) approach,\napplying rank-32 adapters to optimize memory usage while\nadjusting a minimal set of trainable weights. The training\nconfiguration consisted of a batch size of 64, a learning\nrate of 5 \u00d7 10\u22124, and 4000 gradient steps, with image\naugmentation disabled. Training was conducted on four NVIDIA A100 GPUs, al-\nlowing for efficient large-scale optimization while maintain-\ning real-time deployability on UA V hardware. Checkpoints\nwere saved at regular intervals, with evaluations performed\nevery 500 steps to monitor model performance. For a detailed\noverview of the training progression, please refer to the\nlearning curve in Figure 4. V. E VALUATION\nA. CognitiveDroneBench\nThe evaluation of cognitive capabilities in UA Vs poses\nunique challenges that are even more pronounced than\nthose encountered in robotic manipulators. To address these\nchallenges and to enable an objective comparison of VLA\nmodels for UA Vs, we developed an open-source simulation\nbenchmark named CognitiveDroneBench. As illustrated in\nFigure 1, the benchmark is implemented within a high-\nfidelity physical simulation environment that accurately repli-\ncates the dynamics and physics of UA V flight. In our benchmark, the drone is required to traverse a race\ntrack composed of multiple sequential gates. At each stage\nof the track, the drone receives a first-person view (FPV)\nimage along with a task-specific textual instruction. The core\nobjective is to select the correct gate by solving an embedded\ncognitive task, thereby generating a 4D action command that\ndictates its movement. The tasks are categorized into three\ndistinct types: Human Recognition , Symbol Understand-\ning, and Reasoning. For conventional VLA models, such as RaceVLA and the\nbase version of CognitiveDrone, the decision-making process\ninvolves directly processing the FPV image and associated\nprompt to determine the appropriate action. In contrast,\nthe CognitiveDrone-R1 variant incorporates an additional\nreasoning stage using a VLM. This VLM processes the task\ninstruction and visual data to disambiguate and simplify the\ndirective, effectively reducing the complexity of the task\nbefore passing it to the VLA model for high-frequency\ncontrol. Task performance is automatically validated: passing\nthrough the correct gate earns the drone 1 point.\n\nPreparation of Papers for AIAA Journals\nIn terms of maintenance locations, while traditional fixed -wing airlines possess hangars at each airport and their \naffiliated technicians directly maintain the aircraft, UAM operates a bit differently. UAM relies on \"Vertiports,\" which \nserve as terminals or stops within urban areas, playing a similar role to traditional airports. Because these Vertiports \nare scattered throughout the city, it is challenging to centralize maintenance locations, parts, and staff. As a result, \nthere's no need for separate hangars for UAM maintenance. Furthermore, it's essential to develop a system that allows \neven non-experts to identify aircraft defects quickly and easily. B. Anomaly Detection \nAnomaly Detection is a field of artificial intelligence research that identifies abnormal data within a given dataset. It focuses on discovering data (abnormal data) that hasn't appeared yet but could potentially arise. In this context, \n\"abnormal\" refers to something that deviates from a normal state, differs from common experience or knowledge, is \npeculiar or unique, or is dubious and unidentifiable. This includes situations where the shape or state of images, sounds, \nor data deviates from what is typically considered normal. Anomaly Detection serves as a mechanism to detect such abnormal data, mainly to identify machine malfunctions, \nrecognize abnormalities in system logs, or verify abnormal states in images or videos. Essentially, it is used to detect \nconditions that are notably different while a standard state is maintained. This paper aims to study a method to detect \nabnormal conditions of UAM Propellers using anomaly detection artificial intelligence models. According to Chalapathy et al (Chalapathy & Chawla, 2019), Anomaly Detection can be divided into Supervised \nLearning, Semi-supervised Learning, and Unsupervised Learning. Supervised learning is a method where one trains \na classification model (Omar et al., 2013 ) using data labeled as normal and abnormal. When new data is input, the \nmodel estimates whether it's anomalous. Supervised learning has the advantage of guaranteed performance. However, \ndue to the nature of fields where Anomaly Detection is used, it is dif ficult to acquire data on abnormal samples. Additionally, there is a significant data imbalance between normal and abnormal data. Fundamental classification \nmodels such as SVM, Decision Tree, and Deep Neural Network fall under this category. On the other hand, the method most used for Anomaly Detection models is semi -supervised learning. In this \nmethod, the model is trained on one class of data (usually normal data) and determines the range for this trained data. If new incoming data falls out side this range, it is considered abnormal data. Semi -supervised learning has the\n\n5 \n \nadvantage of showing substantial performance levels even when trained with one class and requires less data for \ntraining. However, there's a disadvantage: by determining the range for normal data, it might not reflect all the features \nof a small amount of abnormal data, leading to overfitting. Representative models for this approach include Deep \nSVDD (Zhou et al., 2021 ), Isolation Forest (Liu et al., 2008), and AutoEncoders (Baldi, 2012) that verify normality \nthrough data compression and restoration. The unsupervised learning method detects anomalies based solely on the intrinsic properties of the data.\n\n2503.01378v1\nCognitiveDrone: A VLA Model and Evaluation Benchmark for\nReal-Time Cognitive Task Solving and Reasoning in UA Vs\nArtem Lykov\u2217, Valerii Serpiva\u2217, Muhammad Haris Khan, Oleg Sautenkov,\nArtyom Myshlyaev, Grik Tadevosyan, Yasheerah Yaqoot, and Dzmitry Tsetserukou\nAbstract\u2014 This paper introduces CognitiveDrone, a novel\nVision-Language-Action (VLA) model tailored for complex\nUnmanned Aerial Vehicles (UA Vs) tasks that demand ad-\nvanced cognitive abilities. Trained on a dataset comprising\nover 8,000 simulated flight trajectories across three key cate-\ngories\u2014Human Recognition, Symbol Understanding, and Rea-\nsoning\u2014the model generates real-time 4D action commands\nbased on first-person visual inputs and textual instructions. To\nfurther enhance performance in intricate scenarios, we pro-\npose CognitiveDrone-R1, which integrates an additional Vision-\nLanguage Model (VLM) reasoning module to simplify task\ndirectives prior to high-frequency control. Experimental evalua-\ntions using our open-source benchmark, CognitiveDroneBench,\nreveal that while a racing-oriented model (RaceVLA) achieves\nan overall success rate of 31.3%, the base CognitiveDrone model\nreaches 59.6%, and CognitiveDrone-R1 attains a success rate\nof 77.2%. These results demonstrate improvements of up to\n30% in critical cognitive tasks, underscoring the effectiveness of\nincorporating advanced reasoning capabilities into UA V control\nsystems. Our contributions include the development of a state-\nof-the-art VLA model for UA V control and the introduction\nof the first dedicated benchmark for assessing cognitive tasks\nin drone operations. The complete repository is available at\nhttps://cognitivedrone.github.io. I. I NTRODUCTION In an era marked by rapid advancements in robotics and\nartificial intelligence, enabling robots to perform a wide\nrange of complex tasks in dynamically changing environ-\nments has emerged as a critical challenge. Cognitive robotics\nstrives not only to endow machines with precise control but\nalso to equip them with high-level reasoning and decision-\nmaking capabilities that allow them to adapt to unpredictable\nreal-world scenarios. Despite notable progress in various\ndomains of robotics, one persistent challenge remains: how to\nobjectively evaluate and compare cognitive robotic systems,\nparticularly when they are expected to tackle a multitude of\nintricate tasks. The scarcity of standardized, open-source benchmarks and\ndatasets is especially evident in the realm of Unmanned\nAerial Vehicles (UA Vs), where existing evaluation frame-\nworks are largely confined to racing or basic navigation\ntasks. This limitation not only hinders fair comparison among\ndifferent cognitive UA V systems but also restricts the ex-\n\u2217 These authors contributed equally to this work. The authors are with the Intelligent Space Robotics Laboratory,\nCenter for Digital Engineering, Skolkovo Institute of Science\nand Technology. {Artem. Lykov, Valerii. Serpiva,\nharis.khan, Artyom. Myshlyaev, oleg.sautenkov,\ngrik.tadevosyan, yasheerah.yaqoot,\nd.tsetserukou}@skoltech.ru\nFig. 1. CognitiveDrone is a VLA system for UA Vs that generates\nsmooth 4D control commands from first-person visual inputs and natural\nlanguage instructions. It combines a 7B-parameter VLA model trained on\nan extensive open-source dataset of cognitive tasks\u2014including reasoning,\nhuman recognition, and symbol understanding\u2014with a 7B-parameter VLM\nreasoning module that refines task directives. The system is evaluated within\nCognitiveDroneBench\u2014the first evaluation benchmark for VLA systems\ntailored to cognitive UA Vs\u2014where the drone must navigate a track with\ngates by selecting the appropriate gate through solving cognitive tasks.", "metadata": {"type": "factual", "source": "2503.01378v1.pdf", "context": "the individuals based on external characteristics specified\nwithin the textual prompt. Additionally, the UA V is tasked\nwith navigating to a designated gate associated with a notable\nfigure.\nSymbol Understanding: The model is required to differ-\nentiate between a variety of symbols, including alphanumeric\ncharacters (e.g., numbers and letters), corporate logos, and\npictorial representations of animals.\nReasoning: In this category, the UA V must execute tasks\nnecessitating logical deduction. Exam", "quality_score": 8.25}}
{"id": "test_59", "question": "Why is the compositionality gap in language models an important area of study, according to the paper by Ofir Press et al. (2023)?", "golden_answers": ["The compositionality gap refers to the difference between the performance of language models on individual components versus their overall performance, and measuring and narrowing this gap can help improve the reliability and trustworthiness of these models."], "prediction": "The compositionality gap in language models is an important area of study because it highlights the limitations of these models in understanding and generating complex language structures. Addressing this gap can lead to improvements in the models' ability to comprehend and produce language that reflects the nuanced relationships between words and phrases, ultimately enhancing their performance in various natural language processing tasks.", "f1": 0.4044943820224719, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.00995v1\nIn: The\nTwelfth International Conference on Learning Representations (2024)\n[31] Sta\u0144, I.: Why is the linguistic context important while work-\ning on textual data? (Nov 2023), https://medium.com/@izab.sta/\nwhy-is-the-linguistic-context-important-ba9069cf34de\n[32] Suzgun, M., Scales, N., Sch\u00e4rli, N., Gehrmann, S., Tay, Y., Chung, H.W.,\nChowdhery, A., Le, Q.V., Chi, E.H., Zhou, D., , Wei, J.: Challenging big-\nbench tasks and whether chain-of-thought can solve them. arXiv preprint\narXiv:2210.09261 (2022)\n[33] Tuora, R., Zwierzchowska, A., Zawadzka-Paluektau, N., Klamra, C.,\nKobyli\u0144ski, L.: Poquad - the polish question answering dataset - description\nand analysis. In: Proceedings of the 12th Knowledge Capture Conference\n2023. p. 105\u2013113. K-CAP \u201923, Association for Computing Machinery, New\nYork, NY, USA (2023), https://doi.org/10.1145/3587259.3627548\n[34] Wang, Y., Ma, X., Zhang, G., Ni, Y., Chandra, A., Guo, S., Ren, W., Arulraj,\nA., He, X., Jiang, Z., et al.: Mmlu-pro: A more robust and challenging multi-\ntask language understanding benchmark. arXiv preprint arXiv:2406.01574\n(2024)\n[35] Yang, A., Yang, B., Hui, B., Zheng, B., Yu, B., Zhou, C., Li, C., et al.:\nQwen2 technical report. arXiv preprint arXiv:2407.10671 (2024)\n[36] Zheng, L., Chiang, W.L., Sheng, Y., Zhuang, S., Wu, Z., Zhuang, Y., Lin,\nZ., Li, Z., Li, D., Xing, E.P., Zhang, H., Gonzalez, J.E., Stoica, I.: Judging\nllm-as-a-judge with mt-bench and chatbot arena. In: Proceedings of the\n37th International Conference on Neural Information Processing Systems. NIPS \u201923, Curran Associates Inc., Red Hook, NY, USA (2024)\n[37] Zhou, J., Lu, T., Mishra, S., Brahma, S., Basu, S., Luan, Y., Zhou, D.,\nHou, L.: Instruction-following evaluation for large language models. arXiv\npreprint arXiv:2311.07911 (2023)\n[38] Zhuo, T.Y., Vu, M.C., Chim, J., Hu, H., Yu, W., Widyasari, R., Yusuf,\nI.N.B., Zhan, H., He, J., Paul, I., et al.: Bigcodebench: Benchmarking code\ngeneration with diverse function calls and complex instructions. arXiv\npreprint arXiv:2406.15877 (2024)\n\nFrom Hypothesis to Publication: A Comprehensive Survey of AI-Driven Research Support Systems\nIn Pro-\nceedings of the 2024 Conference on Empirical Meth-\nods in Natural Language Processing, EMNLP 2024,\nMiami, FL, USA, November 12-16, 2024, pages 8783\u2013\n8817. Association for Computational Linguistics. Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xi-\naolei Wang, Yupeng Hou, Yingqian Min, Beichen\nZhang, Junjie Zhang, Zican Dong, and 1 others.\n2023a. A survey of large language models. arXiv\npreprint arXiv:2303.18223.\nXueliang Zhao, Wenda Li, and Lingpeng Kong. 2023b. Decomposing the enigma: Subgoal-based demon-\nstration learning for formal theorem proving. CoRR,\nabs/2305.16366.\nKunhao Zheng, Jesse Michael Han, and Stanislas Polu.\n2022. minif2f: a cross-system benchmark for for-\nmal olympiad-level mathematics. In The Tenth In-\nternational Conference on Learning Representations,\nICLR 2022, Virtual Event, April 25-29, 2022. Open-\nReview.net. Qinkai Zheng, Xiao Xia, Xu Zou, Yuxiao Dong, Shan\nWang, Yufei Xue, Lei Shen, Zihan Wang, Andi Wang,\nYang Li, and 1 others. 2023a. Codegeex: A pre-\ntrained model for code generation with multilingual\nbenchmarking on humaneval-x. In Proceedings of\nthe 29th ACM SIGKDD Conference on Knowledge\nDiscovery and Data Mining, pages 5673\u20135684. Yizhen Zheng, Huan Yee Koh, Jiaxin Ju, Anh T. N.\nNguyen, Lauren T. May, Geoffrey I. Webb, and\nShirui Pan. 2023b. Large language models for sci-\nentific synthesis, inference and explanation. CoRR,\nabs/2310.07984.\nYangqiaoyu Zhou, Haokun Liu, Tejes Srivastava,\nHongyuan Mei, and Chenhao Tan. 2024. Hypoth-\nesis generation with large language models. CoRR,\nabs/2404.04326.\nKun Zhu, Xiaocheng Feng, Xiachong Feng, Yingsheng\nWu, and Bing Qin. 2023. Hierarchical catalogue\ngeneration for literature review: A benchmark. In\nFindings of the Association for Computational Lin-\nguistics: EMNLP 2023, Singapore, December 6-10,\n2023, pages 6790\u20136804. Association for Computa-\ntional Linguistics. Minjun Zhu, Yixuan Weng, Linyi Yang, and Yue Zhang.\n2025. Deepreview: Improving llm-based paper re-\nview with human-like deep thinking process. arXiv\npreprint arXiv:2503.08569. A Further Discussion\nOpen Question: What is the difference between\nAI for science and AI for research? We posit\nthat AI for research constitutes a subset of AI for\nscience. While AI for research primarily focuses\non supporting or automating the research process, it\nis not domain-specific and places greater emphasis\non methodological advancements. In contrast, AI\nfor science extends beyond the research process to\ninclude result-oriented discovery processes within\nspecific domains, such as materials design, drug\ndiscovery, biology, and the solution of partial differ-\nential equations (Zheng et al., 2023b; AI4Science\nand Quantum, 2023; Zhang et al., 2024d). Open Question: What is the difference between\nhypothesis generation and scientific discovery?\nHypothesis generation, which is primarily based\non literature-based review (LBD) (Swanson, 1986;\nSebastian et al., 2017), emphasizing the process by\nwhich researchers generate new concepts, solutions,\nor approaches through existing research and their\nown reasoning. Scientific discovery encompasses\nnot only hypothesis generation, but also innova-\ntion in fields like molecular optimization and drug\ndevelopment (Ye et al., 2024; Liu et al., 2024b),\ndriven by outcome-oriented results. Open Question: What is the difference be-\ntween systematic literature review and related\nwork generation?\n\nFrom Hypothesis to Publication: A Comprehensive Survey of AI-Driven Research Support Systems\nIn Pro-\nceedings of the 2024 Conference on Empirical Meth-\nods in Natural Language Processing, EMNLP 2024,\nMiami, FL, USA, November 12-16, 2024, pages 8783\u2013\n8817. Association for Computational Linguistics. Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xi-\naolei Wang, Yupeng Hou, Yingqian Min, Beichen\nZhang, Junjie Zhang, Zican Dong, and 1 others.\n2023a. A survey of large language models. arXiv\npreprint arXiv:2303.18223.\nXueliang Zhao, Wenda Li, and Lingpeng Kong. 2023b. Decomposing the enigma: Subgoal-based demon-\nstration learning for formal theorem proving. CoRR,\nabs/2305.16366.\nKunhao Zheng, Jesse Michael Han, and Stanislas Polu.\n2022. minif2f: a cross-system benchmark for for-\nmal olympiad-level mathematics. In The Tenth In-\nternational Conference on Learning Representations,\nICLR 2022, Virtual Event, April 25-29, 2022. Open-\nReview.net. Qinkai Zheng, Xiao Xia, Xu Zou, Yuxiao Dong, Shan\nWang, Yufei Xue, Lei Shen, Zihan Wang, Andi Wang,\nYang Li, and 1 others. 2023a. Codegeex: A pre-\ntrained model for code generation with multilingual\nbenchmarking on humaneval-x. In Proceedings of\nthe 29th ACM SIGKDD Conference on Knowledge\nDiscovery and Data Mining, pages 5673\u20135684. Yizhen Zheng, Huan Yee Koh, Jiaxin Ju, Anh T. N.\nNguyen, Lauren T. May, Geoffrey I. Webb, and\nShirui Pan. 2023b. Large language models for sci-\nentific synthesis, inference and explanation. CoRR,\nabs/2310.07984.\nYangqiaoyu Zhou, Haokun Liu, Tejes Srivastava,\nHongyuan Mei, and Chenhao Tan. 2024. Hypoth-\nesis generation with large language models. CoRR,\nabs/2404.04326.\nKun Zhu, Xiaocheng Feng, Xiachong Feng, Yingsheng\nWu, and Bing Qin. 2023. Hierarchical catalogue\ngeneration for literature review: A benchmark. In\nFindings of the Association for Computational Lin-\nguistics: EMNLP 2023, Singapore, December 6-10,\n2023, pages 6790\u20136804. Association for Computa-\ntional Linguistics. Minjun Zhu, Yixuan Weng, Linyi Yang, and Yue Zhang.\n2025. Deepreview: Improving llm-based paper re-\nview with human-like deep thinking process. arXiv\npreprint arXiv:2503.08569. A Further Discussion\nOpen Question: What is the difference between\nAI for science and AI for research? We posit\nthat AI for research constitutes a subset of AI for\nscience. While AI for research primarily focuses\non supporting or automating the research process, it\nis not domain-specific and places greater emphasis\non methodological advancements. In contrast, AI\nfor science extends beyond the research process to\ninclude result-oriented discovery processes within\nspecific domains, such as materials design, drug\ndiscovery, biology, and the solution of partial differ-\nential equations (Zheng et al., 2023b; AI4Science\nand Quantum, 2023; Zhang et al., 2024d). Open Question: What is the difference between\nhypothesis generation and scientific discovery?\nHypothesis generation, which is primarily based\non literature-based review (LBD) (Swanson, 1986;\nSebastian et al., 2017), emphasizing the process by\nwhich researchers generate new concepts, solutions,\nor approaches through existing research and their\nown reasoning. Scientific discovery encompasses\nnot only hypothesis generation, but also innova-\ntion in fields like molecular optimization and drug\ndevelopment (Ye et al., 2024; Liu et al., 2024b),\ndriven by outcome-oriented results. Open Question: What is the difference be-\ntween systematic literature review and related\nwork generation?", "metadata": {"type": "reasoning", "source": "2503.01332v1.pdf", "context": "Teaching models to express their uncertainty in\nwords. arXiv preprint arXiv:2205.14334.\nMoran Mizrahi, Guy Kaplan, Dan Malkin, Rotem Dror,\nDafna Shahaf, and Gabriel Stanovsky. 2024. State\nof what art? a call for multi-prompt llm evaluation.\nTransactions of the Association for Computational\nLinguistics, 12:933\u2013949.\nLong Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,\nCarroll Wainwright, Pamela Mishkin, Chong Zhang,\nSandhini Agarwal, Katarina Slama, Alex Ray, et al.\n2022. Training language models to ", "quality_score": 8.25}}
{"id": "test_60", "question": "Why don't the speakers interrupt each other in the provided audio?", "golden_answers": ["They speak at different times and their overlapping is minimal."], "prediction": "The speakers don't interrupt each other in the provided audio because the first speaker has not provided a signal indicating they are finished speaking, and the flow of conversation suggests that the first speaker is likely to continue. Additionally, the tone of the conversation is casual and friendly, which reduces the likelihood of competitive interruptions.", "f1": 0.10714285714285714, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01174v1\nThe second speaker\u2019s overlap is a mistimedattempt to start their turn, and the first speaker willcontinue, forcing the second speaker to wait for anatural break or pause before speakingQwen2-Audio-Instruct\nB\nInterruption Qwen-Audio-Chat Based solely on the provided audio, it is morelikely that the second speaker\u2019s overlap is a suc-cessful interruption, and they will take over theconversation. This is because the audio endsabruptly as the second speaker begins to speak,suggesting that the first speaker was interrupted. Additionally, the second speaker\u2019s tone soundsconfident and assertive, which is characteristic ofsomeone who is trying to take over a conversation. On the other hand, the first speaker\u2019s response isshort and does not indicate that they are about topause or continue speaking. Whisper+GPT-4o During spontaneous human conversation, inter-ruptions occur frequently and often correspond tobreaks in the information flow between conver-sation partners. Interruptions can happen due toa variety of reasons like urgency, disagreement,etc. Interruptions can be broadly classified intotwo categories: competitive and cooperative in-terruptions. Occurrences of competitive interrup-tions are usually disrupting to the flow of con-versation between speakers while cooperative in-terruptions are more supportive to the flow. Youare examining a short audio clip from a conver-sation between two people. The audio ends sud-denly RIGHT as the second speaker begins to talk,overlapping with the first speaker. It\u2019s impossibleto tell from this brief excerpt if the first speakerwas about to pause, was having trouble finding aword, or would have continued speaking. BasedONLY on the provided audio, is it more likelythat: (a) The second speaker\u2019s overlap is a suc-cessful interruption, and they will take over theconversation? (b) The second speaker\u2019s overlap isa mistimed attempt to start their turn, and the firstspeaker will continue, forcing the second speakerto wait for a natural break or pause before speak-ing? Justify your choice, considering the fac-tors that might lead to a successful interruptionor encourage someone to wait their turn, but fo-cus on how the SPECIFIC TIMING of this over-lap makes one outcome more likely than the other. Based on the provided audio excerpt, it is morelikely that: (b) The second speaker\u2019s overlap is amistimed attempt to start their turn, and the firstspeaker will continue, forcing the second speakerto wait for a natural break or pause before speak-ing. Justification: 1. **Context and Flow**: Thefirst speaker is in the middle of a detailed expla-nation about weather patterns and their impact onsnowfall. They have not yet reached a clear con-clusion or natural pause in their narrative. Thesentence\u00a8But I have played\u00a8suggests that the firstspeaker is about to continue with a related pointor anecdote. 2. **Timing of Overlap**: The over-lap occurs just as the first speaker is transitioningto a new but related point (\u00a8But I have played\u00a8).This timing suggests that the first speaker is notfinished and is likely to continue speaking. Thesecond speaker\u2019s attempt to interject at this mo-ment is mistimed because it interrupts the flow ofthe first speaker\u2019s ongoing thought. 3. **Con-versational Dynamics**: In spontaneous conver-sation, speakers often signal the end of their turnwith a clear pause or a concluding statement.\n\n2503.01174v1\nThefirst speaker has not provided such a signal, mak-ing it more likely that they will continue speak-ing despite the second speaker\u2019s attempt to inter-ject. Given these factors, the specific timing of theoverlap makes it more likely that the first speakerwill continue, and the second speaker will need towait for a more appropriate moment to take theirturn. Table 14: Prompts for audio foundation models on test benchmarks evaluating their ability topredict\nturn-taking events. All open source FMs have same best prompt. 28\n\n2503.01174v1\nOccurrences of competitive interruptionsare usually disrupting to the flow of conversationbetween speakers while cooperative interruptionsare more supportive to the flow. You are analyzinga brief audio clip from a two-person conversation. The clip ends abruptly while the current speaker isstill in the middle of a sentence. It is unclear fromthe provided audio whether the speaker is about topause, is struggling to find the right word, or willcontinue speaking uninterrupted. Based ONLYon the provided audio, is it more likely that: (a)The other speaker will interrupt BEFORE the cur-rent speaker finishes their sentence? (b) The otherspeaker will let the current speaker to continuespeaker? Justify your choice, considering the fac-tors that might lead to an interruption or encouragesomeone to wait their turn. Based on the provided audio, it is more likely that:(b) The other speaker will let the current speakercontinue speaking. Justification: 1. **Flow ofConversation**: The current speaker is narratinga story with a clear sequence of events. The nar-rative seems to be reaching a conclusion, as indi-cated by the speaker\u2019s expression of satisfaction (\u00a8Ijust had the biggest grin on my face\u00a8). 2. **Lis-tener\u2019s Engagement**: The other speaker has al-ready shown engagement and support by interject-ing with\u00a8I\u2019ll bet you did,\u00a8which is a cooperative in-terruption. This indicates that the listener is fol-lowing the story and is likely to allow the speakerto finish their thought. 3. **Lack of Urgency orDisagreement**: There are no signs of urgencyor disagreement in the provided audio. The toneof the conversation is casual and friendly, whichreduces the likelihood of a competitive interrup-tion. 4. **Narrative Completion**: The currentspeaker is in the middle of a sentence that seemsto be wrapping up the story. Interrupting at thispoint would disrupt the natural conclusion of thenarrative. Given these factors, it is more reason-able to expect that the other speaker will wait forthe current speaker to finish their sentence beforeresponding.\nTable 13: Prompts for audio foundation models on test benchmarks evaluating their ability topredict\nturn-taking events. All open source FMs have same best prompt. 27\n\nPublished as a conference paper at ICLR 2025\nTurn-taking event Model Prompts Example Output\nSuccessful SALMONN You are examining a short audio clip from aconversation between two people. The audio endssuddenly RIGHT as the second speaker begins totalk, overlapping with the first speaker. It\u2019simpossible to tell from this brief excerpt if thefirst speaker was about to pause, was havingtrouble finding a word, or would have continuedspeaking. Based ONLY on the provided audio, isit more likely that: (A) The second speaker\u2019soverlap is a successful interruption, and they willtake over the conversation? (B) The secondspeaker\u2019s overlap is a mistimed attempt to starttheir turn, and the first speaker will continue,forcing the second speaker to wait for a naturalbreak or pause before speaking? Output only Aor B, nothing else. Among A or B, the answer is\n(B)", "metadata": {"type": "reasoning", "source": "2503.01174v1.pdf", "context": "with (a) Yes or (b) No.\n(b) No\nInterruption\nSALMONN Do the 2 speakers interrupt\neach other anywhere in the\nprovided audio? Briefly\nexplain your answer. You\nmust reply with (a) Yes or\n(b) No.\nNo, the 2 speakers\ndo not interrupt each\nother in the provided\naudio.\nQwen2-\nAudio-\nInstruct\nNo, the speakers do\nnot interrupt each\nother. They speak at\ndifferent times and\ntheir overlapping is\nminimal.\nQwen-Audio-\nChat\nYes, the two speakers\ninterrupt each other.\nWhisper+GPT-\n4o\nDo the 2 speakers interrupt\ne", "quality_score": 8.25}}
{"id": "test_61", "question": "Why are comonads Mk idempotent, and what does this imply about their relationship to coreflective subcategories?", "golden_answers": ["Their comultiplications \u03b4 are natural isomorphisms. Idempotent comonads on a category C correspond precisely to coreflective subcategories of C."], "prediction": "Comonads Mk are idempotent because their comultiplications \u03b4 are natural isomorphisms. This implies that idempotent comonads on a category C correspond precisely to coreflective subcategories of C, meaning that the inclusion functor from the coreflective subcategory to the original category has a right adjoint.", "f1": 0.631578947368421, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01247v1\n\u2a7d k with root a, and\n(M) for all x, y\u2208 A, x \u227a y if and only if RA(x, y) for some unique R \u2208 \u03c3. \u2022 morphisms: homomorphisms of Kripke models. 1Equivalently, it is a monotone map that preserves the height of elements. 10 SAMSON ABRAMSKY, THOMAS LAURE, AND LUCA REGGIO\nNote that the tree order of a synchronization tree is \u201cdefinable\u201d and hence preserved\nby any homomorphism of Kripke models. Thus the forgetful functor Lk : EM(Mk) \u2192\nStruct\u2022(\u03c3) is fully faithful and can be identified with the inclusion into Struct\u2022(\u03c3) of\nthe full subcategory defined by synchronization trees of height \u2a7d k. Its right adjoint\nFk : Struct\u2022(\u03c3) \u2192 EM(Mk) sends a Kripke model to its k-unravelling.\nRemark 3.5. In fact, the modal comonads Mk are idempotent, meaning that their\ncomultiplications \u03b4 are natural isomorphisms. In turn, idempotent comonads on a\ncategory C correspond precisely to coreflective subcategoriesof C, i.e. full subcategoriesD\nsuch that the inclusion functor D ,\u2192 C has a right adjoint. 3.3. Logical equivalences. In [2, 6] it was shown how game comonads can be used to\ncapture, in a categorical fashion, preservation of various fragments and extensions of the\nlogics FOk, Lk and MLk. We recall here the case of the existential positive fragments\nand the full fragments, and outline the way in which the equality symbol is handled in\nthe framework of game comonads. Existential positive fragments. Given a collection of formulas L \u2286 L\u221e,\u03c9, consider its\nexistential positive fragment\n\u2203+L\nconsisting of formulas with no universal quantifiers and no negations; for modal logic,\nthis corresponds to barring the use of modalities \u25a1R and negations. The next result\nshows that preservation of existential positive fragments is captured by the homomorph-\nism preorder in the Eilenberg\u2013Moore category for the corresponding comonad (for a\nproof, cf. [2, 6] and also [7]).2 Recall that, for a comonad Gk on a category C, we denote\nby Fk : C \u2192 EM(Gk) the right adjoint to the forgetful functor Lk : EM(Gk) \u2192 C.\nTheorem 3.6. The following are equivalent for all (pointed) structures A and B:\n(i) A \u21db\u2203+FOk B if, and only if, there exists an arrow FkA \u2192 FkB in EM(Ek). (ii) A \u21db\u2203+Lk B if, and only if, there exists an arrow FkA \u2192 FkB in EM(Pk).\n(iii) (A, a) \u21db\u2203+MLk (B, b) if, and only if, there exists an arrow Fk(A, a) \u2192 Fk(B, b)\nin EM(Mk). The equality symbol. In their basic form, game comonads capture fragments of logics\nwithout equality. This is sufficient for modal logic, since the image of the standard\ntranslation is contained in the equality-free fragment of FO, and was also sufficient for\nTheorem 3.6, since the fragments \u2203+FOk and \u2203+Lk admit equality elimination. To\nmodel logics with equality, such as the fragments FOk and Lk, we proceed as follows. Given a relational vocabulary \u03c3, consider a fresh binary relation symbol I and the\nexpanded vocabulary\n\u03c3I := \u03c3 \u222a {I}.\n\n2503.01247v2\nIn their basic form, game comonads capture fragments of logics\nwithout equality. This is sufficient for modal logic, since the image of the standard\ntranslation is contained in the equality-free fragment of FO, and was also sufficient for\nTheorem 3.6, since the fragments \u2203+FOk and \u2203+Lk admit equality elimination. To\nmodel logics with equality, such as the fragments FOk and Lk, we proceed as follows. Given a relational vocabulary \u03c3, consider a fresh binary relation symbol I and the\nexpanded vocabulary\n\u03c3I := \u03c3 \u222a {I}. There is a fully faithful functor J : Struct(\u03c3) \u2192 Struct(\u03c3I) that sends a \u03c3-structure to\nthe \u03c3I-structure obtained by interpreting I as the diagonal relation. This functor has a\n2We could equivalently use the homomorphism preorder in the Kleisli category of the comonad, which\ncan be identified with a full subcategory of the Eilenberg\u2013Moore category. EXISTENTIAL AND POSITIVE GAMES: A COMONADIC AND AXIOMATIC VIEW 11\nleft adjoint H : Struct(\u03c3I) \u2192 Struct(\u03c3) that sends a \u03c3I-structure A to the quotient of\n(the \u03c3-reduct of) A by the equivalence relation generated by IA. Thus, the functor J\nintroduces (the interpretation of) the equality symbol, while H eliminates it. Since a\ngeneric game comonad G on Struct(\u03c3) is defined uniformly for any relational vocabulary\n\u03c3, we can consider its variant GI over \u03c3I-structures. If LI \u22a3 FI is the Eilenberg\u2013Moore\nadjunction associated to GI, we have the following situation:\nStruct(\u03c3) \u22a4 Struct(\u03c3I) \u22a4 EM(GI)\nJ FI\nH LI\nLet FI := FIJ : Struct(\u03c3) \u2192 EM(GI). The composite adjunction\nStruct(\u03c3) \u22a4 EM(GI)\nFI\nHLI\nis not comonadic, but is the one that captures logics with equality. Consider e.g. the Ehrenfeucht-Fra\u00a8 \u0131ss\u00b4 e comonadEk. Note that, for any \u03c3-structure A,\nthe interpretation of the relation I in the \u03c3I-structure EkJ(A) consists of those pairs\n(s, t) of sequences such that:\n(i) s, tare comparable in the prefix order \u2291, and\n(ii) their last elements are equal, i.e. \u03b5A(s) = \u03b5A(t). In other words, the relation IEkJ(A) detects repeating sequences. Given \u03c3-structures A\nand B, morphisms\nFI(A) \u2192 FI(B)\nin EM(EI\nk) are in bijection with homomorphisms EI\nkJ(A) \u2192 J(B) in Struct(\u03c3I), which\nin turn correspond precisely to homomorphisms f : Ek(A) \u2192 B in Struct(\u03c3) such that\n\u2200s, t\u2208 Ek(A), if s \u2291 t and \u03b5A(s) = \u03b5A(t) then f(s) = f(t),\ncalled I-morphisms (see [2] or [7, \u00a74]). In the case of the pebbling comonad, I-morphisms\nare defined in a similar fashion. The full fragments. To capture equivalence in the full fragments, we introduce the fol-\nlowing notions, which rely on the concrete description of the Eilenberg\u2013Moore categories\nof the comonads Ek, Pk and Mk provided in Section 3.2. For the remainder of this section,A will denote one of the categories EM(Ek), EM(Pk)\nor EM(Mk). Definition 3.7.\n(1) A path in A is an object whose forest order is finite and linear, i.e. it consists of\na single branch.\n\n2503.01365v1\nThe functor F induces a functor\nF \u2022 : D\u2022 \u2192EA as follows: On Dwe just compose F with the projection E \u2193\nEA \u2192 EA, for d0 we set F \u2022(d0) = E, and for each arrow f : d0 \u2192 d we\nde\ufb01ne F \u2022(f) = F (d). Now, one can think through that the object part of\ncolimd\u2208DF (d) (in E \u2193EA) arises by computing colim d\u2208D\u2022 F \u2022(d) in EA. Hence,\nthe projection E \u2193EA \u2192EA preserves colimits over D, whenever Dis a \ufb01nal\nsubcategory of D\u2022. We will verify the condition in Lemma 2.13, i.e., for each\nd \u2208D\u2022, we show the category d \u2193D is connected. For d = d0, this easily follows\nfrom the assumption that Dis connected. For d \u2208D, the category d \u2193D has\nan initial object id d, hence it is connected. In the case E \u223c\n= 2\n, 2 \u2297\u2212 is isomorphic to the identity on EA, hence it\ntrivially preserves all colimits. Finally, let E \u223c\n= 1\n. We claim that for each\nG \u2208EA, 1 \u2297G \u223c\n= 1\n. Indeed, each homomorphism f : 1 \u2192G, G \u2208EA, is\n10\n\nnecessarily an isomorphism. Thus, so is the homomorphism \u03b91,G : 1 \u223c\n= 1\n\u2297G.\nConsequently,\ncolimd\u2208D1 \u2297F (d) \u223c\n= 1\n\u223c\n= 1\n\u2297colimd\u2208DF (d),\nwhenever Dis non-empty. Next, assume E \u2297\u2212 preserves all colimits over Dand denote D= \u2210\ni\u2208I Di\nthe decomposition of Dinto its connected components. Set F : D\u2192 EA to be\nconstantly equal 2 . Since 2 is the initial object, the obvious cocone (id : 2 \u2192\n2)d\u2208D is a colimiting one. When applying E \u2297\u2212, we essentially obtain a cocone\n(id: E \u2192E)d\u2208D, as 2 is the monoidal unit. However, the colimit of E \u2297F (\u2212)\nis\ncolimd\u2208DE \u2297F (d) = colim d\u2208DE \u22972 \u223c\n= colimd\u2208DE \u223c\n=\n\u2210\ni\u2208I\ncolimd\u2208Di E \u223c\n=\n\u2210\ni\u2208I\nE.\nTherefore, the homomorphism (3.3) becomes in this case the folding homomor-\nphism h: \u2210\ni\u2208I E \u2192E. Clearly, h is an isomorphism only if |I|= 1, in which\ncase Dis connected, or |I|= 0 and E \u223c\n= 2\n, or |I|\u2265 2 and E has no element\na \u0338= 0 , 1, that is, E \u223c\n= 2\nor E \u223c\n= 1\n(note that in EA, a coproduct is a horizontal\nsum). In particular, Theorem 3.5 assures tensor product in EA preserves all co-\nequalizers. On the other hand, coproduct is an essential example o f a colimit\nthat is (in general) not preserved by tensor product in EA. It follows from the\nproof of Theorem 3.5 that given a triple of e\ufb00ect algebras E, F1, F2, the e\ufb00ect\nalgebra E \u2297(F1\n\u2210 F2) is isomorphic to the colimit of the span:\nE \u2297F1\n\u03b9E,F1\n\u2190\u2212\u2212\u2212E\n\u03b9E,F2\n\u2212\u2212\u2212\u2192E \u2297F2. 4 Unital Abelian po-groups\nAn analogous adjunction, as described in Theorem 3.3, arises (base d on the\nauthor\u2019s as yet unpublished computations) in several other categ ories related\nto EA.", "metadata": {"type": "reasoning", "source": "2503.01247v2.pdf", "context": "10 SAMSON ABRAMSKY, THOMAS LAURE, AND LUCA REGGIO\nNote that the tree order of a synchronization tree is \u201cdefinable\u201d and hence preserved\nby any homomorphism of Kripke models. Thus the forgetful functor Lk : EM(Mk) \u2192\nStruct\u2022(\u03c3) is fully faithful and can be identified with the inclusion into Struct\u2022(\u03c3) of\nthe full subcategory defined by synchronization trees of height \u2a7d k. Its right adjoint\nFk : Struct\u2022(\u03c3) \u2192 EM(Mk) sends a Kripke model to its k-unravelling.\nRemark 3.5. In fact, the modal comonads M", "quality_score": 8.25}}
{"id": "test_62", "question": "How does the introduction of dynamic adaptation mechanism parameters \u03b1 and \u03b2 in Equation-18 affect the network's output compared to a classic ResNet?", "golden_answers": ["The new network can adaptively adjust the influence of both the residual term and the input direct connection term, allowing for more robustness and flexibility."], "prediction": "The introduction of dynamic adaptation mechanism parameters \u03b1 and \u03b2 in Equation-18 allows for the adjustment of the influence of the residual term and the input direct connection term, respectively. This enhances the gradient transfer efficiency and learning ability of the model, providing stronger robustness and flexibility for deep feature extraction and learning compared to a classic ResNet, which uses fixed weights in its residual connections.", "f1": 0.3291139240506329, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01217v1\nThe output Y combines the candidate activation state \u02c6Y and the original input Xin, and the update gate \u03a6 controls\nthe information fusion ratio between the two parameters. When calculating the candidate activation state \u02c6H, the\nexponential average attention mechanism uses the Laplace attention function(Equation-15) as the core component. Based on the concept of reduced-bias, it can be improved the reduced-bias Laplace function as Equation-16 to adapt to\nthe introduction of deviation inside.\nFla(x; \u00b5, \u03c3) =\n1 + erf\n\u0010\nx\u2212\u00b5\n\u03c3\n\u221a\n2\n\u0011\n2 (15)\nFrla(x; \u00b5, \u03c3) = Norm(\n1 + erf\n\u0010\nx\u2212\u00b5\n\u03c3\n\u221a\n2\n\u0011\n2 + Xin) (16)\n7\n\nPreprint. This is a preprint paper under reviewing. The Laplace attention function maps the attention score of QKT to a smooth range by dynamically adjusting the\nparameters \u00b5 and \u03c3, providing a more stable gradient and a more flexible attention distribution. This smoothing range is\nmapped to (0, 1) using the erf function, which improves the global context modeling ability of the model, and ultimately\nimproves the expression effect and task performance of Y .\n3.5 Reduced-bias Module\nCompared with the traditional residual connection layer, proposed work have improved on the basis of the classic\nresidual network structure (Residual Network) [20], and added a dynamic adjustment mechanism for the network\nweights before and after the residual connection. Specifically, the proposed Reduced-bias module fits the sensitivity and influence of different weight parameters on\ndownstream gradient updates by constructing an adaptive weight adjustment strategy during the forward propagation\nprocess. In the verification feedback stage, the module can select the optimal parameter configuration through dynamic\noptimization, thereby enhancing the gradient transfer efficiency and learning ability of the model. In addition, this\nimprovement can effectively alleviate the information transfer bias problem caused by fixed weights in traditional\nresidual connections, and provide stronger robustness and flexibility for deep feature extraction and learning of the\nmodel. Classic resnet can be expressed as Equation-17. yl = F(xl, Wl) + xl (17)\nwhere xl is the input of the l-th layer module. F(\u00b7) represents the operation of the network in this layer. Wl is a\nparameter of the l-th module. Among Equation-17, dynamic adaptation mechanism parameters \u03b1 and \u03b2 is introduced. The new network can be\nexpressed as Equation-18. yl = \u03b1l \u00b7 F(xl, Wl) + \u03b2l \u00b7 xl (18)\nwhere \u03b1 controls the influence of the residual term, and \u03b2 controls the influence of the input direct connection term. Besides, l \u2208 L, L represents all the layer connected by Reduced-biased module. tl = \u03c3\n\u0012 \u2202L\n\u2202F(xl, Wl) \u00b7 Wt + bt\n\u0013\n(19)\nwhere L is the loss function, W\u03b1 and W\u03b2 are learnable weight matrices, b\u03b1 and b\u03b2 are bias terms, and \u03c3(\u00b7) is the\nactivation function. By deriving Equation-19, yl can be got by Equation-20. yl = \u03c3\n\u0012 \u2202L\n\u2202F(xl, Wl) \u00b7 W\u03b1 + b\u03b1\n\u0013\n\u00b7 F(xl, Wl)\n+ \u03c3\n\u0012 \u2202L\n\u2202xl\n\u00b7 W\u03b2 + b\u03b2\n\u0013\n\u00b7 xl\n(20)\n\n2503.01217v2\nBased on the\nconcept of reduced-bias, it can be improved the reduced-bias\nLaplace function as Equation (15) to adapt to the introduction\nof deviation inside.\nFla(x; \u00b5, \u03c3) =\n1 + erf\n\u0010\nx\u2212\u00b5\n\u03c3\n\u221a\n2\n\u0011\n2 (14)\nFrla(x; \u00b5, \u03c3) = Norm(\n1 + erf\n\u0010\nx\u2212\u00b5\n\u03c3\n\u221a\n2\n\u0011\n2 + Xin) (15)\nThe Laplace attention function maps the attention score\nof QKT to a smooth range by dynamically adjusting the\nparameters \u00b5 and \u03c3, providing a more stable gradient and a\nmore flexible attention distribution. This smoothing range is\nmapped to (0, 1) using the erf function, which improves the\nglobal context modeling ability of the model, and ultimately\nimproves the expression effect and task performance of Y . D. Reduced-bias Module\nCompared with the traditional residual connection layer,\nproposed work have improved on the basis of the classic\nresidual network structure (Residual Network) [20], and added\na dynamic adjustment mechanism for the network weights\nbefore and after the residual connection. Specifically, the proposed Reduced-bias module fits the\nsensitivity and influence of different weight parameters on\ndownstream gradient updates by constructing an adaptive\nweight adjustment strategy during the forward propagation\nprocess. In the verification feedback stage, the module can\nselect the optimal parameter configuration through dynamic\noptimization, thereby enhancing the gradient transfer effi-\nciency and learning ability of the model. In addition, this\nimprovement can effectively alleviate the information transfer\nbias problem caused by fixed weights in traditional residual\nconnections, and provide stronger robustness and flexibility for\ndeep feature extraction and learning of the model. Classic resnet can be expressed as Equation (16). yl = F(xl, Wl) + xl (16)\nwhere xl is the input of the l-th layer module. F(\u00b7) represents\nthe operation of the network in this layer. Wl is a parameter\nof the l-th module. Among Equation (16), dynamic adaptation mechanism pa-\nrameters \u03b1 and \u03b2 is introduced. The new network can be\nexpressed as Equation (17). yl = \u03b1l \u00b7 F(xl, Wl) + \u03b2l \u00b7 xl (17)\nwhere \u03b1 controls the influence of the residual term, and \u03b2\ncontrols the influence of the input direct connection term. Besides, l \u2208 L, L represents all the layer connected by\nReduced-biased module. tl = \u03c3\n\u0012 \u2202L\n\u2202F(xl, Wl) \u00b7 Wt + bt\n\u0013\n(18)\nwhere L is the loss function, W\u03b1 and W\u03b2 are learnable\nweight matrices, b\u03b1 and b\u03b2 are bias terms, and \u03c3(\u00b7) is the\nactivation function. By deriving Equation (18), yl can be got by Equation (19). yl = \u03c3\n\u0012 \u2202L\n\u2202F(xl, Wl) \u00b7 W\u03b1 + b\u03b1\n\u0013\n\u00b7 F(xl, Wl)\n+ \u03c3\n\u0012 \u2202L\n\u2202xl\n\u00b7 W\u03b2 + b\u03b2\n\u0013\n\u00b7 xl\n(19) Using optimization of the parameters of this layer, the\ncontribution of different paths in the residual connection to\nthe final output can be dynamically adjusted, thus achieving\nadaptive learning and weight optimization. E. Robustly Optimized BERT\nRoBERTa (Robustly Optimized BERT Approach) [6] is\nan improved version of BERT proposed by Facebook AI.\n\n2503.00486v4\nFigure 6a plots the FNR evolution in time for different frame\nsizes S, where each curve is obtained for a speci\ufb01c realization\nof tasks. The \ufb01gure shows the theoretical deterministic gua ran-\ntees offered by CLO, which are satis\ufb01ed for every realizatio n. Figure 6b shows the trade-off between overall average\nprecision, evaluated as 1 \u2212 Fs(x, \u03b8 ), and the transmission\nenergy consumption of all the nodes. The curves are obtained\nby varying the penalty \u03b7 in (27) and by averaging over the\nlast 800 time slots (of the total T = 10 , 000), as well as\nover 10 different realizations. Increasing the average precision\nrequires of\ufb02oading computations to network nodes farther\naway from the users, which increases the transmission energ y\nconsumption. This is con\ufb01rmed by Figure 7, which shows how\nthe nodes decision percentages vary with the nodes depth, fo r\ndifferent values of the precision-energy trade-off parame ter \u03b7. Figures 6a and 6b con\ufb01rm that, in accordance to Proposi-\ntions 1 and 2, increasing the frame size S allows CLO to attain\na higher precision over a \ufb01nite time duration, but a slower\nconvergence to the FNR target value. D. Comparison with LO\nW e compare the CLO performance with the standard LO,\nwhich can only address average reliability constraints. Sp ecif-\nically, for LO we replace the deterministic constraint (23) by\nan average one expressed by\nlim\nF \u2192\u221e\n1\nF\nF \u2212 1\u2211\nf=0\nE\n{\nLk\nf\n}\n\u2264 rk. (38)\nLO guarantees this long-term average reliability by reform u-\nlating it as a queue stability condition associated with vir tual\nqueues {Zk}K\nk=1 [8] (see Section II of the supplementary\nmaterials for further details [45]). Accordingly, while CLO updates the reliability hyperparam -\neters \u03b8k at the end of each time frame (every S time slots),\nthe competitive LO formulation treats them as variables to b e\noptimized at each time slot t. Treating these variables as dis-\ncrete within the set {0. 1, 0. 2, . . . , 0. 9} yields a mixed-integer\noptimization problem, whose complexity grows exponential ly\nwith the number K of users. Thus, to make the LO problem\ncomputationally feasible, in each slot we force all the user s to\n11\n\nemploy the same threshold, i.e., \u03b8k(t) = \u03b8\u2217 (t). 5\nW e consider the single-hop network architecture shown in\nFigure 5a, with an i.i.d. generation of new tasks according t o\na Bernoulli distribution with probability \u03bbk for any user. W e\nsimulate a non-stationary environment, where \u03bbk \u2208 { 0. 4, 0. 8}\nmay switch every 100 slots, with a probability p = 0 . 5. The\nLyapunov and penalty trade-off parameters are V = 100 , and\n\u03b7 \u2208 { 1\u00d710\u2212 2, 5\u00d710\u2212 2, 1\u00d710\u2212 1, 5\u00d710\u2212 1, 1}. The frame size\nfor CLO is S = 10 . T o make fair comparisons between LO\nand CLO, we set for CLO a virtual queue step size \u03b2k = 0 .", "metadata": {"type": "reasoning", "source": "2503.01217v1.pdf", "context": "residual connections, and provide stronger robustness and flexibility for deep feature extraction and learning of the\nmodel.\nClassic resnet can be expressed as Equation-17.\nyl = F(xl, Wl) + xl (17)\nwhere xl is the input of the l-th layer module. F(\u00b7) represents the operation of the network in this layer. Wl is a\nparameter of the l-th module.\nAmong Equation-17, dynamic adaptation mechanism parameters \u03b1 and \u03b2 is introduced. The new network can be\nexpressed as Equation-18.\nyl = \u03b1l \u00b7 F(xl, Wl) + \u03b2l ", "quality_score": 8.25}}
{"id": "test_63", "question": "What is \u03a6p in Eq. (8)?", "golden_answers": ["min v\u2208V (Rp) A\u03f5(v) subject to some constraints."], "prediction": "The documents provided do not contain any information regarding \"\u03a6p\" in Eq. (8).", "f1": 0.0, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.00288v1\nFor each P \u2208 P \u2264m, choose a value \u03b4P \u2208 {\u2212 1, 1} and let\nS(n,m, (\u03b4)m) :=\n{\nQ\u2208 P n | if P \u2208 P \u2264m, then\n(P\nQ\n)\n= \u03b4P\n}\n. Recall that \u03a0 q(m) = \u2211 m\nj=1 \u03c0q(j) and P(m) = \u220f\nP \u2208P\u2264m\nP. Proposition 8.3. For integer m\u2265 1 and large enough integer n\u2265 qm1/ 2\n, we have\n\u2211\nQ\u2208S(n,m, (\u03b4)m)\n(\n\u2212L\u2032(1,\u03c7 Q)\nL(1,\u03c7 Q)\n)\n= \u03c0q(n)\n2\u03a0 q(m)\n\u2211\nP \u2208P\u2264m\nr\u22651 odd\n(\u22121)\n(q\u22121)ndP\n2 \u03b4P\nlog(qdP )\n(qdP )r + Oq\n(\nn2q\nn\n2 +2m)\n. Proof. For each f \u2208 M , let \u03b4f := \u220f\nP |f \u03b4P . For a given Q\u2208 P n, one has\n(8.3)\n\u2211\nf|P(m)\n\u03b4f \u03c7f (Q) =\n\u220f\nP \u2208P\u2264m\n(1 + \u03b4P \u03c7P (Q)) =\n{\n2\u03a0 q(m) if Q\u2208 S(n,m, (\u03b4)m),\n0 otherwise . As shown in [23, Lemma 6.1], for large enough n\u2265 qm1/ 2\n, we have\n(8.4) # S(n,m, (\u03b4)m) = qn\n2\u03a0 q(m)n + Oq\n(\nq\nn\n2 +m)\n. For any real number y >1 and any Q\u2208 P n it follows from [17, Equation (6.8.4)] that\n(8.5) \u2212L\u2032(1,\u03c7 Q)\nL(1,\u03c7 Q) =\n\u2211\nf\u2208M\u2264\u230alogq(y)\u230b\n\u03c7Q(f)\u039b( f)\nN(f) + Oq\n(log(qn)\ny\n1\n2\n)\n. Now, let y:= q2ndP(m) so that \u03c1(n,m ) := log q(y) = 2 ndP(m). From (8.4) we have\n(8.6) # S(n,m, (\u03b4)m) log(qn)\nqndP(m)\n\u226aq\n1\nqn(dP(m)\u22121)2\u03a0 q(m) . By (8.3), the quadratic reciprocity law, and ( \u22121)\n(q\u22121)nrdP\n2 = ( \u22121)\n(q\u22121)ndP\n2 for r\u2265 1 odd,\n(8.7)\n\u2211\nQ\u2208S(n,m, (\u03b4)m)\n\u2211\nh\u2208M\u2264\u03c1 (n,m )\n\u03c7Q(h)\u039b( h)\nN(h) = 1\n2\u03a0 q(m)\n\u2211\nf|P(m)\n\u03b4f\n\u2211\nP \u2208P,r \u22651\nrdP \u2264\u03c1(n,m )\n(\u22121)\n(q\u22121)ndP\n2\nlog(qdP )\n(qdP )r\n\u2211\nQ\u2208Pn\n(Prf\nQ\n)\n. We now separately compute the contribution for squares and non- squares Prf\u2019s in (8.7). Since P(m) is square-free, f is too. Therefore, Prf is a square if and only if f = P and r\nis odd. Thus, the contribution of the squares is\n(8.8) \u03c0q(n)\n2\u03a0 q(m)\n\u2211\nP \u2208P\u2264m\n(\u22121)\n(q\u22121)ndP\n2 \u03b4P log(qdP )\n\u2211\nr\u22651 odd\nrdP \u2264\u03c1(n,m )\n1\n(qdP )r . Now, observe that for any P \u2208 P \u2264m we have\n\u2211\nr\u22651 odd\nrdP >\u03c1(n,m )\n1\n(qdP )r \u2264\n\u221e\u2211\nr=\n\u230a\n\u03c1 (n,m )\ndP\n+1\n\u230b\n1\n(qdP )r \u226aq\n1\nq\u03c1(n,m )+dP\n. 25\n\nTherefore, using (2.3) and (8.2), we can rewrite (8.8) as\n\u03c0q(n)\n2\u03a0 q(m)\n\uf8eb\n\uf8ec\n\uf8ec\n\uf8ed\n\u2211\nP \u2208P\u2264m\nr\u22651 odd\n(\u22121)\n(q\u22121)ndP\n2 \u03b4P\nlog(qdP )\n(qdP )r + Oq\n\uf8eb\n\uf8ed 1\nq\u03c1(n,m )\n\u2211\nP \u2208P\u2264m\ndP\nqdP\n\uf8f6\n\uf8f8\n\uf8f6\n\uf8f7\n\uf8f7\n\uf8f8\n= \u03c0q(n)\n2\u03a0 q(m)\n\u2211\nP \u2208P\u2264m\nr\u22651 odd\n(\u22121)\n(q\u22121)ndP\n2 \u03b4P\nlog(qdP )\n(qdP )r + Oq\n(m\nn \u00b7 1\n2\u03a0 q(m)qn(2dP(m)\u22121)\n)\n.(8.9)\nNow, suppose Prf is not a square.\n\n2503.01207v1\n( 42), the fol-\nlowing expression is obtained:\n\u27e8\u03d5\u03c3\np |X|\u03d5\u03c3\nq \u27e9 = \u27e8\u03d5\u03c3\np |A|\u03d5\u03c3\nq \u27e9\n+ \u27e8\u03d5\u03c3\np |\nn\u2211\n\u00b5 =1\nB\u00b5 e\u00b5 |\u03d5\u03c3\nq \u27e9\n+ \u27e8\u03d5\u03c3\np |\n\u2211\n1\u2264\u00b5<\u03bd \u2264n\nC\u00b5\u03bd e\u00b5 e\u03bd |\u03d5\u03c3\nq \u27e9, (44) The relations in Eq. (\n9) are used to evaluate the three\nterms on the right-hand side of Eq. ( 44). The \ufb01rst term\nis straightforward:\n\u27e8\u03d5\u03c3\np |A|\u03d5\u03c3\nq \u27e9 = \u03b4pqA. (45) For the second term, \ufb01rst consider:\n\u03d5\u03c3\np (r)\nn\u2211\n\u00b5 =1\nB\u00b5 e\u00b5 =\n[\n\u03c6\u03c3 , 0\np (r) \u2212\nn\u2211\n\u03bd =1\n\u03c6\u03c3 ,\u03bd\np (r)e\u03bd\n] n\u2211\n\u00b5 =1\nB\u00b5 e\u00b5\n= \u2212\nn\u2211\n\u00b5 =1\nB\u00b5 e\u00b5\n\u03d5\u03c3\np (r) + 2\nn\u2211\n\u00b5 =1\nB\u00b5 \u03c6\u03c3 ,\u00b5\np (r) + 2\nn\u2211\n\u00b5 =1\nB\u00b5 \u03c6\u03c3 , 0\np (r)e\u00b5 .\n(46)\nThis leads to:\n\u27e8\u03d5\u03c3\np |\nn\u2211\n\u00b5 =1\nB\u00b5 e\u00b5 |\u03d5\u03c3\nq \u27e9\n= \u2212\u03b4pq\nn\u2211\n\u00b5 =1\nB\u00b5 e\u00b5 + 2\nn\u2211\n\u00b5 =1\nB\u00b5 \u27e8\u03c6\u03c3 ,\u00b5\np |\u03d5\u03c3\nq \u27e9\n+ 2\nn\u2211\n\u00b5 =1\nB\u00b5 e\u00b5 \u27e8\u03c6\u03c3 , 0\np |\u03d5\u03c3\nq \u27e9, (47)\nInserting Eq. (\n10) gives:\n2\nn\u2211\n\u00b5 =1\nB\u00b5 \u27e8\u03c6\u03c3 ,\u00b5\np |\u03d5\u03c3\nq \u27e9\n= 2\nn\u2211\n\u00b5 =1\nB\u00b5 \u27e8\u03c6\u03c3 ,\u00b5\np |\u03c6\u03c3 , 0\nq \u27e9+ 2\n\u2211\n1\u2264\u00b5,\u03bd \u2264n\nB\u03bd \u27e8\u03c6\u03c3 ,\u03bd\np |\u03c6\u03c3 ,\u00b5\nq \u27e9e\u00b5 . (48)\nSimilarly,\n2\nn\u2211\n\u00b5 =1\nB\u00b5 e\u00b5 \u27e8\u03c6\u03c3 , 0\np |\u03d5\u03c3\nq \u27e9\n= \u22122\nn\u2211\n\u00b5 =1\nB\u00b5 \u27e8\u03c6\u03c3 , 0\np |\u03c6\u03c3 ,\u00b5\nq \u27e9+ 2\nn\u2211\n\u00b5 =1\nB\u00b5 \u27e8\u03c6\u03c3 , 0\np |\u03c6\u03c3 , 0\nq \u27e9e\u00b5\n+ 2\n\u2211\n1\u2264\u00b5<\u03bd \u2264n\n(\nB\u00b5 \u27e8\u03c6\u03c3 , 0\np |\u03c6\u03c3 ,\u03bd\nq \u27e9 \u2212 B\u03bd \u27e8\u03c6\u03c3 , 0\np |\u03c6\u03c3 ,\u00b5\nq \u27e9\n)\ne\u00b5 e\u03bd . (49)\nDue to Eq. (\n13), the \ufb01rst terms on the right-hand side of\nboth Eqs. ( 48) and ( 49) cancel each other, leading to:\n\u27e8\u03d5\u03c3\np |\nn\u2211\n\u00b5 =1\nB\u00b5 e\u00b5 |\u03d5\u03c3\nq \u27e9\n=\nn\u2211\n\u00b5 =1\n[\n\u2212 \u03b4pqB\u00b5 + 2B\u00b5 \u27e8\u03c6\u03c3 , 0\np |\u03c6\u03c3 , 0\nq \u27e9+ 2\nn\u2211\n\u03bd =1\nB\u03bd \u27e8\u03c6\u03c3 ,\u03bd\np |\u03c6\u03c3 ,\u00b5\nq \u27e9\n]\ne\u00b5\n+\n\u2211\n1\u2264\u00b5<\u03bd \u2264n\n2\n(\nB\u00b5 \u27e8\u03c6\u03c3 , 0\np |\u03c6\u03c3 ,\u03bd\nq \u27e9 \u2212 B\u03bd \u27e8\u03c6\u03c3 , 0\np |\u03c6\u03c3 ,\u00b5\nq \u27e9\n)\ne\u00b5 e\u03bd . (50) For the third term, \ufb01rst consider:\n\u03d5\u03c3\np (r)\n\u2211\n1\u2264\u00b5<\u03bd \u2264n\nC\u00b5\u03bd e\u00b5 e\u03bd\n= [\n\u03c6\u03c3 , 0\np (r) \u2212\nn\u2211\n\u03bd =1\n\u03c6\u03c3 ,\u03bd\np (r)e\u03bd\n] \u2211\n1\u2264\u00b5<\u03bd \u2264n\nC\u00b5\u03bd e\u00b5 e\u03bd\n=\n\u2211\n1\u2264\u00b5<\u03bd \u2264n\nC\u00b5\u03bd e\u00b5 e\u03bd\n\u03d5\u03c3\np (r) + 2\n\u2211\n1\u2264\u00b5<\u03bd \u2264n\nC\u00b5\u03bd \u03c6\u03c3 ,\u00b5\np (r)e\u03bd\n\u2212 2\n\u2211\n1\u2264\u00b5<\u03bd \u2264n\nC\u00b5\u03bd \u03c6\u03c3 ,\u03bd\np (r)e\u00b5 .\n\n2503.01081v1\nThe continuity result in Proposition 8\nensures that any single term within the hypercube can represent all terms in the hypercube\nwith \u201csmall\u201d error as long as we choose layer index k large enough. Since we only need to\nidentify finitely many terms in the ranking to prove identifiability, we can similarly prove\nthat the summation in (S.14) can be separated in order, where every term can dominate\nthe summation of all terms with lower rank. Step 2.4: We then prove that the two concentration points are identical. For simplicity,\nwe only discuss the case when\u03bd2 > . . . > \u03bdp and e\u03bd2 > . . . >e\u03bdep in the sketch. By Proposition\n54\n\n1, we have\nX\n1\u2264j1,...,jn\u2264J\nZ\n(2\u03c0)\u2212K\n2 exp\n\u0010\n\u00b5m + \u03b7T\nm\u03b8 +\nnX\nk=1\n\u00b5jk \u2212\nWX\nk=1\n\u03c9k exp(\u03b1T\nk \u03b8) +\n\u0000\n\u03c6 +\nnX\nk=1\n\u03b7jk\n\u0001T\n\u03b8 \u2212 1\n2\u03b8T\u03b8\n\u0011\nd\u03b8\n=\nX\n1\u2264j1,...,jn\u2264J\nZ\n(2\u03c0)\u2212K\n2 exp\n\u0010\ne\u00b5m + e\u03b7T\nm\u03b8 +\nnX\nk=1\ne\u00b5jk \u2212\nWX\nk=1\n\u03c9k exp(\u03b1T\nk \u03b8) +\n\u0000\n\u03c6 +\nnX\nk=1\ne\u03b7jk\n\u0001T\n\u03b8 \u2212 1\n2\u03b8T\u03b8\n\u0011\nd\u03b8. (S.18)\nWe can easily construct the same concentration points for equation (S.18). Heuristically,\nboth sides of (S.18) are multiplied by exp(logn(\u03b7T\nm\u03b8(\u03bd2, . . . , \u03bdJ )+o(1))) and exp(logn(e\u03b7T\nme\u03b8(e\u03bd2, . . . ,e\u03bdJ )+\no(1))) around the concentration points. Under the generic identifiability framework, we\ncan assume that \u03b7T\n1 \u03b8(\u03bd2, . . . , \u03bdJ ), . . . , \u03b7T\nJ \u03b8(\u03bd2, . . . , \u03bdJ ) are distinct. Hence we can match\nthe two concentration points by (S.15). Then we can match \u03bb1(tq+1), . . . , \u03bbp(tq+1) with\ne\u03bb1(tq+1), . . . ,e\u03bbp(tq+1) by similar method as in Case 1. Step 2.5: We use the same method as in Step 1.3 of Case 1 to match the rest terms. Step 2.6: We use the same method as in Step 1.4 of Case 1 to fix the permutation. Case 3: This case leads to contradiction since the summations on both side of (S.10) has\ndifferent orders according to the discussions in Case 1 and 2. Proof of Theorem 1. For simplicity, we ignore the censoring time and assume that the\nstudying period is [0 , T]. In the following proof, we compare the likelihood function of a\ngiven subject with given sample path on time interval [0 , T] under two competing para-\nmetric models. Denote the intensity functions under two competing parametric models\nas\n\u03bbj(t|Xj, Zj; \u03b8) = exp(\u03b2j0 + \u03b2T\nj Xj(t) + \u03b8T\u03a31/2AT\nj Zj(t)),\ne\u03bbj(t|Xj, Zj; \u03b8) = exp(e\u03b2j0 + e\u03b2T\nj Xj(t) + \u03b8T e\u03a31/2 eAT\nj Zj(t)). where \u03b8 \u223c NK(0, IK). For notation simplicity, denote \u00b5j(t) = \u03b2j0 + \u03b2T\nj Xj(t) and e\u00b5j(t) =\ne\u03b2j0+ e\u03b2T\nj Xj(t) for j = 1, . . . , J.", "metadata": {"type": "factual", "source": "2503.01276v2.pdf", "context": "\u03a6p = min\nv\u2208V (Rp)\nA\u03f5(v) subject to some constraints. (8)\nThe constraints are detailed in Eqs. (3) and (4). Hereafter, \u03a6 p is used to represent the local\nsolutions at macropoint x\u2217\np, regardless of the specific type of local solutions. Since solving the cell\nproblems for every macroscopic point using a very fine mesh remains a huge challenge, we design\na hierarchical multicontinuum homogenization method to overcome this difficulty. For a given\nmacroscopic point x\u2217\np, we assume that the local solu", "quality_score": 8.25}}
{"id": "test_64", "question": "What is a limitation of using deep learning methods for long-range ENSO prediction?", "golden_answers": ["They require 'big data' to train models with enough parameters, which can result in them inheriting some of the biases in the training data."], "prediction": "Many deep learning methods require \"big data,\" currently only obtainable through large climate model ensembles, to train models with enough parameters to capture complex spatiotemporal patterns, which can result in them inheriting some of the biases in the training data.", "f1": 0.7000000000000001, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01412v1\nDespite these limitations, by aggregating forecasts from\nthe world\u2019s leading climate prediction centres, the IRI plume remains the operational\nbenchmark for ENSO forecasting An up-to-date version of the plume can be found at\nthe IRI website (https://iri.columbia.edu/our-expertise/climate/forecasts/\nenso/current/?enso tab=enso-sst table). In recent years, the advent of deep learning has sparked a resurgence of interest in\ndata-driven ENSO forecasting. A prominent example is the work of Ham et al. (2019),\nwho trained a convolutional neural network (CNN) using a transfer-learning approach\n\u2013 first on large collections of climate model simulations from the CMIP5 ensemble, and\nthen on ocean reanalysis data \u2013 to predict the Ni\u02dc no3.4 indexn months ahead based on\nsea surface temperatures and oceanic heat content from the current and previous 2 months. This deep learning model outperformed state-of-the-art dynamical models at lead times\nbeyond 6 months, achieving a pattern correlation with the observed index above 0.5 out\nto 17 months. A follow-up study applied a multitask learning framework to further im-\nprove forecast accuracy by addressing the seasonally varying nature of ENSO precursors\n(Ham et al., 2021). Other researchers have explored more advanced architectures and\nregularisation strategies to push predictive skill to even longer lead times. For instance,\nforecasts generated by the 3D transformer model of Zhou and Zhang (2023) were found\nto be skilful in predicting the Ni\u02dc no3.4 index at up to 18 months lead time, although bi-\nases in the training data (coming from biases in the underlying CMIP6 climate models\ngenerating the data) led to reduced skill in other regions of the Pacific. A few studies\nhave also attempted long-range ENSO prediction using only observational and reanal-\nysis data. Notably, Patil et al. (2023) developed a deep CNN model trained on observed/reanalysed\nsea surface and vertically-averaged subsurface temperatures, with skilful forecasts ob-\ntained out to 20 months lead time. Their CNN model featured multiple forms of reg-\nularisation including dropout, as well as average pooling to reduce the number of model\nparameters. Similar to Ham et al. (2021), it also contained heterogeneous parameters\nfor each target season to account for seasonal variations in precursors, establishing it as\na prime example of the state-of-the-art performance that is obtainable with deep learn-\ning for long-range ENSO prediction. While these results demonstrate the promise of modern machine learning for multi-\nyear ENSO forecasting, they also highlight persistent challenges. Many deep learning meth-\nods require \u201dbig data\u201d, currently only obtainable through large climate model ensem-\nbles, to train models with enough parameters to capture complex spatiotemporal pat-\nterns, which can result in them inheriting some of the biases in the training data. In con-\ntrast, methods trained solely on the limited observational record risk overfitting unless\nthey are specifically designed for the \u201dsmall data\u201d regime. To address these challenges,\nrecent work has proposed entropic learning techniques which are based on sparsified, prob-\nabilistic approximations of the data that employ the principle of maximum entropy from\ninformation theory to avoid overfitting to noisy/uninformative features (Horenko, 2020,\n2022; Vecchi et al., 2022; Horenko et al., 2023).\n\n2503.01412v2\nComparisons of the three-category RPSS against\nthe earlier results for the IRI plume presented in Tippett et al. (2012) demonstrate that\nskill is most improved for target months from June to August at lead times of 0-3 months,\nalong with October to March at lead times greater than 7 months. An important caveat\nto this comparison is that from 2002-2011 the IRI used a different definition for ENSO\nphase, defining El Ni\u02dc no and La Ni\u02dc na events as anomalies in the Ni\u02dc no3.4 region that fall\nin the upper/lower quartile of the climatological distribution for a given season. In recent years, the advent of deep learning has sparked a resurgence of interest in\ndata-driven ENSO forecasting. A prominent example is the work of Ham et al. (2019),\nwho trained a convolutional neural network (CNN) using a transfer-learning approach\n\u2013 first on large collections of climate model simulations from the CMIP5 ensemble, and\nthen on ocean reanalysis data \u2013 to predict the Ni\u02dc no3.4 indexn months ahead based on\nsea surface temperatures and oceanic heat content from the current and previous 2 months. This deep learning model outperformed state-of-the-art dynamical models at lead times\nbeyond 6 months, achieving a pattern correlation with the observed index above 0.5 out\nto 17 months. A follow-up study applied a multitask learning framework to further im-\nprove forecast accuracy by addressing the seasonally varying nature of ENSO precursors\n(Ham et al., 2021). Other researchers have explored more advanced architectures and\nregularisation strategies to push predictive skill to even longer lead times. For instance,\nforecasts generated by the 3D transformer model of Zhou and Zhang (2023) were found\nto be skilful in predicting the Ni\u02dc no3.4 index at up to 18 months lead time, although bi-\nases in the training data (coming from biases in the underlying CMIP6 climate models\ngenerating the data) led to reduced skill in other regions of the Pacific. A few studies\nhave also attempted long-range ENSO prediction using only observational and reanal-\nysis data. Notably, Patil et al. (2023) developed a deep CNN model trained on observed/reanalysed\nsea surface and vertically-averaged subsurface temperatures, with skilful forecasts ob-\ntained out to 20 months lead time. Their CNN model featured multiple forms of reg-\nularisation including dropout, as well as average pooling to reduce the number of model\nparameters. Similar to Ham et al. (2021), it also contained heterogeneous parameters\nfor each target season to account for seasonal variations in precursors, establishing it as\na prime example of the state-of-the-art performance that is obtainable with deep learn-\ning for long-range ENSO prediction. In March 2025 this model was added to the IRI plume. While these results demonstrate the promise of modern machine learning for multi-\nyear ENSO forecasting, they also highlight persistent challenges. Many deep learning meth-\nods require \u201dbig data\u201d, currently only obtainable through large climate model ensem-\nbles, to train models with enough parameters to capture complex spatiotemporal pat-\nterns, which can result in them inheriting some of the biases in the training data.\n\n2503.01412v1\nFor instance, the AUC ob-\ntained by eSPA at the 24-month lead time exceeds that reported for the recent deep con-\nvolutional neural network of Patil et al. (2023) which was trained on similar data, high-\nlighting the advantages of the proposed approach even relative to state-of-the-art deep\nlearning models. Given the promising results presented in this work there are several avenues for fu-\nture research and development, a few of which are highlighted here. Firstly, there is the\npotential to adapt the framework to directly predict the Ni\u02dc no3.4 index in a regression\nsetting (e.g. via the SPARTAN algorithm presented in Horenko et al. (2023)), which may\nprovide additional performance benefits for forecasting ENSO phase due to the order-\ning of targets being naturally enforced in the problem formulation. Such a system should\nbe evaluated with rigorous hindcast experiments in the same manner as this study. A\nsecond useful extension would be to train multiple eSPA/SPARTAN models on differ-\n\u201316\u2013\n\nmanuscript submitted toJournal of Advances in Modeling Earth Systems\nent segments or regimes of the historical record, within an adaptive regime-learning frame-\nwork that is able to handle non-stationarity in the climate system due to interdecadal\nvariability and anthropogenic forcing. This approach could help maintain skill during\nchallenging periods, such as the recent 2022-2023 period, by allowing the forecasting sys-\ntem to adjust to varying background conditions. Seasonal variability in predictors could\nalso be handled in a similar manner, e.g. using the temporally-regularised eSPA method\npresented in Bassetti et al. (2024), avoiding the need to restrict the training data for each\nmodel to only those instances in the given target season. Finally, the methodology de-\nveloped here may be applied to other modes of climate variability beyond ENSO. In par-\nticular, deploying the entropic learning framework to forecast intraseasonal phenomena\nsuch as the Madden\u2013Julian Oscillation, or extending it to multiple outputs for simulta-\nneous prediction of both ENSO and the Indian Ocean Dipole (Ling et al., 2022) are im-\nportant next steps. Pursuing these directions could pave the way toward a unified, data-\ndriven model of intraseasonal to interannual tropical climate variability and improve our\nunderstanding of predictability across different timescales as well as interactions between\ndifferent modes that lead to compound events. Appendix A Features used to train the meta-model\nA given base eSPA model consists of a K \u00d7T affiliation matrix \u0393, a D \u00d7K ma-\ntrix of cluster centroids C, a M\u00d7K matrix of conditional probabilities \u039b and a D-dimensional\nfeature importance vector W, as well as a M \u00d7 T\u2032 array of predictions \u02c6\u03a0 where T\u2032 is\nthe number of unlabelled instances. These matrices/vectors are used to derive the fol-\nlowing real-valued features that are supplied as inputs to the meta-model (where t cor-\nresponds to the most recent unlabelled instance and k denotes the cluster that instance\nhas been assigned to):\n1.", "metadata": {"type": "factual", "source": "2503.01412v1.pdf", "context": "to be skilful in predicting the Ni\u02dc no3.4 index at up to 18 months lead time, although bi-\nases in the training data (coming from biases in the underlying CMIP6 climate models\ngenerating the data) led to reduced skill in other regions of the Pacific. A few studies\nhave also attempted long-range ENSO prediction using only observational and reanal-\nysis data. Notably, Patil et al. (2023) developed a deep CNN model trained on observed/reanalysed\nsea surface and vertically-averaged subsurface temper", "quality_score": 8.25}}
{"id": "test_65", "question": "What is the structure of the provided text?", "golden_answers": ["The provided text appears to be a series of hexadecimal code blocks separated by forward slashes, suggesting it may represent a binary or encoded format."], "prediction": "The structure of the provided text includes a marking scheme with categories for Content (C), Language (L), and Organization (O), along with specific criteria and descriptions for each mark level (7, 6, 5, 4). Each level outlines the expectations for content relevance, idea development, creativity, language accuracy, vocabulary use, spelling and punctuation, register and tone, text organization, and cohesion.", "f1": 0.07792207792207792, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01019v3\nThen we concatenated Q and Xt to\nform the input of the image-text encoder, denoted as EQ,\nencoding it to get output embeddings:\nEQ([Q, Xt]) = [fq, ft] (6)\n= [fq, ft\n[SPE ], ft\nlocal] (7)\nWe employed a cross-attention mechanism [1] to facilitate\ninteraction between learnable embeddings and preliminary\nvisual embeddings. This design enables fq to function as\nthe final visual representation. To ensure clarity over the\nfusion of learnable embeddings and textual representations,\nwe implemented distinct masking strategies within the self-\nattention layers (Figure 2, right panel). Image-text contrastive learning (ITC) The task aims to\nalign visual and textual representations by maximizing their\nmutual information through a contrastive approach. To ac-\ncomplish this, we replaced w[SP E] with w[CLS] to fa-\ncilitate global textual representations denoted as ft\n[CLS] \u2208\nRdt . Furthermore, we implemented uni-modal masking\n(Figure 2, right panel) to enable learnable embeddings\nQ and textual embeddings Xt to attend exclusively to\nthemselves.fq and ft\n[CLS] are then linearly projected to\nrepresentations as:\ngq = Hq\nitc(fq) (8)\ngt = Ht\nitc(ft\n[CLS]) (9)\nwhere Hq\nitc, Ht\nitc are ITC heads. We computed the pairwise\nsimilarity between each visual and textual representationgq\n4\n\nand gt and chose the highest one as the image-text similarity\nto calculate bi-directional contrastive loss:\nL(q|t)\nitc = 1\nN\nNX\nk=1\n\u2212log( exp(max < gq\nk, gt\nk > /\u03c4)\nPN\nn=1 exp(max < gq\nk, gtn > /\u03c4)\n)\n(10)\nL(t|q)\nitc = 1\nN\nNX\nk=1\n\u2212log( exp(max < gq\nk, gt\nk > /\u03c4)\nPN\nn=1 exp(max < gq\nn, gt\nk > /\u03c4)\n)\n(11)\nwhere \u03c4 \u2208 R is a scaling temperature parameter initialized\nto 0.07, N is mini-batch size and <\u00b7, \u00b7> represents the co-\nsine similarity. The overall ITC loss is defined as:\nLitc = 1\n2(L(q|t)\nitc + L(t|q)\nitc ) (12)\nWe here expanded visual representation space from a con-\nventional single vector to a set of vectors e.g.fq \u2208 RLq\u00d7dq\nwhich is different from [26, 63]. Image-text matching (ITM) This task aims to learn a\nprecise alignment by classifying image-text pairs as either\npositive or negative. We implemented a bi-directional mask\n(Figure 2, right panel) that allows all learnable embeddings\nand word token embeddings to attend to one another. The\nresulting output of learned embeddings denoted as fq, cap-\nture enriched multi-modal information. These tokens were\nthen fed into a two-class linear classifier, Hitm, where the\noutputs are averaged across learned embeddings to generate\na logit and compute the Image-Text Matching (ITM) loss:\nLitm = 1\nN\nNX\nk=1\n\u2212log(p(Yk| \u02c6Yk)) (13)\n\u02c6Y = 1\nLq\nLqX\ni=1\nHitm(fq\ni ), (14)\nY represents ground truth labels within mini-batch by hard\nnegative samples mining, as stated in [34]. Image-grounded text generation (ITG) This task is to\ngenerate text conditioned on paired images. To achieve a\ncoherent and precise generation of medical reports within\na unified VLP framework, we chose CLM [5, 47] where\neach word token attends only to preceding tokens, follow-\ning a GPT-style language model architecture [5].\n\n2503.00367v1\nHKDSE English Language Paper Two (Writing) Marking Scheme \n \nMarks Content (C) Language (L) Organization (O) \n7 \u2219 Content entirely fulfills the requirements of the \nquestion \n\u2219 Totally relevant \n\u2219 All ideas are well developed/supported \n\u2219 Creativity and imagination are shown when \nappropriate \n\u2219 Shows a high awareness of audience \n \n\u2219 Very wide range of accurate sentence structures, \nwith a good grasp of more complex structures \n\u2219 Grammar accurate with only very minor slips \n\u2219 Vocabulary well-chosen and often used \nappropriately to express subtleties of meaning \n\u2219 Spelling and punctuation are almost entirely \ncorrect \n\u2219 Register, tone and style are entirely appropriate \nto the genre and text-type \n\u2219 Text is organized extremely effectively, with \nlogical development of ideas  \n\u2219   Cohesion in most parts of the text is very clear \n\u2219 Cohesive ties throughout the text are \nsophisticated \n\u2219 Overall structure is coherent, extremely \nsophisticated and entirely appropriate to the genre \nand text-type \n6 \u2219 Content fulfills the requirements of the question \n\u2219 Almost totally relevant \n\u2219 Most ideas are well developed/supported \n\u2219 Creativity and imagination are shown when \nappropriate \n\u2219 Shows general awareness of audience \n\u2219 Wide range of accurate sentence structures with \na good grasp of simple and complex sentences \n\u2219 Grammar mainly accurate with occasional \ncommon errors that do not affect overall clarity \n\u2219 Vocabulary is wide, with many examples of \nmore sophisticated lexis \n\u2219 Spelling and punctuation are mostly correct \n\u2219 Register, tone and style are appropriate to the \ngenre and text-type \n\u2219 Text is organized effectively, with logical \ndevelopment of ideas  \n\u2219    Cohesion in most parts of the text is clear \n\u2219 Strong cohesive ties throughout the text \n\u2219 Overall structure is coherent, sophisticated and \nappropriate to the genre and text-type \n5 \u2219 Content addresses the requirements of the \nquestion adequately \n\u2219 Mostly relevant \n\u2219 Some ideas are well developed/supported \n\u2219 Creativity and imagination are shown in most \nparts when appropriate  \n\u2219 Shows some awareness of audience \n\u2219 A range of accurate sentence structures with \nsome attempts to use more complex sentences \n\u2219 Grammatical errors occur in more complex \nstructures but overall clarity not affected \n\u2219 Vocabulary is moderately wide and used \nappropriately \n\u2219 Spelling and punctuation are sufficiently \naccurate to convey meaning \n\u2219 Register, tone and style are mostly appropriate \nto the genre and text-type \n\u2219 Text is mostly organized effectively, with \nlogical development of ideas  \n\u2219    Cohesion in most parts of the text is clear \n\u2219 Sound cohesive ties throughout the text \n\u2219 Overall structure is coherent and appropriate to \nthe genre and text-type\n\n28 \n4 \u2219 Content just satisfies the requirements of the \nquestion   \n\u2219 Relevant ideas but may show some gaps or \nredundant information  \n\u2219 Some ideas but not well developed \n\u2219 Some evidence of creativity and imagination \n\u2219 Shows occasional awareness of audience \n\u2219 Simple sentences are generally accurately \nconstructed. \u2219 Occasional attempts are made to use more \ncomplex sentences.\n\n2503.00367v2\nHKDSE English Language Paper Two (Writing) Marking Scheme \nMarks Content (C) Language (L) Organization (O) \n7 \u2219 Content entirely fulfills the requirements of the \nquestion \n\u2219 Totally relevant \n\u2219 All ideas are well developed/supported \n\u2219 Creativity and imagination are shown when \nappropriate \n\u2219 Shows a high awareness of audience \n \n\u2219 Very wide range of accurate sentence structures, \nwith a good grasp of more complex structures \n\u2219 Grammar accurate with only very minor slips \n\u2219 Vocabulary well-chosen and often used \nappropriately to express subtleties of meaning \n\u2219 Spelling and punctuation are almost entirely \ncorrect \n\u2219 Register, tone and style are entirely appropriate \nto the genre and text-type \n\u2219 Text is organized extremely effectively, with \nlogical development of ideas  \n\u2219   Cohesion in most parts of the text is very clear \n\u2219 Cohesive ties throughout the text are \nsophisticated \n\u2219 Overall structure is coherent, extremely \nsophisticated and entirely appropriate to the genre \nand text-type \n6 \u2219 Content fulfills the requirements of the question \n\u2219 Almost totally relevant \n\u2219 Most ideas are well developed/supported \n\u2219 Creativity and imagination are shown when \nappropriate \n\u2219 Shows general awareness of audience \n\u2219 Wide range of accurate sentence structures with \na good grasp of simple and complex sentences \n\u2219 Grammar mainly accurate with occasional \ncommon errors that do not affect overall clarity \n\u2219 Vocabulary is wide, with many examples of \nmore sophisticated lexis \n\u2219 Spelling and punctuation are mostly correct \n\u2219 Text is organized effectively, with logical \ndevelopment of ideas  \n\u2219    Cohesion in most parts of the text is clear \n\u2219 Strong cohesive ties throughout the text \n\u2219 Overall structure is coherent, sophisticated and \nappropriate to the genre and text-type\n\n44 \n\u2219 Register, tone and style are appropriate to the \ngenre and text-type \n5 \u2219 Content addresses the requirements of the \nquestion adequately \n\u2219 Mostly relevant \n\u2219 Some ideas are well developed/supported \n\u2219 Creativity and imagination are shown in most \nparts when appropriate  \n\u2219 Shows some awareness of audience \n\u2219 A range of accurate sentence structures with \nsome attempts to use more complex sentences \n\u2219 Grammatical errors occur in more complex \nstructures but overall clarity not affected \n\u2219 Vocabulary is moderately wide and used \nappropriately \n\u2219 Spelling and punctuation are sufficiently \naccurate to convey meaning \n\u2219 Register, tone and style are mostly appropriate \nto the genre and text-type \n\u2219 Text is mostly organized effectively, with \nlogical development of ideas  \n\u2219    Cohesion in most parts of the text is clear \n\u2219 Sound cohesive ties throughout the text \n\u2219 Overall structure is coherent and appropriate to \nthe genre and text-type \n4 \u2219 Content just satisfies the requirements of the \nquestion   \n\u2219 Relevant ideas but may show some gaps or \nredundant information  \n\u2219 Some ideas but not well developed \n\u2219 Some evidence of creativity and imagination \n\u2219 Shows occasional awareness of audience \n\u2219 Simple sentences are generally accurately \nconstructed. \u2219 Occasional attempts are made to use more \ncomplex sentences.", "metadata": {"type": "factual", "source": "2503.01200v1.pdf", "context": "/uni00000036/uni0000004c/uni00000050/uni00000058/uni0000004f/uni00000044/uni00000057/uni00000048/uni00000047\n/uni00000014/uni00000013/uni00000013/uni00000013\n/uni00000013/uni00000014/uni00000013/uni00000013/uni00000013\n/uni00000033/uni00000052/uni00000056/uni0000004c/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000003/uni0000000b/uni00000051/uni00000050/uni0000000c\n/uni00000013/uni00000011/uni00000013\n/uni00000015/uni00000011/uni00000018\n/uni00000018/uni00000011/uni00000013\n/uni0000001a/", "quality_score": 8.25}}
{"id": "test_66", "question": "What is the main contribution of the proposed method according to Tables II to IV?", "golden_answers": ["The proposed method achieves top performance in regression and F1 scores."], "prediction": "The main contribution of the proposed method is its ability to achieve the highest AUC value, indicating the strongest ability to discriminate between abnormal and normal samples, while also demonstrating exceptional computational efficiency and parallel processing capabilities compared to baseline methods.", "f1": 0.12765957446808512, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "\uf020\nThis approach allows the model to capture \ninformation from different time steps and enables parallel \nprocessing of time series data during the training and inference \nphases. As a result, the model achieves exceptional \ncomputational efficiency and parallel processing capabilities. As shown in Table II, although the number of parameters of the \nproposed model is not the smallest, it is smaller than that of all \nmethods except GLSL. Furthermore, the proposed model \noutperforms all baseline methods in terms of the computational \ncomplexity and inference time measures. To assess the ability of each model to discriminate \nbetween abnormal and normal samples at different thresholds, \nwe also tested the AUC metric for each model. AUC (Area \nUnder the Curve) is the area under the ROC curve, where the \nROC curve plots the False Positive Rate (FPR) on the x -axis \nand the True Positive Rate (TPR) on the y -axis. As the \nthreshold changes from high to low, we obtain a series of (FPR, \nTPR) points that form the ROC curve. The AUC summarizes \nthe TPR and FPR metrics  and reflects the overall performance \nof the model at different thresholds. The higher the AUC, the \nbetter the model's ability to discriminate between abnormal and \nnormal samples. After performing statistical tests, the AUC \nvalues of each model are shown in Table 2. From Table 2, it can \nbe seen that the AUC value of the model we designed is the \nhighest, indicating that our model has the strongest ability to \nperforming between abnormal and normal samples. D. Ablation Experiments \nTo examine the effectiveness and performance of each \ncomponent in the proposed model, we conducted ablation \nexperiments. By systematically removing each component and \nobserving the changes in various metrics, we were able to  \ndetermine the impact of each component. The results of the \nablation experiments are presented in Table III. Here, Pre \nrepresents precision, Rec represents recall, F1 represents the F1 \nscore, Par represents the number of parameters (in millions), \nand FLOPs represent the computational cost in terms of \nfloating-point operations (in millions). TABLE \u2162 \nAblation Experimental Results \n \nScheme 1 is the complete model proposed in this paper. This model employs DWT for time series trend and seasonal \ndecomposition and then inputs them separately into the trend \nencoder and seasonal encoder, with the seasonal encoder using \nMethod Pre (%) Rec (%) F1 (%) AUC Par (M) FLOPs (M) Time (ms) \nCNN-LSTM 79.5 70.0 74.5 0.70 27.9 14,699.7 817.5 \nMTAD-GAT 77.5 87.0 82.0 0.81 1.1 749.2 848.8 \nGAT-GRU 93.3 87.5 90.3 0.84 36.5 14,445.6 13,017.0 \nGLSL 94.5 87.0 90.6 0.93 0.6 3,075.1 2,909.3 \nours 94.7 92.3 93.5 0.97 0.9 148.6 271.0 \nScheme DWT FDAM MFDGCN Pre (%) Rec (%) F1 (%) Par (M) FLOPs (M) \n1 \u221a \u221a \u221a 94.7 92.3 93.5 0.9 148.6 \n2 \u00d7 \u221a \u221a 94.5 92.2 93.4 1.8 324.9 \n3 \u00d7 \u00d7 \u221a 89.1 84.8 86.8 1.8 324.9 \n4 \u00d7 \u00d7 \u00d7 79.0 84.7 81.6 1.7 240.6\n\n8  IEEE SENSORS JOURNAL, VOL. XX, NO. XX, MONTH X, XXXX  \n \nFDAM for feature extraction. Both encoders use the MFDGCN \nfor spatial feature extraction.\n\n2503.00670v1\nResults and Discussion\nOur approach is quantitatively compared with around 17 ex-\nisting approaches including the state-of-the-art on the three\ndatasets. Table 1 shows the quantitative results of the differ-\nent approaches including ours. We observe that our approach\nperforms the best in terms of frame-level AUC on the Ped2\nand Avenue datasets, and performs at par with the state-of-\nthe-art on the ShanghaiTech dataset. The ROC curves for the\nthree datasets shown in Figs. 4(a), (b) and (c) correspond to\nsome of the AUC results in Table 1 including ours, where\nour approach is found to perform at least as good as the other\ncompared methods. From the above observations, we find that\nthe performance of our approach surpasses the state-of-the-art\non the three datasets, which contain varied types of normality\nranging from low to high complexity. For qualitative analysis,\nwe visualize the anomaly score ( LMSE ) for a set of frames\nin a video each from the three datasets in Figs. 3(a), (b) and\n(c), where the corresponding thresholds on the anomaly score\nto detect anomalous activities are also given. As observed\nin the figure, our approach successfully detects a vehicle in\npedestrian path, skipping and running as anomalous events as\nrequired. In Fig. 3(d), loss curves of our one-class few-shot\nlearning on videos from the three datasets are given, which\nshows its efficiency represented by the fast convergence. Ablation study: To understand the effect of the features\nused and the proposed use of self-context in our approach,\nan ablation study is performed using the Avenue dataset. Ta-\nble 2 lists the results, where it is observed that Model I ,which\nuses only the temporal features, performs better than Model\nII, which uses only the spatial features. Temporal features\nmay be more important as anomalies in videos are mostly de-\nscribed by movements. Additionally, we observe that Model\nIV using both the feature types performs better than Model II,\nindicating the positive contribution of spatial features, which\ncapture variations in the target /object appearance. Finally,\nconsider the improvement achieved by Model IV (our final\nmodel) compared to Model III. The use of the input to the en-\ncoder into the decoder as well to form the self-context in our\nmodel is not considered in Model III, where a single pipeline\nwith 2 layers of MSA & LN and MLP & LN modules are\nonly used. The improvement highlights the significance of\nour proposed exploitation of a self-context for V AD. Table 2: An ablation study of our approach on the CUHK Avenue\ndataset. DSF - Self-Context in the Decoder. Model ResNet FlowNet DSF AUC %\nModel I \u00d7 \u2713 \u2713 79.5\nModel II \u2713 \u00d7 \u2713 55.0\nModel III \u2713 \u2713 \u00d7 81.5\nModel IV \u2713 \u2713 \u2713 89.4\n4. CONCLUSION\nA video anomaly detection approach has been proposed based\non a one-class few-shot learning driven transformer predic-\ntion network that considers a self-context.\n\n2503.01426v2\nIn the second method, we choose the rotation to be a consta nt function over each quadrilateral. In\nthis case, the rotation can not be further eliminated, but this varia nt can handle discontinuous coe\ufb03cients\naccurately. In particular, a simple element-wise reconstruction will lead to H(div; \u2126)-conforming stress. Our\nmethod can also be viewed as a mixed-type \ufb01nite volume method, but w e can carry out the error analysis\nin the framework of \ufb01nite element methods. This can simplify the analy sis as it is well-known it is not\nalways easy to analyze \ufb01nite volume method. We emphasize that the c urrent approach shares a conceptual\nsimilarity with the method proposed in [ 29], particularly in the use of primal and dual grids to ensure method\nstability. The \ufb01rst method introduced in this paper, after the elimina tion of stress and rotation variables,\nresults in a smaller system compared to that of [ 30], potentially leading to faster computations. The second\nmethod presented here incorporates displacement and rotation in the \ufb01nal system, with its size determined\nby the number of primal elements. In contrast, the size of the \ufb01na l system in the method proposed by [ 30]\nis dependent on the number of primal edges. Moreover, the metho d from [ 30] is capable of handling highly\ndistorted grids, however, the current methods require the O(h2) mesh condition. We perform a rigorous error analysis for the proposed scheme. Th e unique solvability of the solution is\nestablished. Our method also inherits the locking-free property of standard mixed \ufb01nite element method. Besides, we also prove the superconvergence of L2-error of displacement under the assumption that the\nsolution is smooth enough. In summary, our method owns several a ppealing features, which include: (1) the\nmethod enjoys local conservation, and a simple reconstruction will yield H(div; \u2126)-conforming stress; (2) it\nis locking-free, which allows to handle problems with nearly incompress ible materials; (3) piecewise constant\nfunctions are used for all the unknowns, which makes the implement ation easy; (4) the stress bilinear form\nis block-diagonal, which allows local elimination of stress and reduction to a cell-centered system. All these\nsalient features make our method a good candidate for handling pro blems arising from practical applications. Extensive numerical simulations including three-dimensional tests a re carried out. We observe that both\nmethods deliver at least \ufb01rst-order convergence for all variables in either structured or smooth unstructured\ngrids, superconvergence of displacements and rotation are obse rved. Moreover, by taking average of stress\ntensor inside each element also leads to superconvergence in struc tured and some types of smooth unstructured\ngrids. Besides, our methods are observed to be much more accura te than BDM 1 with mass lumping strategies,\nlocking-free properties are found as expected and the ability to so lve challenging highly heterogeneous media\nare demonstrated. The major contributions of the paper can be summarized as follows:\n1. We design a locally conservative and locking-free method in stress -displacement formulation with piece-\nwise constant approximations that allows reduction to a cell-center ed system. 2.", "metadata": {"type": "factual", "source": "2503.01217v2.pdf", "context": "across scene tasks, enhancing CNER robustness. As shown in\nTables II to IV, proposed method achieves top performance\nin regression and F1 scores. Ablation studies in Table V\nconfirm that hierarchical exponential attention and reduced-\nbias modules expand data depth, excelling in conventional\ntasks in Figure 4 and domain tasks in Figures 5 and 6.\n2) The Hierarchical Reduced-bias EMA architecture enables\nprecise CNER feature extraction. Inspired by DAE [27], the", "quality_score": 8.25}}
{"id": "test_67", "question": "How does the Transformer module adopt the design of Restormer [36] to reduce computational cost?", "golden_answers": ["The Transformer module adopts a simplified design that enables its use across multiple levels, which reduces the computational cost."], "prediction": "The provided documents do not contain information regarding how the Transformer module adopts the design of Restormer [36] to reduce computational cost.", "f1": 0.34285714285714286, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "session 23_paper.pdf\nThe proposed training and compression techniques reduce the parameter size by 15.9-25.5\u00d7 with minimal accuracy loss. When performing inference with these models, T-REX requires 31 to 65.9\u00d7 less EMA and exhibits 1.2 to 3.4\u00d7 higher hardware utilization. We compared T-REX with the previous accelerators. For those works that do not consider EMA, we estimated the energy cost at 3.7pJ/b and the latency cost at 6.4GB/s, both based on the LPDDR3 SDRAM [22,23]. T-REX achieves 68 to 567\u00b5s/token and 0.41 to 3.95\u00b5J/token, marking signi\ufb01cant improvements across several workloads over prior works. Acknowledgement:  This work was supported in part by an SRC AIHW program (Task 3160.002) and by COGNISENSE, one of seven centers in JUMP 2.0, an SRC program sponsored by DARPA. Figure 23.1.1: Challenges in transformer processing and proposed solutions. Figure 23.1.2: Overall architecture of T-REX. Figure 23.1.3: Factorizing training and compressions with hardware support. Figure 23.1.4: Dynamic batching technique for variable input token length. Figure 23.1.5: Input and output buffers based on two-direction accessible register \ufb01le. Figure 23.1.6: Measurement result and comparison table. ISSCC 2025 / February 19, 2025 / 8:00 AM\n407  DIGEST OF TECHNICAL PAPERS  \u2022\n23\n\n\u2022  2025 IEEE International Solid-State Circuits Conference\nISSCC 2025 PAPER CONTINUATIONS AND REFERENCES\n979-8-3315-4101-9/25/$31.00 \u00a92025 IEEE\nFigure 23.1.7: Chip photograph and performance summary. References: [1] Y. Wang et al., \u201cA 28nm 27.5TOPS/W Approximate-Computing-Based Transformer Processor with Asymptotic Sparsity Speculating and Out-of-Order Computing,\u201d ISSCC, pp. 464-465, 2022. [2] F. Tu et al., \u201cA 28nm 15.59uJ/Token Full-Digital Bitline-Transpose CIM-Based Sparse Transformer Accelerator with Pipeline/Parallel Recon\ufb01gurable Modes,\u201d ISSCC, pp. 466-467, 2022. [3] S. Liu et al., \u201cA 28nm 53.8TOPS/W 8b Sparse Transformer Accelerator with In-Memory Butter\ufb02y Zero Skipper for Unstructured-Pruned NN and CIM-Based Local-Attention-Reusable Engine,\u201d ISSCC, pp. 250-251, 2023. [4] Y. Wang et al., \u201cA 28nm 77.35TOPS/W Similar Vector Traceable Transformer Processor with Principal-Component-Prior Speculating and Dynamic Bit-wise Stationary Computing,\u201d IEEE Symp. VLSI Circuits, C16-5, 2023. [5] H. You et al., \u201cViTCoD: Vision Transformer Acceleration via Dedicated Algorithm and Accelerator Co-Design,\u201d IEEE HPCA, 2023. [6] P. Dong et al., \u201cHeatViT: Hardware-Ef\ufb01cient Adaptive Token Pruning for Vision Transformers,\u201d IEEE HPCA, 2023. [7] J. Dass et al., \u201cViTALiTy: Unifying Low-rank and Sparse Approximation for Vision Transformer Acceleration with a Linear Taylor Attention,\u201d IEEE HPCA, 2023. [8] B. Keller et al., \u201cA 17-95.6 TOPS/W Deep Learning Inference Accelerator with Per-Vector Scaled 4-bit Quantization for Transformers in 5nm,\u201d IEEE Symp. VLSI Circuits, C2-1. 2022. [9] S. Moon et al., \u201cA 127.8TOPS/W Arbitrarily Quantized 1-to-8b Scalable-Precision Accelerator for General-Purpose Deep Learning with Reduction of Storage, Logic and Latency Waste,\u201d ISSCC, pp. 330-331, 2023. [10] F. Tu et al., \u201cMulTCIM: A 28nm 2.24uJ/Token Attention-Token-Bit Hybrid Sparse Digital CIM-Based Accelerator for Multimodal Transformers,\u201d ISSCC, pp. 248-249, 2023. [11] H. Mun et al., \u201cA 28 nm 66.8 TOPS/W Sparsity-Aware Dynamic-Precision Deep-Learning Processor,\u201d IEEE Symp. VLSI Circuits, C16-1, 2023. [12] B. Keller et al., \u201cA 95.6-TOPS/W Deep Learning Inference Accelerator With Per-Vector Scaled 4-bit Quantization in 5 nm,\u201d IEEE JSSC, vol. 58, no. 4, pp. 1129-1141, 2023. [13] Y. Qin et al., \u201cFACT: FFN-Attention Co-optimized Transformer Architecture with Eager Correlation Prediction,\u201d IEEE/ACM ISCA, 2023.\n\n2503.01190v1\nThese components are embedded\ninto the transformer\u2019s latent space using dedicated projec-\ntion heads: Vemb, Demb and Lemb.\ncA V= Vemb\n\u0000\nAV\n\u0001\n, c CD = Demb\n\u0000\nCD\n\u0001\n, c L = Lemb\n\u0000\nL\n\u0001\n. To handle both fully and partially conditional cases, we\nused user input (UI) tokens. Each token indicates whether\na component is user-defined (guided) or neutral (uncondi-\ntional). During training, each layout component is either\nprovided or masked with a certain probability, allowing the\nmodel to learn both conditional and unconditional scenar-\nios. This probabilistic masking is applied independently\nto each component. When a component is masked, it is\nreplaced with a \u201cblack\u201c image embedding, and its corre-\nsponding UI token is updated to signal the absence of guid-\nance:\nUI = [UIA V, UICD, UIL],\nallowing flexible control over the conditioning process. The\nfinal conditioning vector is computed as:\nc = cA V+ cCD + cL.\nwhich is fed into the transformer as part of a sequence:\n[BOC, UI, c,EOC, zt],\nwhere BOC and EOC mark the beginning and end of the\nconditioning tokens, respectively. After the transformer\nprocesses this sequence, only the image tokens are retained\nto produce zt\u22121. This design ensures that conditioning sig-\nnals guide the denoising process without remaining entan-\ngled in the final latent representation. A schematic overview\nof our architecture is provided in Figure 2. Training Objective. Following DDPM [27], we adopt a\nnoise prediction loss. Instead of directly modeling \u00b5\u03b8 and\n4\n\n\u03a3\u03b8, our model predicts the noise\u03f5 added at a randomly cho-\nsen timestep t:\nLsimple = Ez0,t,\u03f5\n\u0002\n\u2225\u03f5 \u2212 \u02c6\u03f5\u03b8(zt, t, c)\u22252\u0003\n. (3)\nMinimizing this MSE loss enables the model to accu-\nrately denoise latent representations, effectively learning to\nreverse the diffusion process. By incorporating tokens that\ndifferentiate between user-defined and neutral embeddings\nfor each layout component, the model can both generate\nanatomically guided images when specific conditions are\nprovided, and produce diverse, unconstrained samples in\nthe absence of such guidance. This flexibility ensures that\nthe model adapts seamlessly to varying levels of conditional\ninput, balancing anatomical fidelity with generative diver-\nsity. Sampling. To generate new images, we start from a ran-\ndom Gaussian latent zT \u223c N(0, I) and iteratively remove\nnoise at each diffusion step t. Our model predicts the added\nnoise \u02c6\u03f5\u03b8(zt, t, c), where c includes tokens for A V , CD, and\nL layouts. We employ classifier-free guidance [26] to control how\nclosely the model adheres to provided conditions. At each\nstep, two predictions are made: one conditional (c) and one\nunconditional (c = \u2205). These are combined as:\n\u02c6\u03f5guided\n\u03b8 (zt, t, c) = \u02c6\u03f5\u03b8(zt, t,\u2205) +w\n\u0000\n\u02c6\u03f5\u03b8(zt, t, c) \u2212 \u02c6\u03f5\u03b8(zt, t,\u2205)\n\u0001\n,\n(4)\nwhere w is a guidance scale. Higher w yields more faithful\nadherence to the conditions, lower w allows more diversity. By iteratively applying guided noise predictions until\nreaching z0, we decode z0 using the V AE to produces\na synthetic retinal fundus image.\n\n2503.01190v2\nThese components are embedded\ninto the transformer\u2019s latent space using dedicated projec-\ntion heads: Vemb, Demb and Lemb.\ncA V= Vemb\n\u0000\nAV\n\u0001\n, c CD = Demb\n\u0000\nCD\n\u0001\n, c L = Lemb\n\u0000\nL\n\u0001\n. To handle both fully and partially conditional cases, we\nused user input (UI) tokens. Each token indicates whether\na component is user-defined (guided) or neutral (uncondi-\ntional). During training, each layout component is either\nprovided or masked with a certain probability, allowing the\nmodel to learn both conditional and unconditional scenar-\nios. This probabilistic masking is applied independently\nto each component. When a component is masked, it is\nreplaced with a \u201cblack\u201c image embedding, and its corre-\nsponding UI token is updated to signal the absence of guid-\nance:\nUI = [UIA V, UICD, UIL],\nallowing flexible control over the conditioning process. The\nfinal conditioning vector is computed as:\nc = cA V+ cCD + cL.\nwhich is fed into the transformer as part of a sequence:\n[BOC, UI, c,EOC, zt],\nwhere BOC and EOC mark the beginning and end of the\nconditioning tokens, respectively. After the transformer\nprocesses this sequence, only the image tokens are retained\nto produce zt\u22121. This design ensures that conditioning sig-\nnals guide the denoising process without remaining entan-\ngled in the final latent representation. A schematic overview\nof our architecture is provided in Figure 2. Training Objective. Following DDPM [27], we adopt a\nnoise prediction loss. Instead of directly modeling \u00b5\u03b8 and\n4\n\n\u03a3\u03b8, our model predicts the noise\u03f5 added at a randomly cho-\nsen timestep t:\nLsimple = Ez0,t,\u03f5\n\u0002\n\u2225\u03f5 \u2212 \u02c6\u03f5\u03b8(zt, t, c)\u22252\u0003\n. (3)\nMinimizing this MSE loss enables the model to accu-\nrately denoise latent representations, effectively learning to\nreverse the diffusion process. By incorporating tokens that\ndifferentiate between user-defined and neutral embeddings\nfor each layout component, the model can both generate\nanatomically guided images when specific conditions are\nprovided, and produce diverse, unconstrained samples in\nthe absence of such guidance. This flexibility ensures that\nthe model adapts seamlessly to varying levels of conditional\ninput, balancing anatomical fidelity with generative diver-\nsity. Sampling. To generate new images, we start from a ran-\ndom Gaussian latent zT \u223c N(0, I) and iteratively remove\nnoise at each diffusion step t. Our model predicts the added\nnoise \u02c6\u03f5\u03b8(zt, t, c), where c includes tokens for A V , CD, and\nL layouts. We employ classifier-free guidance [26] to control how\nclosely the model adheres to provided conditions. At each\nstep, two predictions are made: one conditional (c) and one\nunconditional (c = \u2205). These are combined as:\n\u02c6\u03f5guided\n\u03b8 (zt, t, c) = \u02c6\u03f5\u03b8(zt, t,\u2205) +w\n\u0000\n\u02c6\u03f5\u03b8(zt, t, c) \u2212 \u02c6\u03f5\u03b8(zt, t,\u2205)\n\u0001\n,\n(4)\nwhere w is a guidance scale. Higher w yields more faithful\nadherence to the conditions, lower w allows more diversity. By iteratively applying guided noise predictions until\nreaching z0, we decode z0 using the V AE to produces\na synthetic retinal fundus image.", "metadata": {"type": "reasoning", "source": "2503.01265v1.pdf", "context": "calization of suspected lesion regions within these scans. This\ncomponent operates exclusively during the training phase,\ngenerating blurred region-of-interest (ROI) prompts through\nits convolution-based stochastic scaling algorithm, which is\ndetailed in Algorithm 1. It defines a series of convolution\n1The Transformer module adopts the design of Restormer [36], a simplified\nTransformer that reduces the computational cost, enabling its use across\nmultiple levels.", "quality_score": 8}}
{"id": "test_68", "question": "What advantage does our explainability framework, FM Explainer, have over other methods like SHAP and LIME?", "golden_answers": ["It captures both individual and interaction effects, which other methods may overlook."], "prediction": "The FM Explainer has the advantage of capturing both individual feature contributions and their interactions, providing greater explainability and improving its ability to identify manipulated features in multi-feature attack scenarios, which other methods like SHAP and LIME may overlook.", "f1": 0.326530612244898, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01229v1\nWhile attribution focuses on identifying the most impactful\nfeatures, explainability more broadly refers to understanding\nhow a model arrives at its predictions. In recent years,\nexplainability methods have gained traction across various\nfields, particularly in security-related ML applications. These\nmethods provide a means to interpret the behavior of complex\nmodels, which are often referred to as \u201cblack box\u201d due\nto the difficulty in tracing how they make decisions [29]. Using explainability techniques in anomaly detection models\nhelps operators and the public trust these systems, enhancing\ntransparency, reliability, and security management in critical\ninfrastructure.\nChallenges. Although attribution and explainability techniques\nhave been widely used, applying them to water systems\npresents specific challenges. Traditional model-agnostic\nmethods like LIME [24], SHAP [25], and LEMNA [26]\nfocus on individual feature importance by providing linear\napproximations of feature contributions. While SHAP and\nLEMNA can account for some interactions, their outputs are\nstill primarily based on independent feature contributions. In water systems, however, sensors and actuators are tightly\ninterconnected, and understanding these interactions is crucial\nfor identifying the root causes of anomalies [8]. Neglecting\nthese connections could cause attribution methods to overlook\nkey factors behind complex, targeted attacks [30]. In terms\nof explainability, while deep learning models like CNNs\n[31] and LSTMs [32] are effective at detecting novel threats\n[21], their complexity makes understanding their decisions\na significant challenge. In time-sensitive situations, this lack\nof transparency reduces effectiveness, as operators need to\nquickly understand how decisions are made. Explainability\nmethods that focus only on individual features, without\naccounting for interactions, can make it harder to diagnose\nsystem failures or instabilities. Developing explanation\ntechniques that account for feature interactions is important\nfor securing water systems against sophisticated threats, such\nas multi-asset attacks. Scientific Contributions. This work addresses the challenges\nof attribution and explainability in water systems by using\nFactorization Machines (FM) [33], originally developed for\nrecommendation systems [34], as a model-agnostic explainer\nfor existing anomaly detectors. FM identifies both individual\nasset contributions and interactions between components, such\nas sensors and actuators, which can be crucial for diagnosing\nanomalies. By capturing these interactions, our approach of-\nfers more accurate attribution, improving the detection and\nmitigation of complex attacks on water infrastructure. FM provides explainability by capturing both linear feature\ncontributions and second-order interactions (quadratic effects),\noffering a more detailed and precise understanding than tradi-\ntional linear methods. Additionally, FM operates efficiently in\nlinear time [33], making it ideal for real-time applications. Our\napproach improves interpretability and security management\nwhile retaining the underlying detection models. In brief, the\npaper makes the following scientific and pragmatic contribu-\ntions:\n\u2022 We introduce a novel model-agnostic framework that\nleverages Factorization Machines (FM) to enhance attack\nattribution and explainability in water systems. \u2022 We model both linear individual contributions and\nquadratic pairwise interaction effects in water systems\nusing second-order FM equation, enabling more precise\nattack attribution while preserving computational effi-\nciency. \u2022 We validate our proposed approach as a effective plug-\nand-play attack attribution method that seamlessly in-\ntegrates with existing deep learning anomaly detection\nmodels in water systems.\n\n2503.01229v1\nAlthough LEMNA performed competitively with SHAP in some\nmetrics, it struggled with multi-feature attacks, as reflected by\nits higher AvgRank and lower Top-1 and Top-5 accuracies. This\ndemonstrates the FM Explainer\u2019s effectiveness in capturing\ncomplex feature interactions, improving its ability to identify\nmanipulated features in multi-feature attack scenarios. In con-\ntrast, LIME struggled in both aggregated and multi-feature\nattack contexts, particularly in identifying key manipulated\nfeatures. It showed low Top-1 and Top-5 accuracies, likely\ndue to its linear nature and focus on modeling individual\nfeature effects, limiting its ability to capture important in-\nteractions. Overall, the FM-based method showed significant\nimprovements in multi-feature attack scenarios while deliv-\nering comparable results across all attack types. Its ability\nto model pairwise (quadratic) interactions, alongside linear\ncontributions, provides greater explainability. The method is\nalso flexible, as \u03b1 and \u03b2 can be tuned to emphasize either\nindividual features or interactions. All methods, including FM,\nare model-agnostic and operate in linear time, making this a\nfair comparison for practical use in attributing anomalies to\nattack targets and protecting critical water infrastructure from\ncyber-attacks.\nResults on WADI Dataset. We evaluated the attribution per-\nformance of our FM Explainer method against SHAP, LIME,\nand LEMNA on the WADI dataset, focusing on single-feature\nattacks detected by the anomaly detection model. Table II\npresents the performance metrics using a practical timing\nstrategy, which evaluates attribution over the 50 timesteps\nfollowing the detection event. As shown in Table II, our\nFM Explainer achieves strong performance in single-feature\nattacks, delivering competitive AvgRank values. The best-\nperforming FM variant ( \u03b1 = 0.3, \u03b2 = 0.7) achieves an\nAvgRank of 0.1223, closely matching LEMNA\u2019s best AvgRank\nof 0.1174. This demonstrates that, just as in multi-feature\nattacks, FM effectively ranks the attacked features higher\nin single-feature scenarios, outperforming SHAP (AvgRank\n0.1539) and significantly better than LIME (AvgRank 0.3664). At Top-1 accuracy, SHAP outperforms FM. However, this\nadvantage is confined to the Top-1 metric, as FM remains\nhighly competitive or superior across Top-5 and Top-10 met-\nrics. Both FM and LEMNA consistently outperform SHAP\nand significantly outperform LIME, which struggles across\nall metrics. These results show that, beyond the performance\nboost in multi-feature attacks, our FM Explainer also performs\nwell in single-feature attack scenarios. Additionally, it provides\nmore detailed explainability by capturing both individual and\ninteraction effects, which other methods may overlook. G. Explaining Multi-Point Attacks in Water Systems\nThis section demonstrates how our explainability framework\nidentifies and analyzes multi-point attacks in the SWaT system\nby examining both individual feature contributions and their\ninteractions. Figure 4 shows the explainability results for\nAttack ID 27, where sensors AIT402 and AIT502 were\nmanipulated. The left panel (a) shows the linear weights, repre-\nsenting individual feature contributions to the anomaly, while\nthe right panel (b) displays interaction weights, highlighting\ndependencies between components. The linear weights reveal\nthat AIT402, AIT502, and FIT201 are the main contribu-\ntors, consistent with the attack on AIT402 and AIT502. A\nkey advantage of our method over LIME, SHAP, and LEMNA is\nthe ability to model interaction effects between features.\n\n2503.01229v1\nKravchik and Shabtai [46] used a CNN-based model\non the SWaT dataset to identify anomalies through high-\nerror features, while Hwang and Lee [43] applied SHAP with\nan LSTM-based model. More advanced methods, such as\nDeepSHAP [47], have shown promise in capturing complex\nrelationships in cyber-physical systems. Model-agnostic attri-\nbution methods often overlook feature interactions, which are\ninherent in water systems due to the interconnected nature\nof sensors and actuators. This focus on individual features\nleads to incomplete explanations. To address this, we propose\na model-agnostic solution that works across different anomaly\ndetection models, recognizing that deep learning systems are\nfrequently updated or replaced. Our approach uses FM [33]\nfor flexibility across different anomaly detection models while\ncapturing both individual contributions and feature interac-\ntions. Compared to model-agnostic methods like LIME, SHAP,\nand LEMNA, FM offers greater accuracy in anomaly attri-\nbution, particularly in multi-component attacks. Its strength\nlies in modeling both linear and interaction effects, providing\ndeeper insights into system behavior. VI. C ONCLUDING REMARKS AND FUTURE DIRECTIONS In this work, we introduce a novel model-agnostic Factor-\nization Machines (FM)-based attack attribution method specif-\nically tailored for water systems. This approach effectively\naddresses the limitations of existing attribution methods, in-\ncluding LIME, SHAP, and LEMNA, by simultaneously model-\ning both individual contributions and feature interactions. Our\nexperiments on two real-world water system datasets, SWaT\nand W ADI, show that the FM explainer outperforms exist-\ning methods in multi-feature attacks while delivering strong,\ncomparable performance in single-feature attack scenarios. Notably, our approach is computationally efficient, enabling\nit to scale effectively to complex and interconnected water\nsystems. This scalability is crucial for practical applications\nin real-time anomaly detection and attack attribution within\ncritical infrastructure. In our future research endeavors, we\naim to advance our work by expanding water system-related\ndatasets to include more complex and stealthy attack scenarios. Additionally, we plan to enhance our FM-based attribution\nmethod by incorporating higher-order interactions, allowing\nus to estimate group or process stage contributions in water\nsystems, and better assess the effect of group interconnected-\nness on detected anomalies caused by attacks. Recognizing\nthe significant potential for enhancement in existing deep\nlearning detection frameworks, our goal is to harness the\ncapabilities of our FM approach to create a comprehensive\nsolution that seamlessly integrates anomaly detection with\nattack attribution. ACKNOWLEDGMENTS\nThe authors would like to thank the anonymous reviewer\nfor their constructive comments. This work was supported by\nNSF under Grants #2230087 and #2404946. REFERENCES\n[1] Center for Sustainable Systems, University of Michigan, \u201cU.s. wa-\nter supply and distribution factsheet,\u201d http://css.umich.edu/factsheets/\nus-water-supply-and-distribution-factsheet, 2023, pub. No. CSS05-17. [2] N. Neshenko, C. Nader, E. Bou-Harb, and B. Furht, \u201cA survey of\nmethods supporting cyber situational awareness in the context of smart\ncities,\u201d Journal of Big Data, vol. 7, 10 2020. [3] Bleepingcomputer, \u201cKansas water plant cyberattack forces switch to\nmanual operations,\u201d https://www.bleepingcomputer.com/news/security/\nkansas-water-plant-cyberattack-forces-switch-to-manual-operations/,\n2024, accessed: 2024-09-30. [4] D. Goodin, \u201cHackers tried to poison water supply of\nflorida town by remotely accessing treatment plant con-\ntrols,\u201d https://arstechnica.com/information-technology/2021/02/\nhackers-try-to-poison-water-supply-of-florida-town/, 2021, accessed:\n2023-10-15.", "metadata": {"type": "reasoning", "source": "2503.01229v1.pdf", "context": "in single-feature scenarios, outperforming SHAP (AvgRank\n0.1539) and significantly better than LIME (AvgRank 0.3664).\nAt Top-1 accuracy, SHAP outperforms FM. However, this\nadvantage is confined to the Top-1 metric, as FM remains\nhighly competitive or superior across Top-5 and Top-10 met-\nrics. Both FM and LEMNA consistently outperform SHAP\nand significantly outperform LIME, which struggles across\nall metrics. These results show that, beyond the performance\nboost in multi-feature attacks, our FM ", "quality_score": 8}}
{"id": "test_69", "question": "What is the primary focus of the image?", "golden_answers": ["The face and upper body of the woman."], "prediction": "The primary focus of the image is the woman's face and upper body.", "f1": 0.625, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01261v2\nThe background is a solid \nlight gray color, which ensures that the focus remains solely on the \nwoman. The simplicity of the background further accentuates the \ndetails of the woman's face and hair. The image does not contain any \ntext or other discernible objects. The relative position of the woman to \nthe background suggests she is the main subject of this image. The \nimage does not provide any information about the location or setting. The image is a portrait, focusing on the woman's face and upper body.\nOrigin Caption\nShe has arched eyebrows. She is smiling, and young and is wearing \nlipstick. This woman is wearing heavy makeup. She has wavy hair, and \nmouth slightly open. She has mouth slightly open, arched eyebrows, and wavy hair and is \nwearing heavy makeup. She is smiling. This person is attractive and has blond hair, mouth slightly open, and \narched eyebrows. This person has arched eyebrows, wavy hair, and mouth slightly \nopen. She wears lipstick. She is attractive. Long Text\nIn the image, there's an older man who is the main subject. He has a \nbald head and is wearing glasses. His chin is resting on his hand, \nsuggesting a moment of contemplation or deep thought. He is dressed \nin a beige jacket, which adds a professional or formal tone to the image. The background is a blurred gray color, which puts the focus entirely \non the man. There are no other discernible objects or texts in the image. The man's position relative to the background suggests he is standing \nin front of it. The image does not provide any information about the \nlocation or setting. It's a simple yet intriguing portrait of an older man, \ncaptured in a moment of quiet reflection. This person has receding hairline. The man has narrow eyes, receding hairline, and eyeglasses. This man has narrow eyes, big nose, receding hairline, and gray hair. The man has big nose, eyeglasses, and narrow eyes. The person has receding hairline. The image captures a close-up of a woman's face, her gaze directed \nstraight at the camera. Her hair, a vibrant shade of blonde, frames her \nface, adding a touch of warmth to the overall composition. Her eyes, a \nstriking shade of blue, stand out against her complexion, and her lips, \npainted a soft pink, add a subtle contrast. The background, though \nblurred, gives the impression of a room with a window, suggesting an \nindoor setting. The focus on the woman's face and the blurred \nbackground create a depth of field effect, drawing attention to her \nexpressive features. There are no discernible texts or other objects in the \nimage. The relative position of the woman to the background suggests \nshe is in the foreground of the scene. The image does not provide any \ninformation about the actions of the objects or their precise locations. The image is devoid of any aesthetic descriptions, focusing solely on the \nfactual elements present. She is wearing lipstick. She is young and has brown hair, and wavy \nhair. This woman is wearing lipstick. She has arched eyebrows.\n\nA template for the arxiv style\nAs ITM and ITG\nobjectives are incrementally incorporated, performance gradually improves (IDs 2 and 3), highlighting how refined\ncross-modal alignment and multi-modal language modelling enhance the model\u2019s overall capabilities. Interestingly,\nthe model with TIG (ID 4) surpasses the one with ITG (ID 3). We attribute this phenomenon to the relative difficulty\nof generating pixel-level image representations guided by text, as compared to generating word-level representations\nguided by visual input, which leads the model to learn more abstract, well-aligned representations. Ultimately, the\nintegration of all objective types (ID 5) enables the model to achieve optimal performance, underscoring the viability of\nincorporating vision generation into existing frameworks. More elaborate ablation study over more downstream tasks\ncan be found in appendix 5. 5 Conclusion\nIn this paper, we introduce a novel and unified Med-VLP model, MedUnifier, which optimizes four distinct learning\nobjectives simultaneously. By leveraging learnable embeddings and encoding raw images through a pre-trained Vision\nTransformer (ViT), MedUnifier circumvents the need to learn visual embeddings from scratch. Additionally, a VQ-\nV AE-based text-grounded image generation task is further incorporated into the Med-VLP framework to enhance\nits representation learning capacity. It reconstructs pixel-level visual details from both image and report, facilitating\nfine-grained visual understanding commonly available in medical data (subtle visual details e.g. small nodules, slight\nopacities, etc.) and efficient use of multi-modal representations through hierarchical latent adapters of dynamically\nadjusting the abstraction for each mode. The adapters help align vision and texts, ensuring that the each data mode\ncontributes its most relevant features. Our proposed method effectively complements existing Med-VLP frameworks\nand achieves state-of-the-art performance on various downstream tasks, as validated by experimental results. Our work\nalso has significant implications for enhancing the VLP development for radiological applications. 6 Acknowledgement\nThis project is supported by the Ministry of Education, Singapore, under its Academic Research Fund Tier 1 (RG25/24). This project is supported by the Lee Kong Chian School of Medicine - Ministry of Education Start-Up Grant. This\nproject is supported by the Ministry of Education, Singapore, under its Academic Research Fund Tier 1 (RS16/23). This research was supported in part through the computational resources and staff contributions provided for the Quest\nhigh performance computing facility at Northwestern University which is jointly supported by the Office of the Provost,\nthe Office for Research, and Northwestern University Information Technology. 11\n\nReferences\nJean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr, Yana Hasson, Karel Lenc, Arthur Mensch, Katherine\nMillican, Malcolm Reynolds, et al. Flamingo: a visual language model for few-shot learning. Advances in neural information\nprocessing systems, 35:23716\u201323736, 2022. Yogesh Balaji, Seungjun Nah, Xun Huang, Arash Vahdat, Jiaming Song, Qinsheng Zhang, Karsten Kreis, Miika Aittala, Timo Aila,\nSamuli Laine, et al. ediff-i: Text-to-image diffusion models with an ensemble of expert denoisers.arXiv preprint arXiv:2211.01324,\n2022. Shruthi Bannur, Stephanie Hyland, Qianchu Liu, Fernando Perez-Garcia, Maximilian Ilse, Daniel C Castro, Benedikt Boecking,\nHarshita Sharma, Kenza Bouzid, Anja Thieme, et al. Learning to exploit temporal structure for biomedical vision-language\nprocessing. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 15016\u201315027, 2023.\n\n2503.00250v1\nSpecifically, the movement of clouds, as captured\nby continuous frames, does not visually correlate with solar\nirradiance, necessitating additional analytical steps such as\ndirection identification and spatial construction, which are\nchallenging to learn from a limited dataset. Moreover, model 5\u20dd shows that the added value of the\npast 30-minute GHI is not readily apparent, whereas model\n6\u20dd, the SMT using 24-hour historical GHI outperformed the\nalternatives. This underscores the importance of the time\nseries data\u2019s window length. Given that our camera doesn\u2019t\noperate at night, a more appropriate future comparison test\nwould involve frames spanning the past 24 hours, which\nwould provide a direct comparison with model 6\u20dd. Hybrid SMTs like model 7\u20dd and 8\u20dd tend to converge\nmore quickly due to the bottom-up features input into the\ntransformers. However, they are also prone to overfitting. Introducing a dropout rate before the final linear layer of\nthe transformer or within the attention blocks has not signif-\nicantly mitigated this issue, a limitation possibly attributed\nto the size of our dataset. Model 9\u20dd combine LSTNet [19] and CNNLSTM (1\ncamera) [33] through a simple concatenation step before\nmaking the final prediction. Despite the combination of\nthese two strong models on individual data modalities, their\nperformance is still less effective than that of the SMT,\ndemonstrating the effectiveness of the transformer compo-\nnent for a deep integration of spatial and temporal informa-\ntion from diverse data modalities in this task. Although the\nViT has been observed to inadequately model fine details in\nimages, leading to a loss of feature richness due to its sim-\nple tokenization of image patches [44], this limitation is not\na concern for solar forecasting using public camera images. In the case of public cameras, the majority of the captured\nscene, such as buildings and vegetation, remains static, con-\ntaining largely irrelevant information. Unlike tasks such as\nsemantic segmentation, which require recognition of local\nstructures like edges or lines, our focus is primarily on dy-\nnamic elements such as optical flow, cloud movements, and\nthe position of the Sun, etc. Furthermore, the images from\npublic cameras are panoramic, stretched out into a long rect-\nangular format. The different areas of the image are related\nbut not directly connected; for example, pixels representing\nregions at 0\u25e6 North and 180\u25e6 South are in the same line of\nsight but appear disconnected in the image. The transformer\narchitecture enables the establishment of dependencies right\nfrom the outset between pixels that are distantly located yet\nhighly interdependent, in contrast to the \u201cbottom-up\u201d fea-\nture aggregation after layers of CNNs. 4.3.3 Patch shape and attention analysis\nTo investigate how patch shapes influence the performance\nof SMT, we experimented with modifying the patch shapes\nto row or column pixels, in addition to the standard square\npatches of 16 \u00d7 16. Column patches that carry directional\ninformation, are proved to be most effective, see Table 5. Patch RMSE RSE CORR\nSquare 65.434 0.383 0.927\nRow 66.112 0.387 0.923\nColumn 63.756 0.373 0.928\nTable 5. The influence of different patch shapes for SMT. Tested\nfrom 28 Sep.", "metadata": {"type": "factual", "source": "2503.01261v2.pdf", "context": "The image captures a close-up of a young woman with striking blue \neyes and blonde hair. Her hair, styled in loose waves, cascades down \nher shoulders, adding a touch of elegance to her appearance. She is \nwearing a white tank top, which contrasts beautifully with her blonde \nhair. Her gaze is directed straight at the camera, creating a sense of \nconnection with the viewer. A slight smile graces her face, adding a \nwarm and friendly aura to the overall image. The background is a solid \nlight gra", "quality_score": 8}}
{"id": "test_70", "question": "How is the delta function \u03b4(t1 \u2212 t2) regularized for discrete time slices?", "golden_answers": ["as \u03b4n1n2 1 \u2206t, where \u2206t = t N and n = 0, 1, 2, . . . , N\u2212 1"], "prediction": "The delta function \u03b4(t1 \u2212 t2) is regularized as \u03b4(t1 \u2212 t2) = \u03b4(n1\u2206t \u2212 n2\u2206t) = \u03b4n1n2 / \u2206t.", "f1": 0.19354838709677422, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01279v1\nNext, we consider taking discrete time slices tn = n\u2206t,\nwhere \u2206t = t\nN and n = 0, 1, 2, . . . , N\u2212 1. At each time\nstep, we have a random noise term \u03b7ij(n\u2206t). For two\ntimes t1 = n1\u2206t and t2 = n2\u2206t, we choose to regularize\nthe delta function as follows:\n\u03b4(t1 \u2212 t2) = \u03b4(n1\u2206t \u2212 n2\u2206t) = \u03b4n1n2\n1\n\u2206t . (12)\nSo that Eq.(10) becomes\nE(\u03b7ij(n\u2206t)\u03b7kl(m\u2206t)) = 1\n\u2206t\u03bbij\u03b4il\u03b4jk\u03b4nm . (13)\n\n3\nOne can treat Uk as a D2k-dimensional matrix gener-\nated by the operator Lk, with the row and column in-\ndices labeled explicitly as I = {i1, i2, i3, . . . , i2k} and\nJ = {j1, j2, j3, . . . , j2k}\n[Uk]IJ = Ui1j1 U\u2217\ni2,j2 \u00b7\u00b7\u00b7 Ui2k\u22121j2k\u22121 U\u2217\ni2k,j2k (14)\nwhere we take the order of {i} and {j} on the right-hand\nside for convenience. Then, the equation of motion of Uk\nis simply\n\u2202tUk(t) = Lk.Uk(t) . (15)\nTo illustrate the calculation, we first consider the sim-\nplest case of k = 1:\nU1(t) := E[U(t) \u2297 U\u2217(t)] , U1;ij;i\u2032j\u2032 = [exp (L1t)]ij;i\u2032j\u2032 .\n(16)\nOne can obtain the expression for L1 through direct cal-\nculation. From the definition, we have\nUij(t + \u2206t)U\u2217\nkl(t + \u2206t)\n=\nDX\nu,v=1\n\u0010\ne\u2212iH(t)\u2206t\n\u0011\niu\n\u0010\neiH\u2217(t)\u2206t\n\u0011\nkv\nUuj(t)U\u2217\nvl(t) . (17)\nNext, we employ the Taylor series expansion and take the\nnoise ensemble average on both sides, retaining terms up\nto linear order in \u2206 t. Thus, we obtain\nE[Uij(t + \u2206t)U\u2217\nkl(t + \u2206t)]\n= E\n\" DX\nu,v=1\n\u0010\ne\u2212iH(t)\u2206t\n\u0011\niu\n\u0010\neiH\u2217(t)\u2206t\n\u0011\nkv\nUuj(t)U\u2217\nvl(t)\n#\n= E\n\" DX\nu,v=1\n\u0012\nI \u2212 iH(t)\u2206t \u2212 1\n2H2(t)\u2206t2\n\u0013\niu\n\u0012\nI + iH\u2217(t)\u2206t \u2212 1\n2H\u22172(t)\u2206t2\n\u0013\nkv\nUuj(t)U\u2217\nvl(t)\n#\n=\nDX\nu,v=1\nE\n\u0014\n(\u03b4iu \u2212 iEi\u03b4iu\u2206t \u2212 i\u03b7iu(t)\u2206t) (\u03b4kv + iEk\u03b4kv\u2206t + i\u03b7\u2217\nkv(t)\u2206t)\n\u0015\nE[Uuj(t)U\u2217\nvl(t)]\n=\nDX\nu,v=1\n\u0014\n\u03b4iu\u03b4kv \u2212 iEi\u03b4iu\u03b4kv\u2206t + iEk\u03b4iu\u03b4kv\u2206t \u2212 1\n2\nX\ns\n\u03bbis\u03b4iu\u03b4kv\u2206t \u2212 1\n2\nX\ns\n\u03bbks\u03b4iu\u03b4kv\u2206t + \u03bbik\u03b4ik\u03b4uv\u2206t\n\u0015\n\u00d7 E[Uuj(t)U\u2217\nvl(t)]\nwhere I is the identity matrix. We have utilized the\nfact that white noise has no time correlation, such that\nE(A(t)B(t\u2032)) = E(A(t))E(B(t\u2032)) for t \u0338= t\u2032. By comparing\nthe result with the differential equation given in Eq. (15)\nand recognizing L1, we obtain\nL1;ij;i\u2032j\u2032 = wij\u03b4ii\u2032\u03b4jj\u2032 + \u03bbii\u2032\u03b4ij\u03b4i\u2032j\u2032 . (18) Here wij \u2261 \u2212iEi + iEj \u2212 1\n2\nPD\nk=1 (\u03bbik + \u03bbjk). For sim-\nplicity we use the graph representation\nL1;ij;i\u2032j\u2032 = wij\ni\ni\u2032\nj\nj\u2032 + \u03bbii\u2032\ni\nj\ni\u2032\nj\u2032 (19)\nwhere each line with two indices i, jat the endpoints\nof the graph represents a \u201cpropagator\u201d i.e, \u03b4ij. Simi-\nlarly, one can derive expressions for other operators Lk\nwith k \u2265 1. One may regard Lk as the effective time-\nindependent Hamiltonian of an auxiliary system, while\nUk represents the imaginary time evolution. In principle,\nto obtain the dynamics, one needs to diagonalize Lk.\n\n2503.01279v2\nNext, we consider taking discrete time slices tn = n\u2206t,\nwhere \u2206t = t\nN and n = 0, 1, 2, . . . , N\u2212 1. At each time\nstep, we have a random noise term \u03b7ij(n\u2206t). For two\ntimes t1 = n1\u2206t and t2 = n2\u2206t, we choose to regularize\nthe delta function as follows:\n\u03b4(t1 \u2212 t2) = \u03b4(n1\u2206t \u2212 n2\u2206t) = \u03b4n1n2\n1\n\u2206t . (12)\nSo that Eq.(10) becomes\nE(\u03b7ij(n\u2206t)\u03b7kl(m\u2206t)) = 1\n\u2206t\u03bbij\u03b4il\u03b4jk\u03b4nm . (13)\n\n3\nOne can treat Uk as a D2k-dimensional matrix gener-\nated by the operator Lk, with the row and column in-\ndices labeled explicitly as I = {i1, i2, i3, . . . , i2k} and\nJ = {j1, j2, j3, . . . , j2k}\n[Uk]IJ = Ui1j1 U\u2217\ni2,j2 \u00b7\u00b7\u00b7 Ui2k\u22121j2k\u22121 U\u2217\ni2k,j2k (14)\nwhere we take the order of {i} and {j} on the right-hand\nside for convenience. Then, the equation of motion of Uk\nis simply\n\u2202tUk(t) = Lk.Uk(t) . (15)\nTo illustrate the calculation, we first consider the sim-\nplest case of k = 1:\nU1(t) := E[U(t) \u2297 U\u2217(t)] , U1;ij;i\u2032j\u2032 = [exp (L1t)]ij;i\u2032j\u2032 .\n(16)\nOne can obtain the expression for L1 through direct cal-\nculation. From the definition, we have\nUij(t + \u2206t)U\u2217\nkl(t + \u2206t)\n=\nDX\nu,v=1\n\u0010\ne\u2212iH(t)\u2206t\n\u0011\niu\n\u0010\neiH\u2217(t)\u2206t\n\u0011\nkv\nUuj(t)U\u2217\nvl(t) . (17)\nNext, we employ the Taylor series expansion and take the\nnoise ensemble average on both sides, retaining terms up\nto linear order in \u2206 t. Thus, we obtain\nE[Uij(t + \u2206t)U\u2217\nkl(t + \u2206t)]\n= E\n\" DX\nu,v=1\n\u0010\ne\u2212iH(t)\u2206t\n\u0011\niu\n\u0010\neiH\u2217(t)\u2206t\n\u0011\nkv\nUuj(t)U\u2217\nvl(t)\n#\n= E\n\" DX\nu,v=1\n\u0012\nI \u2212 iH(t)\u2206t \u2212 1\n2H2(t)\u2206t2\n\u0013\niu\n\u0012\nI + iH\u2217(t)\u2206t \u2212 1\n2H\u22172(t)\u2206t2\n\u0013\nkv\nUuj(t)U\u2217\nvl(t)\n#\n=\nDX\nu,v=1\nE\n\u0014\n(\u03b4iu \u2212 iEi\u03b4iu\u2206t \u2212 i\u03b7iu(t)\u2206t) (\u03b4kv + iEk\u03b4kv\u2206t + i\u03b7\u2217\nkv(t)\u2206t)\n\u0015\nE[Uuj(t)U\u2217\nvl(t)]\n=\nDX\nu,v=1\n\u0014\n\u03b4iu\u03b4kv \u2212 iEi\u03b4iu\u03b4kv\u2206t + iEk\u03b4iu\u03b4kv\u2206t \u2212 1\n2\nX\ns\n\u03bbis\u03b4iu\u03b4kv\u2206t \u2212 1\n2\nX\ns\n\u03bbks\u03b4iu\u03b4kv\u2206t + \u03bbik\u03b4ik\u03b4uv\u2206t\n\u0015\n\u00d7 E[Uuj(t)U\u2217\nvl(t)]\nwhere I is the identity matrix. We have utilized the\nfact that white noise has no time correlation, such that\nE(A(t)B(t\u2032)) = E(A(t))E(B(t\u2032)) for t \u0338= t\u2032. By comparing\nthe result with the differential equation given in Eq. (15)\nand recognizing L1, we obtain\nL1;ij;i\u2032j\u2032 = wij\u03b4ii\u2032\u03b4jj\u2032 + \u03bbii\u2032\u03b4ij\u03b4i\u2032j\u2032 . (18) Here wij \u2261 \u2212iEi + iEj \u2212 1\n2\nPD\nk=1 (\u03bbik + \u03bbjk). For sim-\nplicity we use the graph representation\nL1;ij;i\u2032j\u2032 = wij\ni\ni\u2032\nj\nj\u2032 + \u03bbii\u2032\ni\nj\ni\u2032\nj\u2032 (19)\nwhere each line with two indices i, jat the endpoints\nof the graph represents a \u201cpropagator\u201d i.e, \u03b4ij. Simi-\nlarly, one can derive expressions for other operators Lk\nwith k \u2265 1. One may regard Lk as the effective time-\nindependent Hamiltonian of an auxiliary system, while\nUk represents the imaginary time evolution. In principle,\nto obtain the dynamics, one needs to diagonalize Lk.\n\n\uf020\nThe scale factor \na  \ncontrols the dilation of the wavelet function \n\uf079 , and the \ntranslation factor \nb  controls the translation of the wavelet \nfunction \n\uf079 . The DWT discretizes both \na  and \nb . In binary \ndiscretization, the values of \na  and \nb  are simplified to powers \nof 2. The discrete wavelet function at this point is as follows: \n \n( ) ( )\n2\n, 22\nj\nj\njk t t k\uf079\uf079\n\u2212 \u2212\n=\u2212  (2) \nwhere \n,j k Z\uf022\uf0ce . The complete formula for the DWT of an input signal \n( )xt\n is as follows: \n \n( ) ( ) ( )\n2, 2 2\nj\nj\nDWT j k x t t k dt\uf079 \uf079\n+\uf0a5\n\u2212\uf0a5\n=\u2212 \uf0f2  (3) \nThis paper uses the Mallat algorithm  (4)(5) to achieve \nmultilevel decomposition with the DWT. ( ) ( ) ( )\n( ) ( )\n1 *\n           2\njj\njk\nA n H n A n\nH k A n k\n+ =\n=\u2212\uf0e5  (4) \n \n( ) ( ) ( )\n( ) ( )\n1 *\n            2\njj\njk\nD n G n A n\nG k A n k\n+ =\n=\u2212\uf0e5  (5) \nwhere \nH  is a low-pass filter, \nG  is a high-pass filter, \n1jA +  \nrepresents the approximation component of the \n1j + -th \ndecomposition level, and \n1jD +  represents the detail component \nof the \n1j + -th decomposition level. The reconstruction formula that uses the Mallat algorithm \nto reconstruct discrete sequences back into their original forms \nis as follows: \n( ) ( ) ( ) ( ) ( )\n( ) ( )\n( ) ( )\n11\n1\n1\n**\n         2\n            2\nj j j\njk\njk\nA n h n A n g n D n\nh n k A k\ng n k D k\n++\n+\n+\n=+\n=\u2212\n+\u2212\n\uf0e5\n\uf0e5\n (6) \nwhere \n( )hn  and \n( )gn  represent the tap coefficient \nsequences of the low -pass and high -pass filters, respectively, \ncorresponding to the selected wavelet function. The block diagram of the Mallat algorithm is shown in \nFigure 2 , where \u210e represents low -pass filtering, \ud835\udc54 represents \nhigh-pass filtering, and \n2\uf0af  indicates downsampling by a \nfactor of 2. The two complementary low -pass and high -pass \nfilters can separate the low -frequency and high -frequency \ncomponents of the input time series, obtaining an \napproximation component \ud835\udc34 and a detail component \ud835\udc37 after \ndownsampling by a factor of 2. This strategy retains all the \ninformation acquired from the original time series without \nincreasing the data volume. Duri ng reconstruction, the \napproximation and detail components are recombined via the \ntap coefficients to restore the original signal. g\nh\n 2 \n 2 \nG1 D1\nH1 A1\nx g\nh\n 2 \n 2 \nG2 D2\nH2 A2\nh  2 H3 A3\n\u00b7 \u00b7 \u00b7  \ng  2 G3 D3\n \nFig. 2. Block Diagram of the Mallat Algorithm \nOn the basis of the above analysis, this paper adopts the \nfirst-order DWT for trend and seasonal decomposition in the \ndesigned model framework (as shown in Figure 1).", "metadata": {"type": "reasoning", "source": "2503.01279v2.pdf", "context": "effective time evolution on 2 k-contours:\nUk \u2261 E[U\u2297k\nt \u2297 U\u2217\u2297k\nt ] \u2261 eLkt . (11)\nNext, we consider taking discrete time slices tn = n\u2206t,\nwhere \u2206t = t\nN and n = 0, 1, 2, . . . , N\u2212 1. At each time\nstep, we have a random noise term \u03b7ij(n\u2206t). For two\ntimes t1 = n1\u2206t and t2 = n2\u2206t, we choose to regularize\nthe delta function as follows:\n\u03b4(t1 \u2212 t2) = \u03b4(n1\u2206t \u2212 n2\u2206t) = \u03b4n1n2\n1\n\u2206t . (12)\nSo that Eq.(10) becomes\nE(\u03b7ij(n\u2206t)\u03b7kl(m\u2206t)) = 1\n\u2206t\u03bbij\u03b4il\u03b4jk\u03b4nm . (13)", "quality_score": 8}}
{"id": "test_71", "question": "How does the time tAB required to reach a given MSD of g change as pB approaches zero?", "golden_answers": ["The time increases by a factor 1 /pA relative to the time tA"], "prediction": "As pB approaches zero, the time tAB required to reach a given MSD of g increases by a factor of 1/pA relative to the time tA required with the pure A dynamics.", "f1": 0.4444444444444444, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01446v1\nBut while it reduces to\nEq. (11) for simple diffusion, it fails for bounded MSD like\nthose of the monomers relative to the ring CM, where af-\nter a suitably delayed time any of our dynamic processes\nwould be predicted to independently contribute an MSD\nof limt\u2192\u221e g2(t) = 2\u27e8R2\ng\u27e9.\nTo arrive at an alternative formulation, we note that\nfor our definition of the relaxation time, \u03c4X = \u27e8R2\ng\u27e9/DX,\nthe null model suggests\n1\n\u03c4AB\n= pA\n\u03c4A\n+ pB\n\u03c4B\n. (A3)\nNow consider\n1\ntAB(g) = pA\ntA(g) + pB\ntB(g) , (A4)\nwhere tX(g) = g\u22121\nX (t) denotes the inverse function of\ngX(t), i.e. the time t required with dynamics X to reach\nan MSD of g. tAB(g) defined by Eq. (A4) and its in-\nverse function gAB(t) are well-behaved in a number of\nlimiting cases. For simple diffusion, gX(t) \u223c DXt so\nthat tX(g) \u223c g/DX, Eq. (A4) reduces to Eq. (11). By\nconstruction, limpB\u21920 tAB(g) = tA(g)/pA: as accepting\nonly a fraction pA of the A moves has the effect to re-\nduce the effectively elapsed time by a corresponding fac-\ntor, the time tAB required to reach a given MSD of g\nincreases by a factor 1 /pA relative to the time tA re-\nquired with the pure A dynamics. In particular, we thus\nfind for the inverse function lim pB\u21920 gAB(t) = gA(pAt)\nas required. Plausibly, if both processes reach g equally\nfast, tA(g) = tB(g), then Eq. (A4) suggests that the time\nrequired by the mixed process\ntAB(g) = tA(g) tB(g)\npAtB(g) + pBtA(g) (A5)\nreduces to tAB(g) = tA(g) = tB(g) for arbitrary pA +\npB = 1. In contrast, if one of the processes reaches g\nmuch faster than the other, tA(g) \u226a tB(g), then over\na wide range of pA-values tAB(g) \u2248 tA(g) pA\nis essentially\ngiven by the time required by the faster process divided\nby the probability to activate the corresponding moves\nin the combined dynamics. Note that this relation holds\nin particular, when the second process by itself never\nreaches g (i.e. when tB(g) = \u221e) and that accord-\ning to Eq. (A4) the mixed process cannot reach MSD,\nwhich none of the pure processes can reach individually\n(tAB(g) = \u221e, if tA(g) = tB(g) = \u221e). Appendix B: Comparison of the null model to\nsimulation data for double-folded rings\nConveniently Eq. (A4) is almost trivial to implement\nfrom a practical point of view, since it is straightforward\n(i) to generate numerically evaluable functions t(g) and\n\n14\n101 103 105 107 109\nt [Ms]\n10\u22124\n10\u22121\n102\n105\ng1(t)\nNm =1000\n(a) null model\npm =0.0\npm =0.5\npm =0.75\npm =0.95\npm = 1.0\n101 103 105 107 109\nt\n\n2503.00099v1\nIn\nsummary, by adding an infinite \u201csheet of mass\u201d with constant\nuniform surface density, one can find the exact same image po-\nsitions given a different source position, size, and luminosity,\ncompletely changing the physical geometry of the system and\nits associated Fermat potential. While the time-delay (\u2206ti j) is an observable, the relative Fer-\nmat potential ( \u2206\u03c4i j) is not. Instead, the Fermat potential is in-\nferred from constraints on two particular features in the imaging\ndata: the quasar image positions and the extended distortions in\nthe lensed arcs. Consequently, the MSD allows degeneracy in\nour observed image positions to seep into our Fermat potential,\nthereby imposing limits on its precision and, via Eq. (9) , on H0\n(e.g., Falco et al. 1985; Kochanek 2002; Saha & Williams 2006;\nSchneider & Sluse 2013, 2014; Birrer et al. 2016; Unruh et al. 2017; Birrer 2021). As the MSD is inherent in the lens model (Saha 2000; Saha\n& Williams 2006), we first note that the MSD is a mathematical\ndegeneracy as opposed to a physical degeneracy. More formally,\nthe MSD is a multiplicative transform of the lens equation that\nyields the same image positions despite a linear source displace-\nment and transformation of the convergence field, \u03ba. In fewer\nwords, but more Greek, we first displace the source by some\nscalar \u03bb:\n\u03b2 \u2192\u03bb\u03b2, (11)\nand transform the convergence field through:\n\u03ba(\u03b8) \u2192\u03bb\u03ba(\u03b8) + (1 \u2212\u03bb). (12)\nThen, solving the lens equation with these quantities, we will\nfind the image positions at:\n\u03b8 \u2192\u03b8. (13)\nIn other words, our direct observable in the imaging data\u2014the\nimage positions\u2014would look the same despite moving the\nsource and changing the convergence field. This is problematic,\nas the linear source displacement in Eq. (11) would yield a mea-\nsurement of:\nH0 \u2192\u03bbH0. (14)\nThis is currently the leading source of uncertainty in time-delay\nmeasurements of H0 today, and it is broken with the non-lensing\nconstraints on the mass distribution, namely stellar velocity dis-\npersion Birrer et al. (2020); Shajib et al. (2023), or by constraints\non the absolute luminosity of the source when it is known. As\ndiscussed in the introduction, this paper is concerned with in-\nformation coming from the lens model itself, and therefore we\ncan neglect the mass sheet transformation, keeping in mind that\nit needs to be considered when converting the inference from\nFermat potential to H0. 2.2.2 Multiplane lensing\nIn addition, the observed time-delays will depend on any galaxy\n(or massive object) having a significant impact on the deflec-\ntion of our source\u2019s light, and these need not be at the same red-\nshift as our lens. In this generalized case, we must combine the\nangular diameter distances of the di fferent lens planes, which\nis done with the multi-plane lens equation (e.g., Blandford &\nNarayan 1986; Kovner 1987; Schneider et al. 1992; Collett &\nAuger 2014; McCully et al. 2014). In our previous assumption,\nour time-delays were proportional to a single, unique time-delay\ndistance. Under the multi-plane lens equation, this is no longer\ntrue.\n\n2503.00157v1\nOn the right,\nthe previous curve for \u03c3 = 0.1 is superimposed with the modified function\n\u02dcf(m) = f(r(m)) =\nZ\nR\nx\u02dc\u03bdm(x)dx ,where \u02dc\u03bdm(x) \u221d exp\n\u0012\n\u2212 1\n\u03c32\n\u0014\nV (x) + 1\n2|x \u2212 m|2 + xh\u2032(m)\n\u0015\u0013\n,\n30\n\nFigure 2 \u2013 Fast convergence to stationary solutions, for \u03c3 = 0 .5 and N = 10 4 particles\ninitialized independently with N(m0, 1/4) with m0 = 1 (in blue) or m0 = \u22121 (in orange). (Left) At time T = 10, histogram of the particles superimposed with the graph of \u00b5\u2212 and \u00b5+. (Right). Trajectory t 7\u2192 \u00afXt up to time T = 1000. Figure 3 \u2013 Same as Figure 2 except N = 105. Figure 4 \u2013 Same as Figure 2 except N = 103, T = 103 and \u03c3 = 0.8 > \u03c3c. 31\n\nFigure 5 \u2013 A metastable transition. Same initial conditions as in Figure 2, but \u03c3 = 0.64 and\nN = 103. (Top) Trajectory t 7\u2192 \u00afXt up to time T = 104. (Bottom) Histogram of the particles\nsuperimposed with the graph of \u00b5\u2212 and \u00b5+, (Left) at time T = 5000 before the transition and\n(Right) at time T = 104 after the transition. 32\n\nFigure 6 \u2013 The initial fixed-point problem and its modification. (Left) The function f at three\ndifferent temperatures: above, at and below criticality. (Right) The function f below the\ncritical temperature and its modification with a non-zero h. still with \u03c3 = 0.1, where r and h are in the spirit of the functions designed in Section 6.1. As a consequence, the fixed-points of \u02dcf are in one-to-one correspondence with the stationary\nsolutions of the modified process (12) with drift (19). We see that \u02dcf is precisely designed to\ncoincide with f as long as possible while ensuring that it has a unique fixed point. This is an\nindication that the modified process is not metastable (as fully proven by applying Theorem 4,\nwith the explicit h designed in Section 6). 8 Perspectives\nThere is a number of directions in which our approach and results could be extended\nor improved. We have already mentioned the questions of obtaining sharp estimates as in\n[33, 52] or of considering kinetic processes or numerical scheme as in Section 4.2. For this\nlatter variation, it would be useful to remove the condition that \u2207V grows faster than linearly\n(since we would rather assume that \u2225\u22072V \u2225\u221e < \u221e), which should not be too difficult (this\ncondition is convenient for the moment bounds estimates of Appendix B.1 or to get that\nlim sup|m|\u2192\u221e |f(m)|/|m| < 1 but it is not crucial). It would be also of interest to go beyond\nthe case of quadratic interaction, and even of pair interactions. For this purpose, it would be\nrelevant to simply Assumption 3. Ideally, we could hope to prove that Assumption 3 holds\nwhen a global non-linear LSI (37) holds for the mean-field problem.", "metadata": {"type": "reasoning", "source": "2503.01446v1.pdf", "context": "1\n\u03c4AB\n= pA\n\u03c4A\n+ pB\n\u03c4B\n. (A3)\nNow consider\n1\ntAB(g) = pA\ntA(g) + pB\ntB(g) , (A4)\nwhere tX(g) = g\u22121\nX (t) denotes the inverse function of\ngX(t), i.e. the time t required with dynamics X to reach\nan MSD of g. tAB(g) defined by Eq. (A4) and its in-\nverse function gAB(t) are well-behaved in a number of\nlimiting cases. For simple diffusion, gX(t) \u223c DXt so\nthat tX(g) \u223c g/DX, Eq. (A4) reduces to Eq. (11). By\nconstruction, limpB\u21920 tAB(g) = tA(g)/pA: as accepting\nonly a fraction pA of the A moves has the ", "quality_score": 8}}
{"id": "test_72", "question": "How does the expression for CBDW(r) differ from that of CCDW(r)?", "golden_answers": ["The expression for CBDW(r) contains additional terms with X \u03b1 h \u27e8c\u2020 i,\u03b1cj+1,\u03b1\u27e9\u27e8ci+1,\u03b1c\u2020 j,\u03b1\u27e9 and other similar terms."], "prediction": "The expression for CBDW(r) includes additional terms involving the differences of operators (Di,A - Di,B) and (Dj,A - Dj,B), while CCDW(r) involves the sums of operators (Zi,A + Zi,B) and (Zj,A + Zj,B). Additionally, the final form of CBDW(r) contains a more complex expression with multiple sine functions and factors, whereas CCDW(r) has a simpler form involving a single sine squared term.", "f1": 0.23529411764705882, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "good title\nSimilarly, we can obtain the connected correlation functions for the CDW and BDW channels as follows:\nCCDW(r) \u2261 (\u22121)i+j\u27e8(Zi,A + Zi,B)(Zj,A + Zj,B)\u27e9 \u2212(\u22121)i+j\u27e8(Zi,A + Zi,B)\u27e9\u27e8(Zj,A + Zj,B)\u27e9\n= ( \u22121)i+j\n\u00ee\n\u27e8c\u2020\ni,Acj,A\u27e9\u27e8ci,Ac\u2020\nj,A\u27e9 + \u27e8c\u2020\ni,Bcj,B\u27e9\u27e8ci,Bc\u2020\nj,B\u27e9\n\u00f3\n= ( \u22121)r+1 2 sin2(\u03c0r/2)\n(\u03c0r)2 , (S10)\nand\nCBDW(r) \u2261 (\u22121)i+j\u27e8(Di,A \u2212 Di,B)(Dj,A \u2212 Dj,B)\u27e9 \u2212(\u22121)i+j\u27e8(Di,A \u2212 Di,B)\u27e9\u27e8(Dj,A \u2212 Dj,B)\u27e9\n= ( \u22121)i+j X\n\u03b1\nh\n\u27e8c\u2020\ni,\u03b1cj+1,\u03b1\u27e9\u27e8ci+1,\u03b1c\u2020\nj,\u03b1\u27e9 + \u27e8c\u2020\ni,\u03b1cj,\u03b1\u27e9\u27e8ci+1,\u03b1c\u2020\nj+1,\u03b1\u27e9\n+ \u27e8c\u2020\ni+1,\u03b1cj+1,\u03b1\u27e9\u27e8ci,\u03b1c\u2020\nj,\u03b1\u27e9 + \u27e8c\u2020\ni+1,\u03b1cj,\u03b1\u27e9\u27e8ci,\u03b1c\u2020\nj+1,\u03b1\u27e9\ni\n= 4( \u22121)r+1\n\u00c7\nsin2(\u03c0r/2)\n(\u03c0r)2 + sin[\u03c0(r + 1)/2] sin[\u03c0(r \u2212 1)/2]\n\u03c02(r + 1)(r \u2212 1)\n\u00e5\n. (S11)\nB. Finite-bond and finite-size extrapolations of the correlation functions at the deconfined critical point\nAs shown in Fig. 2(b) in the main text, the bulk-bulk connected correlations are computed by infinite-size DMRG\nsimulations. Although the thermodynamic limit is approached in a natural way, the calculation of the correlation\nfunctions is still affected by the finite-bond effect (or the finite-entanglement effect). To this end, we first perform a\n\n12\n100 300 500\n\u00ac\n0.02\n0.03\n0.04\n0.05\n0.06\n0.07\nCCDW(r, \u00ac)\nCCDW(r = 15)\nCCDW(r = 25)\nCBDW(r = 15)\nCBDW(r = 25)\n128 192 256\nL\n3\u00a310\u00b05\n4\u00a310\u00b05\n5\u00a310\u00b05\n6\u00a310\u00b05\nCCDW(r, L)\nCCDW(r = 56)\nCCDW(r = 64)\nCBDW(r = 56)\nCBDW(r = 64)0.11\n0.12\n0.13\n0.14\n0.15\n0.16\n0.17\nCBDW(r, \u00ac)\n0.010\n0.011\n0.012\n0.013\nCBDW(r, L) <latexit sha1_base64=\"2RRwxLXlY8TROIoM98j2WcOjpro=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoMQL2FXgnoMevEY0TwgWcLspDcZMju7zMwKIeQTvHhQxKtf5M2/cZLsQRMLGoqqbrq7gkRwbVz328mtrW9sbuW3Czu7e/sHxcOjpo5TxbDBYhGrdkA1Ci6xYbgR2E4U0igQ2ApGtzO/9YRK81g+mnGCfkQHkoecUWOlhzI97xVLbsWdg6wSLyMlyFDvFb+6/ZilEUrDBNW647mJ8SdUGc4ETgvdVGNC2YgOsGOppBFqfzI/dUrOrNInYaxsSUPm6u+JCY20HkeB7YyoGeplbyb+53VSE177Ey6T1KBki0VhKoiJyexv0ucKmRFjSyhT3N5K2JAqyoxNp2BD8JZfXiXNi4p3WaneV0u1myyOPJzAKZTBgyuowR3UoQEMBvAMr/DmCOfFeXc+Fq05J5s5hj9wPn8Ai5mNUw==</latexit>\n( a )\n<latexit sha1_base64=\"KWh0RLJ0bw8em/x3PU2+HIlN2FQ=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoMQL2FXgnoMevEY0TwgWcLspDcZMju7zMwKIeQTvHhQxKtf5M2/cZLsQRMLGoqqbrq7gkRwbVz328mtrW9sbuW3Czu7e/sHxcOjpo5TxbDBYhGrdkA1Ci6xYbgR2E4U0igQ2ApGtzO/9YRK81g+mnGCfkQHkoecUWOlh3Jw3iuW3Io7B1klXkZKkKHeK351+zFLI5SGCap1x3MT40+oMpwJnBa6qcaEshEdYMdSSSPU/mR+6pScWaVPwljZkobM1d8TExppPY4C2xlRM9TL3kz8z+ukJrz2J1wmqUHJFovCVBATk9nfpM8VMiPGllCmuL2VsCFVlBmbTsGG4C2/vEqaFxXvslK9r5ZqN1kceTiBUyiDB1dQgzuoQwMYDOAZXuHNEc6L8+58LFpzTjZzDH/gfP4AjR6NVA==</latexit>\n( b )\nFIG. S4. (a) Each data point of the bulk-bulk correlation function for BDW and CDW orders shown in Fig.2(b) in the main\ntext is obtained by extrapolating to infinite MPS bond dimensions. The dotted and dashed lines are least-squares fittings with\nthe form C(r, \u03c7) = a(100/\u03c7)b + C(r, \u03c7\u2192 \u221e). (b) Each data of the boundary-bulk correlations displayed in Fig.2(c) in the\nmain text is obtained by extrapolating toL \u2192 \u221ewith the fitting form,C(r, L) = a/Lb + C(r, L\u2192 \u221e), whereL is the ladder\nlength. Numerical data are obtained from infinite-size DMRG calculations for (a) and finite-size DMRG calculations for (b)\nwith a sufficiently large bond dimension\u03c7 = 2048 to ensure the convergence of the results forL up to256.\n0 1 2 3 4 5\nk\n0\n1\n2\n3\n4\n5Ek(L)\u00b0E0(L) L= 16\nL= 32\nL= 48\nL= 64\nL= 80\nL= 96\n20 30 40 50 60 70 8090100\nL\n0.5\n0.6\n0.7\n0.8\n0.91.0\n2.0\ne(L) \u00a5E2(L)\u00b0E0(L)\ne(L)\u00aaaL\u00b0z\nz(L)= \u00b0d(lne(L))/d(lnL)\n0.00 0.01 0.02 0.03\n1/L\n0.950\n0.975\n1.000\nz(L)\n\ngood title\nfinite bond extrapolation for eachr of CCDW/BDW(r, \u03c7) to the limit\u03c7 \u2192 \u221eas shown in Fig. S4(a). The extrapolated\nresults CCDW/BDW(r, \u03c7\u2192 \u221e) are then fed into the scaling analysis shown in Fig. 2(b) in the main text. However, the boundary-bulk correlations are obtained from finite-size DMRG calculations. Having chosen a suffi-\nciently large MPS bond dimension, such as\u03c7 = 2048, we can expect the results to converge well with\u03c7. In contrast\nto the bulk-bulk correlations, the accuracy of the boundary-bulk correlations are mainly limited by the finite system\nsize. As shown in Fig. S4(b) , the finite-size effect is eliminated here by extrapolating to the thermodynamic limit using\nCCDW/BDW(r, L) with L up to256. Finally, the extrapolated resultsCCDW/BDW(r, L\u2192 \u221e) are used in Fig. 2(c) in\n\n13\n0.44\n0.41\n-0.31\n-0.34\n0.29\n0.26\n-0.23\n-0.26\n0.23\n0.20\n-0.18\n-0.21\n0.19\n0.14\n-0.16\n-0.17\n0.16\n0.09\n-0.14\n-0.13\n0.13\n0.04\n-0.14\n-0.09\n0.10\n-0.02\n-0.14\n-0.06\n0.09\n-0.05\n-0.14\n-0.04\n0.08\n-0.07\n-0.14\n-0.04\n0.09\n-0.05\n-0.14\n-0.06\n0.10\n-0.02\n-0.14\n-0.09\n0.13\n0.04\n-0.14\n-0.13\n0.16\n0.09\n-0.16\n-0.17\n0.19\n0.14\n-0.18\n-0.21\n0.23\n0.20\n-0.23\n-0.26\n0.29\n0.26\n-0.31\n-0.34\n0.44\n0.41\n0.35\n0.44\n0.52\n0.35\n0.34\n0.57\n0.60\n0.32\n0.30\n0.64\n0.66\n0.28\n0.27\n0.69\n0.70\n0.26\n0.26\n0.72\n0.71\n0.26\n0.28\n0.71\n0.69\n0.30\n0.34\n0.67\n0.63\n0.38\n0.43\n0.59\n0.54\n0.49\n0.54\n0.49\n0.43\n0.59\n0.63\n0.38\n0.34\n0.67\n0.69\n0.30\n0.28\n0.71\n0.71\n0.26\n0.26\n0.72\n0.70\n0.26\n0.27\n0.69\n0.66\n0.28\n0.30\n0.64\n0.60\n0.32\n0.34\n0.57\n0.52\n0.35\n0.35\n0.44\n0.00\n-0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n0.00\n0.41\n0.44\n-0.34\n-0.31\n0.26\n0.29\n-0.26\n-0.23\n0.20\n0.23\n-0.21\n-0.18\n0.14\n0.19\n-0.17\n-0.16\n0.09\n0.16\n-0.13\n-0.14\n0.04\n0.13\n-0.09\n-0.14\n-0.02\n0.10\n-0.06\n-0.14\n-0.05\n0.09\n-0.04\n-0.14\n-0.07\n0.08\n-0.04\n-0.14\n-0.05\n0.09\n-0.06\n-0.14\n-0.02\n0.10\n-0.09\n-0.14\n0.04\n0.13\n-0.13\n-0.14\n0.09\n0.16\n-0.17\n-0.16\n0.14\n0.19\n-0.21\n-0.18\n0.20\n0.23\n-0.26\n-0.23\n0.26\n0.29\n-0.34\n-0.31\n0.41\n0.44\n0.44\n0.35\n0.35\n0.52\n0.57\n0.34\n0.32\n0.60\n0.64\n0.30\n0.28\n0.66\n0.69\n0.27\n0.26\n0.70\n0.72\n0.26\n0.26\n0.71\n0.71\n0.28\n0.30\n0.69\n0.67\n0.34\n0.38\n0.63\n0.59\n0.43\n0.49\n0.54\n0.49\n0.54\n0.59\n0.43\n0.38\n0.63\n0.67\n0.34\n0.30\n0.69\n0.71\n0.28\n0.26\n0.71\n0.72\n0.26\n0.26\n0.70\n0.69\n0.27\n0.28\n0.66\n0.64\n0.30\n0.32\n0.60\n0.57\n0.34\n0.35\n0.52\n0.44\n0.35\n-0.00\n0.00\n-0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n<latexit sha1_base64=\"nslKz2SyATc1OXvZmjuedvLA/7c=\">AAACE3icbVA9TxtBEN0DkhiTDwdKmhVWJJPCuoushNKChtJIGCz5HGtub2yv2Nu77M6hWMf9B5r8lTQUIERLQ8e/Yf1REMiTRnp6b0Yz86JMSUu+/+itrK69efuusl7deP/h46fa580Tm+ZGYFekKjW9CCwqqbFLkhT2MoOQRApPo7ODmX96jsbKVB/TNMNBAmMtR1IAOWlY+9qAYJeHv3KIi5Jf8DCzclj45c8iJPxNRVyWPDSgxwqHtbrf9Ofgr0mwJHW2RGdYewjjVOQJahIKrO0HfkaDAgxJobCshrnFDMQZjLHvqIYE7aCY/1TyL06J+Sg1rjTxufp8ooDE2mkSuc4EaGJfejPxf14/p9HeoJA6ywm1WCwa5YpTymcB8VgaFKSmjoAw0t3KxQQMCHIxVl0IwcuXX5OTb83ge7N11Kq395dxVNg222ENFrAfrM0OWYd1mWCX7C+7ZjfeH+/Ku/XuFq0r3nJmi/0D7/4JmwieDQ==</latexit>\n( a 1) |  d\n0 i\n<latexit sha1_base64=\"xK/Hgv+M0nP5CVeMcrsE3j2hnE4=\">AAACE3icbVA9TxtBEN2D8BHz5UCZZoWFBBTWHUKBEkGT0kjxh+Qz1tze2KzY27vszqFYx/0HGv4KTQqiiDZNuvwb1h9FwDxppKf3ZjQzL8qUtOT7/7yFxQ9LyyurHytr6xubW9VP2y2b5kZgU6QqNZ0ILCqpsUmSFHYyg5BECtvRzcXYb9+isTLV32iUYS+BoZYDKYCc1K8e7sPRAQ+/5xAXJb/jYWZlvwjKqyIk/EFFXJY8NKCHCvvVml/3J+DzJJiRGpuh0a/+DeNU5AlqEgqs7QZ+Rr0CDEmhsKyEucUMxA0MseuohgRtr5j8VPI9p8R8kBpXmvhE/X+igMTaURK5zgTo2r71xuJ7XjenwWmvkDrLCbWYLhrkilPKxwHxWBoUpEaOgDDS3crFNRgQ5GKsuBCCty/Pk9ZRPfhSP748rp2dz+JYZZ/ZLttnATthZ+wra7AmE+yePbIn9st78H56v73naeuCN5vZYa/g/XkBnkueDw==</latexit>\n( a 2) |  d\n1 i\n<latexit sha1_base64=\"qbzpsuEokG0govxlDprVv2VJ8R4=\">AAACBnicbVBNS8NAEN34WetX1KMIi0XwVBIp6rHoxWMFq0JTw2YzrYubTdidiCXm5MW/4sWDIl79Dd78N25rD349GHi8N8PMvCiTwqDnfTgTk1PTM7OVuer8wuLSsruyemrSXHNo81Sm+jxiBqRQ0EaBEs4zDSyJJJxFV4dD/+watBGpOsFBBt2E9ZXoCc7QSqG7cUuDzIiw8MqLIkC4wSIuSxpopvoSQrfm1b0R6F/ij0mNjNEK3fcgTnmegEIumTEd38uwWzCNgksoq0FuIGP8ivWhY6liCZhuMXqjpFtWiWkv1bYU0pH6faJgiTGDJLKdCcNL89sbiv95nRx7+91CqCxHUPxrUS+XFFM6zITGQgNHObCEcS3srZRfMs042uSqNgT/98t/yelO3d+tN44btebBOI4KWSebZJv4ZI80yRFpkTbh5I48kCfy7Nw7j86L8/rVOuGMZ9bIDzhvn+SImWk=</latexit>\n|  d\n0 i\n<latexit sha1_base64=\"wdSdFFF0U84YsspLv8GvvrFvJ/A=\">AAACBnicbVBNS8NAEN34WetX1KMIi0XwVBIp6rHoxWMFq0JTw2YzrYubTdidiCXm5MW/4sWDIl79Dd78N25rD349GHi8N8PMvCiTwqDnfTgTk1PTM7OVuer8wuLSsruyemrSXHNo81Sm+jxiBqRQ0EaBEs4zDSyJJJxFV4dD/+watBGpOsFBBt2E9ZXoCc7QSqG7cUuDzIiw8MuLIkC4wSIuSxpopvoSQrfm1b0R6F/ij0mNjNEK3fcgTnmegEIumTEd38uwWzCNgksoq0FuIGP8ivWhY6liCZhuMXqjpFtWiWkv1bYU0pH6faJgiTGDJLKdCcNL89sbiv95nRx7+91CqCxHUPxrUS+XFFM6zITGQgNHObCEcS3srZRfMs042uSqNgT/98t/yelO3d+tN44btebBOI4KWSebZJv4ZI80yRFpkTbh5I48kCfy7Nw7j86L8/rVOuGMZ9bIDzhvn+YgmWo=</latexit>\n|  d\n1 i\n<latexit sha1_base64=\"VrdkJi09t8gm0wuCYM5oilERs9c=\">AAAB/nicbVDLSgNBEJyNrxhfq+LJy2AQPIVdCeoxxIvHiOYByRJmJ51kyOyDmV4xLAF/xYsHRbz6Hd78GyfJHjSxoKGo6p7pLj+WQqPjfFu5ldW19Y38ZmFre2d3z94/aOgoURzqPJKRavlMgxQh1FGghFasgAW+hKY/up76zQdQWkThPY5j8AI2CEVfcIZG6tpHHYRHTO8SX8eMA60yLfSkaxedkjMDXSZuRookQ61rf3V6EU8CCJFLpnXbdWL0UqZQcAmTQifRYN4fsQG0DQ1ZANpLZ+tP6KlRerQfKVMh0pn6eyJlgdbjwDedAcOhXvSm4n9eO8H+lZeKME4QQj7/qJ9IihGdZkF7QgFHOTaEcSXMrpQPmWIcTWIFE4K7ePIyaZyX3ItS+bZcrFSzOPLkmJyQM+KSS1IhN6RG6oSTlDyTV/JmPVkv1rv1MW/NWdnMIfkD6/MHmB2V5w==</latexit>\nSubspace Basis\n<latexit sha1_base64=\"komu+cSBmmmb6Pqy5yHyo0I49Tc=\">AAACInicbVDLSgMxFM3UV62vqks3wWJxVWak+FgIRTcuK9gHdIYhk962oZnMkGSkZei3uPFX3LhQ1JXgx5g+QG09kHByzr3k3hPEnClt259WZml5ZXUtu57b2Nza3snv7tVVlEgKNRrxSDYDooAzATXNNIdmLIGEAYdG0L8e+417kIpF4k4PY/BC0hWswyjRRvLzF24AXSbSOCRassEI27iIHey65iqahwui/WNeYlexbkj8dDDy8wW7ZE+AF4kzIwU0Q9XPv7vtiCYhCE05Uarl2LH2UiI1oxxGOTdREBPaJ11oGSpICMpLJyuO8JFR2rgTSXOExhP1d0dKQqWGYWAqzbA9Ne+Nxf+8VqI7517KRJxoEHT6USfhWEd4nBduMwlU86EhhEpmZsW0RySh2qSaMyE48ysvkvpJyTktlW/LhcrVLI4sOkCH6Bg56AxV0A2qohqi6AE9oRf0aj1az9ab9TEtzViznn30B9bXN1UHols=</latexit>\n\u2713\n01\n10\n\u25c6\n= \u0000 x\n<latexit sha1_base64=\"uXDSvYBMpdHihJTDvmUyGVHyeNc=\">AAACI3icbVDLSgMxFM34rPVVdekmWCxuLDNSVASh6MZlBfuAzjBk0ts2NJMZkoxYh/6LG3/FjQuluHHhv5g+QG09kHA4517uvSeIOVPatj+thcWl5ZXVzFp2fWNzazu3s1tTUSIpVGnEI9kIiALOBFQ10xwasQQSBhzqQe965NfvQSoWiTvdj8ELSUewNqNEG8nPXbgBdJhI45BoyR4G2MEFbGPXNV8BHzvYBdH6cS+xq1gnJH76OPBzebtoj4HniTMleTRFxc8N3VZEkxCEppwo1XTsWHspkZpRDoOsmyiICe2RDjQNFSQE5aXjGwf40Cgt3I6keULjsfq7IyWhUv0wMJVm2a6a9Ubif14z0e1zL2UiTjQIOhnUTjjWER4FhltMAtW8bwihkpldMe0SSag2sWZNCM7syfOkdlJ0Toul21K+fDWNI4P20QE6Qg46Q2V0gyqoiih6Qi/oDb1bz9arNbQ+JqUL1rRnD/2B9fUNz3eilA==</latexit>\n\u2713\n10\n0\n\ngood title\nfinite bond extrapolation for eachr of CCDW/BDW(r, \u03c7) to the limit\u03c7 \u2192 \u221eas shown in Fig. S4(a). The extrapolated\nresults CCDW/BDW(r, \u03c7\u2192 \u221e) are then fed into the scaling analysis shown in Fig. 2(b) in the main text. However, the boundary-bulk correlations are obtained from finite-size DMRG calculations. Having chosen a suffi-\nciently large MPS bond dimension, such as\u03c7 = 2048, we can expect the results to converge well with\u03c7. In contrast\nto the bulk-bulk correlations, the accuracy of the boundary-bulk correlations are mainly limited by the finite system\nsize. As shown in Fig. S4(b) , the finite-size effect is eliminated here by extrapolating to the thermodynamic limit using\nCCDW/BDW(r, L) with L up to256. Finally, the extrapolated resultsCCDW/BDW(r, L\u2192 \u221e) are used in Fig. 2(c) in\n\n13\n0.44\n0.41\n-0.31\n-0.34\n0.29\n0.26\n-0.23\n-0.26\n0.23\n0.20\n-0.18\n-0.21\n0.19\n0.14\n-0.16\n-0.17\n0.16\n0.09\n-0.14\n-0.13\n0.13\n0.04\n-0.14\n-0.09\n0.10\n-0.02\n-0.14\n-0.06\n0.09\n-0.05\n-0.14\n-0.04\n0.08\n-0.07\n-0.14\n-0.04\n0.09\n-0.05\n-0.14\n-0.06\n0.10\n-0.02\n-0.14\n-0.09\n0.13\n0.04\n-0.14\n-0.13\n0.16\n0.09\n-0.16\n-0.17\n0.19\n0.14\n-0.18\n-0.21\n0.23\n0.20\n-0.23\n-0.26\n0.29\n0.26\n-0.31\n-0.34\n0.44\n0.41\n0.35\n0.44\n0.52\n0.35\n0.34\n0.57\n0.60\n0.32\n0.30\n0.64\n0.66\n0.28\n0.27\n0.69\n0.70\n0.26\n0.26\n0.72\n0.71\n0.26\n0.28\n0.71\n0.69\n0.30\n0.34\n0.67\n0.63\n0.38\n0.43\n0.59\n0.54\n0.49\n0.54\n0.49\n0.43\n0.59\n0.63\n0.38\n0.34\n0.67\n0.69\n0.30\n0.28\n0.71\n0.71\n0.26\n0.26\n0.72\n0.70\n0.26\n0.27\n0.69\n0.66\n0.28\n0.30\n0.64\n0.60\n0.32\n0.34\n0.57\n0.52\n0.35\n0.35\n0.44\n0.00\n-0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n0.00\n0.41\n0.44\n-0.34\n-0.31\n0.26\n0.29\n-0.26\n-0.23\n0.20\n0.23\n-0.21\n-0.18\n0.14\n0.19\n-0.17\n-0.16\n0.09\n0.16\n-0.13\n-0.14\n0.04\n0.13\n-0.09\n-0.14\n-0.02\n0.10\n-0.06\n-0.14\n-0.05\n0.09\n-0.04\n-0.14\n-0.07\n0.08\n-0.04\n-0.14\n-0.05\n0.09\n-0.06\n-0.14\n-0.02\n0.10\n-0.09\n-0.14\n0.04\n0.13\n-0.13\n-0.14\n0.09\n0.16\n-0.17\n-0.16\n0.14\n0.19\n-0.21\n-0.18\n0.20\n0.23\n-0.26\n-0.23\n0.26\n0.29\n-0.34\n-0.31\n0.41\n0.44\n0.44\n0.35\n0.35\n0.52\n0.57\n0.34\n0.32\n0.60\n0.64\n0.30\n0.28\n0.66\n0.69\n0.27\n0.26\n0.70\n0.72\n0.26\n0.26\n0.71\n0.71\n0.28\n0.30\n0.69\n0.67\n0.34\n0.38\n0.63\n0.59\n0.43\n0.49\n0.54\n0.49\n0.54\n0.59\n0.43\n0.38\n0.63\n0.67\n0.34\n0.30\n0.69\n0.71\n0.28\n0.26\n0.71\n0.72\n0.26\n0.26\n0.70\n0.69\n0.27\n0.28\n0.66\n0.64\n0.30\n0.32\n0.60\n0.57\n0.34\n0.35\n0.52\n0.44\n0.35\n-0.00\n0.00\n-0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n<latexit sha1_base64=\"nslKz2SyATc1OXvZmjuedvLA/7c=\">AAACE3icbVA9TxtBEN0DkhiTDwdKmhVWJJPCuoushNKChtJIGCz5HGtub2yv2Nu77M6hWMf9B5r8lTQUIERLQ8e/Yf1REMiTRnp6b0Yz86JMSUu+/+itrK69efuusl7deP/h46fa580Tm+ZGYFekKjW9CCwqqbFLkhT2MoOQRApPo7ODmX96jsbKVB/TNMNBAmMtR1IAOWlY+9qAYJeHv3KIi5Jf8DCzclj45c8iJPxNRVyWPDSgxwqHtbrf9Ofgr0mwJHW2RGdYewjjVOQJahIKrO0HfkaDAgxJobCshrnFDMQZjLHvqIYE7aCY/1TyL06J+Sg1rjTxufp8ooDE2mkSuc4EaGJfejPxf14/p9HeoJA6ywm1WCwa5YpTymcB8VgaFKSmjoAw0t3KxQQMCHIxVl0IwcuXX5OTb83ge7N11Kq395dxVNg222ENFrAfrM0OWYd1mWCX7C+7ZjfeH+/Ku/XuFq0r3nJmi/0D7/4JmwieDQ==</latexit>\n( a 1) |  d\n0 i\n<latexit sha1_base64=\"xK/Hgv+M0nP5CVeMcrsE3j2hnE4=\">AAACE3icbVA9TxtBEN2D8BHz5UCZZoWFBBTWHUKBEkGT0kjxh+Qz1tze2KzY27vszqFYx/0HGv4KTQqiiDZNuvwb1h9FwDxppKf3ZjQzL8qUtOT7/7yFxQ9LyyurHytr6xubW9VP2y2b5kZgU6QqNZ0ILCqpsUmSFHYyg5BECtvRzcXYb9+isTLV32iUYS+BoZYDKYCc1K8e7sPRAQ+/5xAXJb/jYWZlvwjKqyIk/EFFXJY8NKCHCvvVml/3J+DzJJiRGpuh0a/+DeNU5AlqEgqs7QZ+Rr0CDEmhsKyEucUMxA0MseuohgRtr5j8VPI9p8R8kBpXmvhE/X+igMTaURK5zgTo2r71xuJ7XjenwWmvkDrLCbWYLhrkilPKxwHxWBoUpEaOgDDS3crFNRgQ5GKsuBCCty/Pk9ZRPfhSP748rp2dz+JYZZ/ZLttnATthZ+wra7AmE+yePbIn9st78H56v73naeuCN5vZYa/g/XkBnkueDw==</latexit>\n( a 2) |  d\n1 i\n<latexit sha1_base64=\"qbzpsuEokG0govxlDprVv2VJ8R4=\">AAACBnicbVBNS8NAEN34WetX1KMIi0XwVBIp6rHoxWMFq0JTw2YzrYubTdidiCXm5MW/4sWDIl79Dd78N25rD349GHi8N8PMvCiTwqDnfTgTk1PTM7OVuer8wuLSsruyemrSXHNo81Sm+jxiBqRQ0EaBEs4zDSyJJJxFV4dD/+watBGpOsFBBt2E9ZXoCc7QSqG7cUuDzIiw8MqLIkC4wSIuSxpopvoSQrfm1b0R6F/ij0mNjNEK3fcgTnmegEIumTEd38uwWzCNgksoq0FuIGP8ivWhY6liCZhuMXqjpFtWiWkv1bYU0pH6faJgiTGDJLKdCcNL89sbiv95nRx7+91CqCxHUPxrUS+XFFM6zITGQgNHObCEcS3srZRfMs042uSqNgT/98t/yelO3d+tN44btebBOI4KWSebZJv4ZI80yRFpkTbh5I48kCfy7Nw7j86L8/rVOuGMZ9bIDzhvn+SImWk=</latexit>\n|  d\n0 i\n<latexit sha1_base64=\"wdSdFFF0U84YsspLv8GvvrFvJ/A=\">AAACBnicbVBNS8NAEN34WetX1KMIi0XwVBIp6rHoxWMFq0JTw2YzrYubTdidiCXm5MW/4sWDIl79Dd78N25rD349GHi8N8PMvCiTwqDnfTgTk1PTM7OVuer8wuLSsruyemrSXHNo81Sm+jxiBqRQ0EaBEs4zDSyJJJxFV4dD/+watBGpOsFBBt2E9ZXoCc7QSqG7cUuDzIiw8MuLIkC4wSIuSxpopvoSQrfm1b0R6F/ij0mNjNEK3fcgTnmegEIumTEd38uwWzCNgksoq0FuIGP8ivWhY6liCZhuMXqjpFtWiWkv1bYU0pH6faJgiTGDJLKdCcNL89sbiv95nRx7+91CqCxHUPxrUS+XFFM6zITGQgNHObCEcS3srZRfMs042uSqNgT/98t/yelO3d+tN44btebBOI4KWSebZJv4ZI80yRFpkTbh5I48kCfy7Nw7j86L8/rVOuGMZ9bIDzhvn+YgmWo=</latexit>\n|  d\n1 i\n<latexit sha1_base64=\"VrdkJi09t8gm0wuCYM5oilERs9c=\">AAAB/nicbVDLSgNBEJyNrxhfq+LJy2AQPIVdCeoxxIvHiOYByRJmJ51kyOyDmV4xLAF/xYsHRbz6Hd78GyfJHjSxoKGo6p7pLj+WQqPjfFu5ldW19Y38ZmFre2d3z94/aOgoURzqPJKRavlMgxQh1FGghFasgAW+hKY/up76zQdQWkThPY5j8AI2CEVfcIZG6tpHHYRHTO8SX8eMA60yLfSkaxedkjMDXSZuRookQ61rf3V6EU8CCJFLpnXbdWL0UqZQcAmTQifRYN4fsQG0DQ1ZANpLZ+tP6KlRerQfKVMh0pn6eyJlgdbjwDedAcOhXvSm4n9eO8H+lZeKME4QQj7/qJ9IihGdZkF7QgFHOTaEcSXMrpQPmWIcTWIFE4K7ePIyaZyX3ItS+bZcrFSzOPLkmJyQM+KSS1IhN6RG6oSTlDyTV/JmPVkv1rv1MW/NWdnMIfkD6/MHmB2V5w==</latexit>\nSubspace Basis\n<latexit sha1_base64=\"komu+cSBmmmb6Pqy5yHyo0I49Tc=\">AAACInicbVDLSgMxFM3UV62vqks3wWJxVWak+FgIRTcuK9gHdIYhk962oZnMkGSkZei3uPFX3LhQ1JXgx5g+QG09kHByzr3k3hPEnClt259WZml5ZXUtu57b2Nza3snv7tVVlEgKNRrxSDYDooAzATXNNIdmLIGEAYdG0L8e+417kIpF4k4PY/BC0hWswyjRRvLzF24AXSbSOCRassEI27iIHey65iqahwui/WNeYlexbkj8dDDy8wW7ZE+AF4kzIwU0Q9XPv7vtiCYhCE05Uarl2LH2UiI1oxxGOTdREBPaJ11oGSpICMpLJyuO8JFR2rgTSXOExhP1d0dKQqWGYWAqzbA9Ne+Nxf+8VqI7517KRJxoEHT6USfhWEd4nBduMwlU86EhhEpmZsW0RySh2qSaMyE48ysvkvpJyTktlW/LhcrVLI4sOkCH6Bg56AxV0A2qohqi6AE9oRf0aj1az9ab9TEtzViznn30B9bXN1UHols=</latexit>\n\u2713\n01\n10\n\u25c6\n= \u0000 x\n<latexit sha1_base64=\"uXDSvYBMpdHihJTDvmUyGVHyeNc=\">AAACI3icbVDLSgMxFM34rPVVdekmWCxuLDNSVASh6MZlBfuAzjBk0ts2NJMZkoxYh/6LG3/FjQuluHHhv5g+QG09kHA4517uvSeIOVPatj+thcWl5ZXVzFp2fWNzazu3s1tTUSIpVGnEI9kIiALOBFQ10xwasQQSBhzqQe965NfvQSoWiTvdj8ELSUewNqNEG8nPXbgBdJhI45BoyR4G2MEFbGPXNV8BHzvYBdH6cS+xq1gnJH76OPBzebtoj4HniTMleTRFxc8N3VZEkxCEppwo1XTsWHspkZpRDoOsmyiICe2RDjQNFSQE5aXjGwf40Cgt3I6keULjsfq7IyWhUv0wMJVm2a6a9Ubif14z0e1zL2UiTjQIOhnUTjjWER4FhltMAtW8bwihkpldMe0SSag2sWZNCM7syfOkdlJ0Toul21K+fDWNI4P20QE6Qg46Q2V0gyqoiih6Qi/oDb1bz9arNbQ+JqUL1rRnD/2B9fUNz3eilA==</latexit>\n\u2713\n10\n0", "metadata": {"type": "reasoning", "source": "2503.01198v1.pdf", "context": "CCDW(r) \u2261 (\u22121)i+j\u27e8(Zi,A + Zi,B)(Zj,A + Zj,B)\u27e9 \u2212(\u22121)i+j\u27e8(Zi,A + Zi,B)\u27e9\u27e8(Zj,A + Zj,B)\u27e9\n= ( \u22121)i+j\n\u00ee\n\u27e8c\u2020\ni,Acj,A\u27e9\u27e8ci,Ac\u2020\nj,A\u27e9 + \u27e8c\u2020\ni,Bcj,B\u27e9\u27e8ci,Bc\u2020\nj,B\u27e9\n\u00f3\n= ( \u22121)r+1 2 sin2(\u03c0r/2)\n(\u03c0r)2 , (S10)\nand\nCBDW(r) \u2261 (\u22121)i+j\u27e8(Di,A \u2212 Di,B)(Dj,A \u2212 Dj,B)\u27e9 \u2212(\u22121)i+j\u27e8(Di,A \u2212 Di,B)\u27e9\u27e8(Dj,A \u2212 Dj,B)\u27e9\n= ( \u22121)i+j X\n\u03b1\nh\n\u27e8c\u2020\ni,\u03b1cj+1,\u03b1\u27e9\u27e8ci+1,\u03b1c\u2020\nj,\u03b1\u27e9 + \u27e8c\u2020\ni,\u03b1cj,\u03b1\u27e9\u27e8ci+1,\u03b1c\u2020\nj+1,\u03b1\u27e9\n+ \u27e8c\u2020\ni+1,\u03b1cj+1,\u03b1\u27e9\u27e8ci,\u03b1c\u2020\nj,\u03b1\u27e9 + \u27e8c\u2020\ni+1,\u03b1cj,\u03b1\u27e9\u27e8ci,\u03b1c\u2020\nj+1,\u03b1\u27e9\ni\n= 4( \u22121)r+1\n\u00c7\nsin2(\u03c0r/2)\n(\u03c0r)2 + sin[\u03c0(r + 1)/2] sin[\u03c0(r \u2212 1)/2]\n\u03c02(r + 1)(r \u2212 1", "quality_score": 8}}
{"id": "test_73", "question": "What is a key advantage of using DiT and multi-layout-aware diffusion framework for retinal fundus image synthesis?", "golden_answers": ["It captures long-range dependencies, which enhances performance."], "prediction": "A key advantage is the ability to generate diverse yet anatomically accurate retinal images while preserving essential vascular layouts, which enhances segmentation model robustness across diverse imaging conditions.", "f1": 0.12121212121212123, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01190v2\nCondition embeddings for A V , CD, and L are summed\ninto a single embedding, c. The DiT input consists of a beginning-of-conditioning (BOC) token, user input (UI), c, an end-of-conditioning\n(EOC) token, and the noised image latent. The DiT outputs the corresponding denoised image latent. The UI token specifies whether a\nlayout component is guided by user input or defaults to a neutral embedding when absent.\nartery/vein (A V) segmentation, which also differentiates ar-\nteries from veins. This distinction provides insights into\nvessel-specific pathologies[13, 57]. However, A V segmen-\ntation requires complex annotations, making it challenging\nto obtain sufficient labeled data for robust training. Generative models like GANs and V AEs have been ex-\nplored to address data scarcity in medical imaging [21,\n39]. When applied to retinal images, these models often\nencounter challenges, including difficulties in preserving\nanatomical fidelity and issues with training stability [20].\nDiffusion models have recently emerged as powerful tools\nfor generating diverse high-fidelity images, with superior\nstability and detail preservation, compared to GANs and\nV AEs [8, 27]. Despite their success in image synthesis tasks\nacross domains, e.g., natural image generation and text-to-\nimage modeling, their application in medical imaging has\nlargely focused on generating synthetic images rather than\ndirectly enhancing segmentation performance through data\naugmentation. To address these limitations, we propose Retinal Layout-\nAware Diffusion(RLAD), a diffusion-based framework for\nthe controllable generation of synthetic retinal images (Fig-\nure 1). By conditioning on multiple key retinal struc-\ntures\u2014such as artery/vein (A V), the optic cup/disc (CD),\nand lesions (L)\u2014RLAD preserves essential vascular lay-\nouts while introducing variability in other regions. This en-\nables the creation of paired image-segmentation maps that\nexpand training datasets without compromising structural\nintegrity. Synthetic data generated by RLAD improve seg-\nmentation model robustness across diverse imaging condi-\ntions and acquisition settings. We evaluated RLAD-generated data using state-of-the-\nart visual encoders such as Vision Transformers [9] and\nSwin Transformers [48], and demonstrate consistent im-\nprovements in generalization performance under distri-\nbution shifts (up to 8.1%). Additionally, we introduce\nREYIA, the largest multi-source collection of 586 retinal\nimages with human reference A V segmentation, which not\nonly complements our synthetic data but also demonstrates\nstrong baseline performance, further validating the effec-\ntiveness of our synthetic data. In summary, the main contributions of this work are:\n\u2022 A novel multi-layout-aware generative model ( RLAD)\nthat synthesizes diverse yet anatomically accurate retinal\nimages while preserving semantic structures. \u2022 Demonstrating consistent segmentation performance im-\nprovements across state-of-the-art architectures using\nRLAD-generated data.\n\u2022 Introducing REYIA, the largest multi-source collection\nof datasets for A V-segmented retinal fundus images. 2. Related Work\nRetinal A V segmentation plays a critical role in diagnos-\ning microvascular pathologies [22, 37, 65, 67, 75]. Early\nmethods [24, 31, 68, 81, 82], such as Little W-Net [19], fo-\ncused on compact convolutional neural networks to reduce\ncomputational complexity. More recently, LUNet achieved\nstate-of-the-art performance on optic disc-centered images\nbut struggled to generalize to macula-centered images [16]. This underscores the primary challenge of achieving robust\ngeneralization across diverse retinal imaging conditions.\n\n2503.01190v1\nCondition embeddings for A V , CD, and L are summed\ninto a single embedding, c. The DiT input consists of a beginning-of-conditioning (BOC) token, user input (UI), c, an end-of-conditioning\n(EOC) token, and the noised image latent. The DiT outputs the corresponding denoised image latent. The UI token specifies whether a\nlayout component is guided by user input or defaults to a neutral embedding when absent.\nartery/vein (A V) segmentation, which also differentiates ar-\nteries from veins. This distinction provides insights into\nvessel-specific pathologies[13, 57]. However, A V segmen-\ntation requires complex annotations, making it challenging\nto obtain sufficient labeled data for robust training. Generative models like GANs and V AEs have been ex-\nplored to address data scarcity in medical imaging [21,\n39]. When applied to retinal images, these models often\nencounter challenges, including difficulties in preserving\nanatomical fidelity and issues with training stability [20].\nDiffusion models have recently emerged as powerful tools\nfor generating diverse high-fidelity images, with superior\nstability and detail preservation, compared to GANs and\nV AEs [8, 27]. Despite their success in image synthesis tasks\nacross domains, e.g., natural image generation and text-to-\nimage modeling, their application in medical imaging has\nlargely focused on generating synthetic images rather than\ndirectly enhancing segmentation performance through data\naugmentation. To address these limitations, we propose Retinal Layout-\nAware Diffusion(RLAD), a diffusion-based framework for\nthe controllable generation of synthetic retinal images (Fig-\nure 1). By conditioning on multiple key retinal struc-\ntures\u2014such as artery/vein (A V), the optic cup/disc (CD),\nand lesions (L)\u2014RLAD preserves essential vascular lay-\nouts while introducing variability in other regions. This en-\nables the creation of paired image-segmentation maps that\nexpand training datasets without compromising structural\nintegrity. Synthetic data generated by RLAD improve seg-\nmentation model robustness across diverse imaging condi-\ntions and acquisition settings. We evaluated RLAD-generated data using state-of-the-\nart visual encoders such as Vision Transformers [9] and\nSwin Transformers [48], and demonstrate consistent im-\nprovements in generalization performance under distri-\nbution shifts (up to 8.1%). Additionally, we introduce\nREYIA, the largest multi-source collection of 586 retinal\nimages with human reference A V segmentation, which not\nonly complements our synthetic data but also demonstrates\nstrong baseline performance, further validating the effec-\ntiveness of our synthetic data. In summary, the main contributions of this work are:\n\u2022 A novel multi-layout-aware generative model ( RLAD)\nthat synthesizes diverse yet anatomically accurate retinal\nimages while preserving semantic structures. \u2022 Demonstrating consistent segmentation performance im-\nprovements across state-of-the-art architectures using\nRLAD-generated data.\n\u2022 Introducing REYIA, the largest multi-source collection\nof datasets for A V-segmented retinal fundus images. 2. Related Work\nRetinal A V segmentation plays a critical role in diagnos-\ning microvascular pathologies [22, 37, 65, 67, 75]. Early\nmethods [24, 31, 68, 81, 82], such as Little W-Net [19], fo-\ncused on compact convolutional neural networks to reduce\ncomputational complexity. More recently, LUNet achieved\nstate-of-the-art performance on optic disc-centered images\nbut struggled to generalize to macula-centered images [16]. This underscores the primary challenge of achieving robust\ngeneralization across diverse retinal imaging conditions.\n\n2503.01190v1\nEnhancing Retinal Vessel Segmentation Generalization via Layout-Aware\nGenerative Modelling\nJonathan Fhima1,2 Jan Van Eijgen3,4 Lennert Beeckmans4,5 Thomas Jacobs4\nMoti Freiman1 Luis Filipe Nakayama6,7 Ingeborg Stalmans3,4 Chaim Baskin8\u2020 Joachim A. Behar1\u2020\njbehar@technion.ac.il\n\u2020Equal contribution as Principal Investigators. *\nAbstract\nGeneralization in medical segmentation models is challeng-\ning due to limited annotated datasets and imaging vari-\nability. To address this, we propose Retinal Layout-Aware\nDiffusion (RLAD), a novel diffusion-based framework for\ngenerating controllable layout-aware images. RLAD con-\nditions image generation on multiple key layout compo-\nnents extracted from real images, ensuring high structural\nfidelity while enabling diversity in other components. Ap-\nplied to retinal fundus imaging, we augmented the training\ndatasets by synthesizing paired retinal images and vessel\nsegmentations conditioned on extracted blood vessels from\nreal images, while varying other layout components such\nas lesions and the optic disc. Experiments demonstrated\nthat RLAD-generated data improved generalization in reti-\nnal vessel segmentation by up to 8.1%. Furthermore, we\npresent REYIA, a comprehensive dataset comprising 586\nmanually segmented retinal images. To foster reproducibil-\nity and drive innovation, both our code and dataset will be\nmade publicly accessible (upon publication). 1. Introduction\nDeep learning has achieved remarkable success across var-\nious domains, but its progress often depends on access to\nlarge annotated datasets. In fields such as natural language\nprocessing, vision-language modeling, and image genera-\ntion, synthetic data from large models has driven significant\nadvancements [35, 45, 47, 72, 74, 84]. However, in med-\n* 1Faculty of Biomedical Engineering, Technion-IIT, Israel.\n2Faculty of Mathematics, Technion-IIT, Israel.\n3Department of Neurosciences, KU Leuven, Belgium. 4Department of Ophthalmology, UZ Leuven, Belgium. 5Department of Electrical Engineering, KU Leuven, Belgium. 6Ophthalmology Department,S\u02dcao Paulo Federal University, Brazil.\n7Medical Engineering and Science, Massachusetts Institute of Technology, USA.\n8School of Electrical and Computer Engineering, Ben-Gurion University of the Negev, Israel.\nConditional Denoiser\nLayout conditioning\nAV CD L\nNoise\nFigure 1. Retinal Layout-Aware Diffusion generates realistic\nretinal images from noise and user-defined layout components;\nartery/vein (A V), optic cup/disc (CD), and lesions (L). ical imaging, particularly retinal vessel segmentation, data\nscarcity and variability in imaging conditions remain persis-\ntent limitations [16, 19, 38, 68]. Retinal vessel segmentation\nis critical for the diagnosis of ocular and systemic diseases\n[18, 34, 46, 76], yet the creation of annotated datasets de-\nmands a considerable amount of time, specialized expertise,\nand consistency across imaging devices [14]. Retinal vessel segmentation involves two tasks: general\nvessel segmentation, which identifies the vasculature, and\n1\narXiv:2503.01190v1  [cs.CV]  3 Mar 2025\n\nLayout conditioning\nAV\nTimestep t\nVAE\nCD\nL\nVAE\nVAE\nVAE\nV_Emb\nL_Emb\nD_Emb\nI_Emb\nBOC\nEOC DiT\nNoise\n+\n+\nUI\nDiT input sequence\nFigure 2. RLAD Architecture. The original fundus image and segmentation maps for artery/vein (A V), the optic cup/disc (CD), and\nlesions (L) are encoded into latent representations using a frozen V AE. Gaussian noise is added to the image latent, and each latent (image,\nCD, A V , and L) is projected into the DiT [58] input space via distinct projections.", "metadata": {"type": "factual", "source": "2503.01190v1.pdf", "context": "Transformer-based architectures such as DiT [58] further\nenhance performance by capturing long-range dependen-\ncies.\nBuilding on these developments, we propose a multi-\nlayout-aware diffusion framework specifically designed for\nretinal fundus image synthesis. Unlike prior approaches,\nour method conditions generation on multiple retinal lay-\nout components \u2014A V , CD, and L\u2014extracted from real,\nnon-annotated images using pretrained segmentation mod-\nels. This minimizes error propagation and enhanc", "quality_score": 8}}
{"id": "test_74", "question": "What is the primary motivation behind predicting gene expression from pathology slide images?", "golden_answers": ["To preserve spatial information and make spatial profiling of gene expression more clinically beneficial, cost-effective, and technically efficient."], "prediction": "The primary motivation behind predicting gene expression from pathology slide images is to enhance the understanding of spatial transcriptomics and improve the accuracy of gene expression predictions at varying spatial resolutions and spot sizes, which is crucial for real-world applications in biomedical research and precision oncology.", "f1": 0.2622950819672131, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.00374v2\n, \u201cA whole-slide foundation model for digital pathology\nfrom real-world data,\u201d Nature, 2024, :1-8. [38] E. V orontsov et al., \u201cVirchow: a million-slide digital pathology founda-\ntion model,\u201d arXiv preprint arXiv:2309.07778 , 2023. [39] N. A. Koohbanani, B. Unnikrishnan, S. A. Khurram, P. Krishnaswamy,\nand N. Rajpoot, \u201cSelf-path: Self-supervision for classification of pathol-\nogy images with limited annotations,\u201d IEEE Trans. Med. Imaging, 2021,\n40(10):2845-56. [40] K. Singhal et al., \u201cLarge language models encode clinical knowledge,\u201d\nNature, 2023, 620(7972):172-80. [41] M. Y . Lu et al., \u201cA visual-language foundation model for computational\npathology,\u201d Nature Medicine, 2024, 30(3):863-74. [42] C. Li et al., \u201cLlava-med: Training a large language-and-vision assistant\nfor biomedicine in one day,\u201d NeurIPS, 2024, 36. [43] G. Jaume et al., \u201cMultistain pretraining for slide representation learning\nin pathology,\u201d arXiv preprint arXiv:2408.02859 , 2024. [44] Z. Guo, J. Ma, Y . Xu, Y . Wang, L. Wang, and H. Chen, \u201cHistgen:\nHistopathology report generation via local-global feature encoding and\ncross-modal context interaction,\u201d in MICCAI, 2024, :189-99. [45] R. J. Chen et al. , \u201cPathomic fusion: an integrated framework for\nfusing histopathology and genomic features for cancer diagnosis and\nprognosis,\u201d IEEE Trans. Med. Imaging , 2020, 41(41):757-70. [46] Y . Zheng et al., \u201cGraph attention-based fusion of pathology images and\ngene expression for prediction of cancer survival,\u201d IEEE Trans. Med. Imaging, 2024, 43(9):3085-97. [47] Z. Wang, Y . Zhang, Y . Xu, S. Imoto, H. Chen, and J. Song, \u201cHisto-\ngenomic knowledge association for cancer prognosis from histopathol-\nogy whole slide images,\u201d IEEE Trans. Med. Imaging , 2025, :1. [48] Z. Shao et al., \u201cTransmil: Transformer based correlated multiple instance\nlearning for whole slide image classification,\u201d NeurIPS, 2021, 34:2136-\n47. [49] I. Guyon, J. Weston, S. Barnhill, and V . Vapnik, \u201cGene selection for\ncancer classification using support vector machines,\u201d Machine learning,\n2002, 46:389-422. [50] Z. Sondka et al. , \u201cCosmic: a curated database of somatic variants and\nclinical data for cancer,\u201d Nucleic Acids Research, 2024, 52(D1):D1210-\n7. [51] A. v. d. Oord, Y . Li, and O. Vinyals, \u201cRepresentation learning with\ncontrastive predictive coding,\u201d arXiv preprint arXiv:1807.03748 , 2018. [52] S. Kullback and R. A. Leibler, \u201cOn information and sufficiency,\u201d The\nannals of mathematical statistics , 1951, 22(1):79-86. [53] K. He, X. Zhang, S. Ren, and J. Sun, \u201cDeep residual learning for image\nrecognition,\u201d in CVPR, 2016, :770-8. [54] A. Filiot et al., \u201cScaling self-supervised learning for histopathology with\nmasked image modeling,\u201d medRxiv, 2023, :2023-07. [55] M. J. Goldman et al. , \u201cVisualizing and interpreting cancer genomics\ndata via the xena platform,\u201d Nat. Biotechnol., 2020, 38(6):675-8. [56] G. Campanella et al. , \u201cClinical-grade computational pathology using\nweakly supervised deep learning on whole slide images,\u201d Nat. Med. ,\n2019, 25(8):1301-09. [57] N. Otsu et al. , \u201cA threshold selection method from gray-level his-\ntograms,\u201d Automatica, 1975, 11(285-296):23-7. [58] D. Kingma, \u201cAdam: a method for stochastic optimization,\u201d arXiv\npreprint arXiv:1412.6980, 2014. [59] A. Paszke et al., \u201cPytorch: An imperative style, high-performance deep\nlearning library,\u201d NeurIPS, 2019, 32. [60] M. Ilse, J. Tomczak, and M. Welling, \u201cAttention-based deep multiple\ninstance learning,\u201d in ICML, 2018, :2127-36.\n\n2503.01347v1\nIt aggregates features from multiple cells within a single spot, mapping\na fixed crop to gene expression, which results in a loss of spatial resolution and\ncapability of predicting spatially resolved gene expression. Moreover, past methods are designed for spots with a fixed scale and size. However, in practice, there is the need for gene expression prediction at varying\nspatial resolutions and spot sizes, limiting the adaptability of these methods to\nreal-world applications. For example, a model trained to predict gene expression\nfrom 100 \u00b5m spots struggles to generalize when applied to 2\u00b5m spots, as it\nusually relies on larger spot sizes to capture spatial context from the slide image\nfor prediction. Furthermore, the 2\u00b5m spots approximate single-cell resolution\n(i.e., the finest level of detail desired in spatial transcriptomics [4]). However,\nin image space, it usually corresponds to only 20 pixels. This resolution con-\nstraint further restricts the applicability of previous methods to emerging ST\ntechnologies, such as Visium HD, which provides spatial gene expression at 2\n\u00b5m spots. The need for a sufficiently large amount of visual information makes\nit challenging for them to adapt to these advancements. To address these challenges, this paper reformulates spatial gene expression\nprediction from a slide image as a dense prediction task. We introduce PixNet,\na model that maps the entire slide image to a dense gene expression map. For\nany spots of interest, the predicted gene expression is obtained by aggregating\nvalues from the corresponding region in the dense gene expression map. Fig. 1\n(b) illustrates the overall idea. To generate the gene expression map, we leverage\nthe multi-scale nature of slide images [6]. Because slide images contain features\nat varying spatial scales, we extract a pyramidal feature map from the slide\nimage, and progressively decode it into a high-resolution gene expression map,\ncapturing hierarchical features for densely predicting the spatial gene expression. In training, we optimize the network by a sparse loss module that provides su-\npervision signals only at spots with measured ground-truth gene expression, ac-\n\nSpatial Transcriptomics Analysis of Spatially Dense Gene Expression Prediction 3\nDecoder\nResNet18\nEncoder\n<latexit sha1_base64=\"swVY9LgCRlke7UcPo0pNCGREyKQ=\">AAACGXicbVDLSsNAFJ34rPUVdamLYBVclURE3QgFQVy4qGAf0MQwmU7aoZNJmJmIZcjG3/AH3OofuBO3rvwBv8NJm4VtvTDD4Zx7ueeeIKFESNv+NubmFxaXlksr5dW19Y1Nc2u7KeKUI9xAMY15O4ACU8JwQxJJcTvhGEYBxa1gcJnrrQfMBYnZnRwm2Itgj5GQICg15Zt7rnIjKPtBqK4yX9HMzf8LJ7tXN5lvVuyqPSprFjgFqICi6r7543ZjlEaYSUShEB3HTqSnIJcEUZyV3VTgBKIB7OGOhgxGWHhqdEVmHWqma4Ux149Ja8T+nVAwEmIYBbozdyymtZz8T+ukMjz3FGFJKjFD40VhSi0ZW3kkVpdwjCQdagARJ9qrhfqQQyR1cBNbHsdWyzoYZzqGWdA8rjqnVef2pFI7KCIqgV2wD46AA85ADVyDOmgABJ7AC3gFb8az8W58GJ/j1jmjmNkBE2V8/QJRI6GD</latexit>\n{Fl}L\nl=1\n<latexit sha1_base64=\"riBMRaoLAcuTAAzHmmAtlnYG+As=\">AAACBXicbVDLSgMxFL3xWeur6tJNsAquyoyIuiy40V0F+8B2KJk004ZmMkOSEcvQtT/gVv/Anbj1O/wBv8NMOwvbeiBwOOde7snxY8G1cZxvtLS8srq2Xtgobm5t7+yW9vYbOkoUZXUaiUi1fKKZ4JLVDTeCtWLFSOgL1vSH15nffGRK80jem1HMvJD0JQ84JcZKD52QmIEfpLfjbqnsVJwJ8CJxc1KGHLVu6afTi2gSMmmoIFq3XSc2XkqU4VSwcbGTaBYTOiR91rZUkpBpL50kHuMTq/RwECn7pMET9e9GSkKtR6FvJ7OEet7LxP+8dmKCKy/lMk4Mk3R6KEgENhHOvo97XDFqxMgSQhW3WTEdEEWosSXNXHmaRi3aYtz5GhZJ46ziXlTcu/Ny9TivqACHcASn4MIlVOEGalAHChJe4BXe0DN6Rx/oczq6hPKdA5gB+voFHaKZWw==</latexit> I\n<latexit sha1_base64=\"+fRqZOjW2/4C5hjefWRNb5oY9xc=\">AAACBXicbVDLSgMxFL3xWeur6tJNsAquyoyIuiy40GUF+8B2KJk004ZmMkOSEcvQtT/gVv/Anbj1O/wBv8NMOwvbeiBwOOde7snxY8G1cZxvtLS8srq2Xtgobm5t7+yW9vYbOkoUZXUaiUi1fKKZ4JLVDTeCtWLFSOgL1vSH15nffGRK80jem1HMvJD0JQ84JcZKD52QmIEfpDfjbqnsVJwJ8CJxc1KGHLVu6afTi2gSMmmoIFq3XSc2XkqU4VSwcbGTaBYTOiR91rZUkpBpL50kHuMTq/RwECn7pMET9e9GSkKtR6FvJ7OEet7LxP+8dmKCKy/lMk4Mk3R6KEgENhHOvo97XDFqxMgSQhW3WTEdEEWosSXNXHmaRi3aYtz5GhZJ46ziXlTcu/Ny9TivqACHcASn4MIlVOEWalAHChJe4BXe0DN6Rx/oczq6hPKdA5gB+voFGnCZWQ==</latexit>\nG\n<latexit sha1_base64=\"ILwv2DCHb9XZEcxdi8GuYkbqC3Q=\">AAACHHicbVDLSsNAFJ3UV62vqEsXBqvgQkoiom6EghtXUsE+oIlhMp20QyeTMDORlpClv+EPuNU/cCduBX/A73CSZmFbD8zlcM693DvHiygR0jS/tdLC4tLySnm1sra+sbmlb++0RBhzhJsopCHveFBgShhuSiIp7kQcw8CjuO0NrzO//Yi5ICG7l+MIOwHsM+ITBKWSXH3fTkZuwtKTcV55Vu1U1SsrfUhuU1evmjUzhzFPrIJUQYGGq//YvRDFAWYSUShE1zIj6SSQS4IoTit2LHAE0RD2cVdRBgMsnCT/SGocKaVn+CFXj0kjV/9OJDAQYhx4qjOAciBmvUz8z+vG0r90EsKiWGKGJov8mBoyNLJUjB7hGEk6VgQiTtStBhpADpFU2U1tGU1OrahgrNkY5knrtGad16y7s2r9sIioDPbAATgGFrgAdXADGqAJEHgCL+AVvGnP2rv2oX1OWktaMbMLpqB9/QLiXqLg</latexit>\n{xn,y n,r n}N\nn=1\nSlide Image\nPyramidal \nFeature Map Gene Expression Map \nEq. 5\nSpots of Interest\n<latexit sha1_base64=\"Mp9d04cQvCeCIJtu7elTV2uApoE=\">AAACB3icbVDLSsNAFL2pr1pfUZduBqvgqiQi6rLgxoWLCvYBTSiT6aQdOpmEmYlYQj/AH3Crf+BO3PoZ/oDf4aTNwrYeuHA4517u4QQJZ0o7zrdVWlldW98ob1a2tnd29+z9g5aKU0lok8Q8lp0AK8qZoE3NNKedRFIcBZy2g9FN7rcfqVQsFg96nFA/wgPBQkawNpLnRVgPCebZ3QT17KpTc6ZAy8QtSBUKNHr2j9ePSRpRoQnHSnVdJ9F+hqVmhNNJxUsVTTAZ4QHtGipwRJWfTTNP0KlR+iiMpRmh0VT9e5HhSKlxFJjNPKNa9HLxP6+b6vDaz5hIUk0FmT0KU450jPICUJ9JSjQfG4KJZCYrIkMsMdGmprkvT7OoFVOMu1jDMmmd19zLmnt/Ua2fFBWV4QiO4QxcuII63EIDmkAggRd4hTfr2Xq3PqzP2WrJKm4OYQ7W1y9Nz5n6</latexit>\nL\n<latexit sha1_base64=\"23eR8ESHgI7BB6owZkGGa7WYsaQ=\">AAACFnicbVDLSsNAFJ3UV62vqCtxE6yCq5KIqBuh4MaVVLAPaGKYTCft0MkkzEzEMgR/wx9wq3/gTty69Qf8DidtFrb1wAyHc+7l3nuChBIhbfvbKC0sLi2vlFcra+sbm1vm9k5LxClHuIliGvNOAAWmhOGmJJLiTsIxjAKK28HwKvfbD5gLErM7OUqwF8E+IyFBUGrJN/dc5Q6gVKPMVyxz8//Sye7VTeabVbtmj2HNE6cgVVCg4Zs/bi9GaYSZRBQK0XXsRHoKckkQxVnFTQVOIBrCPu5qymCEhafGJ2TWkVZ6Vhhz/Zi0xurfDgUjIUZRoCsjKAdi1svF/7xuKsMLTxGWpBIzNBkUptSSsZXnYfUIx0jSkSYQcaJ3tdAAcoikTm1qyuNk1YoOxpmNYZ60TmrOWc25Pa3WD4uIymAfHIBj4IBzUAfXoAGaAIEn8AJewZvxbLwbH8bnpLRkFD27YArG1y8zjaBp</latexit>\n{\u02c6yn}N\nn=1\n<latexit sha1_base64=\"SRJTUH2/KoQg/vC915oA6D5pJ4k=\">AAACEHicbVDLSsNAFL3xWesr2qWbYBVclURE3QgFN66kgn1AE8NkOmmHTiZhZiKGkJ/wB9zqH7gTt/6BP+B3OH0sbOuBGQ7n3Ms9nCBhVCrb/jaWlldW19ZLG+XNre2dXXNvvyXjVGDSxDGLRSdAkjDKSVNRxUgnEQRFASPtYHg98tuPREga83uVJcSLUJ/TkGKktOSbFTfP/JwXbqH/K6d4yG8L36zaNXsMa5E4U1KFKRq++eP2YpxGhCvMkJRdx06UlyOhKGakKLupJAnCQ9QnXU05ioj08nH4wjrWSs8KY6EfV9ZY/buRo0jKLAr0ZITUQM57I/E/r5uq8NLLKU9SRTieHApTZqnYGjVh9aggWLFME4QF1VktPEACYaX7mrnyNIla1sU48zUsktZpzTmvOXdn1frRtKISHMAhnIADF1CHG2hAEzBk8AKv8GY8G+/Gh/E5GV0ypjsVmIHx9QsGEZ2c</latexit>\n{yn}N\nn=1\nGround Truth\nFig.2: Overview of our framework. We extract a pyramidal feature map{Fl}L\nl=1\nfrom a slide imageI and progressively decode them into a gene expression map\nG. The predicted gene expression values{\u02c6yn}N\nn=1 are aggregated (Eq. 5) fromG\nbased on the positions and radiuses of spots of interest. The lossL is computed\nsparsely on spots with ground truth gene expression{yn}N\nn=1 during training.\ncommodating the sparsity of spatial transcriptomics data. With this generalized\napproach, our network is capable of accurately predicting spatial gene expression\nacross multiple scales at varying sizes. We evaluate our method on 3 common ST\ndatasets and demonstrate its effectiveness in predicting gene expression at scales\nand spot sizes different from those seen during training, outperforming previous\nmethods.\n\n2503.00374v1\nWu, D. Agarwal, and J. Sun, \u201cMedclip: Contrastive\nlearning from unpaired medical images and text,\u201d arXiv preprint\narXiv:2210.10163, 2022. [9] Y . Xu, Y . Wang, F. Zhou, J. Ma, S. Yang, H. Lin, X. Wang, J. Wang,\nL. Liang, A. Han et al., \u201cA multimodal knowledge-enhanced whole-slide\npathology foundation model,\u201d arXiv preprint arXiv:2407.15362 , 2024. [10] K. M. Boehm, P. Khosravi, R. Vanguri, J. Gao, and S. P. Shah,\n\u201cHarnessing multimodal data integration to advance precision oncology,\u201d\nNature Reviews Cancer , vol. 22, no. 2, pp. 114\u2013126, 2022. [11] G. Jaume, L. Oldenburg, A. Vaidya, R. J. Chen, D. F. Williamson,\nT. Peeters, A. H. Song, and F. Mahmood, \u201cTranscriptomics-guided slide\nrepresentation learning in computational pathology,\u201d in Proceedings of\nthe IEEE/CVF Conference on Computer Vision and Pattern Recognition,\n2024, pp. 9632\u20139644. [12] Y . Zhang, Y . Xu, J. Chen, F. Xie, and H. Chen, \u201cPrototypical infor-\nmation bottlenecking and disentangling for multimodal cancer survival\nprediction,\u201d arXiv preprint arXiv:2401.01646 , 2024. [13] G. Jaume, A. Vaidya, R. J. Chen, D. F. Williamson, P. P. Liang, and\nF. Mahmood, \u201cModeling dense multimodal interactions between biolog-\nical pathways and histology for survival prediction,\u201d in Proceedings of\nthe IEEE/CVF Conference on Computer Vision and Pattern Recognition,\n2024, pp. 11 579\u201311 590. [14] A. Vaidya, A. Zhang, G. Jaume, A. H. Song, T. Ding, S. J. Wag-\nner, M. Y . Lu, P. Doucet, H. Robertson, C. Almagro-Perez et al. ,\n\u201cMolecular-driven foundation model for oncologic pathology,\u201d arXiv\npreprint arXiv:2501.16652, 2025. [15] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,\n\u0141. Kaiser, and I. Polosukhin, \u201cAttention is all you need,\u201d Advances in\nneural information processing systems , vol. 30, 2017. [16] K. Tomczak, P. Czerwi \u00b4nska, and M. Wiznerowicz, \u201cReview the cancer\ngenome atlas (tcga): an immeasurable source of knowledge,\u201d Contem-\nporary Oncology/Wsp \u00b4o\u0142czesna Onkologia, vol. 2015, no. 1, pp. 68\u201377,\n2015. [17] T. Chen, S. Kornblith, M. Norouzi, and G. Hinton, \u201cA simple framework\nfor contrastive learning of visual representations,\u201d in International\nconference on machine learning . PMLR, 2020, pp. 1597\u20131607. [18] K. He, H. Fan, Y . Wu, S. Xie, and R. Girshick, \u201cMomentum contrast\nfor unsupervised visual representation learning,\u201d in Proceedings of the\nIEEE/CVF conference on computer vision and pattern recognition, 2020,\npp. 9729\u20139738. [19] H. Bao, L. Dong, S. Piao, and F. Wei, \u201cBeit: Bert pre-training of image\ntransformers,\u201d arXiv preprint arXiv:2106.08254 , 2021. [20] K. He, X. Chen, S. Xie, Y . Li, P. Doll \u00b4ar, and R. Girshick, \u201cMasked au-\ntoencoders are scalable vision learners,\u201d inProceedings of the IEEE/CVF\nconference on computer vision and pattern recognition , 2022, pp. 16 000\u201316 009. [21] J. Zhou, C. Wei, H. Wang, W. Shen, C. Xie, A. Yuille, and T. Kong,\n\u201cibot: Image bert pre-training with online tokenizer,\u201d arXiv preprint\narXiv:2111.07832, 2021. [22] M. Oquab, T. Darcet, T. Moutakanni, H. V o, M. Szafraniec, V . Khalidov,\nP. Fernandez, D. Haziza, F. Massa, A. El-Nouby et al. , \u201cDinov2:\nLearning robust visual features without supervision,\u201d arXiv preprint\narXiv:2304.07193, 2023. [23] C. Jia, Y . Yang, Y .", "metadata": {"type": "factual", "source": "2503.01347v1.pdf", "context": "gate values within spots of interest to predict the gene expression. Our\nPixNet outperforms state-of-the-art methods on 3 common ST datasets,\nwhile showing superior performance in predicting gene expression across\nmultiple spatial scales. The source code will be publicly available.\nKeywords: Spatial transcriptomics\u00b7 Computational pathology\u00b7 Gene\nexpression prediction\u00b7 Tissue slide image\u00b7 Pixel-level prediction.\n1 Introduction\nSpatially profiling gene expression with spatial transcriptomics (ST) ", "quality_score": 8}}
{"id": "test_75", "question": "Why is it necessary to consider memory usage, computation requirements, and mean latency in the evaluation?", "golden_answers": ["Because these factors are crucial for understanding the overall efficiency and feasibility of the proposed approach."], "prediction": "It is necessary to consider memory usage, computation requirements, and mean latency in the evaluation to assess the feasibility and effectiveness of the proposed architecture, especially in resource-constrained environments like TinyML applications. These factors directly impact the performance and efficiency of the model, influencing its ability to operate effectively on limited hardware while meeting the demands of real-time processing.", "f1": 0.20895522388059704, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01025v1\nIn this sense, Google\noffers a profiling tool that tests the latency of the fragments\nfor different distributions and tries to minimise the difference\nbetween the fastest and the slowest one. We will shortly\nanalyse a profiling-based split, but let us first test the default\nsegmentation scheme with a larger input batch. B. Performance on batched inputs with segmented models\nTo exploit the parallel potential of the pipeline, we repeated\nthe experiment with a 50-input batch. In this case, we divide\nthe execution time of the whole batch by its size to obtain the\ntime per inference. Figure ?? reports the speedup with respect\nto a single input and with respect to one TPU. In both layer types, the speedup with respect to a single\ninput is far from ideal (with n TPUs we could expect close\nto \u00d7n). The problem is that the workload distribution is\nunbalanced and there are stages much slower than others\nacting as bottlenecks. When the model fits in device memory\nthe speedup is moderately below ideal because the workload\ndistribution is uneven. When a TPU also needs host memory,\nit becomes a very slow stage in the pipeline that sequences\nthe executions. Therefore, the speedup with respect to a single\ninput drops sharply near \u00d71 when host memory is needed. These load imbalance issues combined with the commu-\nnication overhead make speedups compared to a single TPU\nvery poor for CONV models and for FC models that fit on-\nchip or still need host memory. Recall that in CONV layers the\ncommunication costs are very relevant on their own and it is\nnatural that, despite parallelisation, segmentation is inefficient\n(in many models it is still slower than 1 TPU). However, the\nresults are very positive for FC models that avoid the use\nof host memory completely (because its relative cost is very\nhigh). In these cases, we obtain speedups of several tens with\njust 2, 3 or 4 TPUs compared to using just one. We get up to\n\u00d736 in the largest models (with just 4 TPUs) where the size\nof the layers is already too big to be stored on the host. C. Optimizing model segmentation with profiling\nWe have observed two different issues to improve segmenta-\ntion through a better model distribution. First, it is convenient\nto make a better use of device memory with a more balanced\ndistribution of layers in terms of their size. In this way, we will\nachieve a further reduction in host memory usage for the same\nnumber of devices. Second, it is desirable for the workload to\nbe more evenly distributed so that the pipeline stages exhibit\nsimilar latencies and hence the load imbalance is reduced. In our synthetic models, both purposes match, since all\nlayers are of the same type (they are all either FC or CONV ). As they all exhibit the same arithmetic intensity, a higher\nworkload entails a higher memory usage.\n\n2503.01353v1\nFor instance, for the task of walking upstairs versus downstairs\nin the UCA-EHAR dataset when Dendron is employed, the\naccuracy ranges from 0.84 to 0.89, with only a 0.05 difference\nbetween the maximum and minimum accuracy. Conversely,\nwhen employing the traditional approach, the accuracy ranges\nfrom 0.72 to 0.90, resulting in a larger 0.18 difference between\nthe maximum and minimum accuracy. D. Computation, memory, and latency evaluation\nThis section analyzes the proposed solution focusing on\nmemory usage, computation requirements, and mean latency. Specifically, the assessment is carried out by using the STM32-\nNUCLEO-F401RE evaluation board, commonly utilized in\nTinyML applications. This board serves as a representative\nplatform for evaluating the feasibility and effectiveness of the\nproposed architecture within the TinyML context. 1) On-device inference evaluation: The findings of this\nevaluation are summarized in Table IV. Specifically, The\nresults show that our solution outperformed the existing hier-\narchical solution in terms of memory, computation, and mean\nlatency. Specifically, Dendron has 5\u00d7 less memory usage, 2\u00d7\nless computation load, and requires 2\u00d7 less time per inference\ncompared to the hierarchical solution. Additionally, Dendron\nexhibits only 7 KiB increase in memory compared to the\ntraditional single-model solution, while showing a reduced\ncomputational load compared to the traditional single-model.\n2) On-device learning evaluation: We evaluate the memory\nand time required for the on-device learning of a new task\n\nTABLE IV\nCOMPARISON IN TERMS OF MEMORY , COMPUTATION , AND LATENCY\nUSING THE STM32-NUCLEO-F401RE FOR INFERENCE .\nM(i)\nFE , C(i)\nFE , M(i)\nFC , and C(i)\nFC are respectively the memory, and computation\nload of the i \u2212 th task for the feature extractor (FE), and the fully\nconnected (FC) modules. 3\nSolution Memory Computation\n(MACC)\nMean\nLatency\nSingle-model MFE + MFC CFE + CFC \u2248 47 ms\u2248 60 KiB \u2248 427, 242\nHierarchical\nPn\ni M(i)\nFE + M(i)\nFC\nP\ni C(i)\nFE + C(i)\nFC \u2248 94 ms\u2248 324 KiB \u2248 851, 292\nDendron MFE + Pn\ni M(i)\nFCMFE + Pn\ni M(i)\nFCMFE + Pn\ni M(i)\nFC CFE + P\ni C(i)\nFCCFE + P\ni C(i)\nFCCFE + P\ni C(i)\nFC \u2248 47 ms\u2248 47 ms\u2248 47 ms\u2248 67 KiB\u2248 67 KiB\u2248 67 KiB \u2248 426, 444\u2248 426, 444\u2248 426, 444\nTABLE V\nANALYSIS OF DENDRON ON-DEVICE LEARNING OF A NEW BINARY TASK\nT(new) FOR ONE SAMPLE OF SIZE 2S ON THE\nSTM32-NUCLEO-F401RE. g(\u00b7) IS THE FEATURE EXTRACTOR , AND h(\u00b7)\nIS THE FULL CONNECTED PART OF DENDRON . Time Additional Memory\nForward pass g(\u00b7) \u2248 46 ms 0 Bytes\nh(\u00b7) \u2248 3 ms 0 Bytes\nBackward pass g(\u00b7) Not Required Not Required\nh(\u00b7) \u2248 7 ms 8 Bytes\nT(new) using Dendron. We emphasize that performing on-\ndevice training using traditional approaches is not feasible in a\nTinyML scenario, due to the memory requirements associated\nwith the training of the entire network. The findings of the\nevaluation are summarized in Table V. Specifically, a forward-\nbackward pass for one window sample {xt, . . .\n\n2503.01035v1\nThe runs are heavily penalized by performance drops, but even before the drops,\nthe models perform well below the ideal: 1.4 TOPS in synthetic models and only 0.6\nTOPS in real models (green group). Peak performance would be obtained if there\nwere no fill latencies in the systolic array and, especially, no stalls waiting for data. The observed results suggest that executions are highly memory bound. This also\nexplains the better performance of synthetic models, which only use convolutions,\nversus real models, that also use layers of lower arithmetic intensity (e.g., fully\nconnected). Putting the performance of the Edge TPU into perspective, and although the\ndevice is not used at its full potential, its performance is relatively good in absolute\nterms. Figure 3 shows the inference speedup of our models on the Edge TPU against a\ngeneral-purpose CPU: an 8-core Intel i9-9900K CPU, using 8 threads and running at a\nnominal frequency of 3.6 GHz. With the synthetic models, a speedup of 10\u00d7 is reached\nat the end of the first step and, despite successive performance drops, the speedup\nremains above 2 \u00d7 for the rest of models. With the real models, the improvement is\neven larger in the best-performing group (green color) with speedups close to 12 \u00d7 in\nsome cases. The improvement for the rest of the models (orange and red colors) are\nless dramatic. However, the Edge TPU is never slower than the multi-core CPU. In\nthe following, we focus on understanding and mitigating the performance problems of\nthese models. 4.2 Memory usage\nMotivated by the previous observations, we proceed by analyzing the executions in\nterms of memory accesses. As of today, and to the best of our knowledge, there are\nno profiling tools to obtain this type of metrics. Nevertheless, the model compiler\ngenerates a report that includes the amount of host and device memory used by the\nEdge TPU to store the weights. This information is a good indicator of the cost\nassociated with memory operations, since weight read operations are dominant in the\ninference process in terms of execution time (the tensors associated with reading inputs\nor writing outputs are considerably smaller). Figure 4 shows the performance of the synthetic models along with its device and\nhost memory usage. Memory usage perfectly explains the big performance drops that\nwere previously observed (annotated in blue in the figure). At each step, the device\nmemory usage grows progressively until it almost reaches the available size (8 MiB). Then, a big performance drop occurs, matching with a drastic rise in host memory\nusage (annotated in red in the figure). This happens when part of the model cannot be\n11\n\n0 5 10 15 20 25 30 35 40\nTFLite quantized model size (MiB)\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\n1.2\n1.4\nPerformance (TOPS)\nPerformance\nHost memory\nDevice memory\n0\n5\n10\n15\n20\n25\n30\n35\n40\nAmount of memory used (MiB)\n8 MiB\nBig drop #1\nBig drop #2\nBig drop #3\nBig drop #4\nBig rise #1\nBig rise #2\nBig rise #3\nBig rise #4\nFig.", "metadata": {"type": "reasoning", "source": "2503.01353v1.pdf", "context": "This section is organized as follows. Section IV-A details\nthe datasets used for the evaluation. Section IV-B evaluates\nthe classification capability. Section IV-C evaluates the per-\nformances of adding a new task during the operational life\nof HAR. Finally, Section IV-D discusses the memory usage,\ncomputation requirements, and mean latency.\nA. Datasets\n1) UCA-EHAR dataset: The UCA-EHAR dataset [12] in-\ncludes gyroscopic and accelerometer data collected from smart", "quality_score": 8}}
{"id": "test_76", "question": "Derive the expression for I(1)2m\u22121,i using calculus and explain the steps involved.", "golden_answers": ["I(1)2m\u22121,i = (m\u2212i\u2211 l=0 ((\u22121)m\u2212i\u2212lCl m\u2212i 2m\u2212l)) \u222b 1 0 y2m\u22121 1(y1 + 1 j)2m dy1 + O(1), where the identity m\u2212i\u2211 l=0 (\u22121)lCl m\u2212i m+ i+ l = 1/2mCm\u2212i 2m\u22121 is used."], "prediction": "I(1)2m\u22121,i = (m\u2212i\u2211 l=0 (\u22121)m\u2212i\u2212lCl m\u2212i 2m\u2212 l) \u222b 1 0 y2m\u22121 1 (y1 + 1 j )2m dy1 + O(1)", "f1": 0.5652173913043479, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01246v1\nWe proceed to analyze the integral I2m\u22121 by the explicit expression of \u2126 and P2m.\nIt follows that\nI2m\u22121 =\nm\u2211\ni=0\na2m, 2i\n\u222b\n\u2126\n1\n|y|\n(y1 \u2212 1\nj )2i(y2\n2 + y2\n3)m\u2212i\n|y\u2212 zj|4m+1 y2m\u22121\n1 dy\n= 2 \u03c0\nm\u2211\ni=0\na2m, 2i\n\u222b 0\n\u22121\n\u222b 1\n0\n1\u221a\ny2\n1 + r2\n(y1 \u2212 1\nj )2ir2(m\u2212i)\n\u221a\n(y1 \u2212 1\nj )2 + r2\n4m+1 y2m\u22121\n1 rdrdy1\n= \u2212\u03c0\nm\u2211\ni=0\na2m, 2i\n\u222b 1\n0\n\u222b 1\n0\n1\u221a\ny2\n1 + r\n(y1 + 1\nj )2irm\u2212i\n\u221a\n(y1 + 1\nj )2 + r\n4m+1 y2m\u22121\n1 drdy1. We spilt I2m\u22121 into two parts. For 0 \u2264 i\u2264 m, de\ufb01ne\nI(1)\n2m\u22121,i :=\n\u222b 1\n0\n\u222b 1\n0\n(y1 + 1\nj )2irm\u2212i\n((y1 + 1\nj )2 + r)2m+1 y2m\u22121\n1 drdy1,\nI(2)\n2m\u22121,i :=\n\u222b 1\n0\n\u222b 1\n0\n\uf8eb\n\uf8ed 1\n\u221a\ny2\n1 + r\n\u2212 1\u221a\n(y1 + 1\nj )2 + r\n\uf8f6\n\uf8f8 (y1 + 1\nj )2irm\u2212i\n\u221a\n(y1 + 1\nj )2 + r\n4m+1 y2m\u22121\n1 drdy1. Clearly, I2m\u22121 = \u2212\u03c0\u2211 m\ni=0 a2m, 2i(I(1)\n2m\u22121,i + I(2)\n2m\u22121,i ). From the basic knowledge of\ncalculus, it is seen that\nI(1)\n2m\u22121,i =\nm\u2212i\u2211\nl=0\n\u222b 1\n0\n(y1 + 1\nj)2(m\u2212l)y2m\u22121\n1\n(\u222b (y1+ 1\nj )2+1\n(y1+ 1\nj )2\n(\u22121)m\u2212i\u2212lCl\nm\u2212i\n1\ns2m+1\u2212l ds\n)\ndy1\n=\n(m\u2212i\u2211\nl=0\n(\u22121)m\u2212i\u2212lCl\nm\u2212i\n2m\u2212 l\n) \u222b 1\n0\ny2m\u22121\n1\n(y1 + 1\nj )2m dy1 + O(1)\n=\n(m\u2212i\u2211\nl=0\n(\u22121)lCl\nm\u2212i\nm+ i+ l\n)[ \u222b 1\nj +1\n1\nj\n2m\u22121\u2211\nl=0\nCl\n2m\u22121\n(\n\u2212 1\nj\n) 2m\u22121\u2212l 1\ns2m\u2212l ds\n]\n+ O(1)\n= 1\n2mCm\u2212i\n2m\u22121\nln j+ O(1),\nwhere we note that the identity\nm\u2212i\u2211\nl=0\n(\u22121)lCl\nm\u2212i\nm+ i+ l = 1\n2mCm\u2212i\n2m\u22121\n\n10 C. Wu and J. Yang\nholds. Further, direct calculation shows that\n\u23d0\n\u23d0\n\u23d0\n\u23d0\n\u23d0\n\u23d0\n1\n\u221a\ny2\n1 + r\n\u2212 1\u221a\n(y1 + 1\nj )2 + r\n\u23d0\n\u23d0\n\u23d0\n\u23d0\n\u23d0\n\u23d0\n=\n\u23d0\n\u23d0\n\u23d0\n\u23d0\n\u23d0\n\u23d0\n1\nj (2y1 + 1\nj )\n\u221a\ny2\n1 + r\n\u221a\n(y1 + 1\nj )2 + r(\n\u221a\ny2\n1 + r+\n\u221a\n(y1 + 1\nj )2 + r)\n\u23d0\n\u23d0\n\u23d0\n\u23d0\n\u23d0\n\u23d0\n\u2264 1\nj\n1\u221a\ny2\n1 + r\n1\u221a\n(y1 + 1\nj )2 + r\nfor ( y1,r ) \u2208 (0, 1)2, which implies\n|I(2) 2m\u22121,i | \u2264 1\nj\n\u222b 1\n0\n\u222b 1\n0\n1\u221a\ny2\n1 + r\n(y1 + 1\nj )2irm\u2212i\n((y1 + 1\nj )2 + r)2m+1 y2m\u22121\n1 drdy1\n\u2264 1\nj\n\u222b 1\n0\n\u222b 1\n0\n(y1 + 1\nj )2irm\u2212i\n((y1 + 1\nj )2 + r)2m+1 y2m\u22122\n1 drdy1.\n\n2503.01246v1\n(2.19)\n\n8 C. Wu and J. Yang\nFurther, in view of (2.16), we deduce that\nm\u2211\ni=0\na2m+1, 2i+1\nCm\u2212i\n2m+1\n=\nm+1\u2211\ni=1\na2m+1, 2i\u22121\nCm+1\u2212i\n2m+1\n= \u2212\nm+1\u2211\ni=0\nia2(m+1), 2i\n2(m+ 1)2Cm+1\u2212i\n2m+1\n= \u2212\nm+1\u2211\ni=0\n(m+ 1 + i)a2(m+1), 2i\n2(m+ 1)2Cm+1\u2212i\n2m+1\n+\nm+1\u2211\ni=0\na2(m+1), 2i\n(2m+ 2)Cm+1\u2212i\n2m+1\n= 1\n2m+ 2\nm+1\u2211\ni=0\na2(m+1), 2i\nCm+1\u2212i\n2m+1\n\u2212 1\n2m+ 2\nm+1\u2211\ni=0\n2a2(m+1), 2i\nCm+1\u2212i\n2m+2\n, (2.20)\nwhere m\u2208 N. Analyzing analogously, by (2.17), we can obtain that\nm\u2211\ni=0\na2m, 2i\nCm\u2212i\n2m\n= 1\n2m+ 1\nm\u2211\ni=0\na2m+1, 2i+1\nCm\u2212i\n2m\n\u2212 1\n2m+ 1\nm\u2211\ni=0\n2a2m+1, 2i+1\nCm\u2212i\n2m+1\n(2.21)\nfor m \u2208 N. It is then seen from (2.18) and (2.20), and (2.19) and (2.21) that f or\nm\u2208 N\nm+1\u2211\ni=0\na2(m+1), 2i\nCm+1\u2212i\n2m+2\n= \u2212(m+ 1)\nm\u2211\ni=0\na2m+1, 2i+1\nCm\u2212i\n2m\n\u2212 2m+ 1\n2\nm\u2211\ni=0\na2m+1, 2i+1\nCm\u2212i\n2m+1\n,(2.22) m+1\u2211\ni=0\na2m+3, 2i+1\nCm+1\u2212i\n2m+3\n= \u2212 2m+ 3\n2\nm+1\u2211\ni=0\na2(m+1), 2i\nCm+1\u2212i\n2m+1\n\u2212 (m+ 1) m+1\u2211\ni=0\na2(m+1), 2i\nCm+1\u2212i\n2m+2\n.(2.23)\nFinally, using the induction hypotheses, by (2.18), (2.19), (2.22) an d (2.23) we yield\nthat\nl+1\u2211\ni=0\na2(l+1), 2i\nCl+1\u2212i\n2l+1\n= \u2212 2\n2l+ 3\nl+1\u2211\ni=0\na2l+3, 2i+1\nCl+1\u2212i\n2l+2\n= (2l+ 2)!\n22l+1 ,\n(l+ 2)\nl+1\u2211\ni=0\na2(l+1), 2i\nCl+1\u2212i\n2l+2\n= \u2212\nl+1\u2211\ni=0\na2l+3, 2i+1\nCl+1\u2212i\n2l+3\n= (2l+ 4)!\n22l+3 . In other words, (2.9) and (2.10) are satis\ufb01ed when m = l+ 1. Hence, the proof is\n\ufb01nished by induction. Lemma 2.5. Follow the notations x0 and zj in Theorem 2.2. Suppose x0 =\n(0, 0, 0) and \u03bd(x0) = (1 , 0, 0). For m\u2208 N, de\ufb01ne\nI2m\u22121 :=\n\u222b\n\u2126\n1\n|y|\n(\n\u22022m\n1\n1\n|y\u2212 zj|\n) y2m\u22121\n1 dy,\nI2m :=\n\u222b\n\u2126\n1\n|y|\u22021\n[(\n\u22022m\n1\n1\n|y\u2212 zj|\n)\ny2m\n1\n]\ndy.\nThen for arbitrarily \ufb01xed m\u2208 N, |Im| \u2192 +\u221e as j \u2192 +\u221e.\nProof. The integral is clearly bounded uniformly for j \u2208 N over the part that away\nfrom x0. Further, since \u2202\u2126 \u2208 C\u221e, we can straighten the boundary near x0. Thus,\nthere is no loss of genearlity to assume that \u2126 = {y\u2208 R3,y 2\n2 + y2\n3 <1, \u22121 <y1 <0}. For simplicity, we also set \u03b4= 1 in the de\ufb01nition of zj . Then from Lemma 2.4, it is\n\nBoundary determination for the Schr\u00a8 odinger equation 9\ndeduced that\nI2m\u22121 =\n\u222b\n\u2126\n1\n|y|\nP2m(y1 \u2212 1\nj ,\n\u221a\ny2\n2 + y2\n3)\n|y\u2212 zj|4m+1 y2m\u22121\n1 dy,\nI2m = 2 mI2m\u22121 +\n\u222b\n\u2126\n1\n|y|\nP2m+1(y1 \u2212 1\nj ,\n\u221a\ny2\n2 + y2\n3)\n|y\u2212 zj |4m+3 y2m\n1 dy.\n\n2503.00857v1\nOn one hand, multiplying (1 .2)3 by \u00b5 and using (1 .2)4, and then integrating over TN, one\nobtains after using integration by parts and (2.111) that\nd\ndt\n\u222b\nTN\n(1\n2 |\u2207\u03c6|2 + 1\n4 \u03c1\n\u23d0\n\u23d0\u03c62 \u2212 1\n\u23d0\n\u23d02\n)\n+\n\u222b\nTN\n|\u2207\u00b5|2\n=\n\u222b\nTN\n(u\u00b7 \u2207) \u03c6\u2206 \u03c6\u2264 \u2225 u\u2225\u221e\u2225\u2207\u03c6\u2225\u2225\u2206 \u03c6\u2225 \u2264 8\n(\n\u03b4+ \u03b52\u03ba2\n0\n)3\n2 . (2.115)\nIntegrating the above result over [0 ,t] and taking \u03b4 and \u03b5 are both small enough, we have\n\u2225\u2207\u03c6\u22252 + \u2225\u03c62 \u2212 1\u22252 \u2264 3\n(\n\u03b4+ \u03b52\u03ba2\n0\n)\n, (2.116)\nfor t\u2208 [0,T\u03b5]. On the other hand, combining (1 .2)3 with (1 .2)4, we can rewrite the equation as\n\u03c6t + 1\n\u03c1\u2206\n(\u2206 \u03c6\n\u03c1\n)\n\u2212 2\n\u03c1\u2206 \u03c6= 3\n\u03c1\n(\n\u03c62 \u2212 1\n)\n\u2206 \u03c6\u2212 u\u00b7 \u2207\u03c6+ 6\u03c6\n\u03c1 |\u2207\u03c6|2. (2.117)\nTaking \u2207\u03b1 to (2.117), multiplying the result by \u2207\u03b1\u2206 \u03c6 with |\u03b1| \u2264 s+ 1, we get after using\nintegration by parts that\n1\n2\nd\ndt\n\u222b\nTN\n|\u2207\u03b1\u2207\u03c6|2 +\n\u222b\nTN\n\u23d0\n\u23d0\n\u23d0\n\u23d0\u2207\u03b1\u2207\n(\u2206 \u03c6\n\u03c1\n)\u23d0\n\u23d0\n\u23d0\n\u23d0\n2\n+\n\u222b\nTN\n2\n\u03c1|\u2207\u03b1\u2206 \u03c6|2\n= \u2212\n\u222b\nTN\n\u2207\u03b1\u2206\n(\u2206 \u03c6\n\u03c1\n)[\n\u2207\u03b1\n(1\n\u03c1\u2206 \u03c6\n)\n\u2212 1\n\u03c1\u2207\u03b1\u2206 \u03c6\n]\n+\n\u222b\nTN\n[\n\u2207\u03b1\n(1\n\u03c1\u2206\n(\u2206 \u03c6\n\u03c1\n))\n\u2212 1\n\u03c1\u2207\u03b1\u2206\n(\u2206 \u03c6\n\u03c1\n)]\n\u2207\u03b1\u2206 \u03c6\n\u2212\n\u222b\nTN\n[\n\u2207\u03b1\n(2\n\u03c1\u2206 \u03c6\n)\n\u2212 2\n\u03c1\u2207\u03b1\u2206 \u03c6\n]\n\u2207\u03b1\u2206 \u03c6\u2212\n\u222b\nTN\n\u2207\u03b1\n[ 3\n\u03c1\n(\n\u03c62 \u2212 1\n)\n\u2206 \u03c6\n]\n\u2207\u03b1\u2206 \u03c6\n+\n\u222b\nTN\n\u2207\u03b1 (u\u00b7 \u2207\u03c6) \u2207\u03b1\u2206 \u03c6\u2212\n\u222b\nTN\n\u2207\u03b1\n(6\u03c6\n\u03c1 |\u2207\u03c6|2\n)\n\u2207\u03b1\u2206 \u03c6=\n6\u2211\ni=1\nQi, (2.118)\nwhere we have used the following fact from integration by parts tha t\n\u222b\nTN\n\u2207\u03b1\n(1\n\u03c1\u2206\n(\u2206 \u03c6\n\u03c1\n))\n\u2207\u03b1\u2206 \u03c6\n=\n\u222b\nTN\n[\n\u2207\u03b1\n(1\n\u03c1\u2206\n(\u2206 \u03c6\n\u03c1\n))\n\u2212 1\n\u03c1\u2207\u03b1\u2206\n(\u2206 \u03c6\n\u03c1\n)]\n\u2207\u03b1\u2206 \u03c6+\n\u222b\nTN\n1\n\u03c1\u2207\u03b1\u2206\n(\u2206 \u03c6\n\u03c1\n)\n\u2207\u03b1\u2206 \u03c6\n\nINCOMPRESSIBLE LIMIT FOR DIFFUSE INTERFACE MODELS 33\n=\n\u222b\nTN\n[\n\u2207\u03b1\n(1\n\u03c1\u2206\n(\u2206 \u03c6\n\u03c1\n))\n\u2212 1\n\u03c1\u2207\u03b1\u2206\n(\u2206 \u03c6\n\u03c1\n)]\n\u2207\u03b1\u2206 \u03c6\n\u2212\n\u222b\nTN\n\u2207\u03b1\u2206\n(\u2206 \u03c6\n\u03c1\n)[\n\u2207\u03b1\n(1\n\u03c1\u2206 \u03c6\n)\n\u2212 1\n\u03c1\u2207\u03b1\u2206 \u03c6\n]\n+\n\u222b\nTN\n\u2207\u03b1\u2206\n(\u2206 \u03c6\n\u03c1\n)\n\u2207\u03b1\n(1\n\u03c1\u2206 \u03c6\n)\n=\n\u222b\nTN\n[\n\u2207\u03b1\n(1\n\u03c1\u2206\n(\u2206 \u03c6\n\u03c1\n))\n\u2212 1\n\u03c1\u2207\u03b1\u2206\n(\u2206 \u03c6\n\u03c1\n)]\n\u2207\u03b1\u2206 \u03c6\n\u2212\n\u222b\nTN\n\u2207\u03b1\u2206\n(\u2206 \u03c6\n\u03c1\n)[\n\u2207\u03b1\n(1\n\u03c1\u2206 \u03c6\n)\n\u2212 1\n\u03c1\u2207\u03b1\u2206 \u03c6\n]\n\u2212\n\u222b\nTN\n\u23d0\n\u23d0\n\u23d0\n\u23d0\u2207\u03b1\u2207\n(\u2206 \u03c6\n\u03c1\n)\u23d0\n\u23d0\n\u23d0\n\u23d0\n2\n.", "metadata": {"type": "reasoning", "source": "2503.01246v1.pdf", "context": "Boundary determination for the Schr\u00a8 odinger equation 9\ndeduced that\nI2m\u22121 =\n\u222b\n\u2126\n1\n|y|\nP2m(y1 \u2212 1\nj ,\n\u221a\ny2\n2 + y2\n3)\n|y\u2212 zj|4m+1 y2m\u22121\n1 dy,\nI2m = 2 mI2m\u22121 +\n\u222b\n\u2126\n1\n|y|\nP2m+1(y1 \u2212 1\nj ,\n\u221a\ny2\n2 + y2\n3)\n|y\u2212 zj |4m+3 y2m\n1 dy.\nWe proceed to analyze the integral I2m\u22121 by the explicit expression of \u2126 and P2m.\nIt follows that\nI2m\u22121 =\nm\u2211\ni=0\na2m, 2i\n\u222b\n\u2126\n1\n|y|\n(y1 \u2212 1\nj )2i(y2\n2 + y2\n3)m\u2212i\n|y\u2212 zj|4m+1 y2m\u22121\n1 dy\n= 2 \u03c0\nm\u2211\ni=0\na2m, 2i\n\u222b 0\n\u22121\n\u222b 1\n0\n1\u221a\ny2\n1 + r2\n(y1 \u2212 1\nj )2ir2(m\u2212i)\n\u221a\n(y1 \u2212 1\nj )2 + r2\n4m+1 ", "quality_score": 8}}
{"id": "test_77", "question": "How do the transformation property in equation (8.3) and Lemmas 7.9 and 7.12 imply that there is a canonical injective map from H0(MY,Hr k,Y) to WN \u2264r k (\u0393Y(I))?", "golden_answers": ["The transformation property shows that any section s \u2208 H0 (\u2126, Sym r(HDR(\u03a8 Y)) \u2297 \u03c9(\u03a8 Y)\u2297(k\u2212r))\u0393 Y(I) satisfies a certain transformation equation under the action of \u0393Y(I), which is consistent with the definition of WN \u2264r k (\u0393Y(I)). Lemmas 7.9 and 7.12 provide the necessary conditions for this map to be injective."], "prediction": "The transformation property in equation (8.3) and Lemmas 7.9 and 7.12 imply that there is a canonical injective map from H0(MY,Hr k,Y) to WN \u2264r k (\u0393Y(I)) by establishing the necessary isomorphisms and structures that relate the cohomology groups and the sheaves involved. Specifically, Lemma 7.9 provides the isomorphism between \u03c0\u2217Y(\u03c9Y) and O\u2126, which allows for the identification of the sheaf structures. Lemma 7.12 then shows that the symmetric powers of the cohomology sheaves can be related to the \u0393Y(I)-invariant sections, leading to the conclusion that the map from H0(MY,Hr k,Y) to WN \u2264r k (\u0393Y(I)) is injective due to the properties of the sheaves and the action of the group \u0393Y(I).", "f1": 0.34965034965034963, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01357v1\nPart (ii) follows from (i) and the\nfunctional equation ( 4.8) of the false Eisenstein series E. \u25a1\nObserve that O\u2126 \u03b71 \u2282 HDR(\u03a8 Y) is a \u0393 Y(I)-subsheaf. Before we state our next lemma,\nrecall that \u03c9un = Lie( Eun\nI )\u2228 and \u03c9Y is its restriction to MY, after base change with C\u221e.\nLemma 7.9. We have \u03c0\u2217\nY(\u03c9Y) \u223c= O\u2126 \u03b71 as \u0393Y(I)-sheaves.\nProof. We aim to show that \u03c0\u2217\nY(\u03c9Y) is isomorphic to O\u2126 with a \u0393 Y(I)-structure given by\nmultiplication by j(\u03b3,\u2212)\u22121. Recall the notation in \u00a72.8 and let g \u2208 GL2( \u02c6A) be such that\n\u03c0g = \u03c0Y. By Proposition\n2.40, we see that \u03c0\u2217\nY(\u03c9Y) \u223c= O\u2126 . Using the commutative diagram\nin the proof of [ BBP21, Lem. 10.5], we obtain\n\u03c0\u2217\nY(\u03c9Y) O\u2126\n\u03b3\u2217\u03c0\u2217\nY(\u03c9Y) \u03b3\u2217O\u2126 = O\u2126 . \u223c\n= multiplication by j(\u03b3,\u2212)\n\u223c\nHence under the trivialization \u03c0\u2217\nY(\u03c9Y) \u223c= O\u2126 , we see that \u03b3\u2217O\u2126 = O\u2126 \u2192 O \u2126 is the map\ngiven by the multiplication by j(\u03b3,\u2212)\u22121. Equivalently, the map O\u2126 \u2192 \u03b3\u2217O\u2126 = O\u2126 obtained\nby adjunction, is also the multiplication by j(\u03b3,\u2212)\u22121, \ufb01nishing the proof of the lemma. \u25a1\nDe\ufb01nition 7.10. We de\ufb01ne HDR(\u03a8\nY\n) := HDR(\u03a8 Y)\u0393 Y(I). Furthermore, we set \u03c9(\u03a8 Y) :=\nO\u2126 \u03b71 and \u03c9(\u03a8\nY\n) := \u03c9(\u03a8 Y)\u0393 Y(I).\nRemark 7.11. Note that by Corollary 2.35, HDR(\u03a8\nY\n) = i\u2217\nY(HDR,Y) = Han\nDR,Y. Similarly\n\u03c9(\n\u03a8\nY\n) = \u03c9an\nY . We conclude this section with the following useful lemma. Lemma 7.12. Let r and k be non-negative integers so that k \u2265 r. Then there exists a\ncanonical isomorphism\nSymr(HDR(\u03a8\nY\n)) \u2297 \u03c9(\u03a8\nY\n)\u2297(k\u2212r) \u2243 (Symr(HDR(\u03a8 Y)) \u2297 \u03c9(\u03a8 Y)\u2297(k\u2212r))\u0393 Y(I). Proof. By de\ufb01nition, we have\nSymr(HDR(\u03a8\nY\n)) \u2297 \u03c9(\u03a8\nY\n)\u2297(k\u2212r) \u2243 Symr(HDR(\u03a8 Y)\u0393\nY(I)) \u2297 (\u03c9(\u03a8 Y)\u0393 Y(I))\u2297(k\u2212r). By Corollary\n2.35, applying () \u0393 Y(I) commutes with Sym r and \u2297, and hence we obtain the\nresult. \u25a1\n\n46 O \u02d8GUZ GEZM \u02d9IS \u00b8 AND SRIRAM CHINTHALAGIRI VENKATA\n8. Algebraic nearly holomorphic Drinfeld modular forms\nFor the convenience of the reader, we recall our notation from \u00a76. Let Y be the projective\nA-module of rank two embedded in K2 by Y = g(1,0) + h(0,1) \u2282 K2 for some fractional\nideals g and h of A, which are, without loss of generality, assumed to be integral ideals of\nA. Let I be an ideal of A such that |V(I)| \u2265 2. Let M2\nI,C\u221e = Spec( C\u221e) \u00d7Spec(A) M2\nI and\nset ( M2\nI,C\u221e )an to be the analyti\ufb01cation of M2\nI,C\u221e . Let MY \u2282 (M2\nI,C\u221e )an be the connected\ncomponent of M2\nI,C\u221e so that MY(C\u221e) = \u0393 Y(I) \\ \u2126 and set iY : MY \u2192 M2\nI,C\u221e to be the\ncorresponding inclusion. We also \ufb01x an embedding H \u2192 C\u221e so that MY = M2\nI \u00d7H C\u221e and\nMY := M2\nI \u00d7H C\u221e. We further denote by \u03c9Y the restriction of \u03c9un, after base change with\nC\u221e, to MY.\n\n2503.01043v2\nThen for every proper Y \u2208\nSm/F1 and integer i, the induced morphisms\nHH(X/R) \u2297R HH(YR/R) \u2192 HH(X \u00d7 Y/R),\ngrHKR\n0 HH(X/R) \u2297R HH(YR/R) \u2192 grHKR\n0 HH(X \u00d7 Y/R),\ngrHKR\ni HH(X/R) \u2297R grHKR\n0 HH(YR/R) \u2192 grHKR\ni HH(X \u00d7 Y/R)\nare isomorphisms, where YR := Spec( R) \u00d7 Y . Proof. Argue as in Lemma 7.1, but use the blow-up and projective bundle for mulas\nfor HH( \u2212/R) obtained by the formulas for THH in [14, Theorems 1.4, 1.5] and the\nformulas for Hodge cohomology. \u25a1\nTheorem 7.15. Let S \u2208 Sch. Then the presheaf of complexes R\u0393 Zar(\u2212, \u2126 i\n\u2212/S) on\nSm/S is logarithmic for every integer i \u2265 0. Proof. We can work Zariski locally on S, so we may assume that S = Spec( R)\nfor some ring R. Argue as in Lemma 7.3 and use Lemma 7.14 to show that the\nfollowing conditions are equivalent. (1) \u2113ogHH(X \u00d7 \u25a1 n/R) \u2243 HH(X/R) for all X \u2208 Sm/S and n \u2208 N. (2) \u2113og grHKR\ni HH(X \u00d7 \u25a1 n/R) \u2243 grHKR\ni HH(X) for all X \u2208 Sm/S, i \u2208 Z, and\nn \u2208 N. We have checked that HH( \u2212/R) is logarithmic, so we have (1). Furthermore, (2)\nis what we need to show due to (7.10). \u25a1\nConjecture 7.16. Let S \u2208 Rg. Then the algebraic cobordism spectrum MGL \u2208\nSH(S) due to Voevodsky [68, \u00a76.3] is logarithmic. Conjecture 7.16 is conceptually reasonable but technically more dem anding than\nTheorem 7.10. The proof of Theorem 7.7 heavily uses known combinat orial com-\nputations of Chow groups of toric varieties. Hence we would need to walk through\nmore complicated computations of algebraic cobordism of toric varie ties, see [41,\nCorollary 1.2] for such a computation. If we prove Conjecture 7.16 , then the fol-\nlowing one would be also reachable:\nConjecture 7.17. Let S \u2208 Rg. Then every MGL-module in MS Nis(S) is loga-\nrithmic. This would indicate that there is a close relationship between the full s ubcate-\ngories of orientable objects of MS Nis(S) and logSH( S). CONSTRUCTION OF LOGARITHMIC COHOMOLOGY THEORIES I 51\n8. Motivic representability of logarithmic K-theory\nIn this section, we show that K-theory is representable in logSH( S) for every\nS \u2208 Sch, see Theorem 8.13. We \ufb01rst need to set up a natural transfor mation u as\nfollows. Construction 8.1. Let S \u2208 Sch. Then we have the natural transformation\nu: id \u2192 \u02dc\u2113og: Sh sNis(SmlSm/S, Sp) \u2192 ShsNis(SmlSm/S, Sp)\ngiven as follows. The morphism of spectra u(F)(X), which we denote by uF (X),\nis given by\n(8.1) colim\nn\u2208\u2206 op\nF(X) \u2192 colim\nn\u2208\u2206 op\ncolim\nY \u2208(SBln\nX )op\nF(Y )\nfor F \u2208 ShsNis(SmlSm/S, Sp) and X \u2208 SmlSm\u2032/S, see De\ufb01nition 5.9 for SmlSm \u2032/S. Here, the colimit on the source is the constant colimit, and when n is \ufb01xed, the\nmorphism F(X) \u2192 colimY \u2208(SBln\nX )op F(Y ) factors through F(X) \u2192 F (X \u00d7 \u25a1 n)\ninduced by the projection X \u00d7 \u25a1 n \u2192 X. Proposition 8.2.\n\n2503.01043v2\nSmlSm /S) with a dividing cover g satisfying g = f, where X \u00d7\n(Glog\nm )n \u2192 X \u00d7 \u25a1 n is the canonical map whose underlying morphism of schemes is\nthe identity. Observe that every morphism in SBl n\nX is an admissible blow-up. De\ufb01nition 5.2. For X \u2208 RglRg (resp. X \u2208 SmlSm/S with S \u2208 Sch) and n \u2208\nN, let Sdiv n\nX be the category of dividing covers g : V \u2192 X \u00d7 (Glog\nm )n such that\ng\u22121(X \u00d7 An\nN) \u2192 X \u00d7 An\nN is an isomorphism. We need the following basic result since we often need to check that t wo mor-\nphisms of fs log schemes are equal. Proposition 5.3. Let X \u2208 RglRg (resp. X \u2208 SmlSm/S with S \u2208 Sch). Then the\nlog structure map MX \u2192 O X is injective. Furthermore, for every fs log scheme Y ,\nthe map\nHom(X, Y ) \u2192 Hom(X\n, Y ), f \u21a6\u2192f\nis injective. Proof. If X \u2208 RglRg or S is normal, then the log structure on X is the com-\npactifying log structure by [52, Proposition III.1.7.3(4)], so the log s tructure map\nMX \u2192 O X is injective by de\ufb01nition, and [52, Proposition III.1.6.2] implies the\nother claim. For general S, let f1, f2 : X \u21d2 Y be two morphisms such that f1\n= f2. We have\nthe induced commutative square\nMY OY\nfi\u2217MX fi\u2217OX\nfor i = 1 , 2. If MX \u2192 O X is injective, then the two morphisms MY \u2192 f1\u2217MX\nand MY \u2192 f2\u2217MX agree, so we have f1 = f2. Hence it su\ufb03ces to show that\nMX \u2192 O X is injective. Equivalently, it su\ufb03ces to show that MX,x \u2192 O X,x is\ninjective for every point x \u2208 X. We set A := OX,x. Let P be a neat chat of X at x in the sense of [52, De\ufb01nition\nII.2.3.1(2)]. Then the induced morphism P \u2192 MX,x is an isomorphism, and P \u2243\nNd for some integer d. Let \u03b1: P \u2192 A be the log structure map. Then we have\n\u03b1\u22121(A\u2217) = 0 since P \u2243 MX,x. The log structure MX,x associated with P is\nP \u2295\u03b1\u22121(A\u2217) A\u2217 \u2243 P \u2295 A\u2217, see [52, (II.1.1.1)]. Hence it su\ufb03ces to show that the\ninduced map \u03b7 : P \u2295A\u2217 \u2192 A is injective. Let e1, . . . , e d be the standard coordinates\nin Nd. Observe that \u03b7(ei) is a nonzero divisor for each i since X \u2212 \u2202X is dense in\nX. Let S\u2032 be the normalization of S, and let f : A \u2192 B be the map of rings whose\nspectrum is Spec( OX,x) \u00d7S S\u2032 \u2192 Spec(OX,x). Assume that\n\u03b7(u + a1e1 + \u00b7 \u00b7 \u00b7 + aded) = \u03b7(v + b1e1 + \u00b7 \u00b7 \u00b7 + bded)\n\nCONSTRUCTION OF LOGARITHMIC COHOMOLOGY THEORIES I 31\nwith u, v \u2208 A\u2217 and a1, . . . , a d, b1, . . . , b d \u2208 N.", "metadata": {"type": "reasoning", "source": "2503.01357v1.pdf", "context": "describe the nearly holomorphic Drinfeld modular forms as the global sections of the sheaf\nHr\nk := Sym r(HDR,un) \u2297 \u03c9un\u2297(k\u2212r) pulled back to the appropriate component of M2\nI,C\u221e . To\nachieve our goal, in what follows, we \ufb01rst denote by HDR,Y (HDR,Y resp.) the pull back of\nHDR,un (HDR,un resp.), after base change with C\u221e, to MY (MY resp.) Moreover, we let\nHr\nk,Y := Sym r(HDR,Y) \u2297 \u03c9\u2297(k\u2212r)\nY and Hr\nk,Y := Sym r(HDR,Y) \u2297 \u03c9\u2297(k\u2212r)\nY .\nLet WN \u2264r\nk (\u0393Y(I)) be the C\u221e-vector space of weak nearly holomorphi", "quality_score": 8}}
{"id": "test_78", "question": "Do the speakers interrupt each other in the provided audio?", "golden_answers": ["No, they do not interrupt each other."], "prediction": "(b) No", "f1": 0.22222222222222224, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01174v1\nThe second speaker\u2019s overlap is a mistimedattempt to start their turn, and the first speaker willcontinue, forcing the second speaker to wait for anatural break or pause before speakingQwen2-Audio-Instruct\nB\nInterruption Qwen-Audio-Chat Based solely on the provided audio, it is morelikely that the second speaker\u2019s overlap is a suc-cessful interruption, and they will take over theconversation. This is because the audio endsabruptly as the second speaker begins to speak,suggesting that the first speaker was interrupted. Additionally, the second speaker\u2019s tone soundsconfident and assertive, which is characteristic ofsomeone who is trying to take over a conversation. On the other hand, the first speaker\u2019s response isshort and does not indicate that they are about topause or continue speaking. Whisper+GPT-4o During spontaneous human conversation, inter-ruptions occur frequently and often correspond tobreaks in the information flow between conver-sation partners. Interruptions can happen due toa variety of reasons like urgency, disagreement,etc. Interruptions can be broadly classified intotwo categories: competitive and cooperative in-terruptions. Occurrences of competitive interrup-tions are usually disrupting to the flow of con-versation between speakers while cooperative in-terruptions are more supportive to the flow. Youare examining a short audio clip from a conver-sation between two people. The audio ends sud-denly RIGHT as the second speaker begins to talk,overlapping with the first speaker. It\u2019s impossibleto tell from this brief excerpt if the first speakerwas about to pause, was having trouble finding aword, or would have continued speaking. BasedONLY on the provided audio, is it more likelythat: (a) The second speaker\u2019s overlap is a suc-cessful interruption, and they will take over theconversation? (b) The second speaker\u2019s overlap isa mistimed attempt to start their turn, and the firstspeaker will continue, forcing the second speakerto wait for a natural break or pause before speak-ing? Justify your choice, considering the fac-tors that might lead to a successful interruptionor encourage someone to wait their turn, but fo-cus on how the SPECIFIC TIMING of this over-lap makes one outcome more likely than the other. Based on the provided audio excerpt, it is morelikely that: (b) The second speaker\u2019s overlap is amistimed attempt to start their turn, and the firstspeaker will continue, forcing the second speakerto wait for a natural break or pause before speak-ing. Justification: 1. **Context and Flow**: Thefirst speaker is in the middle of a detailed expla-nation about weather patterns and their impact onsnowfall. They have not yet reached a clear con-clusion or natural pause in their narrative. Thesentence\u00a8But I have played\u00a8suggests that the firstspeaker is about to continue with a related pointor anecdote. 2. **Timing of Overlap**: The over-lap occurs just as the first speaker is transitioningto a new but related point (\u00a8But I have played\u00a8).This timing suggests that the first speaker is notfinished and is likely to continue speaking. Thesecond speaker\u2019s attempt to interject at this mo-ment is mistimed because it interrupts the flow ofthe first speaker\u2019s ongoing thought. 3. **Con-versational Dynamics**: In spontaneous conver-sation, speakers often signal the end of their turnwith a clear pause or a concluding statement.\n\n2503.01174v1\nWhen interrupting speaker takes the floor 51.4 [ 26.2, 83.8]\nWhen interrupting speaker does not take the floor 70.6 [ 14.1, 93.5]\nTable 11: Consistency of the GPT-4o\u2019s turn-taking decisions with judge labels across our proposed\nmetrics along with 95% confidence intervals\n25\n\nPublished as a conference paper at ICLR 2025\nTurn-taking event Model Prompts Example Output\nTurn Change\nSALMONN No, the given audio\ndoes not have a turn\nchange. Qwen2-\nAudio-\nInstruct\nDoes the given audio has a\nturn change anywhere?\nBriefly explain your answer. You must reply with (a) Yes\nor (b) No. No, there is no turn\nchange in the speech\nas the pitch and\ntone remain consis-\ntent throughout the\nrecording. Qwen-Audio-\nChat Yes, there is a turn\nchange in the given\naudio. The male\nspeaker starts speak-\ning and then the fe-\nmale speaker starts\nspeaking. Whisper+GPT-\n4o\nDoes the given audio has\na turn change anywhere?\nBriefly explain your answer. You must reply with (a) Yes\nor (b) No.\n(b) No\nBackchannel\nSALMONN Backchannels are brief\nwords or sounds (like \u2019um,\u2019\n\u2019right,\u2019 or \u2019okay\u2019) that a\nlistener makes to show\nthey\u2019re paying attention. Do\nthe 2 speakers backchannel\nanywhere in the provided\naudio? Briefly explain your\nanswer. You must reply\nwith (a) Yes or (b) No. No, the speakers do\nnot backchannel in\nthe provided audio. Qwen2-\nAudio-\nInstruct\nNo, there are no\nbackchannels in this\naudio. Qwen-Audio-\nChat\nYes, the two speakers\nbackchannel briefly\nin the provided au-\ndio.\nWhisper+GPT-\n4o\nDo the 2 speakers backchan-\nnel anywhere in the pro-\nvided audio? Briefly explain\nyour answer. You must reply\nwith (a) Yes or (b) No.\n(b) No\nInterruption\nSALMONN Do the 2 speakers interrupt\neach other anywhere in the\nprovided audio? Briefly\nexplain your answer. You\nmust reply with (a) Yes or\n(b) No. No, the 2 speakers\ndo not interrupt each\nother in the provided\naudio.\nQwen2-\nAudio-\nInstruct\nNo, the speakers do\nnot interrupt each\nother. They speak at\ndifferent times and\ntheir overlapping is\nminimal. Qwen-Audio-\nChat\nYes, the two speakers\ninterrupt each other. Whisper+GPT-\n4o\nDo the 2 speakers interrupt\neach other anywhere in the\nprovided audio? Briefly ex-\nplain your answer. You must\nreply with (a) Yes or (b) No.\n(b) No\nTable 12: Prompts for audio foundation models on test benchmarks evaluating their ability to un-\nderstand turn-taking events. All open source FMs have same best prompt. 26\n\nPublished as a conference paper at ICLR 2025\nTurn-taking event Model Prompts Example Output\nTurn Change\nSALMONN You are provided the audio of a 2 speakerconversation. The current speaker takes pause atthe end of current audio. Given the providedaudio, do you think that after the pause, thecurrent speaker will (A) continue talking or (B)the second speaker will speak up. Output only Aor B, nothing else. Among A or B, the answer is\n(B) The second speaker will speak up. Qwen2-Audio-Instruct\nThe current speaker will continue talking. Qwen-Audio-Chat B\nWhisper+GPT-4o You are provided the audio of a 2 speaker conver-sation. The current speaker takes pause at the endof current audio.\n\n2503.01174v1\nOccurrences of competitive interruptionsare usually disrupting to the flow of conversationbetween speakers while cooperative interruptionsare more supportive to the flow. You are analyzinga brief audio clip from a two-person conversation. The clip ends abruptly while the current speaker isstill in the middle of a sentence. It is unclear fromthe provided audio whether the speaker is about topause, is struggling to find the right word, or willcontinue speaking uninterrupted. Based ONLYon the provided audio, is it more likely that: (a)The other speaker will interrupt BEFORE the cur-rent speaker finishes their sentence? (b) The otherspeaker will let the current speaker to continuespeaker? Justify your choice, considering the fac-tors that might lead to an interruption or encouragesomeone to wait their turn. Based on the provided audio, it is more likely that:(b) The other speaker will let the current speakercontinue speaking. Justification: 1. **Flow ofConversation**: The current speaker is narratinga story with a clear sequence of events. The nar-rative seems to be reaching a conclusion, as indi-cated by the speaker\u2019s expression of satisfaction (\u00a8Ijust had the biggest grin on my face\u00a8). 2. **Lis-tener\u2019s Engagement**: The other speaker has al-ready shown engagement and support by interject-ing with\u00a8I\u2019ll bet you did,\u00a8which is a cooperative in-terruption. This indicates that the listener is fol-lowing the story and is likely to allow the speakerto finish their thought. 3. **Lack of Urgency orDisagreement**: There are no signs of urgencyor disagreement in the provided audio. The toneof the conversation is casual and friendly, whichreduces the likelihood of a competitive interrup-tion. 4. **Narrative Completion**: The currentspeaker is in the middle of a sentence that seemsto be wrapping up the story. Interrupting at thispoint would disrupt the natural conclusion of thenarrative. Given these factors, it is more reason-able to expect that the other speaker will wait forthe current speaker to finish their sentence beforeresponding.\nTable 13: Prompts for audio foundation models on test benchmarks evaluating their ability topredict\nturn-taking events. All open source FMs have same best prompt. 27\n\nPublished as a conference paper at ICLR 2025\nTurn-taking event Model Prompts Example Output\nSuccessful SALMONN You are examining a short audio clip from aconversation between two people. The audio endssuddenly RIGHT as the second speaker begins totalk, overlapping with the first speaker. It\u2019simpossible to tell from this brief excerpt if thefirst speaker was about to pause, was havingtrouble finding a word, or would have continuedspeaking. Based ONLY on the provided audio, isit more likely that: (A) The second speaker\u2019soverlap is a successful interruption, and they willtake over the conversation? (B) The secondspeaker\u2019s overlap is a mistimed attempt to starttheir turn, and the first speaker will continue,forcing the second speaker to wait for a naturalbreak or pause before speaking? Output only Aor B, nothing else. Among A or B, the answer is\n(B)", "metadata": {"type": "factual", "source": "2503.01174v1.pdf", "context": "with (a) Yes or (b) No.\n(b) No\nInterruption\nSALMONN Do the 2 speakers interrupt\neach other anywhere in the\nprovided audio? Briefly\nexplain your answer. You\nmust reply with (a) Yes or\n(b) No.\nNo, the 2 speakers\ndo not interrupt each\nother in the provided\naudio.\nQwen2-\nAudio-\nInstruct\nNo, the speakers do\nnot interrupt each\nother. They speak at\ndifferent times and\ntheir overlapping is\nminimal.\nQwen-Audio-\nChat\nYes, the two speakers\ninterrupt each other.\nWhisper+GPT-\n4o\nDo the 2 speakers interrupt\ne", "quality_score": 8}}
{"id": "test_79", "question": "What is preserved by any homomorphism of Kripke models?", "golden_answers": ["The tree order of a synchronization tree."], "prediction": "The tree order of a synchronization tree is preserved by any homomorphism of Kripke models.", "f1": 0.5555555555555556, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01247v1\n\u2a7d k with root a, and\n(M) for all x, y\u2208 A, x \u227a y if and only if RA(x, y) for some unique R \u2208 \u03c3. \u2022 morphisms: homomorphisms of Kripke models. 1Equivalently, it is a monotone map that preserves the height of elements. 10 SAMSON ABRAMSKY, THOMAS LAURE, AND LUCA REGGIO\nNote that the tree order of a synchronization tree is \u201cdefinable\u201d and hence preserved\nby any homomorphism of Kripke models. Thus the forgetful functor Lk : EM(Mk) \u2192\nStruct\u2022(\u03c3) is fully faithful and can be identified with the inclusion into Struct\u2022(\u03c3) of\nthe full subcategory defined by synchronization trees of height \u2a7d k. Its right adjoint\nFk : Struct\u2022(\u03c3) \u2192 EM(Mk) sends a Kripke model to its k-unravelling.\nRemark 3.5. In fact, the modal comonads Mk are idempotent, meaning that their\ncomultiplications \u03b4 are natural isomorphisms. In turn, idempotent comonads on a\ncategory C correspond precisely to coreflective subcategoriesof C, i.e. full subcategoriesD\nsuch that the inclusion functor D ,\u2192 C has a right adjoint. 3.3. Logical equivalences. In [2, 6] it was shown how game comonads can be used to\ncapture, in a categorical fashion, preservation of various fragments and extensions of the\nlogics FOk, Lk and MLk. We recall here the case of the existential positive fragments\nand the full fragments, and outline the way in which the equality symbol is handled in\nthe framework of game comonads. Existential positive fragments. Given a collection of formulas L \u2286 L\u221e,\u03c9, consider its\nexistential positive fragment\n\u2203+L\nconsisting of formulas with no universal quantifiers and no negations; for modal logic,\nthis corresponds to barring the use of modalities \u25a1R and negations. The next result\nshows that preservation of existential positive fragments is captured by the homomorph-\nism preorder in the Eilenberg\u2013Moore category for the corresponding comonad (for a\nproof, cf. [2, 6] and also [7]).2 Recall that, for a comonad Gk on a category C, we denote\nby Fk : C \u2192 EM(Gk) the right adjoint to the forgetful functor Lk : EM(Gk) \u2192 C.\nTheorem 3.6. The following are equivalent for all (pointed) structures A and B:\n(i) A \u21db\u2203+FOk B if, and only if, there exists an arrow FkA \u2192 FkB in EM(Ek). (ii) A \u21db\u2203+Lk B if, and only if, there exists an arrow FkA \u2192 FkB in EM(Pk).\n(iii) (A, a) \u21db\u2203+MLk (B, b) if, and only if, there exists an arrow Fk(A, a) \u2192 Fk(B, b)\nin EM(Mk). The equality symbol. In their basic form, game comonads capture fragments of logics\nwithout equality. This is sufficient for modal logic, since the image of the standard\ntranslation is contained in the equality-free fragment of FO, and was also sufficient for\nTheorem 3.6, since the fragments \u2203+FOk and \u2203+Lk admit equality elimination. To\nmodel logics with equality, such as the fragments FOk and Lk, we proceed as follows. Given a relational vocabulary \u03c3, consider a fresh binary relation symbol I and the\nexpanded vocabulary\n\u03c3I := \u03c3 \u222a {I}.\n\n2503.01247v2\nLet \u03c3 be a (multi)modal vocabulary and let D ,\u2192 Struct\u2022(\u03c3) be a full\nsubcategory of pointed Kripke models. The following statements are equivalent:\n(i) D = Mod(\u03c8) for some \u03c8 \u2208 +MLk. (ii) D is upwards closed with respect to the preorder \u21db+MLk, that is\n(A, a) \u21db+MLk (B, b) and (A, a) \u2208 D =\u21d2 (B, b) \u2208 D.\nProof. This well-known fact follows from the existence of finitely many formulas in\n+MLk up to logical equivalence. It can be deduced from the corresponding statement\nfor first-order formulas with bounded quantifier rank, see e.g. [19, Lemma 3.13]. \u25a1\nProof of Theorem 9.1. (i) \u21d2 (ii) If \u03c6 is preserved under surjective homomorphisms\nbetween pointed Kripke models, then the category Mod(\u03c6) is closed in Struct\u2022(\u03c3)\nunder surjective images and saturated under the equivalence relation \u2261MLk. In view of\nLemma 9.3, it suffices to show that Mod(\u03c6) is upwards closed with respect to \u21db+MLk. Suppose that (A, a) \u21db+MLk (B, b). By Theorem 5.3(3), there is a positive bisimulation\nFk(A, a) \u2192 Fk(B, b) in EM(Mk), where the latter can be identified with the full\nsubcategory of Struct\u2022(\u03c3) defined by synchronization trees of height \u2a7d k. Such a\npositive bisimulation is of the form\nZ\nFk(A, a) Fk(B, b)\nf g\nwhere f is a p-morphism of Kripke models and g is a homomorphism of Kripke models\nthat is a p-morphism between the underlying tree orders; in particular g is surjective. Therefore, if Mod(\u03c6) contains (A, a) then it contains its k-unravelling Fk(A, a) because\n(A, a) \u2261MLk Fk(A, a), and so it contains also Z because p-morphisms (preserve and)\n\n40 SAMSON ABRAMSKY, THOMAS LAURE, AND LUCA REGGIO\nreflect the validity of modal formulas. In turn, since g is surjective we get Fk(B, b) \u2208\nMod(\u03c6), and reasoning as before we conclude that ( B, b) \u2208 Mod(\u03c6). The same proof, mutatis mutandis, yields the relativisation to finite Kripke models. Just observe that if ( A, a) and (B, b) are finite, then so are Fk(A, a) and Fk(B, b). The\nKripke model Z is also finite, as it can be identified with the object Z1 constructed in\nthe fourth step of the proof of Proposition 8.12. Concretely, the underlying set of Z is a\nsubset of the underlying set of Fk(A, a) \u00d7 Fk(B, b), hence it is finite.\n(ii) \u21d2 (i) This is a straightforward verification. \u25a1\nAppendix A. Omitted proofs of logical equivalences via games\nIn this appendix we provide detailed proofs for the results in Sections 4 and 5 whose\nproofs were either sketched or omitted.\nProposition 4.2. The following statements are equivalent for all structures A, B:\n(i) A \u21db\u2203FOk B, i.e. every sentence of \u2203FOk that is true in A is true in B.\n(ii) Duplicator has a winning strategy in the k-round existential Ehrenfeucht-Fra\u00a8 \u0131ss\u00b4 e\ngame from A to B.\nProof. (i) \u21d2 (ii) Let C \u2208 {A, B}. For i \u2a7e 0 and c1, . . . , ci \u2208 C, recall that the \u2203FOk-type\nof c1, . . .\n\n2503.01247v2\nThe forgetful functor Lk : EM(Pk) \u2192 Struct(\u03c3) forgets both the forest order and the\npebbling function, and its right adjoint Fk : Struct(\u03c3) \u2192 EM(Pk) sends a structure A\nto (PkA, \u2291, pA), where the pebbling function is given by pA([(p1, a1), . . . ,(pn, an)]) := pn.\nMk-coalgebras. The Eilenberg\u2013Moore category EM(Mk) for the modal comonad Mk is\nisomorphic to the following category:\n\u2022 objects: synchronization trees of height \u2a7d k, i.e. tuples ( A, a,\u2a7d) such that (A, a)\nis a pointed Kripke model, \u2a7d is a tree order on A of height \u2a7d k with root a, and\n(M) for all x, y\u2208 A, x \u227a y if and only if RA(x, y) for some unique R \u2208 \u03c3. \u2022 morphisms: homomorphisms of Kripke models. 1Equivalently, it is a monotone map that preserves the height of elements. 10 SAMSON ABRAMSKY, THOMAS LAURE, AND LUCA REGGIO\nNote that the tree order of a synchronization tree is \u201cdefinable\u201d and hence preserved\nby any homomorphism of Kripke models. Thus the forgetful functor Lk : EM(Mk) \u2192\nStruct\u2022(\u03c3) is fully faithful and can be identified with the inclusion into Struct\u2022(\u03c3) of\nthe full subcategory defined by synchronization trees of height \u2a7d k. Its right adjoint\nFk : Struct\u2022(\u03c3) \u2192 EM(Mk) sends a Kripke model to its k-unravelling.\nRemark 3.5. In fact, the modal comonads Mk are idempotent, meaning that their\ncomultiplications \u03b4 are natural isomorphisms. In turn, idempotent comonads on a\ncategory C correspond precisely to coreflective subcategoriesof C, i.e. full subcategories D\nsuch that the inclusion functor D ,\u2192 C has a right adjoint. 3.3. Logical equivalences. In [2, 6] it was shown how game comonads can be used to\ncapture, in a categorical fashion, preservation of various fragments and extensions of the\nlogics FOk, Lk and MLk. We recall here the case of the existential positive fragments\nand the full fragments, and outline the way in which the equality symbol is handled in\nthe framework of game comonads. Existential positive fragments. Given a collection of formulas L \u2286 L\u221e,\u03c9, consider its\nexistential positive fragment\n\u2203+L\nconsisting of formulas with no universal quantifiers and no negations; for modal logic, this\ncorresponds to barring the use of modalities \u25a1R and negations. The next result shows\nthat preservation of existential positive fragments is captured by the homomorphism\npreorder in the Eilenberg\u2013Moore category for the corresponding comonad (for a proof,\ncf. [2, 6] and also [ 7]).2 Recall that, for a comonad Gk on a category C, we denote by\nFk : C \u2192 EM(Gk) the right adjoint to the forgetful functor Lk : EM(Gk) \u2192 C.\nTheorem 3.6. The following are equivalent for all (pointed) structures A and B:\n(i) A \u21db\u2203+FOk B if, and only if, there exists an arrow FkA \u2192 FkB in EM(Ek). (ii) A \u21db\u2203+Lk B if, and only if, there exists an arrow FkA \u2192 FkB in EM(Pk).\n(iii) (A, a) \u21db\u2203+MLk (B, b) if, and only if, there exists an arrow Fk(A, a) \u2192 Fk(B, b)\nin EM(Mk). The equality symbol.", "metadata": {"type": "factual", "source": "2503.01247v2.pdf", "context": "10 SAMSON ABRAMSKY, THOMAS LAURE, AND LUCA REGGIO\nNote that the tree order of a synchronization tree is \u201cdefinable\u201d and hence preserved\nby any homomorphism of Kripke models. Thus the forgetful functor Lk : EM(Mk) \u2192\nStruct\u2022(\u03c3) is fully faithful and can be identified with the inclusion into Struct\u2022(\u03c3) of\nthe full subcategory defined by synchronization trees of height \u2a7d k. Its right adjoint\nFk : Struct\u2022(\u03c3) \u2192 EM(Mk) sends a Kripke model to its k-unravelling.\nRemark 3.5. In fact, the modal comonads M", "quality_score": 8}}
{"id": "test_80", "question": "What type of learning does the incorporation of control parameters achieve in this model?", "golden_answers": ["The incorporation of specific actions (control parameters) achieves tailored learning for a specific domain or machine setup"], "prediction": "The incorporation of control parameters achieves a probabilistic learning approach, allowing players to learn and adapt their strategies based on the distribution of potential controls and the behavior of opponents.", "f1": 0.29268292682926833, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "The Learning Approach to Games\nJust as a child starts with limited\ncapacities and gradually acquires a rich repertoire, such dynamic structural growth might\nindeed be essential for modeling higher-order intelligence. While this remains far beyond\ncurrent work, it represents a compelling direction for future research. As the player faces the optimization problem (2.6), it is not always feasible to solve for\nthe optimal control. When \u02c6T = 1, the problem might be relatively simple, allowing for\nstraightforward searches for \u03f5-optimal actions. However, for longer horizons, the space of\npotential controls becomes excessively large, complicating the search for optimal solutions. To formalize this, let us first define\n\u03b1 =t,x;i \u02dc\u03b1 if \u03b1(s, y) = \u02dc\u03b1(s, y) \u2200s \u2208 {t, . . . , t+ \u02c6Ti(t, x) \u2212 1}, y \u2208 Ss\nUnder this equivalency relation, we introduce the quotient space\nAt,x;i := Ai/ =t,x;i\nAnd then, to incorporate the potential difficulty and uncertainty in identifying the optimal\ncontrol, we introduce the next learning parameter;\n\u02c6\u03c0 : \u02c6\u2126 \u00d7 T \u00d7 \u2126 \u2192 P(Ai) where ,\n\u02c6\u03c0(\u02c6\u03c9, t, x)(d\u03b1) = \u02c6\u03c0(\u02c6\u03c9, t, x)(d\u02dc\u03b1) whenever \u03b1 =t,x;i \u02dc\u03b1\n(2.7)\nHere, at (\u02c6\u03c9, t, x), \u02c6\u03c0 approximates the potential optimal controls forJ(\u02c6\u03c9, t, x,\u00b7), which will be\ndictated by the equilibrium condition below. Note that, the equality should be understood\nin terms of two subsets of controls having equal probabilities, when they are equal once\nextended with the relation = t,x;i. Also, we didn\u2019t suppress \u02c6\u03c9 as it will be integrated. 9\n\nNow, the crucial observation is that, even when optimal control can be solved exactly,\nuncertainty over the value will naturally induce a probability distribution over controls. That is, given ( \u02c6T ,\u02c6p, \u02c6\u0393, \u02c6F ,\u02c6\u03d5, \u02c6\u03c0), we define \u03a5t,x;i \u2208 P(At,x;i) as\n\u03a5t,x;i(d\u03b1) :=\nZ\n\u02c6\u2126\n\u02c6\u03c0(\u02c6\u03c9, t, x)(d\u03b1)\u02c6P(d\u02c6\u03c9) (2.8)\nWe have introduced distributions over controls, which then further induces distribution over\nactions:\n\u03b3t,x;i(da) := \u03a5t,x;i\u0000\n\u03b1 : \u03b1(t, x) = da\n\u0001\n\u2208 P(At,x;i) (2.9)\nAlthough apriori \u03a5t,x;i appears to be solely induced by \u02c6\u03c0, \u02c6\u03c0 itself is a function of the value\nJi, and hence \u03a5t,x;i is a function from MT \u00d7Mp\u00d7M\u0393\u00d7MF \u00d7M\u03d5\u00d7M\u03c0. We introduced \u02c6\u03c0 to\ncarry out the discussions more explicitly.2 In the two-player example discussed in section 2.1,\n\u02c6\u03c0 solves the optimization by brute force, yielding a deterministic action for each scenario\nin \u02c6\u2126. In the control problem described in section 4, \u02c6 \u03c0 constructs the distribution over\nstrategies relying again on the associated values. Let us note that we induce a distribution\nover controls because it is a more familiar and convenient choice; however, by considering\nsequences of future states, one can easily induce a distribution over sequences of actions. This behavior, represented by \u02c6\u03c0, is well suited for the learning or playing phase and is,\nin essence, Thompson sampling adapted to our framework. During a competition phase,\none might modify \u02c6\u03c0 to be deterministic, selecting the control corresponding to the mode\nof the value. In particular situations, such as performing surgery, it is not only wrong but\nalso unethical to forgo the most likely action and instead select one at random.\n\nThe Learning Approach to Games\nGiven \u02c6p as in (2.2), an initial ( t, x) \u2208 (T, St), and \u20d7 \u03b1\u2208 \u20d7A, player induces a distribution\nPt,x,\u20d7 \u03b1:= P\u02c6p;t,x,\u20d7 \u03b1for the canonical process as usual; for all t \u2264 s and (\u02dcx, y) \u2208 (Ss, Ss+1),\nPt,x,\u20d7 \u03b1(Xs+1 = y|Xs = \u02dcx) = \u02c6p(s, \u02dcx, \u20d7 \u03b1(s, \u02dcx); y), and Pt,x,\u20d7 \u03b1(Xt = x) = 1 (2.3)\nNote that relaxed controls further integrate over the distribution of controls to define (2.3). We instead integrate the value below. It is crucial that players learn about other players\u2019 behavior. To fully understand any\ncomplex game, we cannot overlook this fact. Knowledge of opponents\u2019 strategies intrinsically\nalters the observed events within the game. Even a player\u2019s value depends on it, as different\nopponents might tend to employ varying strategies. Consequently, the value associated with\na strategy cannot disregard the opponents\u2019 reactions. Thus, we assume that a player learns\npotential controls of others based on their own control;\n\u02c6\u0393i : T \u00d7 Ai \u2192 P( \u20d7A) and set \u02c6\u0393i\nt,\u03b1(d\u20d7 \u03b1) := \u02c6\u0393i\nt(\u03b1; d\u20d7 \u03b1) := \u02c6\u0393i(t, \u03b1)(d\u20d7 \u03b1) (2.4)\nDenote M\u0393 as the space of all such mappings. We remark two points for (2.4):\n(i) Here, we assume that players model the others potential controls depending on their\nown control. However, one might model that this depends on the path of states of\nthe players, or in fact, any other observables are legitimate as long as the cost (2.6)\nis well-defined. Our choice here is to illustrate the optimization in a visible manner. (ii) It is crucial for players to learn reliable \u02c6\u0393. To not only compete with but also cooperate\nwith other players, they must generate reliable estimates of the actions of others. We\nwill show in the two-player game discussed in Section 2.1 that because the costs to\nthe players depend on each other\u2019s states, omitting this aspect from the player model\nwon\u2019t accurately capture the observed dynamics. A crucial notion to introduce is the value of a player. We observe that value is fundamen-\ntally a formalism used to determine an optimal action. We do not regard it as something\n7\n\ntangible that a player necessarily obtains, which might only be the case in limited situations. However, even in these situations, value is typically considered an expectation rather than\na definitive quantity. Now, we introduce two concepts: transition costs and state values,\nwhich are akin to running costs and terminal costs in the literature 1:\n\u02c6F : \u02c6\u2126 \u00d7 T \u00d7 \u2126 \u00d7 \u20d7A \u2192 R, \u02c6\u03d5 : \u02c6\u2126 \u00d7 T \u00d7 \u2126 \u2192 R, (2.5)\nand let MF , M\u03d5 denote the sets of mappings as in (2.5). An important difference is that the\nplayer models these as random variables on some probability space ( \u02c6\u2126, \u02c6F, \u02c6P). In particular\ncases, it might be useful to characterize the measure space ( \u02c6\u2126, \u02c6F, \u02c6P), however, once can\nalso fix the sufficiently large probability space ([0 , 1], B([0, 1]), m) and concentrate on the\nrandom variables.\n\nThe Learning Approach to Games\nGiven ( x0, a0) \u2208 S \u00d7 A, introduce an induced distribution\nfrom the model of the player \u02c6p and \u03b3x as\n\uf8f1\n\uf8f2\n\uf8f3\n\u02dcPx0,a0(Xs+1 = dy, Is+1 = d\u02dca|Xs = x, Is = a) := \u02c6p(x, a; dy)\u03b3y(d\u02dca), s \u2265 0\n\u02dcPx0,a0(X0 = x0, I0 = a0) = 1\nNow, we can introduce a related Q-function,\nQ(x, a) := E\n\u02dcPx,a\nhX\nt\u22650\n\u03bbt \u02c6F(Xt, It)\ni\nFor notation, we didn\u2019t keep track of learning index n, but both \u02dcP and \u02c6F (and consequently\nQ) are evolving as learning progresses. Note that Q satisfies a Bellman type relation\nQ(x, a) = \u02c6F(x, a) + \u03bb\nZ\nS\u00d7A\nQ(y, \u02dca) \u02c6p(x, a; dy) \u00d7 \u03b3y(d\u02dca)\nNow, if we knew exactly what p = \u02c6p, F = \u02c6F are, and were able to compute the optimal\ncontrols for the infinite horizon, then\u03b3x would have support on the maximizers, andV (x) :=\nsupa Q(x, a) =\nR\nA Q(x, \u02dca)\u03b3x(d\u02dca). That is, we recovered the standard Bellman equation:\nV (x) = sup\na\n\u001a\nF(x, a) + \u03bb\nZ\nS\nV (y) p(x, a; dy)\n\u001b\nAs usual, however, it is almost never feasible to know these parameters in reality, nor do\nthey truly exist and fully represent the system at hand. We remark that,\nZ\n\u02c6\u2126\n\u0012Z\nA\nJ(\u02c6\u03c9, x; \u03b1)\u02c6\u03c0(\u02c6\u03c9, x)(d\u03b1|\u03b1(t, x) = a)\n\u0013\nd\u02c6P(\u02c6\u03c9)\nassigns a scalar value for (x, a), which is better suited in our framework as it does not intro-\nduce simplifications. We also note that, in simpler settings, it might be more appropriate\nto learn a single estimate Q(x, a) directly, and avoid all the estimations we have introduced. This is of course a design choice for the player. We briefly illustrate a method for learning CartPole [21]. The goal is not to propose\na novel learning method, but to further emphasize the connections by learning \u02c6\u03d5 under a\n30\n\nfixed horizon T = 8. Let us revisit the basics of the CartPole problem. The state space\nis S = R4 representing position, velocity, angle, and angular velocity. The action space is\nA = {0, 1}, where the actions represent applying force to the left or right of the cart. The\nplayer gains a reward at each time step if the pole is vertical within some bounds. The player has a memory for recording observations, including states, actions, and\nepisode-level evaluations. After each episode, a performance metric is computed as the\naverage of the agent\u2019s relative and absolute performance. In this problem, \u02c6p is deterministic and can be learned. However, as it is not of our\ninterest, we took it as given. We also set \u02c6F = 0 to only model the state values \u02c6\u03d5. Introduce\n{Nk\n\u03d5 }K\u03d5\nk=1 for some K\u03d5 \u2208 N as neural networks S \u2192 R+ for state values. Let L\u03d5 : E \u2192\n(\u02c6\u2126 \u00d7 S \u2192 R+)\nL\u03d5(nO) :=\nK\u03d5X\nk=1\n\u03b4Nk\n\u03d5\n1{k}(\u02c6\u03c9), \u02c6\u03c9 \u2208 \u02c6\u2126 := {1, . . .", "metadata": {"type": "factual", "source": "2503.01411v2.pdf", "context": "and reliability of the machine parameters and whether these\nparameters are truly indicative of the underlying process the\nmodel aims to capture. Unlike traditional SSL methods (e.g.,\ncontrastive learning or I-JEPA), which aim to learn general-\npurpose representations, this model is tailored to a specific\ndomain or machine setup by incorporating a predictive mod-\nule. The incorporation of specific actions (control parameters)", "quality_score": 8}}
{"id": "test_81", "question": "What is explicitly known about the number nI?", "golden_answers": ["nI is a finite number which can be described explicitly."], "prediction": "The documents do not provide explicit information about the number nI.", "f1": 0.2222222222222222, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01026v1\n(3)\n3\n\nWe now obtain some explicit estimates for the quantities Ni+j \u2212 \u03b1jNi. These will be\nuseful later in the paper. For k \u2265 0 we have\nNi+k \u2212 \u03b1kNi = (Ni+k \u2212 c1\u03b1i+k) \u2212 \u03b1k(Ni \u2212 c1\u03b1i),\nand so by the triangle inequality and (3) we get\n|Ni+k \u2212 \u03b1kNi| \u2264 |Ni+k \u2212 c1\u03b1i+k| + \u03b1k|Ni \u2212 c1\u03b1i|\n\u2264 2|c2|(|\u03b2|k + \u03b1k)|\u03b2|i. (4)\nClosed forms for \u03b1, \u03b2, \u03b3, c1, c2, c3 were given by Lin [31], and from these we can easily\ncompute approximations to their values, as follows:\n\u03b1 .= 1.46557123187676802665673\n\u03b2 .= \u22120.2327856159383840133283656 + 0.7925519925154478483258983i\n\u03b3 .= \u22120.2327856159383840133283656 \u2212 0.7925519925154478483258983i\n|\u03b2| = |\u03b3| .= 0.826031357654186955968987\nc1 = \u03b15/(\u03b13 + 2) .= 1.313423059852349798783263\nc2 = \u03b25/(\u03b23 + 2) .= \u22120.15671152992617489939163 \u2212 0.001340333618411808095189i\nc3 = \u03b35/(\u03b23 + 2) .= \u22120.15671152992617489939163 + 0.001340333618411808095189i\n|c2| = |c3| .= 0.15671726167213060374568596. Now for k = 1, 2, 3, using (4) and the numerical approximations above, we get\n|Ni+1 \u2212 \u03b1Ni| < 0.71827(0.82604)i (5)\n|Ni+2 \u2212 \u03b12Ni| < 0.88710(0.82604)i (6)\n|Ni+3 \u2212 \u03b13Ni| < 1.16332(0.82604)i. (7)\nWe now prove a useful lemma. Lemma 5. For i \u2265 0 we have the bounds\n\u22120.79521 < [(i)N 0]N \u2212 \u03b1i <1.046298 (8)\n\u22121.09219 < [(i)N 00]N \u2212 \u03b12i <1.69794 (9)\n\u22121.09644 < [(i)N 000]N \u2212 \u03b13i <1.702181. (10)\nProof. (i) Our starting point is the inequalities (5)\u2013(7). Write i in its Narayana representa-\ntion: i = Ne1 + \u00b7\u00b7\u00b7 + Nes for some integers 0 \u2264 e1 < e2 < \u00b7\u00b7\u00b7 < es. Then\n[(i)N 0]N = Ne1+1 + \u00b7\u00b7\u00b7 + Nes+1,\nand hence\n[(i)N 0]N \u2212 \u03b1i =\nX\n1\u2264j\u2264s\n(Nej+1 \u2212 \u03b1Nej ). 4\n\nNow we split the sum on the right-hand side into two pieces: one where ej \u2264 30, and one\nwhere ej > 30:\n[(i)N 0]N \u2212 \u03b1i =\nX\n0\u2264ej\u226430\n(Nej+1 \u2212 \u03b1Nej ) +\nX\nk>30\n(Nk+1 \u2212 \u03b1Nk),\nand hence\n[(i)N 0]N \u2212 \u03b1i \u2212\nX\n0\u2264ej\u226430\n(Nej+1 \u2212 \u03b1Nej ) \u2264\nX\nk>30\n|Nk+1 \u2212 \u03b1Nk|\n<\nX\nk>30\n.71827(0.82604)k\n< .01104. (11)\nWe now compute bounds on P\n1\u2264ej\u226430(Nej+1 \u2212 \u03b1Nej ) by direct computation. If we examine\nall k in the range 0 \u2264 k < N31 = 125491, then we see the last 30 bits of all possible Narayana\nexpansions. By direct calculation we get\n\u22120.7841638 <\nX\n1\u2264ej\u226430\n(Nej+1 \u2212 \u03b1Nej ) < 1.035258. Putting this together with (11) we get\n\u22120.79521 < [(i)N 0]N \u2212 \u03b1i <1.046298, (12)\nas desired. (ii) and (iii) can be proved in exactly the same way. Remark 6. We can improve the upper and lower bounds by doing more computation, replac-\ning the 30 with a large number. Similar, but weaker numerical results were previously obtained by Dilcher [13] and\nLetouzey [29] in, however, more generality than what we obtained here. 4 Finite automata and Walnut\nFor more about the theory of finite automata, see [23], for example. We consider sequences (fi)i\u22650 defined by finite automata that take, as inputs, the Narayana\nrepresentation of one or more integers.\n\n2503.01026v2\nWe therefore get, using the triangle inequality\nand (2), that\n|Ni \u2212 c1\u03b1i| \u2264 |c2\u03b2i + c3\u03b3i| \u2264 |c2\u03b2i| + |c3\u03b3i| = |c2||\u03b2|i + |c3||\u03b3|i = 2|c2||\u03b2|i. (3)\nWe now obtain some explicit estimates for the quantities Ni+j \u2212 \u03b1jNi. These will be\nuseful later in Section 5.9, Theorem 26. For k \u2265 0 we have\nNi+k \u2212 \u03b1kNi = (Ni+k \u2212 c1\u03b1i+k) \u2212 \u03b1k(Ni \u2212 c1\u03b1i),\nand so by the triangle inequality and (3) we get\n|Ni+k \u2212 \u03b1kNi| \u2264 |Ni+k \u2212 c1\u03b1i+k| + \u03b1k|Ni \u2212 c1\u03b1i|\n\u2264 2|c2|(|\u03b2|k + \u03b1k)|\u03b2|i. (4)\nClosed forms for \u03b1, \u03b2, \u03b3, c1, c2, c3 were given by Lin [31], and from these we can easily\ncompute approximations to their values, as follows:\n\u03b1 .= 1.46557123187676802665673\n\u03b2 .= \u22120.2327856159383840133283656 + 0.7925519925154478483258983i\n\u03b3 .= \u22120.2327856159383840133283656 \u2212 0.7925519925154478483258983i\n|\u03b2| = |\u03b3| .= 0.826031357654186955968987\nc1 = \u03b15/(\u03b13 + 2) .= 1.313423059852349798783263\nc2 = \u03b25/(\u03b23 + 2) .= \u22120.15671152992617489939163 \u2212 0.001340333618411808095189i\nc3 = \u03b35/(\u03b23 + 2) .= \u22120.15671152992617489939163 + 0.001340333618411808095189i\n|c2| = |c3| .= 0.15671726167213060374568596. Now for k = 1, 2, 3, using (4) and the numerical approximations above, we get\n|Ni+1 \u2212 \u03b1Ni| < 0.71826736534411(0.8260313576542)i (5)\n|Ni+2 \u2212 \u03b12Ni| < 0.887090800406(0.8260313576542)i (6)\n|Ni+3 \u2212 \u03b13Ni| < 1.16331950440432(0.8260313576542)i. (7)\nWe now prove a useful lemma. Lemma 5. For i \u2265 0 we have the bounds\n\u22120.79752082381 < [(i)N 0]N \u2212 \u03b1i <1.04861494527 (8)\n\u22121.09505816541 < [(i)N 00]N \u2212 \u03b12i <1.684304571609 (9)\n\u22121.10019497962 < [(i)N 000]N \u2212 \u03b13i <1.70593793584. (10)\n4\n\nProof. (i) Our starting point is the inequalities (5)\u2013(7). Write i in its Narayana representa-\ntion: i = Nf1 + \u00b7\u00b7\u00b7 + Nfs for some integers 0 \u2264 f1 < f2 < \u00b7\u00b7\u00b7 < fs. Then\n[(i)N 0]N = Nf1+1 + \u00b7\u00b7\u00b7 + Nfs+1,\nand hence\n[(i)N 0]N \u2212 \u03b1i =\nX\n1\u2264j\u2264s\n(Nfj+1 \u2212 \u03b1Nfj ). Now we split the sum on the right-hand side into two pieces: one where fj < 30, and one\nwhere fj \u2265 30:\n[(i)N 0]N \u2212 \u03b1i =\nX\n0\u2264fj<30\n(Nfj+1 \u2212 \u03b1Nfj ) +\nX\nk\u226530\n(Nk+1 \u2212 \u03b1Nk),\nand hence\n|[(i)N 0]N \u2212 \u03b1i \u2212\nX\n0\u2264fj<30\n(Nfj+1 \u2212 \u03b1Nfj )| \u2264\nX\nk\u226530\n|Nk+1 \u2212 \u03b1Nk|\n<\nX\nk\u226530\n0.71826736534411(0.8260313576542)i\n< 0.01335706955. (11)\nWe now compute bounds on P\n0\u2264fj<30(Nfj+1 \u2212 \u03b1Nfj ) by direct computation. If we examine\nall k in the range 0 \u2264 k < N31 = 125491, then we see the last 30 bits of all possible Narayana\nexpansions. By direct calculation we get\n\u22120.7841637542588 <\nX\n0\u2264fj<30\n(Nfj+1 \u2212 \u03b1Nfj ) < 1.035257875716. Putting this together with (11) we get\n\u22120.79752082381 < [(i)N 0]N \u2212 \u03b1i <1.04861494527, (12)\nas desired. (ii) and (iii) can be proved in exactly the same way. Remark 6. We can easily improve the upper and lower bounds by doing more computation,\nreplacing the 30 with a large number. Similar, but weaker numerical results were previously obtained by Dilcher [13] and\nLetouzey [29] in, however, more generality than what we obtained here. 5\n\n4 Finite automata and Walnut\nFor more about the theory of finite automata, see [23], for example.\n\n2503.01026v3\nWe therefore get, using the triangle inequality\nand (2), that\n|Ni \u2212 c1\u03b1i| \u2264 |c2\u03b2i + c3\u03b3i| \u2264 |c2\u03b2i| + |c3\u03b3i| = |c2||\u03b2|i + |c3||\u03b3|i = 2|c2||\u03b2|i. (3)\nWe now obtain some explicit estimates for the quantities Ni+j \u2212 \u03b1jNi. These will be\nuseful later in Section 5.9, Theorem 26. For k \u2265 0 we have\nNi+k \u2212 \u03b1kNi = (Ni+k \u2212 c1\u03b1i+k) \u2212 \u03b1k(Ni \u2212 c1\u03b1i),\nand so by the triangle inequality and (3) we get\n|Ni+k \u2212 \u03b1kNi| \u2264 |Ni+k \u2212 c1\u03b1i+k| + \u03b1k|Ni \u2212 c1\u03b1i|\n\u2264 2|c2|(|\u03b2|k + \u03b1k)|\u03b2|i. (4)\nClosed forms for \u03b1, \u03b2, \u03b3, c1, c2, c3 were given by Lin [31], and from these we can easily\ncompute approximations to their values, as follows:\n\u03b1 .= 1.46557123187676802665673\n\u03b2 .= \u22120.2327856159383840133283656 + 0.7925519925154478483258983i\n\u03b3 .= \u22120.2327856159383840133283656 \u2212 0.7925519925154478483258983i\n|\u03b2| = |\u03b3| .= 0.826031357654186955968987\nc1 = \u03b15/(\u03b13 + 2) .= 1.313423059852349798783263\nc2 = \u03b25/(\u03b23 + 2) .= \u22120.15671152992617489939163 \u2212 0.001340333618411808095189i\nc3 = \u03b35/(\u03b23 + 2) .= \u22120.15671152992617489939163 + 0.001340333618411808095189i\n|c2| = |c3| .= 0.15671726167213060374568596. Now for k = 1, 2, 3, using (4) and the numerical approximations above, we get\n|Ni+1 \u2212 \u03b1Ni| < 0.71826736534411(0.8260313576542)i (5)\n|Ni+2 \u2212 \u03b12Ni| < 0.887090800406(0.8260313576542)i (6)\n|Ni+3 \u2212 \u03b13Ni| < 1.16331950440432(0.8260313576542)i. (7)\nWe now prove a useful lemma. Lemma 5. For i \u2265 0 we have the bounds\n\u22120.79752082381 < [(i)N 0]N \u2212 \u03b1i <1.04861494527 (8)\n\u22121.09505816541 < [(i)N 00]N \u2212 \u03b12i <1.684304571609 (9)\n\u22121.10019497962 < [(i)N 000]N \u2212 \u03b13i <1.70593793584. (10)\n4\n\nProof. To prove Eq. (8), we start by writing i in its Narayana representation: i = Nf1 +\n\u00b7\u00b7\u00b7 + Nfs for some integers 0 \u2264 f1 < f2 < \u00b7\u00b7\u00b7 < fs. Then\n[(i)N 0]N = Nf1+1 + \u00b7\u00b7\u00b7 + Nfs+1,\nand hence\n[(i)N 0]N \u2212 \u03b1i =\nX\n1\u2264j\u2264s\n(Nfj+1 \u2212 \u03b1Nfj ). Now we split the sum on the right-hand side into two pieces: one where fj < 30, and one\nwhere fj \u2265 30:\n[(i)N 0]N \u2212 \u03b1i =\nX\n0\u2264fj<30\n(Nfj+1 \u2212 \u03b1Nfj ) +\nX\nfj\u226530\n(Nfj+1 \u2212 \u03b1Nfj ),\nand hence, by using Eq. (5), we get\n|[(i)N 0]N \u2212 \u03b1i \u2212\nX\n0\u2264fj<30\n(Nfj+1 \u2212 \u03b1Nfj )| \u2264\nX\nk\u226530\n|Nk+1 \u2212 \u03b1Nk|\n<\nX\nk\u226530\n0.71826736534411(0.8260313576542)k\n< 0.01335706955. (11)\nWe now compute bounds on P\n0\u2264fj<30(Nfj+1 \u2212 \u03b1Nfj ) by direct computation. If we examine\nall k in the range 0 \u2264 k < N31 = 125491, then we see the last 30 bits of all possible Narayana\nexpansions. By direct calculation we get\n\u22120.7841637542588 <\nX\n0\u2264fj<30\n(Nfj+1 \u2212 \u03b1Nfj ) < 1.035257875716. Putting this together with (11) we get\n\u22120.79752082381 < [(i)N 0]N \u2212 \u03b1i <1.04861494527, (12)\nas desired. Eqs. (6) and (7) can be proved in exactly the same way. Remark 6. We can easily improve the upper and lower bounds by doing more computation,\nreplacing the 30 with a large number. Similar, but weaker numerical results were previously obtained by Dilcher [13] and\nLetouzey [29] in, however, more generality than what we obtained here.", "metadata": {"type": "factual", "source": "2503.01357v1.pdf", "context": "(\nc1 c2\n0 1\n)\n\u2208\nGL2( \u02c6A) for c1,c2 \u2208 \u02c6A inside\nGL0\n2 and set nI := [\nGL0\n2 :\nG] and by [ Leh09, Ch.5,Prop.3.5],\nwe know that nI is a \ufb01nite number which can be described explicitly. For any \u03b1\u2208 G, from\nthe proof of [ Leh09, Prop.2.5], we see that \u03b1\u2217(\u03c6,\u03bb) = ( \u03c6,\u03bb \u25e6 \u03b1\u22121). Consequently, for any\ntwo representatives \u03c3,\u03c3\u2032 \u2208 GL0\n2 of the same coset in\nGL0\n2/\nG, we have that the underlying\nDrinfeld modules of \u03c3\u2217(\u03c6,\u03bb) and \u03c3\u2032\n\u2217(\u03c6,\u03bb) are the same and di\ufb00er only in the level I-structure\nby an element in G. We", "quality_score": 8}}
{"id": "test_82", "question": "How can one infer the content or purpose of this text based on its structure?", "golden_answers": ["Given the presence of multiple blocks with different codes and the use of forward slashes as separators, it is likely that this text represents a compressed or encoded form of data, possibly requiring decoding to reveal its original content."], "prediction": "The text is structured into sections that outline a systematic approach to analyzing differences in text distributions based on group assignments. It begins with a motivation for the research, followed by a description of challenges in testing for differences, and then proposes methods for addressing these challenges, including the use of machine learning tools and causal themes. The organization suggests a focus on statistical analysis and the application of natural language processing (NLP) techniques to improve text classification and understanding of textual data.", "f1": 0.2181818181818182, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.00725v1\nInstead,\nwe need to find ways of describing core aspects of the differences across Y |W=1 and Y |W=0 in a\nmanageable and statistically valid way, based on a potentially small sample {(Yi, Wi)}n\ni=1. In the\nfollowing three chapters, we tackle this challenge by providing an approach to addressing whether\n7\n\nthere is a difference between Y |W=1 and Y |W=0 (Section 4), what the difference is (Section 5),\nand how complete our description of said difference is (Section 6). 4 Testing for an Effect on Text\nOur first goal is to detect whether the two distributions Y |W=1 and Y |W=0 over text documents\nare the same. That is, before asking how the two distributions differ, we first want to checkwhether\nthere is any statistically significant difference at all. Even for this seemingly more effortless task,\nstandard approaches for testing for differences across two distributions are limited. First, we could\nchoose a few features of the text documents by hand that we think could be affected by treatment\nand then run a joint test for average differences in those features across the two groups. For example,\nwe could hypothesize that the texts are longer in one group than the other, that a specific word\n(or group of words) is more likely to appear in one group, and/or that the sentiment of the text\n(as measured by some pre-defined algorithm) differs in a systematic way. But the number of ways\nin which we could provide simple features of complex texts is so vast that this approach is likely to\nmiss important signals unless we have strong and correct priors about which aspect of text is most\naffected. Second, we could instead search through many such features automatically by trying them\none by one. However, this approach risks leading to spurious findings, requiring us to apply severe\ncorrections to avoid excess false positives. In the context of a very high number of potential features\nrelative to a small or moderate number of text documents, these corrections may make detecting\nsignificant effects very hard, if not impossible. Finally, we could apply general non-parametric\ntests that have been proposed for detecting the difference between two distributions, such as multi-\ndimensional generalizations of the Kolmogorov\u2013Smirnov test. Yet even such tests would rely on\nspecific representations of the text, as they typically focus on relatively low-dimensional outcome\nvectors and may quickly lose power otherwise. Instead of relying on tests that compare text features across the two groups, we adapt a trick\nfrom Ludwig, Mullainathan, and Spiess (2017) and ask: Given a document Yi in our sample, can\nwe predict its group assignment Wi better than some trivial benchmark? That is, rather than\nasking whether W has a causal effect on Y , we ask whether Y is predictive of W. This change\nin framing allows us to leverage non-parametric tools from machine learning directly, since these\ntools excel at predicting some simple outcome (here: Wi) from complex covariates (here: Yi) by\nsystematically searching over good predictors.\n\n2503.01159v1\nMotivation\nThe expansion of the internet and complete digitalization of various domains, such as healthcare, triggered the continuous\ngeneration of textual data, and as a result, vast piles of textual data are accumulated. This presents text data management\nand analysis as not only challenges but also interesting research opportunities. The need to proficiently organize\ntextual data and transform it into a structured format is guiding the research focus to dig deeper into the possibility of\nautomatically assigning predefined categories to text, thus improving access to information through NLP tasks like text\nclassification, named entity recognition (Ghali et al., 2024), and others. There are various motivations behind the research revolving around efficiently categorizing collected text data, especially\nsince text classification constitutes a foundation task for multiple NLP applications. Sebastiani (2002) highlights its\napplications to include text indexing for Boolean Information Retrieval, document categorization, and filtering, in\naddition to Word Sense Disambiguation (WSD). In an information retrieval system, the text indexing is based on a\ncontrollable dictionary where documents are paired with one keyword or more. Considering the ensemble of vocabulary\ncontained in the controllable dictionary as categories, text indexing, which facilitates information retrieval, can be\n3\n\nviewed as text classification. Additionally, this results in an automated categorization of the documents considered,\nwhich can also be extended to web pages, and using the assigned labels, text filtering is permitted. Besides, WSD is\nanother application of text classification, where the categories here are the sense of the ambiguous word given the context\nin which it appears. This can be particularly useful for other NLP tasks such as Machine Translation. Furthermore,\ntext classification is useful for understanding and enhancing customer or user experience through Sentiment Analysis\n(SA) (Pang et al., 2002). SA is a special case of text classification where the categories considered are the sentiments\n(e.g., positive, negative, mixed, neutral). This spotlights the potential practical applications of text classification, which\nwould consist of customer feedback analysis and understanding. Moreover, spam detection is another motivation behind\ndeveloping adequate text classification techniques for email classification (Dada et al., 2019). In the same context,\ncontent moderation also relies on text classification (Nobata et al., 2016), which is an additional driver fueling this\nresearch. In healthcare, text classification is gaining importance, especially since medical textual data is growing at an exponential\nrate. Text classification automatically extracts valuable insights from various types of continuously generated healthcare\nnarratives, such as clinical notes, patients\u2019 feedback, and medical research papers. This is particularly crucial since\nit would improve patient care by exploiting available data that is usually challenging to extract, which results in\nmore efficient healthcare systems (Spasic and Nenadic, 2020). There are diverse healthcare NLP tasks to which\ntext classification can significantly contribute by providing clinical decision support. Examples include automated\ndiagnosis coding (Karimi et al., 2017) and identifying at-risk patients for certain diseases (Bittar et al., 2019). These\ntext classifications would be useful for early intervention and anticipated treatment planning.\n\n2503.00725v1\nWhile the former challenge points to the massive potential of using machine-learning\ntools that search through complex data and hypotheses, the latter challenge also foreshadows their\ninherent limitations. We first define what we mean by describing differences across text distributions, leading to\nthe notion of causal themes (Section 5.1). We then propose an LLM-based implementation to\nhypothesize such themes (Section 5.2), before discussing their validation (Sections 5.4 and 5.5). We\nclose this section by emphasizing the role of human analysts beyond scoring (Section 5.6). 5.1 Causal Themes\nTo tackle the challenge of describing systematic differences in complex outcomes across different\ngroups, we consider a simple description vector Y f = f(Y ) \u2208 Dthat includes core aspects of\ndocuments across the two groups. Specifically, we score texts according to k core themes, where k\nis a small number. Each of these themes may correspond to a specific topic covered in a document,\nto its style, or to the sentiment it expresses. For each topic j, we obtain a score Y f\nj \u2208 Dj within\na simple set Dj. That simple set will typically be a continuous or discrete scale, such as when the\nprevalence of a topic is scored from 0 to 100 or sentiment as {\u22121, 0, +1}. Or it can be a discrete\nclassification into a few groups, for example whether the poetic form of a document is a sonnet, a\nhaiku, or neither (Dj = {sonnet, haiku, other}). In any case, we assume that descriptions are easily\nunderstood and that we can use standard statistical tools to estimate causal effects on the low-\ndimensional vector (Y f\n1 , \u00b7\u00b7\u00b7 , Yf\nk ) = Y f = f(Y ) \u2208 D= D1 \u00d7 \u00b7\u00b7\u00b7 \u00d7 Dk. By using these descriptions,\n11\n\nwe turn the task of considering the intractable effect of W on full documents Y into describing\ndifferences between scores Y f\nj |W = 1 and Y f\nj |W = 0. An optimal scoring Y f = f(Y ) that summarizes a complex document Y in terms of core themes\nshould provide mutually exclusive, differentially complete, and causally meaningful descriptions of\nthe text. By mutually exclusive, we mean that components Y f\nj describe themes that do not overlap\nin meaning and are entirely separate. By differentially complete, we specifically refer to the ability\nof the given description to capture the systematic differences across the two groups as well as\npossible. (In this sense, a good set of causal themes differs markedly from a complete description\nof the text, which instead may include features that are common across groups.) Finally, by\ncausally meaningful, we mean that the aspects of text captured by the description are descriptions\nof plausible outcomes described in the text. This latter criterion is meant to rule out cases where\ndescriptions do not have a clear relationship to the content of the text or represent aspects that are\nunhelpful in describing effects of interest.", "metadata": {"type": "reasoning", "source": "2503.01200v1.pdf", "context": "/uni00000036/uni0000004c/uni00000050/uni00000058/uni0000004f/uni00000044/uni00000057/uni00000048/uni00000047\n/uni00000014/uni00000013/uni00000013/uni00000013\n/uni00000013/uni00000014/uni00000013/uni00000013/uni00000013\n/uni00000033/uni00000052/uni00000056/uni0000004c/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000003/uni0000000b/uni00000051/uni00000050/uni0000000c\n/uni00000013/uni00000011/uni00000013\n/uni00000015/uni00000011/uni00000018\n/uni00000018/uni00000011/uni00000013\n/uni0000001a/", "quality_score": 8}}
{"id": "test_83", "question": "What is the characteristic age (\u03c4c) of pulsars in this study, and what does it indicate?", "golden_answers": ["The characteristic age \u03c4c is a reasonable estimate of the true age of pulsars. It is indicative of the time since the supernova explosion that formed the neutron star."], "prediction": "The characteristic age (\u03c4c) of pulsars in this study is defined through their rotational period and its derivative, calculated as \u03c4c = P/(2 \u02d9P). It indicates a reasonable estimate of the true pulsar age, providing a lower bound on the age of a neutron star since they are formed in supernovae of massive stars located in the thin disc at z \u22480 kpc.", "f1": 0.4358974358974359, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01429v1\n2 we show the kinematic age\ndistributions\u2014-that follow from the sets of pulsar trajectories\u2014\nversus the characteristic ages. Indeed, the assumption of LSR\nisotropy results in the majority of the median kinematic age esti-\nmates to differ less than\u223c20% from the corresponding character-\nistic ages. There are, however, a few pulsars with \u03c4kin exceeding\n\u03c4c substantially, which could either mean that the assumption of\nLSR isotropy is invalid or that\u03c4c is not indicative of the true age\n(e.g. due to post-SN fallback on the NS, as discussed by Igoshev\net al. 2016a). In particular, we considered pulsars where median\n\u03c4kin exceeds \u03c4c with more than 5 Myr to have potentially un-\ncertain ages. Nevertheless, in general we deem the characteristic\nage a reliable age estimate and consistent with the assumption of\nLSR isotropy. In order to use the method of Disberg et al. (2024b) to kine-\nmatically constrain the natal kick of the pulsars, we first in-\nvestigated the shape (i.e. eccentricity) of their Galactic trajec-\ntories. After all, a larger kick disturbs the initial circular orbits\nmore and therefore results in a more eccentric path through the\nGalaxy. Since we have established that\u03c4c is a reasonable age es-\ntimate, we limited our analysis to the pulsar trajectories that do\nnot deviate from the Galactic disc when traced back for a pe-\nriod equal to the characteristic age. That is, we conservatively\nadopted the constraint that the traced-back trajectories should be\npositioned within R \u2264 20 kpc and |z| \u2264 1 kpc at t = \u03c4c. Al-\nthough for a few pulsars this decreases the amount of trajecto-\nries significantly (i.e. J1321 +8323, J1543+0929, J1840+5640,\nJ2046+1540, J2046\u20130421, J2248\u20130101, J2346\u20130609), the me-\ndian exclusion rate is only 3%. We evaluate the cylindrical radii\nArticle number, page 4 of 15\n\nP. Disberg et al.: A kinematically constrained kick distribution for isolated neutron stars\n(i.e. the Galactic distances projected on the Galactic plane) of the\nselected trajectories and take their minimum and maximum val-\nues (Rmin and Rmax, respectively). The eccentricity of the Galac-\ntic orbit is then defined as:\n\u02dce = Rmax \u2212Rmin\nRmax + Rmin\n, (6)\nanalogous to a Keplerian eccentricity (although the trajecto-\nries are not Keplerian due to the Galactic potential). If an ob-\nject that starts in a circular Galactic orbits experiences no kick,\nthen Rmin = Rmax and \u02dce = 0. In contrast, if the object re-\nceives an extremely large kick, it will escape the Galaxy meaning\nRmax \u226bRmin and \u02dce \u22481.\nIn Fig. 3 we show the resulting eccentricity distributions (cf.\nFig. 9 of Disberg et al. 2024b) for four subsets: the \u201cyoung\u201d pul-\nsars as defined by Igoshev (2020, i.e. \u03c4c \u22643 Myr) and Verbunt\net al. (2017, i.e. \u03c4c \u226410 Myr), as well as old pulsars (i.e. 40\nMyr \u2264\u03c4c \u22641 Gyr) that have obtained (galactocentric) velocities\n\u223c200 km/s (independent of kick distribution, see Appendix B of\nDisberg et al. 2024a) and pulsars in between these two categories\n(i.e. 10 Myr \u2264\u03c4c \u226440 Myr, see Appendix A of Disberg et al.\n2024a).\n\n2503.01429v1\nFor each sampled pulsar\nlocation, we took a uniformly sampled value of u and calculated\nvr which combined with ut determines the velocity vector. Having obtained 10 2 locations and velocities for each pul-\nsars, we flipped the estimated velocity vectors and used GALPY2\nv.1.10.0 (Bovy 2015) to trace back the trajectories through\nthe Milky Way using the Galactic potential of McMillan (2017),\nwhere we\u2014similarly to Disberg et al. (2024a,b)\u2014set the circu-\nlar velocity at R\u2299equal to v\u03d5,\u2299= 245.6 km/s (GRA VITY Collab. et al. 2018). We computed the pulsar trajectories for 1 Gyr and\nevaluated them every 1 Myr. The sets of pulsar trajectories allowed us to estimate the kine-\nmatic ages (\u03c4kin) of the pulsars, which are defined as the time that\n1 https://www.atnf.csiro.au/research/pulsar/psrcat.\n2 http://github.com/jobovy/galpy. Article number, page 3 of 15\n\nA&A proofs:manuscript no. main\nFig. 2. Kinematic ages ( \u03c4kin) versus charac-\nteristic spin-down ages ( \u03c4c) for the pulsars in\nthe sample of Verbunt et al. (2017, blue) and\nthe expansion of Igoshev (2020, red) with char-\nacteristic ages below 40 Myr. The kinematic\nages were determined through the sets of pul-\nsar trajectories, where the squares are set at the\nmedian values and the whiskers show the 68%\nranges. The dotted line depicts \u03c4kin = \u03c4c and the\nshaded region shows a 20% error on \u03c4c. If the\nmedian kinematic age exceeds the characteris-\ntic age with more than 5 Myr we show it as a tri-\nangle instead of a square, because the question\narises whether these pulsars affect the accuracy\nof resulting kick distributions.\nFig. 3. Galactic eccentricities for the pulsars in the samples of Verbunt et al. (2017, blue) and Igoshev (2020, red), as defined in Eq. 6. The\ndistributions are shown in histograms with bins of 0.01, and divided in four ranges of \u03c4c consisting of N pulsars.\nhas passed since their last disc crossing (i.e. at z = 0 kpc). Af-\nter all, since NSs are formed in SNe of massive stars, which are\nlocated in the thin disc at z \u22480 kpc, the last disc crossing can\nprovide a lower bound on the age of a NS. The kinematic ages\ncan, then, be compared to the characteristic spin-down ages of\nthe pulsars (\u03c4c), which are defined through their rotational period\nand its derivative (\u03c4c = P/(2 \u02d9P), e.g. Shapiro & Teukolsky 1983). Although in some cases it seems to be inaccurate (e.g. Jiang et al.\n2013; Zhang et al. 2022), the characteristic age is usually consid-\nered a reasonable estimate of the true pulsar age (as e.g. argued\nby Maoz & Nakar 2024). Several studies have compared kine-\nmatic and characteristic ages (e.g. Lyne et al. 1982; Cordes &\nChernoff 1998; Brisken et al. 2003a) and in particular Noutsos\net al. (2013) and Igoshev (2019) find a general agreement be-\ntween the two (independent) age estimates. Here, we compared\n\u03c4kin to \u03c4c in order to test whether the assumption of LSR isotropy\nin the distribution of vr (which influences \u03c4kin) is consistent with\nthe assumptions behind \u03c4c. In Fig.\n\nA kinematically constrained kick distribution for isolated neutron stars\nAlthough in some cases it seems to be inaccurate (e.g. Jiang et al.\n2013; Zhang et al. 2022), the characteristic age is usually consid-\nered a reasonable estimate of the true pulsar age (as e.g. argued\nby Maoz & Nakar 2025). Several studies have compared kine-\nmatic and characteristic ages (e.g. Lyne et al. 1982; Cordes &\nChernoff 1998; Brisken et al. 2003a) and in particular Noutsos\net al. (2013) and Igoshev (2019) find a general agreement be-\ntween the two (independent) age estimates. Here, we compared\n\u03c4kin to \u03c4c in order to test whether the assumption of LSR isotropy\nin the distribution of vr (which influences \u03c4kin) is consistent with\nthe assumptions behind \u03c4c. In Fig. 2 we show the kinematic age\ndistributions\u2014-that follow from the sets of pulsar trajectories\u2014\nversus the characteristic ages. Indeed, the assumption of LSR\nisotropy results in the majority of the median kinematic age esti-\nmates to differ less than\u223c20% from the corresponding character-\nistic ages. There are, however, a few pulsars with \u03c4kin exceeding\n\u03c4c substantially, which could either mean that the assumption of\nLSR isotropy is invalid or that\u03c4c is not indicative of the true age\n(e.g. due to post-SN fallback on the NS, as discussed by Igoshev\net al. 2016a). In particular, we considered pulsars where median\n\u03c4kin exceeds \u03c4c with more than 5 Myr to have potentially un-\ncertain ages. Nevertheless, in general we deem the characteristic\nage a reliable age estimate and consistent with the assumption of\nLSR isotropy. In order to use the method of Disberg et al. (2024b) to kine-\nmatically constrain the natal kick of the pulsars, we first in-\nvestigated the shape (i.e. eccentricity) of their Galactic trajec-\ntories. After all, a larger kick disturbs the initial circular orbits\nmore and therefore results in a more eccentric path through the\nGalaxy. Since we have established that\u03c4c is a reasonable age es-\ntimate, we limited our analysis to the pulsar trajectories that do\nnot deviate from the Galactic disc when traced back for a pe-\nriod equal to the characteristic age. That is, we conservatively\nadopted the constraint that the traced-back trajectories should be\npositioned within R \u2264 20 kpc and |z| \u2264 1 kpc at t = \u03c4c. Al-\nthough for a few pulsars this decreases the amount of trajecto-\nries significantly (i.e. J1321 +8323, J1543+0929, J1840+5640,\nArticle number, page 4 of 15\n\nP. Disberg et al.: A kinematically constrained kick distribution for isolated neutron stars\nJ2046+1540, J2046\u20130421, J2248\u20130101, J2346\u20130609), the me-\ndian exclusion rate is only 3%. We evaluate the cylindrical radii\n(i.e. the Galactic distances projected on the Galactic plane) of the\nselected trajectories and take their minimum and maximum val-\nues (Rmin and Rmax, respectively). The eccentricity of the Galac-\ntic orbit is then defined as:\n\u02dce = Rmax \u2212Rmin\nRmax + Rmin\n, (6)\nanalogous to a Keplerian eccentricity (although the trajecto-\nries are not Keplerian due to the Galactic potential). If an ob-\nject that starts in a circular Galactic orbits experiences no kick,\nthen Rmin = Rmax and \u02dce = 0.", "metadata": {"type": "factual", "source": "2503.01429v2.pdf", "context": "istic ages. There are, however, a few pulsars with \u03c4kin exceeding\n\u03c4c substantially, which could either mean that the assumption of\nLSR isotropy is invalid or that\u03c4c is not indicative of the true age\n(e.g. due to post-SN fallback on the NS, as discussed by Igoshev\net al. 2016a). In particular, we considered pulsars where median\n\u03c4kin exceeds \u03c4c with more than 5 Myr to have potentially un-\ncertain ages. Nevertheless, in general we deem the characteristic\nage a reliable age estimate and consistent w", "quality_score": 8}}
{"id": "test_84", "question": "How do hierarchical exponential attention and reduced-bias modules contribute to the overall performance of the model, as shown by ablation studies in Table V?", "golden_answers": ["They expand data depth, excelling in conventional tasks (Figure 4) and domain tasks (Figures 5 and 6)."], "prediction": "Hierarchical exponential attention and reduced-bias modules effectively expand the deep dimensions of the data, leading to improved performance in both regression and F1 indicators, as demonstrated in the ablation studies in Table V.", "f1": 0.21276595744680848, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01217v2\nHowever, compared with\nthe precision of DAE (69.68), proposed method still has a\ncertain gap in accuracy, which suggests that proposed model\nstill has room for improvement in accurate prediction when\ndealing with noisy social media data. 2) Ablation Studies: Ablation Study in Table V evaluates\nthe proposed structure through two experiments: (1) module\nremoval to assess synergy, and (2) BERT replacement/removal\nto analyze word embedding impacts. a) Comparison between the base model and different\nBERT models: The experimental results of comparing the base\nmodel (S.N.1) with the models that introduce different BERT\nvariants (S.N.2 and S.N.3) show that RoBERTa outperforms\nBERT in terms of vocabulary vectorization. b) Comparison between naive attention and hierarchical\nEMA: When comparing the naive attention model (S.N.4) with\nthe model based on hierarchical exponential moving average\n(Hierarchical EMA) (S.N.5), the experimental results show\nthat the hierarchical attention mechanism can more effectively\nextract the weight distribution of key information under the\nconstraint of exponential gain weights. c) Comparison between static and dynamic reduced-bias\nmodels: By comparing the immutable Reduced-bias model\n(S.N.4) with the self-learning Reduced-bias model (S.N.5), the\nresults verify that the dynamically changing coefficients can\nbe adaptively adjusted according to the input text features,\nthereby improving the model\u2019s ability to express features. d) Comparison of the proposed model with the naive\nBERT model: In the comparison of the final model (S.N.8)\nwith the ordinary BERT model (S.N.7), the experimental\nresults show that even with the introduction of a rich feature\nextraction module, RoBERTa can still efficiently capture the\ndeep features of the text and show a superior feature learning\nability. TABLE V\nABLATION STUDIES ON MSRA\nS.N. Module Metric\nA H R BERT P R F1\n1 84.65 80.68 82.62\n2 BERT-base 91.02 92.09 91.55\n3 RoBERTa 92.21 92.57 92.38\n4 \u221a 87.42 85.78 86.60\n5 \u221a 91.35 90.62 90.98\n6 \u221a \u221a 92.92 93.09 93.01\n7 \u221a \u221a BERT-base 93.55 93.88 93.71\n8 (Ours) \u221a \u221a RoBERTa 94.58 93.98 94.28\nE. Parameter Selection\nIn the design of the attention module based on the EMA\n(Exponential Moving Average) mechanism, the number of\nattention heads is considered to be one of the important factors\naffecting the model performance. In order to determine the\noptimal configuration of attention heads, different numbers\nof attention heads (16, 32, 64, 128) is set in the experiment\nand evaluated the performance of the model on the validation\nset. The experimental results show that when the number\nof attention heads is set to 64, the model achieves the best\nperformance in performance indicators such as precision,\nrecall, and F1 score. As seen from the Table VI, too few attention heads with\n16 or 32, may cause the model to be unable to fully capture\nfeature representations, thereby limiting the performance of\nthe model. When the number of attention heads increases to\n64, the performance of the model reaches its peak. However,\nwhen the number of attention heads is further increased to\n128), the performance of the model does not continue to\n\nFig. 5. Cases in the MSRA validation set are selected for analysis.\n\n2503.01217v1\nThe following are the main findings and discussions derived from the experimental results:\n1) Proposed method can be matched with the comparative experiment and the ablation experiment to prove that the\nmodel can adapt to different types of semantic information under different scene tasks and adaptively improve the\nrobustness of CNER. Comparing the experimental results of Table-2, Table-4, and Table-3, proposed model achieves the\nbest performance in both regression and F1 indicators. The ablation experiment in Table-5 shows that the hierarchical\nexponential attention and reduced-biased modules can effectively expand the deep dimensions of the data compared\nwith the baseline model. It performs well in the conventional tasks in Figure-5. 2) Proposed research shows that the Hierarchical Reduced-bias EMA architecture can bring accurate feature extraction\nfor CNER tasks. The modeling of the attention mechanism is to understand the text content from the vector dimension,\nwhich is used in the latest LLMs models (such as GPT, Llama). In the field of transfer learning, inspired by DAE [27],\nproposed model can be used in other sequence modeling tasks. The sequence modeling task uses BERT to model the\ntext vectorization input, and the output is the probability weight of the same length as the input text. It is believed\nthat the model can be applied to NER tasks such as text understanding, text classification, and emotion recognition\nsimultaneously.\n3) Increasing the number of attention heads will significantly increase the number of parameters in the multi-head\nattention mechanism, thereby increasing the training time and inference time of the model. When selecting the number\nof attention heads, proposed study comprehensively considered the trade-off between performance and efficiency and\nselected EMA head of 64. 13\n\nPreprint. This is a preprint paper under reviewing. 5 Conclusion\nProposed study focus on CNER model that combines RoBERTa, reduced-biased Hierarchical EMA, BiLSTM, and\nCRF, which conducts extensive experimental verification on multiple Chinese datasets. Experimental results show that\nproposed method has achieved leading performance on MSRA, Resume, and Weibo datasets, demonstrating strong\nadaptability to diverse language scenarios. Despite the excellent experimental results, there are still some directions\nworth exploring. In the future, stronger feature fusion strategies, more robust pre-trained models, and regularization\ntechniques that adapt to diverse scenarios will be explored to further improve model performance and generalization\ncapabilities. Acknowledgments\nThis was was supported in part by Agency for Science, Technology and Research. References\n[1] Yue Zhang and Jie Yang. Chinese ner using lattice lstm. arXiv preprint arXiv:1805.02023, 2018. [2] Xiaonan Li, Hang Yan, Xipeng Qiu, and Xuanjing Huang. Flat: Chinese ner using flat-lattice transformer. arXiv\npreprint arXiv:2004.11795, 2020. [3] Chen Jia, Yuefeng Shi, Qinrong Yang, and Yue Zhang. Entity enhanced bert pre-training for chinese ner. In\nProceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages\n6384\u20136396, 2020. [4] J Stuart Hunter. The exponentially weighted moving average. Journal of quality technology, 18(4):203\u2013210, 1986. [5] Xuezhe Ma, Chunting Zhou, Xiang Kong, Junxian He, Liangke Gui, Graham Neubig, Jonathan May, and Luke\nZettlemoyer. Mega: moving average equipped gated attention. arXiv preprint arXiv:2209.10655, 2022.\n\n2503.01234v3\nAblation Study\nIn the ablation experiments, baseline model YOLOv8n is\ncompared marked as S.N.1 in Table III,IV,V. And its different\nimproved versions (M-DET, G-DET, GC-DET and GCM-\nDET) in three datasets (CD5-DET, NEU-DET and GC10-\nDET).\n1) Remove the SSM module and verify whether the state-\nspace search method is effective. Comparing the baseline\nmodel (S.N.1) and SSM (S.N.2) models in Table III, Table IV\nand Table V, SSM achieved a 19.0% performance improve-\nment in the CD5-DET dataset, a 4.8% performance improve-\nment in NEU-DET, and a 1.8% improvement in GC10-DET\non the mAP@0.5 indicator. 2) Remove the dynamic gamma module and verify\nwhether the gamma coefficient correction improves the\nindicators. The baseline model and the Gamma (S.N.3) model\nhave improved performance in all three datasets, indicating\nthat the dynamically changing Gamma coefficient can repair\nthe grayscale features of the model. Then, the experiment\nshows that the Carafe (S.N.3) model can obtain more up-\nsampling features compared with the Gamma-Carafe (S.N.4)\nmodule with grayscale correction added.\n3) Verify whether the fusion model is effective. By\nmerging the backbone network of the SSM architecture and\nthe Gamma-Carafe coefficient, proposed model achieved all-\nround performance improvement.\nG. Sensitivity Analysis of SSMs\nTable VI shows the specific parameters of Mamba models. The results in the Figure 5 show that Mamba models of\ndifferent sizes have different sensitivities to different features. For the container damage detection task, Mamba-B is the best\nwindow size. TABLE II\nDETECTION RESULTS OF DIFFERENT MODELS IN NEU-DET\nMethod AP@0.5 mAP@0.5 mAP@0.5:0.95 Params(M) GFLOPs Size(Mb)\nCr. In. Pa. Ps. Rs. Sc.\nRCNN-ResNet50 0.462 0.838 0.895 0.875 0.558 0.905 0.756 - 41.37 13.40 -\nRCNN-ResNet101 0.586 0.875 0.879 0.895 0.603 0.936 0.796 - 60.37 18.20 -\nDF-DERT 0.440 0.814 0.933 0.875 0.701 0.947 0.785 - 41.00 13.60 -\nFocus-DERT 0.553 0.849 0.942 0.826 0.634 0.957 0.793 - 49.20 11.30 -\nES-Net 0.560 0.876 0.883 0.874 0.604 0.949 0.791 - 147.98 - -\nDEA 0.609 0.825 0.943 0.958 0.672 0.741 0.791 - 42.20 - -\nYOLOv5n 0.494 0.852 0.920 0.830 0.607 0.907 0.768 0.456 2.50 7.10 5.03\nYOLOv5s 0.527 0.806 0.888 0.861 0.616 0.939 0.773 0.452 9.11 23.80 17.60\nYOLOv6n 0.437 0.846 0.926 0.847 0.631 0.925 0.769 0.459 4.23 11.80 8.30\nYOLOv6s 0.507 0.852 0.888 0.830 0.653 0.896 0.771 0.439 16.30 44.00 31.30\nYOLOv7n-tiny 0.451 0.798 0.904 0.869 0.616 0.827 0.744 0.379 6.02 13.10 11.70\nYOLOv8n 0.473 0.843 0.923 0.823 0.624 0.926 0.769 0.444 3.01 8.10 5.97\nYOLOv8s 0.508 0.840 0.908 0.847 0.619 0.926 0.775 0.454 11.10 28.40 21.40\nLiFSO-Net 0.481 0.864 0.942 0.880 0.644 0.942 0.792 0.479 1.77 5.70 3.69\nRDD-YOLO 0.529 0.859 0.944 0.862 0.707 0.966 0.811 - - - -\nMD-YOLO 0.467 0.814 0.913 0.851 0.726 0.920 0.782 - 9.00 14.10 -\nGCM-DET(Ours) 0.619 0.727 0.980 0.996 0.536 0.979 0.835 0.496 21.80 49.70 83.90\nTABLE III\nABLATION EXPERIMENTS PERFORMED ON CD5-DET. S.N. Method Metric\nGamma Carafe SSM mAP@0.5 mAP@0.5:0.95 Precision Recall\n1 0.257 0.132 0.378 0.288\n2 \u221a 0.447 0.243 0.622", "metadata": {"type": "reasoning", "source": "2503.01217v2.pdf", "context": "across scene tasks, enhancing CNER robustness. As shown in\nTables II to IV, proposed method achieves top performance\nin regression and F1 scores. Ablation studies in Table V\nconfirm that hierarchical exponential attention and reduced-\nbias modules expand data depth, excelling in conventional\ntasks in Figure 4 and domain tasks in Figures 5 and 6.\n2) The Hierarchical Reduced-bias EMA architecture enables\nprecise CNER feature extraction. Inspired by DAE [27], the", "quality_score": 8}}
{"id": "test_85", "question": "Why would a fast CU partition strategy based on texture and neighboring partition information be beneficial in Versatile Video Coding Intra Coding?", "golden_answers": ["A fast CU partition strategy based on texture and neighboring partition information would be beneficial as it can improve the efficiency of the encoding process by reducing computational complexity, while also maintaining or improving coding performance."], "prediction": "A fast CU partition strategy based on texture and neighboring partition information would be beneficial in Versatile Video Coding Intra Coding because it can enhance encoding efficiency by quickly determining the optimal partitioning structure. This approach reduces computational complexity and processing time by leveraging the characteristics of the texture and the context provided by neighboring partitions, leading to improved performance in terms of bitrate and visual quality. Additionally, it minimizes the search space for partitioning decisions, allowing for faster encoding while maintaining high compression efficiency.", "f1": 0.46428571428571425, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.01415v1\n[13] X. Shang, G. Li, X. Zhao, and Y . Zuo, \u201cLow Complexity Inter Coding\nScheme for Versatile Video Coding (VVC),\u201d Journal of Visual Commu-\nnication and Image Representation , vol. 90, p. 103683, 2023. [14] Y . Li, Z. He, and Q. Zhang, \u201cFast Decision-Tree-Based Series Parti-\ntioning and Mode Prediction Termination Algorithm for H.266/VVC,\u201d\nElectronics, vol. 13, no. 7, p. 1250, 2024. [15] Y . Liu, M. Abdoli, T. Guionnet, C. Guillemot, and A. Roumy, \u201cLight-\nWeight CNN-Based VVC Inter Partitioning Acceleration,\u201d in 2022 IEEE\n14th Image, Video, and Multidimensional Signal Processing Workshop\n(IVMSP), pp. 1\u20135, IEEE, 2022. [16] Z. Peng and L. Shen, \u201cA Classification-Prediction Joint Framework to\nAccelerate QTMT-Based CU Partition of Inter-Mode VVC,\u201d Electronics\nLetters, vol. 59, no. 7, p. e12770, 2023. [17] X. Jiang, M. Xiang, J. Jin, and T. Song, \u201cExtreme Learning Machine-\nEnabled Coding Unit Partitioning Algorithm for Versatile Video Cod-\ning,\u201d Information, vol. 14, no. 9, p. 494, 2023. [18] J. Lin, H. Lin, Z. Zhang, and Y . Xu, \u201cEfficient Inter Partitioning of\nVersatile Video Coding Based on Supervised Contrastive Learning,\u201d\nKnowledge-Based Systems, vol. 296, p. 111902, 2024. [19] A. Wieckowski, J. Brandenburg, T. Hinz, C. Bartnik, V . George,\nG. Hege, C. Helmrich, A. Henkel, C. Lehmann, C. Stoffers, et al. ,\n\u201cVVenC: An Open and Optimized VVC Encoder Implementation,\u201d in\n2021 IEEE International Conference on Multimedia & Expo Workshops\n(ICMEW), pp. 1\u20132, IEEE, 2021. [20] A. Wieckowski, G. Hege, C. Lehmann, B. Bross, D. Marpe, C. Feld-\nmann, and M. Smole, \u201cVVC in the Cloud and Browser Playback: It\nWorks,\u201d in Proceedings of the 1st Mile-High Video Conference , pp. 19\u2013\n24, 2022. [21] E. C \u00b8 etinkaya, H. Amirpour, M. Ghanbari, and C. Timmerer, \u201cCTU Depth\nDecision Algorithms for HEVC: A Survey,\u201d Signal Processing: Image\nCommunication, vol. 99, p. 116442, 2021. [22] Y . Liu, H. Amirpour, M. Abdoli, C. Timmerer, and T. Guionnet,\n\u201cPreparing VVC for Streaming: A Fast Multi-Rate Encoding Approach,\u201d\nin 2023 IEEE International Conference on Visual Communications and\nImage Processing (VCIP) , (Jeju, Korea, Republic of), pp. 1\u20135, IEEE,\nDec. 2023. [23] J. Brandenburg, A. Wieckowski, T. Hinz, A. Henkel, V . George, I. Zu-\npancic, C. Stoffers, B. Bross, H. Schwarz, and D. Marpe, \u201cTowards\nFast and Efficient VVC Encoding,\u201d in 2020 IEEE 22nd International\nWorkshop on Multimedia Signal Processing (MMSP) , pp. 1\u20136, IEEE,\n2020. [24] V . V . Menon, H. Amirpour, C. Timmerer, and M. Ghanbari, \u201cINCEPT:\nIntra CU Depth Prediction for HEVC,\u201d in 2021 IEEE 23rd Interna-\ntional Workshop on Multimedia Signal Processing (MMSP) , (Tampere,\nFinland), pp. 1\u20136, IEEE, Oct. 2021. [25] H. Yang, H. Chen, J. Chen, S. Esenlik, S. Sethuraman, X. Xiu,\nE. Alshina, and J. Luo, \u201cSubblock-Based Motion Derivation and Inter\nPrediction Refinement in the Versatile Video Coding Standard,\u201d IEEE\ntransactions on circuits and systems for video technology, vol. 31, no. 10,\npp. 3862\u20133877, 2021.\n\n2503.01404v1\nLiu, M. Abdoli, T. Guionnet, C. Guillemot, and A. Roumy, \u201cLight-\nWeight CNN-Based VVC Inter Partitioning Acceleration,\u201d in 2022 IEEE\n14th Image, Video, and Multidimensional Signal Processing Workshop\n(IVMSP), pp. 1\u20135, IEEE, 2022. [25] Z. Peng and L. Shen, \u201cA Classification-Prediction Joint Framework to\nAccelerate QTMT-Based CU Partition of Inter-Mode VVC,\u201d Electronics\nLetters, vol. 59, no. 7, p. e12770, 2023. [26] J. Lin, H. Lin, Z. Zhang, and Y . Xu, \u201cEfficient Inter Partitioning of\nVersatile Video Coding Based on Supervised Contrastive Learning,\u201d\nKnowledge-Based Systems, vol. 296, p. 111902, 2024. [27] E. Franc \u00b8ois, M. Kerdranvat, R. Julian, C. Chevance, P. DeLagrange,\nF. Urban, T. Poirier, and Y . Chen, \u201cVVC Per-Tool Performance Evalu-\nation Compared to HEVC,\u201d in IBC, 2020. [28] M. Saldanha, G. Sanchez, C. Marcon, and L. Agostini, \u201cComplexity\nAnalysis of VVC Intra Coding,\u201d in 2020 IEEE international conference\non image processing (ICIP), pp. 3119\u20133123, IEEE, 2020. [29] A. Tissier, A. Mercat, T. Amestoy, W. Hamidouche, J. Vanne, and\nD. Menard, \u201cComplexity Reduction Opportunities in the Future VVC\nIntra Encoder,\u201d in2019 IEEE 21st international workshop on multimedia\nsignal processing (MMSP), pp. 1\u20136, IEEE, 2019. [30] Y .-W. Huang, J. An, H. Huang, X. Li, S.-T. Hsiang, K. Zhang, H. Gao,\nJ. Ma, and O. Chubach, \u201cBlock Partitioning Structure in the VVC Stan-\ndard,\u201d IEEE Transactions on Circuits and Systems for Video Technology,\nvol. 31, no. 10, pp. 3818\u20133833, 2021. [31] H. Yang, H. Chen, J. Chen, S. Esenlik, S. Sethuraman, X. Xiu,\nE. Alshina, and J. Luo, \u201cSubblock-Based Motion Derivation and Inter\nPrediction Refinement in the Versatile Video Coding Standard,\u201d IEEE\ntransactions on circuits and systems for video technology, vol. 31, no. 10,\npp. 3862\u20133877, 2021. [32] H. Gao, X. Chen, S. Esenlik, J. Chen, and E. Steinbach, \u201cDecoder-\nSide Motion Vector Refinement in VVC: Algorithm and Hardware\nImplementation Considerations,\u201d IEEE Transactions on Circuits and\nSystems for Video Technology, vol. 31, no. 8, pp. 3197\u20133211, 2020. [33] S. De-Lux \u00b4an-Hern\u00b4andez, V . George, J. Ma, T. Nguyen, H. Schwarz,\nD. Marpe, and T. Wiegand, \u201cAn Intra Subpartition Coding Mode for\nVVC,\u201d in 2019 IEEE International Conference on Image Processing\n(ICIP), pp. 1203\u20131207, IEEE, 2019. [34] X. Zhao, S.-H. Kim, Y . Zhao, H. E. Egilmez, M. Koo, S. Liu, J. Lainema,\nand M. Karczewicz, \u201cTransform Coding in the VVC Standard,\u201d IEEE\nTransactions on Circuits and Systems for Video Technology, vol. 31,\nno. 10, pp. 3878\u20133890, 2021. [35] Apple, \u201cHTTP Live Streaming (HLS) Authoring Specification for Apple\nDevices | Apple Developer Documentation,\u201d 2015. [36] A. Stergiou and R. Poppe, \u201cAdapool: Exponential Adaptive Pooling\nfor Information-Retaining Downsampling,\u201d IEEE Transactions on Image\nProcessing, vol. 32, pp. 251\u2013266, 2022. [37] V . V . Menon, C. Feldmann, H. Amirpour, M. Ghanbari, and C. Tim-\nmerer, \u201cVCA: Video Complexity Analyzer,\u201d in Proceedings of the 13th\nACM multimedia systems conference, pp. 259\u2013264, 2022. [38] C. Herglotz, S. Le Moan, and A. Mercat, \u201cEnergy Reduction Opportu-\nnities in HDR Video Encoding,\u201d in 2024 IEEE International Conference\non Image Processing (ICIP), pp. 3654\u20133660, IEEE, 2024. [39] Y .\n\n2503.01415v1\nQT has square-shaped CUs,\nwhich can be further split into quad-split or MTT split until\nthe minimum allowed depth. MTT has a rectangular shape and\ncan only be further split into more MTTs until the minimum\nallowed depth is reached. The minimum allowed depth for a\nCU is 4 \u00d7 4. When a CU is split into QT, it contains four\nblocks, with each block having a quarter of the size. A CU\nmay remain unsplit, which is referred to as a non-split (NS)\npartition. The MTT is made up of four shapes: Binary Tree\nHorizontal (BTH), Binary Tree Vertical (BTV), Ternary Tree\nHorizontal (TTH), and Ternary Tree Vertical (TTV) [3]. In VVC, as opposed to HEVC, the concepts of CU, PU,\nand TU are simplified. In general, the size of CU, PU, and\nTU are the same, which significantly impacts the signaling\noverhead, except when subblock-based temporal motion vec-\ntor prediction (SbTMVP) [25], decoder-side motion vector\nrefinement (DMVR) [26], Intra subpartition (ISP) [27], or\nsubblock transform (SBT) [28] is performed. Under these\ncircumstances, the CU or TU is divided into subblocks, and\nthis side information might or might not need to be signaled. III. E ARLY TERMINATION USING REFERENCE FRAMES\nThe Random Access (RA) configuration effectively balances\ncompression efficiency and random access, making it suitable\nfor adaptive streaming and live broadcasting. In this config-\nuration, frames in lower temporal layers are encoded first,\nserving as reference frames for higher layers. Although these\nreference frames are typically employed for motion compensa-\ntion, the inherent similarity in the partitioning structure among\nFig. 1: Temporal Layers for GOP 32.\ncollocated CTUs has not been fully exploited to optimize\npartitioning patterns. This method aims to leverage partitioning\ninformation from previously encoded frames in lower temporal\nlayers to enhance the efficiency of encoding frames in higher\ntemporal layers. One of the main challenges is optimizing the search space\ndue to the varying distance between the current frame and\nits nearest reference frames. In higher temporal layers, such\nas layers five and four (see Fig. 1), reference frames are\none and two frames apart, respectively, resulting in high\npartitioning consistency. However, as temporal layers decrease,\ne.g., layers 3, 2, 1, and 0, the distance increases to 4, 8, 16,\nand 32 frames, respectively. This greater distance reduces the\ncorrelation between collocated CUs, leading to partitioning\nerrors that propagate, ultimately increasing bitrate. To effectively control bitrate and improve encoding effi-\nciency, the proposed ETRF method is applied to temporal\nlayers two through five. By maintaining the distance between\nthe current frame and its reference frames within eight frames,\nETRF maximizes partitioning similarity and minimizes errors. This approach reduces the search space of a CU by referencing\nco-located CUs in the temporally closest frames. For frames\nin temporal layers two through five, RD cost calculations\nfor partitioning above the defined bounds are skipped, and\nearly termination is applied below the bounds to optimize CU\nprocessing. The flowchart of ETRF is shown in Fig. 2.", "metadata": {"type": "reasoning", "source": "2503.01404v1.pdf", "context": "[12] V . V . Menon, H. Amirpour, M. Ghanbari, and C. Timmerer, \u201cEMES:\nEfficient Multi-Encoding Schemes for HEVC-Based Adaptive Bitrate\nStreaming,\u201d ACM Transactions on Multimedia Computing, Communica-\ntions and Applications, vol. 19, no. 3s, pp. 1\u201320, 2023.\n[13] Y . Liu, H. Amirpour, M. Abdoli, C. Timmerer, and T. Guionnet,\n\u201cPreparing VVC for Streaming: A Fast Multi-Rate Encoding Approach,\u201d\nin 2023 IEEE International Conference on Visual Communications and\nImage Processing (VCIP), pp. 1\u20135, IEEE, ", "quality_score": 8}}
{"id": "test_86", "question": "What is a potential benefit of combining equivariance with data augmentation?", "golden_answers": ["Competitive performance and approximate equivariance"], "prediction": "A potential benefit of combining equivariance with data augmentation is that it can enhance the robustness and generalization of machine learning models by allowing them to learn invariant features across different transformations of the input data.", "f1": 0.10526315789473685, "em": 0.0, "topk_used": 3, "did_retrieve": true, "config": "k=3 (fixed)", "retrieved_text": "2503.00094v1\nFor this reason, uncertainty quantification has become a golden\nstandard in many industrial applications. It can be achieved in\nseveral ways. A first approach consists in combining standard ML algo-\nrithms with model-free UQ techniques. Standard ML algo-\nrithms already used in the literature to build surrogate models\ninclude gradient boosting methods, polynomial chaos expan-\nsion, random forest, response surface methods, and polynomial\nsplines. It can be plugged with model-free UQ techniques\nsuch as Monte Carlo, conformal predictions, and various en-\nsemble methods (Bootstrap prediction intervals, infinitesimal\nJackknife, and Out-Of-Bag errors). This first approach offers\ngreat flexibility in the surrogate model selection, and UQ\nmethods rely on mild assumptions that are often respected. The\nmain drawback of these model-free UQ techniques is that they\ntend to produce overly large confidence intervals with small\ndatasets. They also have a high computational cost, making\nthem poorly suited to building fast-to-evaluate uncertainty-\naware surrogate models. A second possible approach consists in adapting existing\nprediction models to enable them to quantify uncertainty. For\nexample, quantile regression (QR) methods modify the loss\nfunction so that the machine learning model predicts a specific\nquantile of the expected output. Predicting the median, the 5%,\nand the 95% quantiles allows obtaining a prediction and the\nassociated 90% confidence interval. Other works also propose\nto combine the predictive power of artificial neural networks\n(ANN) with deep-learning-specific UQ techniques, such as the\ndelta method, the mean-variance estimation, the lower upper\nbound estimation, and quality-driven ensemble methods. There\nare two drawbacks to this second approach. First, for both\nQR and ANN, a lot of data is required to train the models\neffectively. Second, the obtained surrogate model is black-box,\nwhich is undesirable for safety-critical applications such as\nensuring power grid security. A third increasingly adopted solution to build accuracy-\naware surrogate models is Gaussian processes. Instead of\na simple prediction, GPs provide a full posterior Gaussian\ndistribution N\n\u0000\n\u00b5\u2217, \u03c32\n\u2217\n\u0001\nof the outcome, which is much more\ninformative. The posterior mean \u00b5\u2217 constitutes the prediction,\nand the posterior standard deviation \u03c3\u2217 is used for UQ. Many\nreasons explain the growing popularity of GPs. \u2022 GPs are flexible non-parametric models . Many ma-\nchine learning models are parametric. They learn an\napproximation \u02dcf that belongs to a parametric set of\nfunctions { \u02dcf\u03b8, \u03b8 \u2208 \u0398} (polynomial regressors, neural\nnetworks...). The hyperparameters \u03b8 are optimized with\nthe train data that no longer contribute to the model\nafterward. All the exploited information is compressed\ninto \u03b8. Unlike these models, the GP does not assume a\nfixed number of parameters to approximate the function. Instead, it automatically adapts the model\u2019s complexity\nto the dataset size, which is very flexible. \u2022 GPs provide both prediction and UQ . Instead of\nlooking for one prediction that best fits the data, the\nGP assumes that many approximations could plausibly\nmodel the data. The GP then assigns to each approx-\nimation a probability of actually representing the true\nfunction. The most probable approximation constitutes\nthe GP prediction; the other likely ones contribute to\nUQ.\n\n2503.01126v2\n2.1.5 Emulation with Mixed Basis Functions\nThe parametric mean and covariance functions in Eq.1 can be formulated in many ways. While most advancements\nhave focused on designing the kernel, the mean function in Eq.1a plays an important role in many applications,\nespecially in MF modeling. In our approach, we feed the learnt representations of t and s into the mean function instead of the original categor-\nical variables and reparameterize m(x, t, s; \u03b2) to m(x, h, z; \u03b2) [41], see Fig.2. Following this reformulation, we can\nuse mixed basis functions where a unique mean function is learnt for specific combinations of the categorical variables\n(e.g., in MF modeling, we can learn a unique mean function for each of thes data sources) which can be advantageous\nto learning a global mean function for all combinations of t and s. 2.2 Proposed Acquisition Function\nThe choice of AF is crucial in BO as it balances exploration and exploitation during sampling. In MFBO, this choice\nbecomes even more critical, as the AF must also account for biases in LF data and source-dependent sampling costs. Additionally, when constraints are present, the AF must ensure feasibility while optimizing information gain and cost. To handle the biases of the LF sources and balance information gain and cost, separate AFs are defined inMFBO for\nLF and HF sources where the cheap LF sources are primarily used for exploration while the expensive HF samples are\nmaximally exploited. Following this idea, the AF of the jth LF source (j \u0338= l, l denotes the HF source) is defined as\nthe exploration part of the expected improvement (EI) in MFBO:\n\u03b3LF (u; j) = \u03c4j(u)\u03d5(y\u2217\nj \u2212 \u00b5j(u)\n\u03c4j(u) ) (10)\nwhere y\u2217\nj is the best (potentially noisy) function value obtained so far from source j and \u03d5(\u00b7) denotes the probabil-\nity density function (PDF) of the standard normal variable. \u03c4j(u) and \u00b5j(u) are the standard deviation and mean,\nrespectively, of point u from source j which we estimate via Eq.5. MFBO utilizes improvement as the AF for the HF data source since it is computationally efficient and emphasizes\nexploitation:\n\u03b3HF (u; l) = y\u2217\nl \u2212 \u00b5l(u) (11)\nWe extend these AFs in CMFBO to incorporate constraints which are either known or unknown. While the former\ncan be evaluated analytically, the latter are more complex and require costly simulations. Therefore, we specifically\nfocus on unknown constraints and note that the proposed approach can easily handle known ones in a similar way. 5\n\nThe optimization problem with unknown constraints is formulated as follows:\nmin\nu\nfl(u) subject to Gk\nl (u) \u2264 0, k= 1, . . . , K. where fl(u) is the HF black-box function we aim to optimize and Gk\nl (u) denotes the kth unknown constraint corre-\nsponding to the HF source. The unknown constraints are black-box functions observed alongside yj(u). So, in constrained MFBO, in addition\nto the function value yj(u), K constraint values are also observed ( gk\nj (u), k= 1 , . . . , K) for source j.\n\n2503.01126v1\n2.1.5 Emulation with Mixed Basis Functions\nThe parametric mean and covariance functions in Eq.1 can be formulated in many ways. While most advancements\nhave focused on designing the kernel, the mean function in Eq.1a plays an important role in many applications,\nespecially in MF modeling. In our approach, we feed the learnt representations of t and s into the mean function instead of the original categor-\nical variables and reparameterize m(x, t, s; \u03b2) to m(x, h, z; \u03b2) [41], see Fig.2. Following this reformulation, we can\nuse mixed basis functions where a unique mean function is learnt for specific combinations of the categorical variables\n(e.g., in MF modeling, we can learn a unique mean function for each of thes data sources) which can be advantageous\nto learning a global mean function for all combinations of t and s. 2.2 Proposed Acquisition Function\nThe choice of AF is crucial in BO as it balances exploration and exploitation during sampling. In MFBO, this choice\nbecomes even more critical, as the AF must also account for biases in LF data and source-dependent sampling costs. Additionally, when constraints are present, the AF must ensure feasibility while optimizing information gain and cost. To handle the biases of the LF sources and balance information gain and cost, separate AFs are defined inMFBO for\nLF and HF sources where the cheap LF sources are primarily used for exploration while the expensive HF samples are\nmaximally exploited. Following this idea, the AF of the jth LF source (j \u0338= l, l denotes the HF source) is defined as\nthe exploration part of the expected improvement (EI) in MFBO:\n\u03b3LF (u; j) = \u03c4j(u)\u03d5(y\u2217\nj \u2212 \u00b5j(u)\n\u03c4j(u) ) (10)\nwhere y\u2217\nj is the best (potentially noisy) function value obtained so far from source j and \u03d5(\u00b7) denotes the probabil-\nity density function (PDF) of the standard normal variable. \u03c4j(u) and \u00b5j(u) are the standard deviation and mean,\nrespectively, of point u from source j which we estimate via Eq.5. MFBO utilizes improvement as the AF for the HF data source since it is computationally efficient and emphasizes\nexploitation:\n\u03b3HF (u; l) = y\u2217\nl \u2212 \u00b5l(u) (11)\nWe extend these AFs in CMFBO to incorporate constraints which are either known or unknown. While the former\ncan be evaluated analytically, the latter are more complex and require costly simulations. Therefore, we specifically\nfocus on unknown constraints and note that the proposed approach can easily handle known ones in a similar way. 5\n\nThe optimization problem with unknown constraints is formulated as follows:\nmin\nu\nfl(u) subject to Gk\nl (u) \u2264 0, k= 1, . . . , K. where fl(u) is the HF black-box function we aim to optimize and Gk\nl (u) denotes the kth unknown constraint corre-\nsponding to the HF source. The unknown constraints are black-box functions observed alongside yj(u). So, in constrained MFBO, in addition\nto the function value yj(u), K constraint values are also observed ( gk\nj (u), k= 1 , . . . , K) for source j.", "metadata": {"type": "factual", "source": "2503.01431v2.pdf", "context": "equivariance combined with data augmentation results in competitive performance and approximate\nequivariance. Several theoretical works also suggest that unconstrained models can produce equivariant\noutputs under certain circumstances Gerken and Kessel[27], Nordenfors and Flinth[28], Puny et al.\n[45]. In contrast, the performance effects of removing energy conservation are less clear. Although\nbenchmarking results suggest non-conservative models can perform stable MD simulations [35]. Bigi et al", "quality_score": 8}}

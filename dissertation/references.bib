% ============================================================================
% Bibliography
% ============================================================================

% RAG Foundations
@article{lewis2020rag,
  title={Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks},
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9459--9474},
  year={2020}
}

% FlashRAG
@article{flashrag,
  title={FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation Research},
  author={Jin, Jiajie and others},
  journal={arXiv preprint arXiv:2405.13576},
  year={2024}
}

% Dense Retrieval
@inproceedings{dpr,
  title={Dense Passage Retrieval for Open-Domain Question Answering},
  author={Karpukhin, Vladimir and O{\u{g}}uz, Barlas and Min, Sewon and Lewis, Patrick and Wu, Ledell and Edunov, Sergey and Chen, Danqi and Yih, Wen-tau},
  booktitle={Proceedings of EMNLP},
  year={2020}
}

@article{e5,
  title={Text Embeddings by Weakly-Supervised Contrastive Pre-training},
  author={Wang, Liang and Yang, Nan and Huang, Xiaolong and Jiao, Binxing and Yang, Linjun and Jiang, Daxin and Majumder, Rangan and Wei, Furu},
  journal={arXiv preprint arXiv:2212.03533},
  year={2022}
}

% Adaptive Retrieval
@article{selfrag,
  title={Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection},
  author={Asai, Akari and Wu, Zeqiu and Wang, Yizhong and Sil, Avi and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2310.11511},
  year={2023}
}

@article{adaptiverag,
  title={Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity},
  author={Jeong, Soyeong and Baek, Jinheon and Cho, Sukmin and Hwang, Sung Ju and Park, Jong C},
  journal={arXiv preprint arXiv:2403.14403},
  year={2024}
}

@article{flare,
  title={Active Retrieval Augmented Generation},
  author={Jiang, Zhengbao and Xu, Frank F and Gao, Luyu and Sun, Zhiqing and Liu, Qian and Dwivedi-Yu, Jane and Yang, Yiming and Callan, Jamie and Neubig, Graham},
  journal={arXiv preprint arXiv:2305.06983},
  year={2023}
}

% RL for RAG
@article{agentlightning,
  title={Agent Lightning: A Framework for Training Agentic Language Models},
  author={Wang, Yifan and others},
  journal={arXiv preprint},
  year={2024}
}

@article{mmoarag,
  title={MMOA-RAG: Multi-Module Optimization Approach for RAG via Cooperative Multi-Agent RL},
  author={Zhang, Yi and others},
  journal={arXiv preprint},
  year={2024}
}

@article{maferw,
  title={MaFeRw: Query Rewriting with Multi-Aspect Feedback for Retrieval-Augmented Large Language Models},
  author={Chen, Yujing and others},
  journal={arXiv preprint},
  year={2024}
}

@article{kulkarni,
  title={Reinforcement Learning for Optimizing RAG for Domain Chatbots},
  author={Kulkarni, Vyas and others},
  journal={arXiv preprint},
  year={2024}
}

% RL Fundamentals
@article{williams1992,
  title={Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning},
  author={Williams, Ronald J},
  journal={Machine Learning},
  volume={8},
  number={3},
  pages={229--256},
  year={1992},
  publisher={Springer}
}

@article{ppo,
  title={Proximal Policy Optimization Algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

% Benchmarks
@inproceedings{hotpotqa,
  title={HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering},
  author={Yang, Zhilin and Qi, Peng and Zhang, Saizheng and Bengio, Yoshua and Cohen, William W and Salakhutdinov, Ruslan and Manning, Christopher D},
  booktitle={Proceedings of EMNLP},
  year={2018}
}

@article{mtrag,
  title={MT-RAG: A Multi-Turn Conversational Benchmark for Retrieval-Augmented Generation},
  author={Kim, Jinheon and others},
  journal={arXiv preprint},
  year={2024}
}

% LLMs
@article{gpt4,
  title={GPT-4 Technical Report},
  author={OpenAI},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{llama,
  title={LLaMA: Open and Efficient Foundation Language Models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

% Information Retrieval
@article{bm25,
  title={The Probabilistic Relevance Framework: BM25 and Beyond},
  author={Robertson, Stephen and Zaragoza, Hugo},
  journal={Foundations and Trends in Information Retrieval},
  volume={3},
  number={4},
  pages={333--389},
  year={2009}
}

@article{faiss,
  title={Billion-Scale Similarity Search with GPUs},
  author={Johnson, Jeff and Douze, Matthijs and J{\'e}gou, Herv{\'e}},
  journal={IEEE Transactions on Big Data},
  volume={7},
  number={3},
  pages={535--547},
  year={2019}
}

% Evaluation
@inproceedings{squad,
  title={SQuAD: 100,000+ Questions for Machine Comprehension of Text},
  author={Rajpurkar, Pranav and Zhang, Jian and Lopyrev, Konstantin and Liang, Percy},
  booktitle={Proceedings of EMNLP},
  year={2016}
}
